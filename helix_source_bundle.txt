========================================
FILE: src/utils/constants.py
========================================
"""
Helix AI Studio - Constants
ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§ä½¿ç”¨ã•ã‚Œã‚‹å®šæ•°ã‚’å®šç¾©
"""

# =============================================================================
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±
# =============================================================================
APP_NAME = "Helix AI Studio"
APP_VERSION = "9.5.0"
APP_CODENAME = "Cross-Device Sync"
APP_DESCRIPTION = (
    "Helix AI Studio v9.5.0 'Cross-Device Sync' - "
    "Webå®Ÿè¡Œãƒ­ãƒƒã‚¯ãƒ»ãƒ¢ãƒã‚¤ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ãƒ»ãƒ‡ãƒã‚¤ã‚¹é–“è»¢é€ãƒ»ãƒ­ã‚°ã‚¢ã‚¦ãƒˆå¾Œãƒãƒ£ãƒƒãƒˆé–²è¦§"
)

# v8.5.0: æƒ…å ±åé›†ãƒ•ã‚©ãƒ«ãƒ€
INFORMATION_FOLDER = "data/information"
SUPPORTED_DOC_EXTENSIONS = {'.txt', '.md', '.pdf', '.docx', '.csv', '.json'}

# v8.5.0: ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
DEFAULT_CHUNK_SIZE = 512          # ãƒˆãƒ¼ã‚¯ãƒ³
DEFAULT_CHUNK_OVERLAP = 64        # ãƒˆãƒ¼ã‚¯ãƒ³
MAX_FILE_SIZE_MB = 50             # 1ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€å¤§ã‚µã‚¤ã‚º

# v8.5.0 Patch 1: RAGè¨­å®šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
RAG_DEFAULT_TIME_LIMIT = 90       # åˆ†
RAG_MIN_TIME_LIMIT = 10           # åˆ†
RAG_MAX_TIME_LIMIT = 1440         # åˆ†ï¼ˆ24æ™‚é–“ï¼‰
RAG_TIME_STEP = 10                # åˆ†åˆ»ã¿
RAG_CHUNK_STEP = 64               # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºåˆ»ã¿
RAG_OVERLAP_STEP = 8              # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—åˆ»ã¿

# v8.5.0: RAGæ§‹ç¯‰ï¼ˆå¾Œæ–¹äº’æ›ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼‰
RAG_MIN_TIME_MINUTES = RAG_MIN_TIME_LIMIT
RAG_MAX_TIME_MINUTES = RAG_MAX_TIME_LIMIT
RAG_VERIFICATION_SAMPLE_SIZE = 10 # æ¤œè¨¼æ™‚ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°

# v8.5.0: ãƒ­ãƒƒã‚¯
RAG_LOCK_POLL_INTERVAL_MS = 1000  # ãƒ­ãƒƒã‚¯çŠ¶æ…‹ç¢ºèªé–“éš”

# v8.4.0: Mid-Session Summaryè¨­å®š
MID_SESSION_TRIGGER_COUNT = 5    # ä¸­é–“è¦ç´„ãƒˆãƒªã‚¬ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é–“éš”
MID_SESSION_CONTEXT_CHARS = 600  # ä¸­é–“è¦ç´„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æœ€å¤§æ–‡å­—æ•°

# =============================================================================
# Claude æ€è€ƒãƒ¢ãƒ¼ãƒ‰ (Thinking Mode)
# =============================================================================
class ThinkingMode:
    """Claudeã®æ€è€ƒãƒ¢ãƒ¼ãƒ‰å®šæ•°"""
    OFF = "OFF"           # é€šå¸¸ã®å¿œç­”ãƒ¢ãƒ¼ãƒ‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
    STANDARD = "Standard"  # å›ç­”å‰ã«æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ
    DEEP = "Deep"         # è©³ç´°ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ (ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå»¶é•·)

    @classmethod
    def all_modes(cls) -> list:
        """å…¨ã¦ã®æ€è€ƒãƒ¢ãƒ¼ãƒ‰ã‚’ãƒªã‚¹ãƒˆã§è¿”ã™"""
        return [cls.OFF, cls.STANDARD, cls.DEEP]

    @classmethod
    def get_timeout_multiplier(cls, mode: str) -> float:
        """æ€è€ƒãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€ç‡ã‚’è¿”ã™"""
        multipliers = {
            cls.OFF: 1.0,
            cls.STANDARD: 1.5,
            cls.DEEP: 3.0,
        }
        return multipliers.get(mode, 1.0)

# =============================================================================
# AIãƒ¢ãƒ‡ãƒ«è¨­å®š
# =============================================================================
# v7.1.0: Claudeãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆå‹•çš„é¸æŠå¯¾å¿œï¼‰
CLAUDE_MODELS = [
    {"id": "claude-opus-4-6", "display_name": "Claude Opus 4.6 (æœ€é«˜çŸ¥èƒ½)", "description": "æœ€ã‚‚é«˜åº¦ã§çŸ¥çš„ãªãƒ¢ãƒ‡ãƒ«ã€‚è¤‡é›‘ãªæ¨è«–ãƒ»è¨ˆç”»ç«‹æ¡ˆã«æœ€é©", "tier": "opus", "is_default": True},
    {"id": "claude-opus-4-5-20250929", "display_name": "Claude Opus 4.5 (é«˜å“è³ª)", "description": "é«˜å“è³ªã§ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸå¿œç­”ã€‚å®‰å®šæ€§é‡è¦–", "tier": "opus", "is_default": False},
    {"id": "claude-sonnet-4-5-20250929", "display_name": "Claude Sonnet 4.5 (é«˜é€Ÿ)", "description": "é«˜é€Ÿå¿œç­”ã¨ã‚³ã‚¹ãƒˆåŠ¹ç‡ã€‚æ—¥å¸¸ã‚¿ã‚¹ã‚¯å‘ã", "tier": "sonnet", "is_default": False},
]
DEFAULT_CLAUDE_MODEL_ID = "claude-opus-4-6"


def get_claude_model_by_id(model_id: str) -> dict | None:
    """ãƒ¢ãƒ‡ãƒ«IDã‹ã‚‰ãƒ¢ãƒ‡ãƒ«å®šç¾©ã‚’å–å¾—"""
    for m in CLAUDE_MODELS:
        if m["id"] == model_id:
            return m
    return None


def get_default_claude_model() -> dict:
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®Claudeãƒ¢ãƒ‡ãƒ«å®šç¾©ã‚’å–å¾—"""
    for m in CLAUDE_MODELS:
        if m["is_default"]:
            return m
    return CLAUDE_MODELS[0]


class ClaudeModels:
    """Claudeãƒ¢ãƒ‡ãƒ«å®šæ•°ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ç¶­æŒï¼‰"""
    SONNET_45 = "Claude Sonnet 4.5 (é«˜é€Ÿ)"
    OPUS_45 = "Claude Opus 4.5 (é«˜å“è³ª)"
    OPUS_46 = "Claude Opus 4.6 (æœ€é«˜çŸ¥èƒ½)"

    @classmethod
    def all_models(cls) -> list:
        """å…¨ã¦ã®Claudeãƒ¢ãƒ‡ãƒ«è¡¨ç¤ºåã‚’ãƒªã‚¹ãƒˆã§è¿”ã™"""
        return [m["display_name"] for m in CLAUDE_MODELS]

class GeminiModels:
    """Geminiãƒ¢ãƒ‡ãƒ«å®šæ•°"""
    PRO_3 = "Gemini 3 Pro (æ¨å¥¨)"
    FLASH_3 = "Gemini 3 Flash (é«˜é€Ÿ)"

    @classmethod
    def all_models(cls) -> list:
        """å…¨ã¦ã®Geminiãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚¹ãƒˆã§è¿”ã™"""
        return [cls.PRO_3, cls.FLASH_3]

# =============================================================================
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šå€¤
# =============================================================================
class DefaultSettings:
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šå€¤"""
    CLAUDE_TIMEOUT_MIN = 30     # Claudeã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (åˆ†)
    GEMINI_TIMEOUT_MIN = 5      # Geminiã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (åˆ†)
    FONT_SIZE = 10              # åŸºæœ¬ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
    DARK_MODE = True            # ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    AUTO_SAVE = True            # è‡ªå‹•ä¿å­˜ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    AUTO_CONTEXT = True         # è‡ªå‹•ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

# =============================================================================
# MCPã‚µãƒ¼ãƒãƒ¼
# =============================================================================
class MCPServers:
    """MCPã‚µãƒ¼ãƒãƒ¼è­˜åˆ¥å­"""
    FILESYSTEM = "filesystem"
    GIT = "git"
    BRAVE_SEARCH = "brave-search"
    GITHUB = "github"
    SLACK = "slack"
    GOOGLE_DRIVE = "google-drive"

# =============================================================================
# Workflow State Machine (å·¥ç¨‹çŠ¶æ…‹æ©Ÿæ¢°)
# =============================================================================
class WorkflowPhase:
    """å·¥ç¨‹ï¼ˆPhaseï¼‰ã®å®šç¾©"""
    S0_INTAKE = "S0_INTAKE"              # ä¾é ¼å—é ˜
    S1_CONTEXT = "S1_CONTEXT"            # BIBLE/ç¾çŠ¶èª­è¾¼
    S2_PLAN = "S2_PLAN"                  # è¨ˆç”»
    S3_RISK_GATE = "S3_RISK_GATE"        # å±é™ºåˆ¤å®šãƒ»æ‰¿èª
    S4_IMPLEMENT = "S4_IMPLEMENT"        # å®Ÿè£…
    S5_VERIFY = "S5_VERIFY"              # ãƒ†ã‚¹ãƒˆ/é™çš„æ¤œè¨¼
    S6_REVIEW = "S6_REVIEW"              # å·®åˆ†ãƒ¬ãƒ“ãƒ¥ãƒ¼
    S7_RELEASE = "S7_RELEASE"            # ç¢ºå®šãƒ»è¨˜éŒ²

    @classmethod
    def all_phases(cls) -> list:
        """å…¨ã¦ã®å·¥ç¨‹ã‚’ãƒªã‚¹ãƒˆã§è¿”ã™"""
        return [
            cls.S0_INTAKE,
            cls.S1_CONTEXT,
            cls.S2_PLAN,
            cls.S3_RISK_GATE,
            cls.S4_IMPLEMENT,
            cls.S5_VERIFY,
            cls.S6_REVIEW,
            cls.S7_RELEASE,
        ]

    @classmethod
    def get_display_name(cls, phase: str) -> str:
        """å·¥ç¨‹ã®è¡¨ç¤ºåã‚’è¿”ã™"""
        display_names = {
            cls.S0_INTAKE: "S0: ä¾é ¼å—é ˜ (Intake)",
            cls.S1_CONTEXT: "S1: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆèª­è¾¼ (Context Load)",
            cls.S2_PLAN: "S2: è¨ˆç”» (Plan)",
            cls.S3_RISK_GATE: "S3: å±é™ºåˆ¤å®šãƒ»æ‰¿èª (Risk Gate)",
            cls.S4_IMPLEMENT: "S4: å®Ÿè£… (Implement)",
            cls.S5_VERIFY: "S5: ãƒ†ã‚¹ãƒˆ/æ¤œè¨¼ (Verify)",
            cls.S6_REVIEW: "S6: å·®åˆ†ãƒ¬ãƒ“ãƒ¥ãƒ¼ (Review)",
            cls.S7_RELEASE: "S7: ç¢ºå®šãƒ»è¨˜éŒ² (Release)",
        }
        return display_names.get(phase, phase)

    @classmethod
    def get_description(cls, phase: str) -> str:
        """å·¥ç¨‹ã®èª¬æ˜ã‚’è¿”ã™"""
        descriptions = {
            cls.S0_INTAKE: "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ä¾é ¼ã‚’å—é ˜ã—ã€è¦ä»¶ã‚’æ•´ç†ã—ã¾ã™ã€‚",
            cls.S1_CONTEXT: "PROJECT_BIBLEã‚„ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã¿ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚",
            cls.S2_PLAN: "å®Ÿè£…è¨ˆç”»ã‚’ä½œæˆã—ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ±ºå®šã—ã¾ã™ã€‚",
            cls.S3_RISK_GATE: "å±é™ºãªæ“ä½œï¼ˆæ›¸ãè¾¼ã¿ãƒ»å‰Šé™¤ç­‰ï¼‰ã®å®Ÿè¡Œå¯å¦ã‚’åˆ¤å®šã—ã€æ‰¿èªã‚’å–å¾—ã—ã¾ã™ã€‚",
            cls.S4_IMPLEMENT: "å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰å®Ÿè£…ã‚’è¡Œã„ã¾ã™ã€‚",
            cls.S5_VERIFY: "ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚„é™çš„è§£æã«ã‚ˆã‚Šã€å®Ÿè£…ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚",
            cls.S6_REVIEW: "ã‚³ãƒ¼ãƒ‰ã®å·®åˆ†ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¤‰æ›´å†…å®¹ã‚’ç¢ºèªã—ã¾ã™ã€‚",
            cls.S7_RELEASE: "å¤‰æ›´ã‚’ç¢ºå®šã—ã€è¨˜éŒ²ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚",
        }
        return descriptions.get(phase, "")

# =============================================================================
# ãƒ‘ã‚¹è¨­å®š
# =============================================================================
class Paths:
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å®šæ•°"""
    DATA_DIR = "data"
    CONFIG_DIR = "config"
    LOGS_DIR = "logs"

    # Workflow State
    WORKFLOW_STATE_FILE = "data/workflow_state.json"
    WORKFLOW_LOG_FILE = "logs/workflow.log"

========================================
FILE: src/backends/local_agent.py
========================================
"""
Helix AI Studio - ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ©ãƒ³ãƒŠãƒ¼ (v9.3.0)

Ollama APIã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æ©Ÿèƒ½ã‚’ä½¿ã„ã€ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã‚’å«ã‚€
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ã€‚Claude CLIã®ä»£æ›¿ã¨ã—ã¦æ©Ÿèƒ½ã€‚

å¯¾å¿œãƒ„ãƒ¼ãƒ«:
  - read_file: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Š
  - list_dir: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§
  - search_files: ãƒ•ã‚¡ã‚¤ãƒ«å/å†…å®¹æ¤œç´¢
  - write_file: ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ï¼ˆç¢ºèªä»˜ãï¼‰
  - create_file: ãƒ•ã‚¡ã‚¤ãƒ«æ–°è¦ä½œæˆï¼ˆç¢ºèªä»˜ãï¼‰
"""

import json
import os
import logging
from pathlib import Path
from typing import Callable, Optional

import httpx

logger = logging.getLogger(__name__)

OLLAMA_HOST = "http://localhost:11434"
MAX_AGENT_LOOPS = 15          # æœ€å¤§ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—å›æ•°
MAX_FILE_READ_SIZE = 512_000  # 500KB
MAX_SEARCH_RESULTS = 20


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ„ãƒ¼ãƒ«å®šç¾©ï¼ˆOllama API tools ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å½¢å¼ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

AGENT_TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿å–ã‚‹ã€‚ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "èª­ã¿å–ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ï¼‰"
                    }
                },
                "required": ["path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "list_dir",
            "description": "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ä¸€è¦§ã‚’å–å¾—ã™ã‚‹ã€‚ãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚µã‚¤ã‚ºã€ç¨®åˆ¥ã‚’è¿”ã™ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "ä¸€è¦§å–å¾—ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã€ç©ºæ–‡å­—ã§ãƒ«ãƒ¼ãƒˆï¼‰"
                    }
                },
                "required": ["path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_files",
            "description": "ãƒ•ã‚¡ã‚¤ãƒ«åã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã™ã‚‹ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"
                    },
                    "search_content": {
                        "type": "boolean",
                        "description": "trueã§ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚‚æ¤œç´¢ã€falseã§ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿"
                    }
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "write_file",
            "description": "æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ä¸Šæ›¸ãä¿å­˜ã™ã‚‹ã€‚ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "æ›¸ãè¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
                    },
                    "content": {
                        "type": "string",
                        "description": "æ›¸ãè¾¼ã‚€å†…å®¹"
                    }
                },
                "required": ["path", "content"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "create_file",
            "description": "æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ã€‚è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è‡ªå‹•ä½œæˆã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "ä½œæˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹"
                    },
                    "content": {
                        "type": "string",
                        "description": "ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹"
                    }
                },
                "required": ["path", "content"]
            }
        }
    },
]

# èª­ã¿å–ã‚Šå°‚ç”¨ãƒ„ãƒ¼ãƒ«ï¼ˆwriteç¢ºèªä¸è¦ï¼‰
READ_ONLY_TOOLS = {"read_file", "list_dir", "search_files"}
WRITE_TOOLS = {"write_file", "create_file"}

# é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
EXCLUDED_DIRS = {'.git', 'node_modules', '__pycache__', '.venv', 'dist',
                 'build', '.next', '.cache', 'data'}


class LocalAgentRunner:
    """ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ã‚ˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ"""

    def __init__(self, model_name: str, project_dir: str,
                 tools_config: dict = None,
                 ollama_host: str = OLLAMA_HOST,
                 timeout: int = 1800):
        self.model_name = model_name
        self.project_dir = Path(project_dir) if project_dir else Path(".")
        self.tools_config = tools_config or {}
        self.ollama_host = ollama_host
        self.timeout = timeout

        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        self.on_streaming: Optional[Callable[[str], None]] = None
        self.on_tool_call: Optional[Callable[[str, dict], None]] = None
        self.on_write_confirm: Optional[Callable[[str, str, str], bool]] = None

        # æ›¸ãè¾¼ã¿ç¢ºèªãŒå¿…è¦ã‹ã©ã†ã‹
        self.require_write_confirmation = self.tools_config.get(
            "require_write_confirmation", True)

        # åˆ©ç”¨å¯èƒ½ãƒ„ãƒ¼ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿
        self._active_tools = self._build_active_tools()

        # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚°
        self.tool_log: list[dict] = []

    def _build_active_tools(self) -> list:
        """è¨­å®šã«åŸºã¥ã„ã¦æœ‰åŠ¹ãªãƒ„ãƒ¼ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿"""
        active = []
        for tool in AGENT_TOOLS:
            tool_name = tool["function"]["name"]
            if self.tools_config.get(tool_name, True):
                active.append(tool)
        return active

    # â•â•â• ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ— â•â•â•

    def run(self, system_prompt: str, user_prompt: str) -> str:
        """
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã€‚

        1. LLMã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + ãƒ„ãƒ¼ãƒ«å®šç¾©ã‚’é€ä¿¡
        2. LLMãŒãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’è¿”ã—ãŸå ´åˆ â†’ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ â†’ çµæœã‚’LLMã«è¿”ã™
        3. LLMãŒãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã‚’è¿”ã—ãŸå ´åˆ â†’ å®Œäº†

        Returns:
            æœ€çµ‚çš„ãªãƒ†ã‚­ã‚¹ãƒˆå¿œç­”
        """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        for loop_count in range(MAX_AGENT_LOOPS):
            response = self._call_ollama_chat(messages)

            if not response:
                return "ã‚¨ãƒ©ãƒ¼: Ollama APIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“"

            message = response.get("message", {})
            tool_calls = message.get("tool_calls", [])

            # ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ãŒã‚ã‚‹å ´åˆã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›
            if message.get("content"):
                if self.on_streaming:
                    self.on_streaming(message["content"])

            # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒãªã„å ´åˆ â†’ å®Œäº†
            if not tool_calls:
                return message.get("content", "")

            # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å‡¦ç†
            messages.append(message)  # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 

            for tool_call in tool_calls:
                func_name = tool_call["function"]["name"]
                func_args = tool_call["function"].get("arguments", {})

                # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é€šçŸ¥
                if self.on_tool_call:
                    self.on_tool_call(func_name, func_args)

                # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ
                result = self._execute_tool(func_name, func_args)

                # ãƒ­ã‚°è¨˜éŒ²
                self.tool_log.append({
                    "tool": func_name,
                    "args": func_args,
                    "result_length": len(str(result)),
                    "loop": loop_count,
                })

                # ãƒ„ãƒ¼ãƒ«çµæœã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
                messages.append({
                    "role": "tool",
                    "content": json.dumps(result, ensure_ascii=False),
                })

        return "è­¦å‘Š: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒä¸Šé™ã«é”ã—ã¾ã—ãŸï¼ˆæœ€å¤§15å›ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ï¼‰"

    # â•â•â• Ollama APIå‘¼ã³å‡ºã— â•â•â•

    def _call_ollama_chat(self, messages: list) -> dict | None:
        """Ollama Chat APIï¼ˆãƒ„ãƒ¼ãƒ«å¯¾å¿œï¼‰ã‚’å‘¼ã³å‡ºã—"""
        try:
            with httpx.Client(timeout=self.timeout) as client:
                resp = client.post(
                    f"{self.ollama_host}/api/chat",
                    json={
                        "model": self.model_name,
                        "messages": messages,
                        "tools": self._active_tools,
                        "stream": False,
                        "options": {
                            "temperature": 0.2,
                            "num_predict": 8192,
                        },
                    },
                )
                resp.raise_for_status()
                return resp.json()
        except httpx.TimeoutException:
            logger.error(f"Ollama timeout ({self.timeout}s)")
            return None
        except Exception as e:
            logger.error(f"Ollama API error: {e}")
            return None

    # â•â•â• ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ â•â•â•

    def _execute_tool(self, name: str, args: dict) -> dict:
        """ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã—ã¦çµæœã‚’è¿”ã™"""
        # ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢
        if "path" in args:
            if not self._validate_path(args["path"]):
                return {"error": f"ãƒ‘ã‚¹ãŒä¸æ­£ã§ã™: {args['path']}"}

        try:
            if name == "read_file":
                return self._tool_read_file(args["path"])
            elif name == "list_dir":
                return self._tool_list_dir(args.get("path", ""))
            elif name == "search_files":
                return self._tool_search_files(
                    args["query"], args.get("search_content", False))
            elif name == "write_file":
                return self._tool_write_file(args["path"], args["content"])
            elif name == "create_file":
                return self._tool_create_file(args["path"], args["content"])
            else:
                return {"error": f"æœªçŸ¥ã®ãƒ„ãƒ¼ãƒ«: {name}"}
        except Exception as e:
            return {"error": str(e)}

    def _validate_path(self, rel_path: str) -> bool:
        """ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢"""
        try:
            target = (self.project_dir / rel_path).resolve()
            return str(target).startswith(str(self.project_dir.resolve()))
        except Exception:
            return False

    # â•â•â• å„ãƒ„ãƒ¼ãƒ«å®Ÿè£… â•â•â•

    def _tool_read_file(self, rel_path: str) -> dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Š"""
        target = self.project_dir / rel_path
        if not target.is_file():
            return {"error": f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {rel_path}"}
        if target.stat().st_size > MAX_FILE_READ_SIZE:
            return {"error": f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã™ãã¾ã™: {target.stat().st_size} bytes (ä¸Šé™ 500KB)"}
        try:
            content = target.read_text(encoding='utf-8', errors='replace')
            return {"content": content, "path": rel_path,
                    "size": len(content), "lines": content.count('\n') + 1}
        except Exception as e:
            return {"error": f"èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}"}

    def _tool_list_dir(self, rel_path: str) -> dict:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§"""
        target = self.project_dir / rel_path if rel_path else self.project_dir
        if not target.is_dir():
            return {"error": f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {rel_path}"}
        items = []
        try:
            for entry in sorted(target.iterdir()):
                if entry.name in EXCLUDED_DIRS or entry.name.startswith('.'):
                    continue
                items.append({
                    "name": entry.name,
                    "type": "dir" if entry.is_dir() else "file",
                    "size": entry.stat().st_size if entry.is_file() else None,
                    "extension": entry.suffix if entry.is_file() else None,
                })
            return {"path": rel_path or ".", "items": items, "count": len(items)}
        except Exception as e:
            return {"error": str(e)}

    def _tool_search_files(self, query: str, search_content: bool = False) -> dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢"""
        results = []
        query_lower = query.lower()

        for root, dirs, files in os.walk(self.project_dir):
            # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—
            dirs[:] = [d for d in dirs if d not in EXCLUDED_DIRS and not d.startswith('.')]

            for filename in files:
                if len(results) >= MAX_SEARCH_RESULTS:
                    break

                filepath = Path(root) / filename
                rel_path = str(filepath.relative_to(self.project_dir))

                # ãƒ•ã‚¡ã‚¤ãƒ«åæ¤œç´¢
                if query_lower in filename.lower():
                    results.append({"path": rel_path, "match_type": "filename"})
                    continue

                # å†…å®¹æ¤œç´¢
                if search_content and filepath.suffix in {'.py', '.js', '.jsx', '.ts',
                    '.tsx', '.json', '.md', '.txt', '.html', '.css', '.yaml', '.toml'}:
                    try:
                        if filepath.stat().st_size > MAX_FILE_READ_SIZE:
                            continue
                        content = filepath.read_text(encoding='utf-8', errors='ignore')
                        if query_lower in content.lower():
                            # ãƒãƒƒãƒè¡Œã‚’æŠ½å‡º
                            for i, line in enumerate(content.split('\n'), 1):
                                if query_lower in line.lower():
                                    results.append({
                                        "path": rel_path,
                                        "match_type": "content",
                                        "line": i,
                                        "context": line.strip()[:200],
                                    })
                                    break
                    except Exception:
                        pass

        return {"query": query, "results": results, "count": len(results)}

    def _tool_write_file(self, rel_path: str, content: str) -> dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ï¼ˆç¢ºèªä»˜ãï¼‰"""
        target = self.project_dir / rel_path
        if not target.is_file():
            return {"error": f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {rel_path}ï¼ˆæ–°è¦ä½œæˆã¯create_fileã‚’ä½¿ç”¨ï¼‰"}

        # æ›¸ãè¾¼ã¿ç¢ºèª
        if self.require_write_confirmation and self.on_write_confirm:
            approved = self.on_write_confirm("write_file", rel_path, content[:500])
            if not approved:
                return {"status": "cancelled", "message": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ"}

        try:
            target.write_text(content, encoding='utf-8')
            return {"status": "ok", "path": rel_path, "size": len(content)}
        except Exception as e:
            return {"error": f"æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"}

    def _tool_create_file(self, rel_path: str, content: str) -> dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ–°è¦ä½œæˆï¼ˆç¢ºèªä»˜ãï¼‰"""
        target = self.project_dir / rel_path
        if target.exists():
            return {"error": f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™: {rel_path}ï¼ˆä¸Šæ›¸ãã¯write_fileã‚’ä½¿ç”¨ï¼‰"}

        # æ›¸ãè¾¼ã¿ç¢ºèª
        if self.require_write_confirmation and self.on_write_confirm:
            approved = self.on_write_confirm("create_file", rel_path, content[:500])
            if not approved:
                return {"status": "cancelled", "message": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ"}

        try:
            target.parent.mkdir(parents=True, exist_ok=True)
            target.write_text(content, encoding='utf-8')
            return {"status": "ok", "path": rel_path, "size": len(content)}
        except Exception as e:
            return {"error": f"ä½œæˆã‚¨ãƒ©ãƒ¼: {e}"}

========================================
FILE: src/backends/mix_orchestrator.py
========================================
"""
mixAI 3Phaseçµ±åˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ v9.3.0

æ–°3Phaseå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³:
  Phase 1: Claude CLIè¨ˆç”»ç«‹æ¡ˆï¼ˆ--cwdã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãã€ãƒ„ãƒ¼ãƒ«ä½¿ç”¨æŒ‡ç¤ºã‚’æ˜è¨˜ï¼‰
  Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œï¼ˆOllama APIã§1ãƒ¢ãƒ‡ãƒ«ãšã¤ãƒ­ãƒ¼ãƒ‰â†’å®Ÿè¡Œâ†’ã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
  Phase 3: Claude CLIæ¯”è¼ƒçµ±åˆï¼ˆ2å›ç›®å‘¼ã³å‡ºã—ã€Phase 1+Phase 2å…¨çµæœã‚’æ¸¡ã™ï¼‰

v7.0.0: æ—§5Phaseâ†’æ–°3Phaseã¸ã®å…¨é¢æ›¸ãæ›ãˆ
v9.3.0: P1/P3ã‚¨ãƒ³ã‚¸ãƒ³åˆ‡æ›¿ï¼ˆClaude CLI / ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ†å²ï¼‰
  - orchestrator_engine ãŒ claude- ã§å§‹ã¾ã‚‹ â†’ Claude CLI
  - ãã‚Œä»¥å¤– â†’ ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆlocal_agent.pyï¼‰
"""

import subprocess
import json
import os
import time

from ..utils.subprocess_utils import run_hidden
import logging
from datetime import datetime
from pathlib import Path

# PyQt6ã¯GUIãƒ—ãƒ­ã‚»ã‚¹ã§ã®ã¿å¿…è¦ã€‚Webã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰
# backends/__init__.py çµŒç”±ã§importã•ã‚ŒãŸå ´åˆã«PyQt6ã®é€£é–importã‚’
# é˜²ããŸã‚ã€åˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿importã™ã‚‹ã€‚
try:
    from PyQt6.QtCore import QThread, pyqtSignal
except ImportError:
    import threading

    class QThread:
        """QThreadã®ã‚¹ã‚¿ãƒ–ï¼ˆWebã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ç”¨ï¼‰"""
        def __init__(self, *args, **kwargs):
            self._thread = None
        def start(self):
            self._thread = threading.Thread(target=self.run, daemon=True)
            self._thread.start()
        def run(self):
            pass
        def isRunning(self):
            return self._thread is not None and self._thread.is_alive()

    class pyqtSignal:
        """pyqtSignalã®ã‚¹ã‚¿ãƒ–ï¼ˆã‚¯ãƒ©ã‚¹å±æ€§ã¨ã—ã¦ä½¿ç”¨å¯èƒ½ï¼‰"""
        def __init__(self, *args, **kwargs):
            pass
        def __set_name__(self, owner, name):
            self._name = name
        def __get__(self, obj, objtype=None):
            return self
        def emit(self, *args, **kwargs):
            pass
        def connect(self, *args, **kwargs):
            pass
        def disconnect(self, *args, **kwargs):
            pass

from .sequential_executor import (
    SequentialExecutor,
    SequentialTask,
    SequentialResult,
    filter_chain_of_thought,
)
from ..utils.constants import DEFAULT_CLAUDE_MODEL_ID

logger = logging.getLogger(__name__)

# Phase 1å‡ºåŠ›ã‹ã‚‰æŠ½å‡ºã™ã‚‹JSONã®ã‚­ãƒ¼
PHASE1_JSON_KEYS = ("claude_answer", "local_llm_instructions", "complexity")

# Phase 3ã«æ¸¡ã™çµæœã®æœ€å¤§æ–‡å­—æ•°ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åœ§è¿«é˜²æ­¢ï¼‰
MAX_PHASE1_ANSWER_CHARS = 8000
MAX_PHASE2_RESULT_CHARS_PER_ITEM = 5000


class MixAIOrchestrator(QThread):
    """mixAIã‚¿ãƒ–ã®3Phaseå®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³ v8.0.0 (BIBLE Managerçµ±åˆ)"""

    # â•â•â• UIé€šçŸ¥ç”¨ã‚·ã‚°ãƒŠãƒ« â•â•â•
    phase_changed = pyqtSignal(int, str)       # (phaseç•ªå·, èª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆ)
    streaming_output = pyqtSignal(str)         # Phase 1/3ã®Claudeå‡ºåŠ›ï¼ˆé€æ¬¡è¡¨ç¤ºç”¨ï¼‰
    local_llm_started = pyqtSignal(str, str)   # (category, modelå)
    local_llm_finished = pyqtSignal(str, bool, float)  # (category, success, elapsed)
    phase2_progress = pyqtSignal(int, int)     # (å®Œäº†æ•°, ç·æ•°)
    all_finished = pyqtSignal(str)             # æœ€çµ‚å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
    error_occurred = pyqtSignal(str)           # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    bible_action_proposed = pyqtSignal(object, str)  # v8.0.0: (BibleAction, reason)

    def __init__(
        self,
        user_prompt: str,
        attached_files: list[str],
        model_assignments: dict[str, str],
        config: dict,
    ):
        """
        Args:
            user_prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            attached_files: æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆï¼ˆ--cwdã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ï¼‰
            model_assignments: ã‚«ãƒ†ã‚´ãƒªâ†’Ollamaãƒ¢ãƒ‡ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°
                ä¾‹: {"coding": "devstral-2:123b",
                     "research": "command-a:latest",
                     "reasoning": "gpt-oss:120b",
                     "vision": "gemma3:27b",
                     "translation": "translategemma:27b"}
            config: ã‚¢ãƒ—ãƒªè¨­å®šdictã€‚ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å‚ç…§:
                - claude_model: str (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ "opus")
                - timeout: int (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 600)
                - auto_knowledge: bool (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ True)
                - project_dir: str (Claude CLIã®--cwdã«æ¸¡ã™ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª)
                - max_phase2_retries: int (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 2)
        """
        super().__init__()
        self.user_prompt = user_prompt
        self.attached_files = attached_files
        self.model_assignments = model_assignments
        self.config = config
        self._cancelled = False
        self._phase2_results: list[SequentialResult] = []
        self._phase_times: dict[str, float] = {}
        self._bible_context = None  # v8.0.0: BibleInfo or None
        self._memory_manager = None  # v8.1.0: HelixMemoryManager or None

    def set_bible_context(self, bible):
        """v8.0.0: BIBLEã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š"""
        self._bible_context = bible

    def set_memory_manager(self, memory_manager):
        """v8.1.0: ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’è¨­å®š"""
        self._memory_manager = memory_manager

    def cancel(self):
        """å®Ÿè¡Œã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        self._cancelled = True

    def get_phase2_results(self) -> list[SequentialResult]:
        """Phase 2ã®çµæœã‚’å–å¾—"""
        return self._phase2_results

    def get_phase_times(self) -> dict[str, float]:
        """å„Phaseã®å®Ÿè¡Œæ™‚é–“ã‚’å–å¾—"""
        return self._phase_times

    def run(self):
        try:
            self._execute_pipeline()
        except Exception as e:
            logger.exception("ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚¨ãƒ©ãƒ¼")
            self.error_occurred.emit(f"ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def _execute_pipeline(self):
        """3Phase ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ"""

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆï¼ˆçŸ­æœŸè¨˜æ†¶ï¼‰
        self._session_dir = self._create_session_dir()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Phase 1: Claudeè¨ˆç”»ç«‹æ¡ˆï¼ˆCLIå‘¼ã³å‡ºã— 1/2ï¼‰
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.phase_changed.emit(1, "Phase 1: Claudeè¨ˆç”»ç«‹æ¡ˆä¸­...")
        phase1_start = time.time()

        phase1_result = self._execute_phase1()
        self._phase_times["phase1"] = time.time() - phase1_start

        if self._cancelled:
            return

        # Phase 1çµæœã®ãƒ‘ãƒ¼ã‚¹
        claude_answer = phase1_result.get("claude_answer", "")
        llm_instructions = phase1_result.get("local_llm_instructions", {})
        complexity = phase1_result.get("complexity", "low")
        skip_phase2 = phase1_result.get("skip_phase2", False)

        # v8.4.0: acceptance_criteriaã‚’æŠ½å‡ºï¼ˆPhase 3ã§ä½¿ç”¨ï¼‰
        self._acceptance_criteria = self._extract_acceptance_criteria(llm_instructions)

        # Phase 1ã®çµæœã‚’çŸ­æœŸè¨˜æ†¶ã«ä¿å­˜
        self._save_session_phase1(phase1_result, claude_answer)

        # complexityãŒlowã¾ãŸã¯skip_phase2=trueã®å ´åˆã€Phase 2-3ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if skip_phase2 or complexity == "low":
            logger.info(f"Phase 2-3ã‚¹ã‚­ãƒƒãƒ—: complexity={complexity}, skip_phase2={skip_phase2}")
            self._save_session_metadata(claude_answer, skipped=True)
            self.all_finished.emit(claude_answer)
            return

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œï¼ˆClaudeå‘¼å‡ºãªã—ï¼‰
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.phase_changed.emit(2, "Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œä¸­...")
        phase2_start = time.time()

        tasks = self._build_phase2_tasks(llm_instructions)

        if not tasks:
            # ã‚¿ã‚¹ã‚¯ãŒãªã„å ´åˆã¯Phase 1ã®å›ç­”ã‚’ãã®ã¾ã¾è¿”ã™
            logger.info("Phase 2ã‚¿ã‚¹ã‚¯ãªã— â†’ Phase 1å›ç­”ã‚’è¿”å´")
            self.all_finished.emit(claude_answer)
            return

        executor = SequentialExecutor()
        self._phase2_results = []
        total_tasks = len(tasks)

        for i, task in enumerate(tasks):
            if self._cancelled:
                return

            # v8.2.0: Phase 2 RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥
            if self._memory_manager:
                try:
                    rag_ctx = self._memory_manager.build_context_for_phase2(
                        self.user_prompt, task.category
                    )
                    if rag_ctx:
                        task.prompt = f"{rag_ctx}\n{task.prompt}"
                        logger.info(
                            f"Phase 2 RAG context injected for {task.category}: "
                            f"{len(rag_ctx)} chars"
                        )
                except Exception as e:
                    logger.warning(f"Phase 2 RAG context failed for {task.category}: {e}")

            self.local_llm_started.emit(task.category, task.model)
            result = executor.execute_task(task)
            self._phase2_results.append(result)
            self.local_llm_finished.emit(result.category, result.success, result.elapsed)
            self.phase2_progress.emit(i + 1, total_tasks)

        self._phase_times["phase2"] = time.time() - phase2_start

        # Phase 2ã®çµæœã‚’çŸ­æœŸè¨˜æ†¶ã«ä¿å­˜
        self.save_phase2_results(os.path.join(self._session_dir, "phase2"))

        if self._cancelled:
            return

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Phase 3: Claudeæ¯”è¼ƒçµ±åˆï¼ˆCLIå‘¼ã³å‡ºã— 2/2ï¼‰
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.phase_changed.emit(3, "Phase 3: Claudeæ¯”è¼ƒçµ±åˆä¸­...")
        phase3_start = time.time()

        final_output = self._execute_phase3(claude_answer, self._phase2_results)
        self._phase_times["phase3"] = time.time() - phase3_start

        if self._cancelled:
            return

        # çµ±åˆçµæœã‚’è§£æï¼ˆå“è³ªä¸è¶³ã«ã‚ˆã‚‹å†å®Ÿè¡ŒæŒ‡ç¤ºãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼‰
        retry_result = self._check_phase3_retry(final_output)

        if retry_result is not None:
            # å†å®Ÿè¡Œãƒ«ãƒ¼ãƒ—ï¼ˆæœ€å¤§2å›ï¼‰
            max_retries = self.config.get("max_phase2_retries", 2)
            for retry_count in range(max_retries):
                if self._cancelled:
                    return

                retry_tasks = retry_result.get("retry_tasks", [])
                if not retry_tasks:
                    break

                self.phase_changed.emit(2, f"Phase 2: å†å®Ÿè¡Œä¸­ ({retry_count + 1}/{max_retries})...")

                for task_spec in retry_tasks:
                    if self._cancelled:
                        return
                    retry_prompt = task_spec.get("instruction", "")
                    # v8.2.0: å†å®Ÿè¡Œæ™‚ã‚‚RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥
                    if self._memory_manager:
                        try:
                            rag_ctx = self._memory_manager.build_context_for_phase2(
                                self.user_prompt, task_spec.get("category", "unknown")
                            )
                            if rag_ctx:
                                retry_prompt = f"{rag_ctx}\n{retry_prompt}"
                                logger.info(
                                    f"Phase 2 RAG context injected for retry "
                                    f"{task_spec.get('category', '?')}: {len(rag_ctx)} chars"
                                )
                        except Exception as e:
                            logger.warning(f"Phase 2 RAG retry context failed: {e}")

                    retry_task = SequentialTask(
                        category=task_spec.get("category", "unknown"),
                        model=task_spec.get("model", ""),
                        prompt=retry_prompt,
                        expected_output=task_spec.get("expected_output", ""),
                        timeout=task_spec.get("timeout_seconds", 300),
                        order=task_spec.get("order", 99),
                    )
                    self.local_llm_started.emit(retry_task.category, retry_task.model)
                    result = executor.execute_task(retry_task)
                    # è©²å½“ã‚«ãƒ†ã‚´ãƒªã®çµæœã‚’æ›´æ–°
                    self._phase2_results = [
                        result if r.category == result.category else r
                        for r in self._phase2_results
                    ]
                    self.local_llm_finished.emit(result.category, result.success, result.elapsed)

                # å†åº¦Phase 3ã‚’å®Ÿè¡Œ
                self.phase_changed.emit(3, f"Phase 3: å†çµ±åˆä¸­ ({retry_count + 1}/{max_retries})...")
                final_output = self._execute_phase3(claude_answer, self._phase2_results)

                retry_result = self._check_phase3_retry(final_output)
                if retry_result is None:
                    break

        # æœ€çµ‚å›ç­”ã‚’æŠ½å‡º
        if isinstance(final_output, dict):
            answer = final_output.get("final_answer", final_output.get("claude_answer", str(final_output)))
        else:
            answer = str(final_output)

        # Phase 3ã®çµæœã¨æœ€çµ‚å›ç­”ã‚’çŸ­æœŸè¨˜æ†¶ã«ä¿å­˜
        self._save_session_phase3(answer)
        self._save_session_metadata(answer, skipped=False)

        self.all_finished.emit(answer)

        # v8.1.0: Post-Phase Memory Risk Gate
        if self._memory_manager:
            try:
                import asyncio
                loop = asyncio.new_event_loop()
                loop.run_until_complete(
                    self._memory_manager.evaluate_and_store(
                        f"mixai_{int(time.time())}", answer, self.user_prompt
                    )
                )
                loop.close()
                logger.info("Memory Risk Gate completed (mixAI)")
                # v8.3.1: RAPTORéåŒæœŸãƒˆãƒªã‚¬ãƒ¼ (åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰)
                import threading
                _session_id = f"mixai_{int(time.time())}"
                _mm = self._memory_manager
                _msgs = [{"role": "user", "content": self.user_prompt},
                         {"role": "assistant", "content": answer}]
                def _raptor_bg():
                    try:
                        _mm.raptor_summarize_session(_session_id, _msgs)
                        _mm.raptor_try_weekly()
                    except Exception as _e:
                        logger.warning(f"RAPTOR background: {_e}")
                threading.Thread(target=_raptor_bg, daemon=True).start()
            except Exception as e:
                logger.warning(f"Memory Risk Gate failed: {e}")

        # v8.0.0: Post-Phase BIBLEè‡ªå¾‹ç®¡ç†
        if self._bible_context and self.config.get("bible_auto_manage", True):
            try:
                from ..bible.bible_lifecycle import BibleLifecycleManager, BibleAction
                execution_result = {
                    "changed_files": [],
                    "app_version": self.config.get("app_version", ""),
                }
                action, reason = BibleLifecycleManager.determine_action(
                    self._bible_context, execution_result, self.config
                )
                if action != BibleAction.NONE:
                    self.bible_action_proposed.emit(action, reason)
            except Exception as e:
                logger.warning(f"BIBLE lifecycle check failed: {e}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Phase 1: Claudeè¨ˆç”»ç«‹æ¡ˆ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _execute_phase1(self) -> dict:
        """Phase 1: ã‚¨ãƒ³ã‚¸ãƒ³ã«å¿œã˜ãŸè¨ˆç”»ç«‹æ¡ˆï¼ˆv9.3.0: ã‚¨ãƒ³ã‚¸ãƒ³åˆ†å²å¯¾å¿œï¼‰"""
        engine = self.config.get("orchestrator_engine",
                                 self.config.get("claude_model_id", DEFAULT_CLAUDE_MODEL_ID))

        if engine.startswith("claude-"):
            return self._execute_phase1_claude(engine)
        else:
            return self._execute_phase1_local(engine)

    def _execute_phase1_claude(self, model_id: str) -> dict:
        """Phase 1: Claude CLIç‰ˆï¼ˆå¾“æ¥ã®å®Ÿè£…ï¼‰"""
        system_prompt = self._build_phase1_system_prompt()

        # v8.0.0: BIBLEã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥
        bible_block = ""
        if self._bible_context:
            try:
                from ..bible.bible_injector import BibleInjector
                bible_ctx = BibleInjector.build_context(self._bible_context, mode="phase1")
                bible_block = f"<project_context>\n{bible_ctx}\n</project_context>\n\n"
            except Exception as e:
                logger.warning(f"BIBLE context injection failed: {e}")

        # v8.1.0: è¨˜æ†¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥
        memory_block = ""
        if self._memory_manager:
            try:
                mem_ctx = self._memory_manager.build_context_for_phase1(self.user_prompt)
                if mem_ctx:
                    memory_block = f"<memory_context>\n{mem_ctx}\n</memory_context>\n\n"
            except Exception as e:
                logger.warning(f"Memory context injection failed: {e}")

        full_prompt = f"{system_prompt}\n\n{bible_block}{memory_block}## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚:\n{self.user_prompt}"

        # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ãƒ‘ã‚¹æƒ…å ±ã®ã¿ä¼ãˆã‚‹ï¼ˆå†…å®¹ã®åŸ‹ã‚è¾¼ã¿ã¯ã—ãªã„ï¼‰
        if self.attached_files:
            files_info = "\n".join(f"- {f}" for f in self.attached_files)
            full_prompt += f"\n\n## æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆReadãƒ„ãƒ¼ãƒ«ã§å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰:\n{files_info}"

        raw_output = self._run_claude_cli(full_prompt, model_id=model_id)
        return self._parse_phase1_output(raw_output)

    def _execute_phase1_local(self, model_name: str) -> dict:
        """Phase 1: ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç‰ˆï¼ˆv9.3.0ï¼‰"""
        from .local_agent import LocalAgentRunner

        agent = LocalAgentRunner(
            model_name=model_name,
            project_dir=self.config.get("project_dir", ""),
            tools_config=self.config.get("local_agent_tools", {}),
            timeout=self.config.get("timeout", 1800),
        )

        system_prompt = self._build_phase1_system_prompt()

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ã‚’UIã«è»¢é€
        agent.on_streaming = lambda text: self.streaming_output.emit(text)
        agent.on_tool_call = lambda tool, args: self.streaming_output.emit(
            f"\nğŸ”§ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ: {tool}({json.dumps(args, ensure_ascii=False)[:100]})\n"
        )

        # BIBLEã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥
        bible_block = ""
        if self._bible_context:
            try:
                from ..bible.bible_injector import BibleInjector
                bible_ctx = BibleInjector.build_context(self._bible_context, mode="phase1")
                bible_block = f"<project_context>\n{bible_ctx}\n</project_context>\n\n"
            except Exception as e:
                logger.warning(f"BIBLE context injection failed: {e}")

        user_prompt = f"{bible_block}## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚:\n{self.user_prompt}"

        if self.attached_files:
            files_info = "\n".join(f"- {f}" for f in self.attached_files)
            user_prompt += f"\n\n## æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«:\n{files_info}"

        result = agent.run(system_prompt, user_prompt)
        return self._parse_phase1_output(result)

    def _build_phase1_system_prompt(self) -> str:
        """v8.4.0: Phase 1ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â€” 2æ®µéšæ§‹é€ åŒ–ï¼ˆè¨­è¨ˆåˆ†æâ†’æŒ‡ç¤ºæ›¸ç”Ÿæˆï¼‰"""
        return """ã‚ãªãŸã¯Helix AI Studioã®è¨ˆç”»ç«‹æ¡ˆAIã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã«å¯¾ã—ã¦ã€**2æ®µéš**ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚

## Step 1: è¨­è¨ˆåˆ†æ (Design Analysis)
ã¾ãšä»¥ä¸‹ã‚’åˆ†æã—ã¦ãã ã•ã„:
- å•é¡Œã®åˆ†è§£ã¨è¦ä»¶æ•´ç†
- å¿…è¦ãªæŠ€è¡“è¦ç´ ã¨ä¾å­˜é–¢ä¿‚
- ãƒªã‚¹ã‚¯ãƒ»åˆ¶ç´„ã®æ´—ã„å‡ºã—
- å„ã‚«ãƒ†ã‚´ãƒªï¼ˆcoding/research/reasoning/translation/visionï¼‰ã¸ã®ã‚¿ã‚¹ã‚¯åˆ†é…æ–¹é‡

## Step 2: æŒ‡ç¤ºæ›¸ç”Ÿæˆ (Instruction Generation)
Step 1ã®åˆ†æã‚’è¸ã¾ãˆã€ä»¥ä¸‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:
- å„ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®è©³ç´°ãªæŒ‡ç¤ºæ›¸ï¼ˆJSONå½¢å¼ï¼‰
- å„æŒ‡ç¤ºæ›¸ã« **acceptance_criteria** ã‚’å¿…ãšå«ã‚ã‚‹
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ä¸­é–“å ±å‘Šï¼ˆåˆå›å›ç­”ï¼‰

## åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ï¼ˆç©æ¥µçš„ã«ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼‰
- **Read**: ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ç›´æ¥ç¢ºèªï¼ˆæ¨æ¸¬ã›ãšå®Ÿéš›ã«èª­ã‚“ã§ãã ã•ã„ï¼‰
- **Bash**: ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆgit status, npm install, pytestç­‰ï¼‰
- **Glob/Grep**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ»ã‚³ãƒ¼ãƒ‰æ¤œç´¢
- **WebSearch**: æœ€æ–°æŠ€è¡“æƒ…å ±ã€ã‚¨ãƒ©ãƒ¼è§£æ±ºç­–ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæƒ…å ±ã®æ¤œç´¢
- **WebFetch**: URLå…ˆã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»APIä»•æ§˜ã®å–å¾—

## ä½œæ¥­æ–¹é‡
1. ã¾ãšãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’ Glob/Read ã§ç¢ºèª
2. å¿…è¦ã«å¿œã˜ã¦ WebSearch ã§æœ€æ–°æƒ…å ±ã‚’å–å¾—
3. **Step 1: è¨­è¨ˆåˆ†æ** â€” å•é¡Œåˆ†è§£ãƒ»æŠ€è¡“è¦ç´ ãƒ»ãƒªã‚¹ã‚¯ãƒ»ã‚¿ã‚¹ã‚¯åˆ†é…ã‚’æ•´ç†
4. **Step 2: æŒ‡ç¤ºæ›¸ç”Ÿæˆ** â€” è¨­è¨ˆåˆ†æçµæœã«åŸºã¥ã„ã¦ç²¾å¯†ãªæŒ‡ç¤ºæ›¸ã‚’ç”Ÿæˆ

codingã‚«ãƒ†ã‚´ãƒªã®æŒ‡ç¤ºæ›¸ã‚’ç”Ÿæˆã™ã‚‹éš›ã¯ã€ä½¿ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ»
ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æœ€æ–°APIã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚Context7 MCPãŒ
åˆ©ç”¨å¯èƒ½ãªå ´åˆã€æœ€æ–°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦æŒ‡ç¤ºæ›¸ã«åæ˜ ã—ã¦
ãã ã•ã„ã€‚

## å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆ```json ã§å›²ã‚“ã§ãã ã•ã„ï¼‰:

```json
{
  "claude_answer": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å›ç­”ï¼ˆè‡ªç„¶ãªæ—¥æœ¬èªï¼‰",
  "design_analysis": {
    "requirements": ["è¦ä»¶1", "è¦ä»¶2"],
    "tech_elements": ["æŠ€è¡“è¦ç´ 1", "æŠ€è¡“è¦ç´ 2"],
    "risks": ["ãƒªã‚¹ã‚¯1"],
    "task_distribution": "ã‚¿ã‚¹ã‚¯åˆ†é…ã®æ–¹é‡èª¬æ˜"
  },
  "local_llm_instructions": {
    "coding": {
      "prompt": "å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŒ‡ç¤º",
      "expected_output": "æœŸå¾…ã™ã‚‹å‡ºåŠ›å½¢å¼",
      "context": "é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãƒ»APIä»•æ§˜ç­‰",
      "acceptance_criteria": [
        "åŸºæº–1: å…·ä½“çš„ãªå®Œäº†æ¡ä»¶",
        "åŸºæº–2: æ¤œè¨¼å¯èƒ½ãªå“è³ªåŸºæº–"
      ],
      "expected_output_format": "å‡ºåŠ›å½¢å¼ã®æŒ‡å®š",
      "skip": false
    },
    "research": {
      "prompt": "å…·ä½“çš„ãªèª¿æŸ»æŒ‡ç¤º",
      "expected_output": "æœŸå¾…ã™ã‚‹å‡ºåŠ›å½¢å¼",
      "context": "",
      "acceptance_criteria": ["åŸºæº–1"],
      "expected_output_format": "",
      "skip": false
    },
    "reasoning": {
      "prompt": "å…·ä½“çš„ãªæ¨è«–ãƒ»æ¤œè¨¼æŒ‡ç¤º",
      "expected_output": "æœŸå¾…ã™ã‚‹å‡ºåŠ›å½¢å¼",
      "context": "",
      "acceptance_criteria": ["åŸºæº–1"],
      "expected_output_format": "",
      "skip": false
    },
    "vision": {
      "prompt": "å…·ä½“çš„ãªç”»åƒè§£ææŒ‡ç¤º",
      "expected_output": "æœŸå¾…ã™ã‚‹å‡ºåŠ›å½¢å¼",
      "context": "",
      "acceptance_criteria": [],
      "expected_output_format": "",
      "skip": true
    },
    "translation": {
      "prompt": "å…·ä½“çš„ãªç¿»è¨³æŒ‡ç¤º",
      "expected_output": "æœŸå¾…ã™ã‚‹å‡ºåŠ›å½¢å¼",
      "context": "",
      "acceptance_criteria": [],
      "expected_output_format": "",
      "skip": true
    }
  },
  "complexity": "simple|moderate|complex",
  "skip_phase2": false,
  "tools_used": ["Read", "WebSearch"]
}
```

## complexityåˆ¤å®šåŸºæº–
- **simple**: æŒ¨æ‹¶ã€é›‘è«‡ã€ç°¡å˜ãªQ&A â†’ skip_phase2: true
- **moderate**: 1ã‚«ãƒ†ã‚´ãƒªã®ã¿ã§å¯¾å¿œå¯èƒ½ãªæŠ€è¡“çš„è³ªå•
- **complex**: è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã®å”èª¿ãŒå¿…è¦ãªé«˜åº¦ãªã‚¿ã‚¹ã‚¯

## skip_phase2ã®åˆ¤å®š
- æŒ¨æ‹¶ãƒ»é›‘è«‡ãƒ»ä¸€èˆ¬çŸ¥è­˜ã®å•ã„åˆã‚ã› â†’ true
- æŠ€è¡“çš„ãªå®Ÿè£…ãƒ»è¨­è¨ˆãƒ»åˆ†æãŒå¿…è¦ â†’ false

## å„ã‚«ãƒ†ã‚´ãƒªã®æŒ‡ç¤ºæ–‡ä½œæˆãƒ«ãƒ¼ãƒ«
- å„promptã«ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®å…¨æ–‡è„ˆã‚’å«ã‚ã‚‹ï¼ˆLLMã¯ä¼šè©±å±¥æ­´ã‚’æŒãŸãªã„ï¼‰
- **acceptance_criteria**: å„ã‚«ãƒ†ã‚´ãƒªã«æ¤œè¨¼å¯èƒ½ãªå®Œäº†æ¡ä»¶ã‚’æœ€ä½1ã¤å«ã‚ã‚‹ï¼ˆPhase 3è©•ä¾¡ã§ä½¿ç”¨ï¼‰
- **context**: é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚„APIä»•æ§˜ã‚’å«ã‚ã‚‹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMã®ç²¾åº¦å‘ä¸Šã«ç›´çµï¼‰
- coding: ä½¿ç”¨è¨€èªã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€å‘½åè¦å‰‡ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’æ˜è¨˜
- research: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å€™è£œã€åé›†ã™ã¹ãæƒ…å ±ã®ç¨®é¡ã‚’æ˜è¨˜
- reasoning: æ¤œè¨¼ã™ã¹ãè«–ç†çš„è¦³ç‚¹ã€å“è³ªãƒã‚§ãƒƒã‚¯åŸºæº–ã‚’æ˜è¨˜
- vision: ç”»åƒåˆ†æã®è¦³ç‚¹ã‚’æ˜è¨˜ï¼ˆç”»åƒã‚¿ã‚¹ã‚¯ãŒã‚ã‚‹å ´åˆã®ã¿skip: falseï¼‰
- translation: åŸæ–‡ã®è¨€èªã€ç¿»è¨³å…ˆè¨€èªã€å°‚é–€ç”¨èªã®å–æ‰±ã„ã‚’æ˜è¨˜
- ä¸è¦ãªã‚«ãƒ†ã‚´ãƒªã¯skip: trueã«è¨­å®š"""

    def _parse_phase1_output(self, raw_output: str) -> dict:
        """Phase 1ã®Claudeå‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦JSONã‚’æŠ½å‡º"""
        if not raw_output or not raw_output.strip():
            logger.warning("Phase 1: ç©ºã®å‡ºåŠ›ã‚’å—ä¿¡")
            return {"claude_answer": "", "local_llm_instructions": {}, "complexity": "low", "skip_phase2": True}

        # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºï¼ˆ```json ... ``` å½¢å¼ï¼‰
        import re
        json_blocks = re.findall(r'```json\s*([\s\S]*?)\s*```', raw_output)

        for json_str in reversed(json_blocks):
            try:
                parsed = json.loads(json_str.strip())
                if isinstance(parsed, dict) and "claude_answer" in parsed:
                    logger.info("Phase 1: æœ‰åŠ¹ãªJSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œå‡º")
                    return parsed
            except json.JSONDecodeError:
                continue

        # ```jsonå½¢å¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ç”Ÿã®JSONæ¤œç´¢
        json_pattern = r'\{\s*"claude_answer"\s*:[\s\S]*?\n\}'
        match = re.search(json_pattern, raw_output)
        if match:
            try:
                parsed = json.loads(match.group(0))
                if isinstance(parsed, dict):
                    logger.info("Phase 1: ç”ŸJSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œå‡º")
                    return parsed
            except json.JSONDecodeError:
                pass

        # JSONè§£æå¤±æ•— â†’ Claudeå›ç­”å…¨ä½“ã‚’claude_answerã¨ã—ã¦è¿”ã™ï¼ˆPhase 2ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        logger.warning("Phase 1: JSONè§£æå¤±æ•— â†’ Phase 2ã‚¹ã‚­ãƒƒãƒ—")
        return {
            "claude_answer": raw_output.strip(),
            "local_llm_instructions": {},
            "complexity": "low",
            "skip_phase2": True,
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Phase 2: ã‚¿ã‚¹ã‚¯æ§‹ç¯‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _build_phase2_tasks(self, llm_instructions: dict) -> list[SequentialTask]:
        """Phase 1ã®local_llm_instructionsã‹ã‚‰Phase 2ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰"""
        tasks = []
        order = 1

        for category, spec in llm_instructions.items():
            if not isinstance(spec, dict):
                continue
            # skip: trueã®ã‚«ãƒ†ã‚´ãƒªã¯é™¤å¤–
            if spec.get("skip", False):
                continue
            # ãƒ¢ãƒ‡ãƒ«ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ãªã„ã‚«ãƒ†ã‚´ãƒªã¯é™¤å¤–
            model = self.model_assignments.get(category)
            if not model:
                logger.debug(f"Phase 2: ã‚«ãƒ†ã‚´ãƒª '{category}' ã«ãƒ¢ãƒ‡ãƒ«æœªå‰²å½“ â†’ ã‚¹ã‚­ãƒƒãƒ—")
                continue
            # æŒ‡ç¤ºæ–‡ãŒç©ºã®ã‚«ãƒ†ã‚´ãƒªã¯é™¤å¤–
            prompt = spec.get("prompt", "").strip()
            if not prompt:
                continue

            tasks.append(SequentialTask(
                category=category,
                model=model,
                prompt=prompt,
                expected_output=spec.get("expected_output", ""),
                timeout=spec.get("timeout_seconds", 300),
                order=order,
            ))
            order += 1

        # orderé †ã«ã‚½ãƒ¼ãƒˆ
        tasks.sort(key=lambda t: t.order)
        return tasks

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Phase 3: Claudeæ¯”è¼ƒçµ±åˆ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _extract_acceptance_criteria(self, llm_instructions: dict) -> dict:
        """v8.4.0: Phase 1æŒ‡ç¤ºæ›¸ã‹ã‚‰acceptance_criteriaã‚’æŠ½å‡º"""
        criteria = {}
        for category, spec in llm_instructions.items():
            if isinstance(spec, dict) and not spec.get("skip", True):
                ac = spec.get("acceptance_criteria", [])
                if ac:
                    criteria[category] = ac
        return criteria

    def _execute_phase3(self, phase1_answer: str, phase2_results: list[SequentialResult]) -> dict:
        """Phase 3: ã‚¨ãƒ³ã‚¸ãƒ³ã«å¿œã˜ãŸæ¯”è¼ƒçµ±åˆï¼ˆv9.3.0: ã‚¨ãƒ³ã‚¸ãƒ³åˆ†å²å¯¾å¿œï¼‰"""
        engine = self.config.get("orchestrator_engine",
                                 self.config.get("claude_model_id", DEFAULT_CLAUDE_MODEL_ID))

        if engine.startswith("claude-"):
            return self._execute_phase3_claude(phase1_answer, phase2_results, engine)
        else:
            return self._execute_phase3_local(phase1_answer, phase2_results, engine)

    def _execute_phase3_claude(self, phase1_answer: str,
                                phase2_results: list[SequentialResult], model_id: str) -> dict:
        """Phase 3: Claude CLIç‰ˆï¼ˆå¾“æ¥ã®å®Ÿè£…ï¼‰"""
        system_prompt = self._build_phase3_system_prompt(phase1_answer, phase2_results)

        # v8.0.0: BIBLEã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥ï¼ˆPhase 3ç”¨ï¼‰
        bible_block = ""
        if self._bible_context:
            try:
                from ..bible.bible_injector import BibleInjector
                bible_ctx = BibleInjector.build_context(self._bible_context, mode="phase3")
                bible_block = f"\n\n<project_context>\n{bible_ctx}\n</project_context>"
            except Exception as e:
                logger.warning(f"BIBLE Phase 3 context injection failed: {e}")

        # v8.1.0: è¨˜æ†¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥ï¼ˆPhase 3ç”¨ï¼‰
        memory_block = ""
        if self._memory_manager:
            try:
                mem_ctx = self._memory_manager.build_context_for_phase3(
                    self.user_prompt, phase1_answer)
                if mem_ctx:
                    memory_block = f"\n\n<memory_context>\n{mem_ctx}\n</memory_context>"
            except Exception as e:
                logger.warning(f"Memory Phase 3 context injection failed: {e}")

        full_prompt = f"{system_prompt}{bible_block}{memory_block}\n\nçµ±åˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"

        raw_output = self._run_claude_cli(full_prompt, model_id=model_id)
        return self._parse_phase3_output(raw_output)

    def _execute_phase3_local(self, phase1_answer: str,
                               phase2_results: list[SequentialResult], model_name: str) -> dict:
        """Phase 3: ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç‰ˆï¼ˆv9.3.0ï¼‰"""
        from .local_agent import LocalAgentRunner

        agent = LocalAgentRunner(
            model_name=model_name,
            project_dir=self.config.get("project_dir", ""),
            tools_config=self.config.get("local_agent_tools", {}),
            timeout=self.config.get("timeout", 1800),
        )

        agent.on_streaming = lambda text: self.streaming_output.emit(text)
        agent.on_tool_call = lambda tool, args: self.streaming_output.emit(
            f"\nğŸ”§ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ: {tool}({json.dumps(args, ensure_ascii=False)[:100]})\n"
        )

        system_prompt = self._build_phase3_system_prompt(phase1_answer, phase2_results)
        user_prompt = "ä¸Šè¨˜ã®æƒ…å ±ã‚’çµ±åˆã—ã€æœ€çµ‚å›ç­”ã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"

        result = agent.run(system_prompt, user_prompt)
        return self._parse_phase3_output(result)

    def _build_phase3_system_prompt(self, phase1_answer: str, phase2_results: list[SequentialResult]) -> str:
        """v8.4.0: Phase 3ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â€” Acceptance Criteriaè©•ä¾¡ + çµ±åˆ"""
        results_text = self._format_phase2_results(phase2_results)

        # v8.4.0: Acceptance Criteriaã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹ç¯‰
        criteria_section = ""
        criteria = getattr(self, '_acceptance_criteria', {})
        if criteria:
            criteria_lines = []
            for cat, items in criteria.items():
                criteria_lines.append(f"### {cat}ã‚«ãƒ†ã‚´ãƒª")
                for i, c in enumerate(items, 1):
                    criteria_lines.append(f"  {i}. {c}")
            criteria_json = "\n".join(criteria_lines)
            criteria_section = f"""

## å“è³ªè©•ä¾¡ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ (Acceptance Criteria)
ä»¥ä¸‹ã®Acceptance Criteriaã«å¯¾ã—ã¦ã€å„Phase 2å‡ºåŠ›ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

{criteria_json}

å„åŸºæº–ã«å¯¾ã—ã¦ä»¥ä¸‹ã®å½¢å¼ã§åˆ¤å®š:
- **PASS**: åŸºæº–ã‚’æº€ãŸã—ã¦ã„ã‚‹ï¼ˆæ ¹æ‹ ã‚’1æ–‡ã§ï¼‰
- **FAIL**: åŸºæº–ã‚’æº€ãŸã—ã¦ã„ãªã„ï¼ˆä¸è¶³ç‚¹ã¨å†å®Ÿè¡ŒæŒ‡ç¤ºï¼‰

å…¨åŸºæº–PASSã®å ´åˆã®ã¿æœ€çµ‚çµ±åˆå›ç­”ã‚’ç”Ÿæˆã€‚
1ã¤ã§ã‚‚FAILãŒã‚ã‚Œã°å†å®Ÿè¡Œã‚«ãƒ†ã‚´ãƒªã¨å…·ä½“çš„æŒ‡ç¤ºã‚’è¿”å´ã€‚
"""

        return f"""ã‚ãªãŸã¯Helix AI Studioã®çµ±åˆAIã§ã™ã€‚

## Phase 1ã§ã‚ãªãŸãŒç«‹æ¡ˆã—ãŸè¨ˆç”»ã¨åˆå›å›ç­”:
{phase1_answer[:MAX_PHASE1_ANSWER_CHARS]}

## Phase 2ã§ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒãƒ¼ãƒ ãŒç”Ÿæˆã—ãŸçµæœ:
{results_text}
{criteria_section}
## åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ï¼ˆå¿…è¦ã«å¿œã˜ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼‰
- **Read/Write/Edit**: ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªãƒ»ä¿®æ­£ãƒ»ç”Ÿæˆ
- **Bash**: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã€ãƒ“ãƒ«ãƒ‰ã€gitæ“ä½œ
- **WebSearch**: ä¸æ˜ç‚¹ã®èª¿æŸ»

## çµ±åˆæ–¹é‡
1. Acceptance Criteriaã«åŸºã¥ã„ã¦å„ãƒ­ãƒ¼ã‚«ãƒ«LLMã®çµæœã‚’PASS/FAILåˆ¤å®š
2. è‡ªèº«ã®Phase 1ã®å›ç­”ã¨æ¯”è¼ƒã—ã€å„ªã‚ŒãŸç‚¹ã‚’å–ã‚Šè¾¼ã‚€
3. å¿…è¦ã«å¿œã˜ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ä¿®æ­£ï¼ˆWrite/Editï¼‰
4. ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦å“è³ªã‚’æ¤œè¨¼ï¼ˆBashï¼‰
5. æœ€çµ‚å›ç­”ã‚’è‡ªç„¶ãªæ—¥æœ¬èªã§ç”Ÿæˆ

## å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆ```json ã§å›²ã‚“ã§ãã ã•ã„ï¼‰:

å“è³ªãŒååˆ†ãªå ´åˆï¼ˆå…¨åŸºæº–PASSï¼‰:
```json
{{
  "status": "complete",
  "final_answer": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ€çµ‚å›ç­”ï¼ˆè‡ªç„¶ãªæ—¥æœ¬èªï¼‰",
  "criteria_evaluation": {{
    "coding": [{{"criterion": "åŸºæº–1", "result": "PASS", "reason": "æ ¹æ‹ "}}],
    "research": [{{"criterion": "åŸºæº–1", "result": "PASS", "reason": "æ ¹æ‹ "}}]
  }},
  "integration_notes": "çµ±åˆæ™‚ã®åˆ¤æ–­ãƒ¡ãƒ¢"
}}
```

å“è³ªä¸è¶³ã§å†å®Ÿè¡ŒãŒå¿…è¦ãªå ´åˆï¼ˆ1ã¤ä»¥ä¸ŠFAILï¼‰:
```json
{{
  "status": "retry_needed",
  "final_answer": "ç¾æ™‚ç‚¹ã§ã®æš«å®šå›ç­”",
  "criteria_evaluation": {{
    "coding": [{{"criterion": "åŸºæº–1", "result": "FAIL", "reason": "ä¸è¶³ç‚¹"}}]
  }},
  "retry_tasks": [
    {{
      "category": "coding",
      "model": "devstral-2:123b",
      "instruction": "æ”¹å–„ã•ã‚ŒãŸæŒ‡ç¤ºæ–‡ï¼ˆFAILåŸºæº–ã‚’æº€ãŸã™ãŸã‚ã®å…·ä½“çš„æŒ‡ç¤ºï¼‰",
      "expected_output": "æœŸå¾…ã™ã‚‹å‡ºåŠ›",
      "order": 1,
      "timeout_seconds": 300
    }}
  ],
  "retry_reason": "å†å®Ÿè¡ŒãŒå¿…è¦ãªç†ç”±"
}}
```

## é‡è¦ãªãƒ«ãƒ¼ãƒ«
- Acceptance CriteriaãŒå­˜åœ¨ã™ã‚‹å ´åˆã€å„åŸºæº–ã‚’å¿…ãšPASS/FAILåˆ¤å®šã—ã¦ãã ã•ã„
- ãƒ­ãƒ¼ã‚«ãƒ«LLMãŒå„ªã‚ŒãŸæŒ‡æ‘˜ãƒ»ææ¡ˆã‚’ã—ã¦ã„ã‚‹å ´åˆã€ã‚ãªãŸã®å›ç­”ã«çµ±åˆã—ã¦ãã ã•ã„
- ãƒ­ãƒ¼ã‚«ãƒ«LLMã®çµæœãŒã‚ãªãŸã®åˆ¤æ–­ã¨çŸ›ç›¾ã™ã‚‹å ´åˆã€ã‚ãªãŸè‡ªèº«ã®åˆ¤æ–­ã‚’å„ªå…ˆã—ã¦ãã ã•ã„
- æœ€çµ‚åˆ¤æ–­ã¯å¸¸ã«ã‚ãªãŸãŒè¡Œã„ã¾ã™
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å›ç­”ã¯è‡ªç„¶ãªæ–‡ç« ã§æç¤ºã—ã¦ãã ã•ã„ã€‚ãƒ­ãƒ¼ã‚«ãƒ«LLMã®å­˜åœ¨ã«è¨€åŠã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“"""

    def _format_phase2_results(self, results: list[SequentialResult]) -> str:
        """Phase 2ã®å…¨çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not results:
            return "(Phase 2ã®çµæœã¯ã‚ã‚Šã¾ã›ã‚“)"

        sections = []
        for r in results:
            if not r.success:
                sections.append(
                    f"### {r.category}æ‹…å½“ï¼ˆ{r.model}ï¼‰: å¤±æ•—\n"
                    f"ç†ç”±: {r.response[:200]}"
                )
                continue

            truncated = r.response[:MAX_PHASE2_RESULT_CHARS_PER_ITEM]
            sections.append(
                f"### {r.category}æ‹…å½“ï¼ˆ{r.model}ï¼‰: æˆåŠŸ ({r.elapsed:.1f}ç§’)\n"
                f"{truncated}"
            )

        return "\n\n".join(sections)

    def _parse_phase3_output(self, raw_output: str) -> dict:
        """Phase 3ã®Claudeå‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹"""
        if not raw_output or not raw_output.strip():
            return {"status": "complete", "final_answer": ""}

        import re
        json_blocks = re.findall(r'```json\s*([\s\S]*?)\s*```', raw_output)

        for json_str in reversed(json_blocks):
            try:
                parsed = json.loads(json_str.strip())
                if isinstance(parsed, dict) and "final_answer" in parsed:
                    return parsed
            except json.JSONDecodeError:
                continue

        # JSONè§£æå¤±æ•— â†’ å‡ºåŠ›å…¨ä½“ã‚’æœ€çµ‚å›ç­”ã¨ã—ã¦è¿”ã™
        return {"status": "complete", "final_answer": raw_output.strip()}

    def _check_phase3_retry(self, phase3_output: dict) -> dict | None:
        """çµ±åˆãƒ•ã‚§ãƒ¼ã‚ºã®å‡ºåŠ›ã‹ã‚‰å“è³ªå†å®Ÿè¡ŒæŒ‡ç¤ºãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        if isinstance(phase3_output, dict) and phase3_output.get("status") == "retry_needed":
            retry_tasks = phase3_output.get("retry_tasks", [])
            if retry_tasks:
                return phase3_output
        return None

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Claude CLIå®Ÿè¡Œ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _run_claude_cli(self, prompt: str, model_id: str = None) -> str:
        """
        Claude Code CLIã‚’éå¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã€‚

        v7.0.0å¤‰æ›´:
        - --cwdã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ ã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š
        - ãƒ•ã‚¡ã‚¤ãƒ«åŸ‹ã‚è¾¼ã¿æ–¹å¼ã‚’å»ƒæ­¢ï¼ˆClaudeãŒè‡ªåˆ†ã§Readãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ï¼‰
        - stdinã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡
        v7.1.0å¤‰æ›´:
        - model_idãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ ï¼ˆCLAUDE_MODELSã®idã‚’ç›´æ¥æ¸¡ã™ï¼‰
        """
        # v7.1.0: model_id â†’ --model ã«ç›´æ¥æ¸¡ã™
        effective_model = model_id or self.config.get("claude_model_id") or self.config.get("claude_model", DEFAULT_CLAUDE_MODEL_ID)

        cmd = [
            "claude",
            "-p",                              # éå¯¾è©±ï¼ˆãƒ‘ã‚¤ãƒ—ï¼‰ãƒ¢ãƒ¼ãƒ‰
            "--dangerously-skip-permissions",   # å…¨ãƒ„ãƒ¼ãƒ«è‡ªå‹•è¨±å¯
            "--output-format", "json",          # JSONå‡ºåŠ›
            "--model", effective_model,
        ]

        # v7.0.0: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆsubprocess.runã®cwdãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æŒ‡å®šï¼‰
        project_dir = self.config.get("project_dir")
        run_cwd = project_dir if project_dir and os.path.isdir(project_dir) else None

        try:
            result = run_hidden(
                cmd,
                input=prompt,
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='replace',
                timeout=self.config.get("timeout", 600),
                env={**os.environ, "FORCE_COLOR": "0", "PYTHONIOENCODING": "utf-8"},
                cwd=run_cwd,
            )

            stdout = result.stdout or ""
            stderr = result.stderr or ""

            if result.returncode == 0:
                try:
                    output_data = json.loads(stdout)
                    return output_data.get("result", stdout)
                except json.JSONDecodeError:
                    return stdout.strip()
            else:
                raise RuntimeError(
                    f"Claude CLIçµ‚äº†ã‚³ãƒ¼ãƒ‰ {result.returncode}: "
                    f"{stderr[:500] if stderr else 'ã‚¨ãƒ©ãƒ¼è©³ç´°ãªã—'}"
                )

        except subprocess.TimeoutExpired:
            raise RuntimeError(
                f"Claude CLIãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ({self.config.get('timeout', 600)}ç§’)ã—ã¾ã—ãŸ"
            )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Phase 2çµæœã®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def save_phase2_results(self, session_dir: str = None):
        """Phase 2ã®çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if not self._phase2_results:
            return

        save_dir = session_dir or os.path.join("data", "phase2")
        os.makedirs(save_dir, exist_ok=True)

        for result in self._phase2_results:
            filename = f"task_{result.order}_{result.model.replace(':', '_').replace('/', '_')}.txt"
            filepath = os.path.join(save_dir, filename)
            try:
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(f"Category: {result.category}\n")
                    f.write(f"Model: {result.model}\n")
                    f.write(f"Success: {result.success}\n")
                    f.write(f"Elapsed: {result.elapsed:.1f}s\n")
                    f.write(f"Order: {result.order}\n")
                    f.write("=" * 60 + "\n")
                    f.write(result.response)
                logger.info(f"Phase 2çµæœä¿å­˜: {filepath}")
            except Exception as e:
                logger.error(f"Phase 2çµæœã®ä¿å­˜å¤±æ•—: {filepath}: {e}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # v7.0.0: çŸ­æœŸè¨˜æ†¶ï¼ˆSession Memoryï¼‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _create_session_dir(self) -> str:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        session_dir = os.path.join("data", "sessions", timestamp)
        os.makedirs(session_dir, exist_ok=True)
        os.makedirs(os.path.join(session_dir, "phase2"), exist_ok=True)
        logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {session_dir}")
        return session_dir

    def _save_session_phase1(self, phase1_result: dict, claude_answer: str):
        """Phase 1ã®è¨ˆç”»JSONã¨Claudeå›ç­”ã‚’çŸ­æœŸè¨˜æ†¶ã«ä¿å­˜"""
        try:
            # Phase 1è¨ˆç”»JSON
            plan_path = os.path.join(self._session_dir, "phase1_plan.json")
            with open(plan_path, 'w', encoding='utf-8') as f:
                json.dump(phase1_result, f, ensure_ascii=False, indent=2)

            # Phase 1 Claudeå›ç­”
            answer_path = os.path.join(self._session_dir, "phase1_claude_answer.txt")
            with open(answer_path, 'w', encoding='utf-8') as f:
                f.write(claude_answer)

            logger.info(f"Phase 1çµæœã‚’çŸ­æœŸè¨˜æ†¶ã«ä¿å­˜: {self._session_dir}")
        except Exception as e:
            logger.error(f"Phase 1çŸ­æœŸè¨˜æ†¶ã®ä¿å­˜å¤±æ•—: {e}")

    def _save_session_phase3(self, final_answer: str):
        """Phase 3ã®çµ±åˆçµæœã‚’çŸ­æœŸè¨˜æ†¶ã«ä¿å­˜"""
        try:
            path = os.path.join(self._session_dir, "phase3_integration.txt")
            with open(path, 'w', encoding='utf-8') as f:
                f.write(final_answer)
            logger.info(f"Phase 3çµæœã‚’çŸ­æœŸè¨˜æ†¶ã«ä¿å­˜: {path}")
        except Exception as e:
            logger.error(f"Phase 3çŸ­æœŸè¨˜æ†¶ã®ä¿å­˜å¤±æ•—: {e}")

    def _save_session_metadata(self, final_answer: str, skipped: bool = False):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’çŸ­æœŸè¨˜æ†¶ã«ä¿å­˜"""
        try:
            metadata = {
                "session_start": getattr(self, '_session_dir', '').split(os.sep)[-1],
                "user_prompt": self.user_prompt[:500],
                "project_dir": self.config.get("project_dir", ""),
                "phase_times": self._phase_times,
                "phase2_skipped": skipped,
                "phase2_results_count": len(self._phase2_results),
                "final_answer_length": len(final_answer),
                "timestamp": datetime.now().isoformat(),
                # v8.4.0: Acceptance Criteriaè¿½è·¡
                "acceptance_criteria": getattr(self, '_acceptance_criteria', {}),
            }
            path = os.path.join(self._session_dir, "metadata.json")
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {path}")
        except Exception as e:
            logger.error(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜å¤±æ•—: {e}")

========================================
FILE: src/memory/memory_manager.py
========================================
"""
Helix AI Studio - 4-Layer Memory Manager (v8.1.0 "Adaptive Memory")

4å±¤ãƒ¡ãƒ¢ãƒªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:
  Layer 1: Thread Memoryï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å†…çŸ­æœŸè¨˜æ†¶ï¼‰
  Layer 2: Episodic Memoryï¼ˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ = ä¼šè©±ãƒ­ã‚°æ¤œç´¢ï¼‰
  Layer 3: Semantic Memoryï¼ˆæ„å‘³è¨˜æ†¶ = Temporal Knowledge Graphï¼‰
  Layer 4: Procedural Memoryï¼ˆæ‰‹ç¶šãè¨˜æ†¶ = å†åˆ©ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰

+ Memory Risk Gateï¼ˆministral-3:8bã«ã‚ˆã‚‹è¨˜æ†¶å“è³ªåˆ¤å®šï¼‰
"""

import json
import sqlite3
import logging
import time
import struct
from datetime import datetime, date
from pathlib import Path
from typing import List, Optional, Dict, Tuple, Any

import aiohttp
import asyncio

logger = logging.getLogger(__name__)

# =============================================================================
# å®šæ•°
# =============================================================================
DEFAULT_DB_PATH = "data/helix_memory.db"
DEFAULT_OLLAMA_HOST = "http://localhost:11434"
EMBEDDING_MODEL = "qwen3-embedding:4b"
CONTROL_MODEL = "ministral-3:8b"
EMBEDDING_DIM = 768
MAX_THREAD_MESSAGES = 50


def _cosine_similarity(a: bytes, b: bytes) -> float:
    """BLOBãƒ™ã‚¯ãƒˆãƒ«ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    if not a or not b:
        return 0.0
    try:
        n = len(a) // 4
        va = struct.unpack(f'{n}f', a)
        vb = struct.unpack(f'{n}f', b)
        dot = sum(x * y for x, y in zip(va, vb))
        norm_a = sum(x * x for x in va) ** 0.5
        norm_b = sum(x * x for x in vb) ** 0.5
        if norm_a == 0 or norm_b == 0:
            return 0.0
        return dot / (norm_a * norm_b)
    except Exception:
        return 0.0


def _embedding_to_blob(embedding: List[float]) -> bytes:
    """floaté…åˆ—ã‚’BLOBã«å¤‰æ›"""
    return struct.pack(f'{len(embedding)}f', *embedding)


# =============================================================================
# Memory Risk Gate
# =============================================================================

class MemoryRiskGate:
    """è¨˜æ†¶ã®å“è³ªã‚’åˆ¤å®šã™ã‚‹ã‚²ãƒ¼ãƒˆ
    ministral-3:8b ãŒå¸¸é§ã—ã¦ã„ã‚‹ãŸã‚å³å¿œå¯èƒ½"""

    EXTRACTION_PROMPT = """ä»¥ä¸‹ã®AIå¿œç­”ã‹ã‚‰ã€é•·æœŸçš„ã«è¨˜æ†¶ã™ã¹ãæƒ…å ±ã‚’æŠ½å‡ºã—ã¦JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•]
{user_query}

[AIã®å¿œç­”]
{ai_response}

ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªã§æŠ½å‡º:
- facts: äº‹å®Ÿæƒ…å ±ï¼ˆè¨­å®šå€¤ã€ä»•æ§˜æ±ºå®šã€ç’°å¢ƒæƒ…å ±ã€ãƒ¦ãƒ¼ã‚¶å—œå¥½ï¼‰
- procedures: å†åˆ©ç”¨å¯èƒ½ãªæ‰‹é †ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒã‚°ä¿®æ­£æ‰‹é †ã€è¨­å®šæ–¹æ³•ï¼‰
- episode_tags: ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å¾Œã§æ¤œç´¢ã™ã‚‹ãŸã‚ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰

å‡ºåŠ›å½¢å¼ï¼ˆJSON ã®ã¿å‡ºåŠ›ã€‚èª¬æ˜ä¸è¦ï¼‰:
{{
  "facts": [
    {{"entity": "...", "attribute": "...", "value": "...", "confidence": 0.0-1.0}}
  ],
  "procedures": [
    {{"title": "...", "content": "...", "tags": ["...", "..."]}}
  ],
  "episode_tags": ["...", "..."]
}}

æŠ½å‡ºã™ã¹ãæƒ…å ±ãŒãªã„å ´åˆã¯å„é…åˆ—ã‚’ç©ºã«ã—ã¦ãã ã•ã„ã€‚"""

    VALIDATION_PROMPT = """ä»¥ä¸‹ã®è¨˜æ†¶å€™è£œãŒæ—¢å­˜ã®è¨˜æ†¶ã¨çŸ›ç›¾ãƒ»é‡è¤‡ã—ãªã„ã‹åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

[æ–°è¦å€™è£œ]
{candidate}

[æ—¢å­˜ã®é–¢é€£è¨˜æ†¶]
{existing_memories}

å„å€™è£œã«å¯¾ã—ã¦ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š:
- ADD: æ–°è¦è¿½åŠ ï¼ˆé‡è¤‡ãªã—ã€æœ‰ç”¨ï¼‰
- UPDATE: æ—¢å­˜ã‚’æ›´æ–°ï¼ˆåŒã˜entity+attributeã§å€¤ãŒå¤‰åŒ–ï¼‰
- DEPRECATE: æ—¢å­˜ã‚’ç„¡åŠ¹åŒ–ï¼ˆçŸ›ç›¾ã™ã‚‹å¤ã„æƒ…å ±ï¼‰
- SKIP: ä¿å­˜ä¸è¦ï¼ˆæ®ç™ºæ€§ãŒé«˜ã„ã€å†åˆ©ç”¨æ€§ãŒä½ã„ã€é‡è¤‡ï¼‰

å‡ºåŠ›å½¢å¼ï¼ˆJSON ã®ã¿ï¼‰:
[
  {{"index": 0, "action": "ADD|UPDATE|DEPRECATE|SKIP", "reason": "..."}}
]"""

    EPISODE_SUMMARY_PROMPT = """ä»¥ä¸‹ã®ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’1-2æ–‡ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
é‡è¦ãªæ±ºå®šäº‹é …ã€è§£æ±ºã—ãŸå•é¡Œã€ä½¿ç”¨ã—ãŸæŠ€è¡“ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚

{session_messages}

å‡ºåŠ›ï¼ˆæ—¥æœ¬èªã€1-2æ–‡ã®ã¿ï¼‰:"""

    WEEKLY_SUMMARY_PROMPT = """ä»¥ä¸‹ã¯ä»Šé€±ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„ç¾¤ã§ã™ã€‚
é€±æ¬¡ã®ä¸»è¦ãªé€²æ—ã¨æ±ºå®šäº‹é …ã‚’3-5æ–‡ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

{session_summaries}

å‡ºåŠ›ï¼ˆæ—¥æœ¬èªã€3-5æ–‡ã®ã¿ï¼‰:"""

    def __init__(self, ollama_host: str = DEFAULT_OLLAMA_HOST):
        self.ollama_host = ollama_host

    async def _call_ollama(self, model: str, prompt: str) -> str:
        """Ollamaãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã™"""
        url = f"{self.ollama_host}/api/generate"
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": False,
            "options": {"temperature": 0.1, "num_predict": 2048}
        }
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, timeout=aiohttp.ClientTimeout(total=60)) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return data.get("response", "")
                    else:
                        logger.warning(f"Ollama API error: {resp.status}")
                        return ""
        except Exception as e:
            logger.error(f"Ollama call failed: {e}")
            return ""

    async def _get_embedding(self, text: str) -> Optional[List[float]]:
        """qwen3-embedding:4bã§Embeddingã‚’å–å¾—"""
        url = f"{self.ollama_host}/api/embed"
        payload = {"model": EMBEDDING_MODEL, "input": text}
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, timeout=aiohttp.ClientTimeout(total=30)) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        embeddings = data.get("embeddings", [])
                        if embeddings and len(embeddings) > 0:
                            return embeddings[0]
                    return None
        except Exception as e:
            logger.error(f"Embedding generation failed: {e}")
            return None

    async def extract_memories(self, user_query: str, ai_response: str) -> dict:
        """å¿œç­”ã‹ã‚‰è¨˜æ†¶å€™è£œã‚’æŠ½å‡º"""
        prompt = self.EXTRACTION_PROMPT.format(
            user_query=user_query[:2000],
            ai_response=ai_response[:4000]
        )
        raw = await self._call_ollama(CONTROL_MODEL, prompt)
        try:
            # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            start = raw.find('{')
            end = raw.rfind('}') + 1
            if start >= 0 and end > start:
                return json.loads(raw[start:end])
        except json.JSONDecodeError:
            logger.warning("Failed to parse memory extraction result")
        return {"facts": [], "procedures": [], "episode_tags": []}

    async def validate_memories(self, candidates: list, existing: list) -> list:
        """è¨˜æ†¶å€™è£œã®é‡è¤‡ãƒ»çŸ›ç›¾ãƒã‚§ãƒƒã‚¯"""
        if not candidates:
            return []
        prompt = self.VALIDATION_PROMPT.format(
            candidate=json.dumps(candidates, ensure_ascii=False, indent=2),
            existing_memories=json.dumps(existing[:20], ensure_ascii=False, indent=2)
        )
        raw = await self._call_ollama(CONTROL_MODEL, prompt)
        try:
            start = raw.find('[')
            end = raw.rfind(']') + 1
            if start >= 0 and end > start:
                return json.loads(raw[start:end])
        except json.JSONDecodeError:
            logger.warning("Failed to parse validation result")
        return [{"index": i, "action": "ADD", "reason": "validation_failed"} for i in range(len(candidates))]

    async def summarize_episode(self, messages: list) -> str:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è¦ç´„"""
        msg_text = "\n".join(
            f"[{m.get('role', '?')}] {m.get('content', '')[:300]}"
            for m in messages[:20]
        )
        prompt = self.EPISODE_SUMMARY_PROMPT.format(session_messages=msg_text)
        return await self._call_ollama(CONTROL_MODEL, prompt)

    async def summarize_weekly(self, summaries: list) -> str:
        """é€±æ¬¡è¦ç´„ã‚’ç”Ÿæˆ"""
        text = "\n".join(f"- {s}" for s in summaries)
        prompt = self.WEEKLY_SUMMARY_PROMPT.format(session_summaries=text)
        return await self._call_ollama(CONTROL_MODEL, prompt)


# =============================================================================
# HelixMemoryManager â€” 4å±¤ãƒ¡ãƒ¢ãƒªçµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
# =============================================================================

class HelixMemoryManager:
    """4å±¤ãƒ¡ãƒ¢ãƒªã®çµ±åˆç®¡ç†"""

    def __init__(self, db_path: str = DEFAULT_DB_PATH,
                 ollama_host: str = DEFAULT_OLLAMA_HOST):
        self.db_path = db_path
        self.ollama_host = ollama_host
        self.risk_gate = MemoryRiskGate(ollama_host)

        # Layer 1: Thread Memoryï¼ˆã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªï¼‰
        self._thread: List[Dict[str, Any]] = []

        # SQLiteåˆæœŸåŒ–
        Path(db_path).parent.mkdir(parents=True, exist_ok=True)
        self._init_db()

        logger.info(f"HelixMemoryManager initialized: db={db_path}")

    def _init_db(self):
        """SQLite 4å±¤ã‚¹ã‚­ãƒ¼ãƒã‚’åˆæœŸåŒ–"""
        conn = sqlite3.connect(self.db_path)
        c = conn.cursor()

        # Layer 2: Episodic Memory
        c.execute("""
            CREATE TABLE IF NOT EXISTS episodes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT UNIQUE NOT NULL,
                tab TEXT NOT NULL CHECK(tab IN ('mixAI', 'soloAI')),
                summary TEXT,
                summary_embedding BLOB,
                detail_log TEXT,
                token_count INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                weekly_summary_id INTEGER REFERENCES episode_summaries(id)
            )
        """)

        # Layer 2: å¤šæ®µè¦ç´„ï¼ˆRAPTORé¢¨ï¼‰
        c.execute("""
            CREATE TABLE IF NOT EXISTS episode_summaries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                level TEXT NOT NULL CHECK(level IN ('session', 'weekly', 'version', 'mid_session')),
                period_start TIMESTAMP,
                period_end TIMESTAMP,
                summary TEXT NOT NULL,
                summary_embedding BLOB,
                episode_ids TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # Layer 3: Semantic Memory (Temporal Knowledge Graph ãƒãƒ¼ãƒ‰)
        c.execute("""
            CREATE TABLE IF NOT EXISTS semantic_nodes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                entity TEXT NOT NULL,
                attribute TEXT NOT NULL,
                value TEXT NOT NULL,
                value_embedding BLOB,
                confidence FLOAT DEFAULT 1.0,
                source_session TEXT,
                valid_from TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                valid_to TIMESTAMP,
                UNIQUE(entity, attribute, valid_from)
            )
        """)

        # Layer 3: Semantic Memory (Temporal Knowledge Graph ã‚¨ãƒƒã‚¸)
        c.execute("""
            CREATE TABLE IF NOT EXISTS semantic_edges (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_node_id INTEGER REFERENCES semantic_nodes(id),
                target_node_id INTEGER REFERENCES semantic_nodes(id),
                relation TEXT NOT NULL,
                weight FLOAT DEFAULT 1.0,
                valid_from TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                valid_to TIMESTAMP
            )
        """)

        # Layer 4: Procedural Memory
        c.execute("""
            CREATE TABLE IF NOT EXISTS procedures (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                content_embedding BLOB,
                tags TEXT,
                source_session TEXT,
                use_count INTEGER DEFAULT 0,
                last_used TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        c.execute("CREATE INDEX IF NOT EXISTS idx_episodes_session ON episodes(session_id)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_episodes_tab ON episodes(tab)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_semantic_entity ON semantic_nodes(entity, attribute)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_semantic_valid ON semantic_nodes(valid_to)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_procedures_tags ON procedures(tags)")

        # v8.3.1: semantic_edges é‡è¤‡é˜²æ­¢UNIQUEã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        c.execute("""CREATE UNIQUE INDEX IF NOT EXISTS idx_edge_unique
                     ON semantic_edges(source_node_id, target_node_id, relation)""")

        # v8.3.1: episode_summaries ã«statusã‚«ãƒ©ãƒ è¿½åŠ ï¼ˆå†è©¦è¡Œå¯¾å¿œï¼‰
        try:
            c.execute("ALTER TABLE episode_summaries ADD COLUMN status TEXT DEFAULT 'completed'")
        except Exception:
            pass  # ã‚«ãƒ©ãƒ æ—¢å­˜

        conn.commit()
        conn.close()
        logger.info("Memory database schema initialized")

    def _get_conn(self) -> sqlite3.Connection:
        """SQLiteæ¥ç¶šã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    # =========================================================================
    # Layer 1: Thread Memoryï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å†…çŸ­æœŸè¨˜æ†¶ï¼‰
    # =========================================================================

    def push_thread(self, role: str, content: str, metadata: dict = None):
        """ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ """
        entry = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "metadata": metadata or {}
        }
        self._thread.append(entry)
        if len(self._thread) > MAX_THREAD_MESSAGES:
            self._thread = self._thread[-MAX_THREAD_MESSAGES:]

    def get_thread_context(self, max_tokens: int = 4000) -> str:
        """ç›´è¿‘ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        if not self._thread:
            return ""
        lines = []
        total = 0
        for msg in reversed(self._thread):
            line = f"[{msg['role']}] {msg['content']}"
            est_tokens = len(line) // 3
            if total + est_tokens > max_tokens:
                break
            lines.insert(0, line)
            total += est_tokens
        return "\n".join(lines)

    def clear_thread(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ã‚¯ãƒªã‚¢"""
        self._thread.clear()

    # =========================================================================
    # Layer 2: Episodic Memoryï¼ˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ï¼‰
    # =========================================================================

    def save_episode(self, session_id: str, messages: list,
                     tab: str = "soloAI", summary: str = None,
                     summary_embedding: bytes = None) -> int:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã¨ã—ã¦ä¿å­˜"""
        conn = self._get_conn()
        try:
            detail_log = json.dumps(messages, ensure_ascii=False)
            token_count = sum(len(m.get("content", "")) // 3 for m in messages)
            conn.execute("""
                INSERT OR REPLACE INTO episodes
                (session_id, tab, summary, summary_embedding, detail_log, token_count)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (session_id, tab, summary, summary_embedding, detail_log, token_count))
            conn.commit()
            episode_id = conn.execute(
                "SELECT id FROM episodes WHERE session_id = ?", (session_id,)
            ).fetchone()["id"]
            logger.info(f"Episode saved: session={session_id}, tokens={token_count}")
            return episode_id
        finally:
            conn.close()

    def search_episodes(self, query_embedding: bytes, top_k: int = 5) -> list:
        """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’æ¤œç´¢"""
        conn = self._get_conn()
        try:
            rows = conn.execute(
                "SELECT id, session_id, tab, summary, summary_embedding, created_at "
                "FROM episodes WHERE summary_embedding IS NOT NULL"
            ).fetchall()
            scored = []
            for row in rows:
                sim = _cosine_similarity(query_embedding, row["summary_embedding"])
                scored.append({
                    "id": row["id"],
                    "session_id": row["session_id"],
                    "tab": row["tab"],
                    "summary": row["summary"],
                    "similarity": sim,
                    "created_at": row["created_at"]
                })
            scored.sort(key=lambda x: x["similarity"], reverse=True)
            return scored[:top_k]
        finally:
            conn.close()

    def get_episode_summary(self, session_id: str) -> str:
        """ç‰¹å®šã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®è¦ç´„ã‚’å–å¾—"""
        conn = self._get_conn()
        try:
            row = conn.execute(
                "SELECT summary FROM episodes WHERE session_id = ?", (session_id,)
            ).fetchone()
            return row["summary"] if row and row["summary"] else ""
        finally:
            conn.close()

    # =========================================================================
    # Layer 3: Semantic Memory (Temporal Knowledge Graph)
    # =========================================================================

    def add_fact(self, entity: str, attribute: str, value: str,
                 source_session: str, confidence: float = 1.0,
                 value_embedding: bytes = None):
        """äº‹å®Ÿãƒãƒ¼ãƒ‰ã‚’è¿½åŠ ï¼ˆåŒentity+attributeã®æ—¢å­˜factã¯æœŸé–“ã‚’é–‰ã˜ã‚‹ï¼‰"""
        conn = self._get_conn()
        now = datetime.now().isoformat()
        try:
            # æ—¢å­˜ã®æœ‰åŠ¹ãƒãƒ¼ãƒ‰ã‚’æœŸé–“çµ‚äº†
            conn.execute("""
                UPDATE semantic_nodes SET valid_to = ?
                WHERE entity = ? AND attribute = ? AND valid_to IS NULL
            """, (now, entity, attribute))
            # æ–°è¦ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
            conn.execute("""
                INSERT INTO semantic_nodes
                (entity, attribute, value, value_embedding, confidence,
                 source_session, valid_from, valid_to)
                VALUES (?, ?, ?, ?, ?, ?, ?, NULL)
            """, (entity, attribute, value, value_embedding, confidence,
                  source_session, now))
            conn.commit()
            logger.debug(f"Fact added: {entity}.{attribute} = {value[:50]}")
        finally:
            conn.close()

    def get_current_facts(self, entity: str = None) -> list:
        """æœ‰åŠ¹ãªäº‹å®Ÿã®ã¿è¿”ã™ï¼ˆvalid_to is Noneï¼‰"""
        conn = self._get_conn()
        try:
            if entity:
                rows = conn.execute(
                    "SELECT * FROM semantic_nodes WHERE entity = ? AND valid_to IS NULL",
                    (entity,)
                ).fetchall()
            else:
                rows = conn.execute(
                    "SELECT * FROM semantic_nodes WHERE valid_to IS NULL"
                ).fetchall()
            return [dict(row) for row in rows]
        finally:
            conn.close()

    def search_semantic(self, query_embedding: bytes, top_k: int = 10) -> list:
        """æ„å‘³æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰"""
        conn = self._get_conn()
        try:
            rows = conn.execute(
                "SELECT * FROM semantic_nodes WHERE valid_to IS NULL AND value_embedding IS NOT NULL"
            ).fetchall()
            scored = []
            for row in rows:
                sim = _cosine_similarity(query_embedding, row["value_embedding"])
                item = dict(row)
                item["similarity"] = sim
                scored.append(item)
            scored.sort(key=lambda x: x["similarity"], reverse=True)
            return scored[:top_k]
        finally:
            conn.close()

    def get_fact_history(self, entity: str, attribute: str) -> list:
        """äº‹å®Ÿã®å¤‰é·å±¥æ­´ï¼ˆTemporalï¼‰"""
        conn = self._get_conn()
        try:
            rows = conn.execute(
                "SELECT * FROM semantic_nodes WHERE entity = ? AND attribute = ? "
                "ORDER BY valid_from ASC",
                (entity, attribute)
            ).fetchall()
            return [dict(row) for row in rows]
        finally:
            conn.close()

    # =========================================================================
    # Layer 4: Procedural Memoryï¼ˆæ‰‹ç¶šãè¨˜æ†¶ï¼‰
    # =========================================================================

    def save_procedure(self, title: str, content: str,
                       tags: list, source_session: str,
                       content_embedding: bytes = None):
        """æ‰‹ç¶šããƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿å­˜"""
        conn = self._get_conn()
        try:
            conn.execute("""
                INSERT INTO procedures
                (title, content, content_embedding, tags, source_session)
                VALUES (?, ?, ?, ?, ?)
            """, (title, content, content_embedding,
                  json.dumps(tags, ensure_ascii=False), source_session))
            conn.commit()
            logger.info(f"Procedure saved: {title}")
        finally:
            conn.close()

    def search_procedures(self, query_embedding: bytes = None,
                          tags: list = None, top_k: int = 5) -> list:
        """ã‚¿ã‚° + ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢"""
        conn = self._get_conn()
        try:
            rows = conn.execute("SELECT * FROM procedures").fetchall()
            scored = []
            for row in rows:
                score = 0.0
                row_dict = dict(row)
                # ã‚¿ã‚°ãƒãƒƒãƒã‚¹ã‚³ã‚¢
                if tags:
                    row_tags = json.loads(row_dict.get("tags", "[]"))
                    overlap = len(set(tags) & set(row_tags))
                    score += overlap * 0.3
                # ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢
                if query_embedding and row_dict.get("content_embedding"):
                    sim = _cosine_similarity(query_embedding, row_dict["content_embedding"])
                    score += sim * 0.7
                row_dict["score"] = score
                scored.append(row_dict)
            scored.sort(key=lambda x: x["score"], reverse=True)
            return scored[:top_k]
        finally:
            conn.close()

    # =========================================================================
    # Memory Risk Gate â€” è©•ä¾¡ã¨æŒ¯ã‚Šåˆ†ã‘
    # =========================================================================

    async def evaluate_and_store(self, session_id: str,
                                 ai_response: str, user_query: str):
        """å¿œç­”å¾Œã«è¨˜æ†¶å€™è£œã‚’æŠ½å‡ºã—ã€Risk Gateã§åˆ¤å®šã—ã¦ä¿å­˜"""
        try:
            # 1. è¨˜æ†¶å€™è£œã‚’æŠ½å‡º
            extracted = await self.risk_gate.extract_memories(user_query, ai_response)
            facts = extracted.get("facts", [])
            procedures = extracted.get("procedures", [])
            episode_tags = extracted.get("episode_tags", [])

            if not facts and not procedures:
                logger.debug("No memory candidates extracted")
                return

            # 2. æ—¢å­˜ã®é–¢é€£è¨˜æ†¶ã‚’å–å¾—
            existing_facts = self.get_current_facts()

            # 3. Facts ã®æ¤œè¨¼ã¨ä¿å­˜
            if facts:
                validations = await self.risk_gate.validate_memories(facts, existing_facts)
                for validation in validations:
                    idx = validation.get("index", 0)
                    action = validation.get("action", "SKIP")
                    if idx >= len(facts):
                        continue
                    fact = facts[idx]

                    if action in ("ADD", "UPDATE"):
                        # Embeddingã‚’ç”Ÿæˆ
                        text = f"{fact['entity']} {fact['attribute']} {fact['value']}"
                        emb = await self.risk_gate._get_embedding(text)
                        emb_blob = _embedding_to_blob(emb) if emb else None
                        self.add_fact(
                            entity=fact["entity"],
                            attribute=fact["attribute"],
                            value=fact["value"],
                            source_session=session_id,
                            confidence=fact.get("confidence", 0.8),
                            value_embedding=emb_blob
                        )
                        logger.info(f"Memory {action}: {fact['entity']}.{fact['attribute']}")
                    elif action == "DEPRECATE":
                        # æ—¢å­˜ã‚’ç„¡åŠ¹åŒ–
                        conn = self._get_conn()
                        try:
                            conn.execute("""
                                UPDATE semantic_nodes SET valid_to = ?
                                WHERE entity = ? AND attribute = ? AND valid_to IS NULL
                            """, (datetime.now().isoformat(),
                                  fact["entity"], fact["attribute"]))
                            conn.commit()
                        finally:
                            conn.close()
                        logger.info(f"Memory DEPRECATE: {fact['entity']}.{fact['attribute']}")

            # 4. Procedures ã®ä¿å­˜
            for proc in procedures:
                emb = await self.risk_gate._get_embedding(proc.get("content", ""))
                emb_blob = _embedding_to_blob(emb) if emb else None
                self.save_procedure(
                    title=proc.get("title", "untitled"),
                    content=proc.get("content", ""),
                    tags=proc.get("tags", []),
                    source_session=session_id,
                    content_embedding=emb_blob
                )

            # v8.3.0: Temporal KG â€” åŒä¸€sessionå†…ã®facté–“ã«co-occurrence edgeã‚’è‡ªå‹•è¿½åŠ 
            if len(facts) >= 2:
                try:
                    self._auto_link_session_facts(session_id, facts)
                except Exception as link_err:
                    logger.debug(f"TKG auto-link failed: {link_err}")

            logger.info(
                f"Memory evaluation complete: {len(facts)} facts, "
                f"{len(procedures)} procedures processed"
            )
        except Exception as e:
            logger.error(f"Memory evaluation failed: {e}", exc_info=True)

    def _auto_link_session_facts(self, session_id: str, facts: list):
        """v8.3.1: åŒä¸€sessionå†…ã®facté–“ã«co-occurrenceã‚¨ãƒƒã‚¸ã‚’å¼µã‚‹ï¼ˆO(nÂ²)ç·©å’Œç‰ˆï¼‰"""
        # v8.3.1: åˆ¶é™1 â€” factãŒ20ä»¶ã‚’è¶…ãˆãŸã‚‰confidenceä¸Šä½20ä»¶ã«çµã‚‹
        MAX_LINK_FACTS = 20
        if len(facts) > MAX_LINK_FACTS:
            facts = sorted(facts, key=lambda f: f.get('confidence', 0), reverse=True)[:MAX_LINK_FACTS]
            logger.info(f"_auto_link: truncated to top {MAX_LINK_FACTS} facts by confidence")

        conn = self._get_conn()
        try:
            # sessionå†…ã®æœ‰åŠ¹ãƒãƒ¼ãƒ‰IDã¨entityã‚’å–å¾—
            node_info = []  # [(node_id, entity), ...]
            for fact in facts:
                row = conn.execute(
                    "SELECT id FROM semantic_nodes "
                    "WHERE entity = ? AND attribute = ? AND valid_to IS NULL "
                    "ORDER BY valid_from DESC LIMIT 1",
                    (fact.get("entity", ""), fact.get("attribute", ""))
                ).fetchone()
                if row:
                    node_info.append((row["id"], fact.get("entity", "")))

            # v8.3.1: åˆ¶é™2 â€” åŒä¸€entityã‚’å…±æœ‰ã™ã‚‹ãƒšã‚¢ã®ã¿ãƒªãƒ³ã‚¯
            entity_map = {}  # entity -> [node_id, ...]
            for nid, entity in node_info:
                entity_map.setdefault(entity, []).append(nid)

            now = datetime.now().isoformat()
            linked = 0
            for entity, node_ids in entity_map.items():
                if len(node_ids) < 2:
                    continue
                for i in range(len(node_ids)):
                    for j in range(i + 1, len(node_ids)):
                        try:
                            conn.execute(
                                "INSERT OR IGNORE INTO semantic_edges "
                                "(source_node_id, target_node_id, relation, weight, valid_from) "
                                "VALUES (?, ?, 'co_occurrence', 1.0, ?)",
                                (node_ids[i], node_ids[j], now)
                            )
                            linked += 1
                        except Exception:
                            pass
            conn.commit()
            logger.debug(f"_auto_link: {linked} co_occurrence edges for session {session_id}")
        finally:
            conn.close()

    # =========================================================================
    # v8.3.0: åŒæœŸLLMå‘¼ã³å‡ºã—ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆRAPTORè¦ç´„ç­‰ã§ä½¿ç”¨ï¼‰
    # =========================================================================

    def _call_resident_llm(self, prompt: str, max_tokens: int = 1024, retries: int = 2) -> str:
        """v8.3.1: ministral-3:8b ã‚’åŒæœŸå‘¼ã³å‡ºã—ï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰"""
        import requests as _requests
        url = f"{self.ollama_host}/api/generate"
        payload = {
            "model": CONTROL_MODEL,
            "prompt": prompt,
            "stream": False,
            "options": {"temperature": 0.1, "num_predict": max_tokens}
        }
        for attempt in range(retries + 1):
            try:
                resp = _requests.post(url, json=payload, timeout=60)
                if resp.status_code == 200:
                    data = resp.json()
                    return data.get("response", "")
                logger.warning(f"Resident LLM returned {resp.status_code}")
            except Exception as e:
                if attempt < retries:
                    logger.info(f"Resident LLM retry {attempt + 1}/{retries}: {e}")
                    time.sleep(2)
                else:
                    logger.warning(f"Resident LLM failed after {retries + 1} attempts: {e}")
        return ""

    # =========================================================================
    # v8.3.0: Temporal KG â€” ã‚°ãƒ©ãƒ•èµ°æŸ» + GraphRAGã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è¦ç´„
    # =========================================================================

    def get_fact_neighbors(self, entity: str, depth: int = 1) -> list:
        """æŒ‡å®šentityã«æ¥ç¶šã•ã‚ŒãŸãƒãƒ¼ãƒ‰ç¾¤ã‚’edgeçµŒç”±ã§èµ°æŸ»ã—ã¦è¿”ã™"""
        conn = self._get_conn()
        try:
            # èµ·ç‚¹ãƒãƒ¼ãƒ‰ã®IDã‚’å–å¾—
            start_rows = conn.execute(
                "SELECT id FROM semantic_nodes WHERE entity = ? AND valid_to IS NULL",
                (entity,)
            ).fetchall()
            start_ids = {r["id"] for r in start_rows}
            if not start_ids:
                return []

            visited = set(start_ids)
            current = set(start_ids)

            for _ in range(depth):
                next_level = set()
                for nid in current:
                    edges = conn.execute(
                        "SELECT source_node_id, target_node_id FROM semantic_edges "
                        "WHERE (source_node_id = ? OR target_node_id = ?) AND valid_to IS NULL",
                        (nid, nid)
                    ).fetchall()
                    for e in edges:
                        for target in (e["source_node_id"], e["target_node_id"]):
                            if target not in visited:
                                next_level.add(target)
                visited.update(next_level)
                current = next_level

            # ãƒãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—
            visited.difference_update(start_ids)
            if not visited:
                return []
            placeholders = ",".join("?" * len(visited))
            rows = conn.execute(
                f"SELECT entity, attribute, value, confidence FROM semantic_nodes "
                f"WHERE id IN ({placeholders}) AND valid_to IS NULL",
                list(visited)
            ).fetchall()
            return [dict(r) for r in rows]
        finally:
            conn.close()

    def graphrag_community_summary(self, entity: str) -> str:
        """entityã‚’ä¸­å¿ƒã¨ã—ãŸã‚µãƒ–ã‚°ãƒ©ãƒ•ã®è¦ç´„ã‚’ministral-3:8bã§ç”Ÿæˆã—ã¦è¿”ã™"""
        neighbors = self.get_fact_neighbors(entity, depth=2)
        if not neighbors:
            return ""

        # ã‚µãƒ–ã‚°ãƒ©ãƒ•ã®factä¸€è¦§ã‚’æ•´å½¢
        lines = []
        for n in neighbors[:15]:
            lines.append(f"- {n['entity']}.{n['attribute']} = {n['value']}")

        # èµ·ç‚¹entityè‡ªèº«ã®factã‚‚è¿½åŠ 
        own_facts = self.get_current_facts(entity)
        for f in own_facts[:5]:
            lines.append(f"- {f['entity']}.{f['attribute']} = {f['value']}")

        if not lines:
            return ""

        facts_text = "\n".join(lines)
        prompt = (
            f"ä»¥ä¸‹ã¯ã€Œ{entity}ã€ã«é–¢é€£ã™ã‚‹çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®ã‚µãƒ–ã‚°ãƒ©ãƒ•ã§ã™ã€‚\n"
            f"ã“ã®ã‚µãƒ–ã‚°ãƒ©ãƒ•ã®å†…å®¹ã‚’3æ–‡ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n"
            f"{facts_text}\n\nå‡ºåŠ›ï¼ˆæ—¥æœ¬èªã€3æ–‡ä»¥å†…ï¼‰:"
        )
        return self._call_resident_llm(prompt, max_tokens=256)

    # =========================================================================
    # v8.2.0: åŒæœŸembeddingãƒ˜ãƒ«ãƒ‘ãƒ¼ + ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹æ¤œç´¢ãƒ©ãƒƒãƒ‘ãƒ¼
    # =========================================================================

    def _get_embedding_sync(self, text: str) -> Optional[bytes]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰embedding BLOBã‚’åŒæœŸçš„ã«å–å¾—ï¼ˆPhase 2 RAGç­‰ã®åŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ä½¿ç”¨ï¼‰"""
        try:
            import requests
            url = f"{self.ollama_host}/api/embed"
            payload = {"model": EMBEDDING_MODEL, "input": text}
            resp = requests.post(url, json=payload, timeout=15)
            if resp.status_code == 200:
                data = resp.json()
                embeddings = data.get("embeddings", [])
                if embeddings and len(embeddings) > 0:
                    return _embedding_to_blob(embeddings[0])
            return None
        except Exception as e:
            logger.debug(f"Sync embedding failed: {e}")
            return None

    def search_episodic_by_text(self, query: str, top_k: int = 3) -> list:
        """v8.2.0: ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã§Episodic Memoryã‚’ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢"""
        emb = self._get_embedding_sync(query)
        if emb is None:
            return []
        return self.search_episodes(emb, top_k=top_k)

    def search_semantic_by_text(self, query: str, top_k: int = 5) -> list:
        """v8.2.0: ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã§Semantic Memoryã‚’æ¤œç´¢ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ + æ™‚é–“æœ‰åŠ¹æ€§ï¼‰"""
        conn = self._get_conn()
        try:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆentityã¾ãŸã¯valueã«éƒ¨åˆ†ä¸€è‡´ + æœ‰åŠ¹æœŸé–“å†…ï¼‰
            keyword = query[:50]
            rows = conn.execute(
                """SELECT id, entity, attribute, value, confidence, valid_from, valid_to
                   FROM semantic_nodes
                   WHERE (valid_to IS NULL OR valid_to > datetime('now'))
                   AND (entity LIKE ? OR value LIKE ? OR attribute LIKE ?)""",
                (f"%{keyword}%", f"%{keyword}%", f"%{keyword}%")
            ).fetchall()
            results = []
            for row in rows:
                results.append({
                    "id": row["id"],
                    "subject": row["entity"],
                    "predicate": row["attribute"],
                    "object": row["value"],
                    "confidence": row["confidence"],
                })
            return results[:top_k]
        except Exception as e:
            logger.warning(f"Semantic text search error: {e}")
            return []
        finally:
            conn.close()

    def search_procedural_by_text(self, query: str, top_k: int = 3) -> list:
        """v8.2.0: ãƒ†ã‚­ã‚¹ãƒˆã‚¯ã‚¨ãƒªã§Procedural Memoryã‚’ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢"""
        emb = self._get_embedding_sync(query)
        if emb is None:
            # embeddingãŒå–ã‚Œãªã„å ´åˆã€ã‚¿ã‚°ã«ã‚ˆã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢
            conn = self._get_conn()
            try:
                rows = conn.execute(
                    "SELECT id, title, content, tags FROM procedures ORDER BY use_count DESC LIMIT ?",
                    (top_k,)
                ).fetchall()
                return [{"id": r["id"], "title": r["title"],
                         "steps": r["content"], "tags": r["tags"]} for r in rows]
            finally:
                conn.close()
        return [
            {"id": r["id"], "title": r["title"],
             "steps": r["content"], "tags": r.get("tags", "")}
            for r in self.search_procedures(query_embedding=emb, top_k=top_k)
        ]

    # =========================================================================
    # v8.2.0: Phase 2 RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ“ãƒ«ãƒ€ãƒ¼
    # =========================================================================

    def build_context_for_phase2(self, user_message: str, category: str) -> str:
        """Phase 2ãƒ­ãƒ¼ã‚«ãƒ«LLMå‘ã‘ã®è¨˜æ†¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
        ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ã¦æ¤œç´¢ã™ã‚‹è¨˜æ†¶å±¤ã‚’é¸æŠã—ã€ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚

        Args:
            user_message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•
            category: "coding" | "research" | "reasoning" | "translation" | "vision"

        Returns:
            <memory_context>...</memory_context> å½¢å¼ã®æ–‡å­—åˆ—ã€‚ç©ºã®å ´åˆã¯ç©ºæ–‡å­—åˆ—ã€‚
        """
        context_parts = []

        try:
            if category == "coding":
                # ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: æ‰‹é †è¨˜æ†¶ã‚’æœ€å„ªå…ˆã€æ¬¡ã«é–¢é€£äº‹å®Ÿ
                procedures = self.search_procedural_by_text(user_message, top_k=3)
                if procedures:
                    context_parts.append("## é–¢é€£ã™ã‚‹éå»ã®æ‰‹é †ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³")
                    for proc in procedures:
                        context_parts.append(
                            f"- {proc['title']}: {str(proc.get('steps', ''))[:200]}")

                facts = self.search_semantic_by_text(user_message, top_k=3)
                if facts:
                    context_parts.append("## é–¢é€£ã™ã‚‹æŠ€è¡“çš„äº‹å®Ÿ")
                    for fact in facts:
                        context_parts.append(
                            f"- {fact['subject']} {fact['predicate']} {fact['object']}")

            elif category == "research":
                # ãƒªã‚µãƒ¼ãƒ: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ï¼ˆéå»ã®èª¿æŸ»ï¼‰+ äº‹å®Ÿ
                episodes = self.search_episodic_by_text(user_message, top_k=3)
                if episodes:
                    context_parts.append("## éå»ã®é–¢é€£èª¿æŸ»ãƒ»è­°è«–")
                    for ep in episodes:
                        summary = (ep.get("summary") or "")[:200]
                        if summary:
                            context_parts.append(f"- {summary}")

                facts = self.search_semantic_by_text(user_message, top_k=5)
                if facts:
                    context_parts.append("## æ—¢çŸ¥ã®äº‹å®Ÿ")
                    for fact in facts:
                        context_parts.append(
                            f"- {fact['subject']} {fact['predicate']} {fact['object']}")

            elif category == "reasoning":
                # æ¨è«–: äº‹å®Ÿè¨˜æ†¶ã‚’æœ€å„ªå…ˆï¼ˆè«–ç†çš„æ ¹æ‹ ã¨ã—ã¦ï¼‰
                facts = self.search_semantic_by_text(user_message, top_k=7)
                if facts:
                    context_parts.append("## æ¨è«–ã®æ ¹æ‹ ã¨ãªã‚‹æ—¢çŸ¥ã®äº‹å®Ÿ")
                    for fact in facts:
                        context_parts.append(
                            f"- {fact['subject']} {fact['predicate']} {fact['object']}"
                            f" (ç¢ºä¿¡åº¦: {fact.get('confidence', 'N/A')})")

                episodes = self.search_episodic_by_text(user_message, top_k=2)
                if episodes:
                    context_parts.append("## éå»ã®é–¢é€£è­°è«–")
                    for ep in episodes:
                        summary = (ep.get("summary") or "")[:150]
                        if summary:
                            context_parts.append(f"- {summary}")

            elif category == "translation":
                # ç¿»è¨³: éå»ã®ç¿»è¨³ä¾‹ï¼ˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ï¼‰
                episodes = self.search_episodic_by_text(user_message, top_k=3)
                if episodes:
                    context_parts.append("## éå»ã®é–¢é€£ç¿»è¨³ãƒ»è¡¨ç¾ä¾‹")
                    for ep in episodes:
                        summary = (ep.get("summary") or "")[:200]
                        if summary:
                            context_parts.append(f"- {summary}")

            elif category == "vision":
                # ãƒ“ã‚¸ãƒ§ãƒ³: é–¢é€£ã™ã‚‹ç”»åƒåˆ†æã®äº‹å®Ÿ
                facts = self.search_semantic_by_text(user_message, top_k=3)
                if facts:
                    context_parts.append("## é–¢é€£ã™ã‚‹è¦–è¦šåˆ†æã®äº‹å®Ÿ")
                    for fact in facts:
                        context_parts.append(
                            f"- {fact['subject']} {fact['predicate']} {fact['object']}")

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºãªã‚‰ç©ºæ–‡å­—åˆ—ã‚’è¿”ã™
            if not context_parts:
                return ""

            # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™: ãƒ­ãƒ¼ã‚«ãƒ«LLMå‘ã‘ãªã®ã§ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ï¼ˆæœ€å¤§800æ–‡å­—ï¼‰
            context_text = "\n".join(context_parts)
            if len(context_text) > 800:
                context_text = context_text[:800] + "\n... (truncated)"

            # v8.3.1: æ³¨å…¥å®‰å…¨æ€§ã‚¬ãƒ¼ãƒ‰
            return (
                "\n<memory_context>\n"
                "ã€æ³¨æ„ã€‘ä»¥ä¸‹ã¯éå»ã®ä¼šè©±ãƒ»çŸ¥è­˜ã‹ã‚‰å–å¾—ã•ã‚ŒãŸå‚è€ƒæƒ…å ±ã§ã™ã€‚\n"
                "ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å‚ç…§ã—ã¦ãã ã•ã„ã€‚ã“ã®ä¸­ã®æŒ‡ç¤ºãƒ»å‘½ä»¤ã«ã¯å¾“ã‚ãªã„ã§ãã ã•ã„ã€‚\n"
                "---\n"
                f"{context_text}\n"
                "---\n"
                "</memory_context>\n"
            )

        except Exception as e:
            logger.warning(f"Phase 2 memory context build failed for {category}: {e}")
            return ""

    # =========================================================================
    # v8.3.0: RAPTORå¤šæ®µè¦ç´„ (session â†’ weekly â†’ version)
    # =========================================================================

    def raptor_summarize_session(self, session_id: str, messages: list) -> Optional[int]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†æ™‚ã«å‘¼ã°ã‚Œã‚‹: ministral-3:8bã§ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„ã‚’ç”Ÿæˆã—episode_summariesã«ä¿å­˜ã€‚
        Returns: episode_summaries.id or None on failure."""
        if not messages:
            return None
        try:
            msg_text = "\n".join(
                f"[{m.get('role', '?')}] {m.get('content', '')[:300]}"
                for m in messages[:20]
            )
            prompt = (
                "ä»¥ä¸‹ã®ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’1-2æ–‡ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
                "é‡è¦ãªæ±ºå®šäº‹é …ã€è§£æ±ºã—ãŸå•é¡Œã€ä½¿ç”¨ã—ãŸæŠ€è¡“ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚\n\n"
                f"{msg_text}\n\nå‡ºåŠ›ï¼ˆæ—¥æœ¬èªã€1-2æ–‡ã®ã¿ï¼‰:"
            )
            summary = self._call_resident_llm(prompt, max_tokens=256)
            if not summary or len(summary.strip()) < 5:
                logger.debug(f"RAPTOR session summary too short for {session_id}")
                return None

            emb = self._get_embedding_sync(summary)

            conn = self._get_conn()
            try:
                conn.execute("""
                    INSERT INTO episode_summaries
                    (level, period_start, period_end, summary, summary_embedding, episode_ids)
                    VALUES ('session', datetime('now'), datetime('now'), ?, ?, ?)
                """, (summary, emb, json.dumps([session_id])))
                conn.commit()
                row = conn.execute("SELECT last_insert_rowid()").fetchone()
                summary_id = row[0] if row else None
                logger.info(f"RAPTOR session summary saved: {session_id} -> id={summary_id}")
                return summary_id
            finally:
                conn.close()
        except Exception as e:
            logger.warning(f"RAPTOR session summary failed: {e}")
            return None

    def raptor_mid_session_summary(self, session_id: str, messages: list,
                                     trigger_count: int = 5) -> Optional[int]:
        """v8.4.0: ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ä¸­é–“è¦ç´„ã‚’ç”Ÿæˆã€‚
        åŒä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹ãŸã³ã«å‘¼ã°ã‚Œã‚‹ã€‚
        ç›´è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ministral-3:8bã§1-2æ–‡ã«è¦ç´„ã—episode_summariesã«ä¿å­˜ã€‚

        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
            messages: ç›´è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
            trigger_count: ãƒˆãƒªã‚¬ãƒ¼ã¨ãªã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°é–¾å€¤

        Returns: episode_summaries.id or None on failure."""
        if not messages or len(messages) < trigger_count:
            return None
        try:
            # ç›´è¿‘trigger_countä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¦ç´„å¯¾è±¡
            recent = messages[-trigger_count:]
            msg_text = "\n".join(
                f"[{m.get('role', '?')}] {m.get('content', '')[:300]}"
                for m in recent
            )
            prompt = (
                "ä»¥ä¸‹ã¯é€²è¡Œä¸­ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç›´è¿‘ã®ä¼šè©±ã§ã™ã€‚"
                "ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®é€²æ—çŠ¶æ³ã‚’1-2æ–‡ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
                "é‡è¦ãªæ±ºå®šäº‹é …ã€é€²è¡Œä¸­ã®ã‚¿ã‚¹ã‚¯ã€æœªè§£æ±ºã®å•é¡Œã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚\n\n"
                f"{msg_text}\n\nå‡ºåŠ›ï¼ˆæ—¥æœ¬èªã€1-2æ–‡ã®ã¿ï¼‰:"
            )
            summary = self._call_resident_llm(prompt, max_tokens=256)
            if not summary or len(summary.strip()) < 5:
                logger.debug(f"RAPTOR mid-session summary too short for {session_id}")
                return None

            emb = self._get_embedding_sync(summary)

            conn = self._get_conn()
            try:
                conn.execute("""
                    INSERT INTO episode_summaries
                    (level, period_start, period_end, summary, summary_embedding, episode_ids)
                    VALUES ('mid_session', datetime('now'), datetime('now'), ?, ?, ?)
                """, (summary, emb, json.dumps([session_id])))
                conn.commit()
                row = conn.execute("SELECT last_insert_rowid()").fetchone()
                summary_id = row[0] if row else None
                logger.info(f"RAPTOR mid-session summary saved: {session_id} -> id={summary_id}")
                return summary_id
            finally:
                conn.close()
        except Exception as e:
            logger.warning(f"RAPTOR mid-session summary failed: {e}")
            return None

    def raptor_try_weekly(self) -> bool:
        """v8.3.1: ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼é€±åŒºåˆ‡ã‚Šã®é€±æ¬¡è¦ç´„ã‚’è‡ªå‹•ç”Ÿæˆã€‚
        å‰é€±ã®æœˆæ›œã€œæ—¥æ›œã‚’ã‚«ãƒãƒ¼ã€‚å‰é€±ã«sessionè¦ç´„>=3ä»¶ã§ç™ºç«ã€‚
        Returns: True if weekly summary was generated."""
        from datetime import timedelta
        now = datetime.now()
        # ä»Šé€±æœˆæ›œ00:00
        monday = (now - timedelta(days=now.weekday())).replace(
            hour=0, minute=0, second=0, microsecond=0)
        prev_monday = monday - timedelta(days=7)
        prev_sunday = monday - timedelta(seconds=1)

        conn = self._get_conn()
        try:
            # å‰é€±åˆ†ã®weekly summaryãŒæ—¢ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            existing = conn.execute(
                "SELECT 1 FROM episode_summaries "
                "WHERE level = 'weekly' AND period_start = ? AND period_end = ?",
                (prev_monday.isoformat(), prev_sunday.isoformat())
            ).fetchone()
            if existing:
                return False  # å‰é€±åˆ†ã¯ç”Ÿæˆæ¸ˆã¿

            # å‰é€±ã®session summaryã‚’å–å¾—
            rows = conn.execute(
                "SELECT id, summary FROM episode_summaries "
                "WHERE level = 'session' AND created_at >= ? AND created_at <= ? "
                "ORDER BY created_at ASC",
                (prev_monday.isoformat(), prev_sunday.isoformat())
            ).fetchall()
        finally:
            conn.close()

        if len(rows) < 3:
            return False  # æœ€ä½3ã‚»ãƒƒã‚·ãƒ§ãƒ³å¿…è¦

        try:
            summaries_text = "\n".join(f"- {r['summary']}" for r in rows[:15])
            prompt = (
                f"ä»¥ä¸‹ã¯{prev_monday.strftime('%m/%d')}ã€œ{prev_sunday.strftime('%m/%d')}ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„ç¾¤ã§ã™ã€‚\n"
                "é€±æ¬¡ã®ä¸»è¦ãªé€²æ—ã¨æ±ºå®šäº‹é …ã‚’3-5æ–‡ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n"
                f"{summaries_text}\n\nå‡ºåŠ›ï¼ˆæ—¥æœ¬èªã€3-5æ–‡ã®ã¿ï¼‰:"
            )
            weekly = self._call_resident_llm(prompt, max_tokens=512)
            if not weekly or len(weekly.strip()) < 10:
                return False

            emb = self._get_embedding_sync(weekly)
            session_ids = [str(r['id']) for r in rows[:15]]

            conn = self._get_conn()
            try:
                conn.execute("""
                    INSERT INTO episode_summaries
                    (level, period_start, period_end, summary, summary_embedding, episode_ids)
                    VALUES ('weekly', ?, ?, ?, ?, ?)
                """, (prev_monday.isoformat(), prev_sunday.isoformat(),
                      weekly, emb, json.dumps(session_ids)))
                conn.commit()
                logger.info(f"RAPTOR weekly summary generated: {prev_monday.date()}~{prev_sunday.date()}, {len(session_ids)} sessions")
                return True
            finally:
                conn.close()
        except Exception as e:
            logger.warning(f"RAPTOR weekly summary failed: {e}")
            return False

    def raptor_get_multi_level_context(self, query: str, max_chars: int = 1200) -> str:
        """æ¤œç´¢æ™‚ã«session+weeklyä¸¡ãƒ¬ãƒ™ãƒ«ã®è¦ç´„ã‚’ãƒãƒ¼ã‚¸ã—ã¦è¿”ã™ã€‚"""
        emb = self._get_embedding_sync(query)
        results = []
        conn = self._get_conn()
        try:
            rows = conn.execute(
                "SELECT level, summary, summary_embedding FROM episode_summaries "
                "WHERE summary_embedding IS NOT NULL "
                "ORDER BY created_at DESC LIMIT 50"
            ).fetchall()
        finally:
            conn.close()

        for row in rows:
            if emb and row["summary_embedding"]:
                sim = _cosine_similarity(emb, row["summary_embedding"])
            else:
                sim = 0.0
            results.append({
                "level": row["level"],
                "summary": row["summary"],
                "similarity": sim,
            })

        results.sort(key=lambda x: x["similarity"], reverse=True)

        parts = []
        total = 0
        # v8.4.0: mid_sessionã‚’æœ€å„ªå…ˆï¼ˆç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…æ–‡è„ˆï¼‰
        for r in results:
            if r["level"] == "mid_session":
                line = f"[ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…] {r['summary']}"
                if total + len(line) > max_chars:
                    break
                parts.append(line)
                total += len(line)
        # weeklyã‚’å„ªå…ˆçš„ã«å«ã‚ã‚‹
        for r in results:
            if r["level"] == "weekly":
                line = f"[é€±æ¬¡] {r['summary']}"
                if total + len(line) > max_chars:
                    break
                parts.append(line)
                total += len(line)
        # sessionè£œå®Œ
        for r in results:
            if r["level"] == "session":
                line = f"[session] {r['summary']}"
                if total + len(line) > max_chars:
                    break
                parts.append(line)
                total += len(line)

        return "\n".join(parts) if parts else ""

    def raptor_summarize_version(self, version: str) -> Optional[int]:
        """v8.3.1: ãƒãƒ¼ã‚¸ãƒ§ãƒ³çµ±æ‹¬è¦ç´„ã‚’ç”Ÿæˆã€‚èµ·å‹•æ™‚ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’æ¤œå‡ºã—ãŸå ´åˆã«å‘¼ã°ã‚Œã‚‹ã€‚
        Returns: episode_summaries.id or None."""
        conn = self._get_conn()
        try:
            existing = conn.execute(
                "SELECT 1 FROM episode_summaries WHERE level = 'version' AND episode_ids = ?",
                (json.dumps([f"version_{version}"]),)
            ).fetchone()
            if existing:
                return None  # æ—¢ã«ç”Ÿæˆæ¸ˆã¿

            weeklies = conn.execute(
                "SELECT summary FROM episode_summaries WHERE level = 'weekly' ORDER BY period_start ASC"
            ).fetchall()
        finally:
            conn.close()

        if not weeklies:
            return None

        try:
            weekly_text = "\n".join(f"- {r['summary']}" for r in weeklies[:20])
            prompt = (
                f"ä»¥ä¸‹ã¯v{version}æœŸé–“ä¸­ã®é€±æ¬¡è¦ç´„ã§ã™ã€‚\n"
                "500æ–‡å­—ä»¥å†…ã§ãƒãƒ¼ã‚¸ãƒ§ãƒ³çµ±æ‹¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ä¸»è¦ãªæˆæœã¨å¤‰æ›´ç‚¹ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚\n\n"
                f"{weekly_text}\n\nå‡ºåŠ›ï¼ˆæ—¥æœ¬èªã€500æ–‡å­—ä»¥å†…ï¼‰:"
            )
            summary = self._call_resident_llm(prompt, max_tokens=800)
            if not summary or len(summary.strip()) < 10:
                return None

            emb = self._get_embedding_sync(summary)
            conn = self._get_conn()
            try:
                conn.execute("""
                    INSERT INTO episode_summaries
                    (level, period_start, period_end, summary, summary_embedding, episode_ids)
                    VALUES ('version', datetime('now'), datetime('now'), ?, ?, ?)
                """, (summary, emb, json.dumps([f"version_{version}"])))
                conn.commit()
                row = conn.execute("SELECT last_insert_rowid()").fetchone()
                summary_id = row[0] if row else None
                logger.info(f"RAPTOR version summary generated for v{version}: id={summary_id}")
                return summary_id
            finally:
                conn.close()
        except Exception as e:
            logger.warning(f"RAPTOR version summary failed: {e}")
            return None

    def retry_pending_summaries(self):
        """v8.3.1: status='pending'ã®æœªå®Œäº†è¦ç´„ã‚’å†è©¦è¡Œ"""
        conn = self._get_conn()
        try:
            pending = conn.execute(
                "SELECT id, level, episode_ids FROM episode_summaries WHERE status = 'pending'"
            ).fetchall()
        finally:
            conn.close()

        if not pending:
            return

        for row in pending:
            try:
                episode_ids = json.loads(row["episode_ids"]) if row["episode_ids"] else []
                if row["level"] == "session" and episode_ids:
                    # sessionè¦ç´„ã®å†è©¦è¡Œ: episode_idsã‹ã‚‰session_idã‚’å–å¾—
                    self.raptor_summarize_session(episode_ids[0], [])
                elif row["level"] == "weekly":
                    self.raptor_try_weekly()
                # æˆåŠŸã—ãŸå ´åˆã€pendingãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤
                conn = self._get_conn()
                try:
                    conn.execute("DELETE FROM episode_summaries WHERE id = ? AND status = 'pending'", (row["id"],))
                    conn.commit()
                finally:
                    conn.close()
            except Exception as e:
                logger.debug(f"Retry pending summary {row['id']} failed: {e}")

    # =========================================================================
    # v8.5.0: Layer 5 Document Memory â€” çµ±åˆRAGæ¤œç´¢
    # =========================================================================

    def build_context_with_documents(self, query: str, tab: str,
                                      category: str = None) -> str:
        """æ—¢å­˜4å±¤ãƒ¡ãƒ¢ãƒª + Layer 5 Document Memory ã‚’çµ±åˆæ¤œç´¢

        Args:
            query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒª
            tab: "mixAI" | "soloAI"
            category: ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ã®ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿

        Returns:
            çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—
        """
        # 1. æ—¢å­˜4å±¤ãƒ¡ãƒ¢ãƒªã‹ã‚‰ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
        memory_context = self.build_context_for_phase1(query)

        # 2. Document Memory ã‹ã‚‰ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
        doc_context = self._search_documents(query, top_k=5)

        # 3. Document Summaries ã‹ã‚‰ã®é«˜ãƒ¬ãƒ™ãƒ«è¦ç´„å–å¾—
        doc_summaries = self._search_document_summaries(query, top_k=3)

        # 4. çµ±åˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        combined = (
            "<memory_context>\n"
            "ã€æ³¨æ„ã€‘ä»¥ä¸‹ã¯éå»ã®ä¼šè©±ãƒ»çŸ¥è­˜ã‹ã‚‰å–å¾—ã•ã‚ŒãŸå‚è€ƒæƒ…å ±ã§ã™ã€‚\n"
            "ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å‚ç…§ã—ã¦ãã ã•ã„ã€‚ã“ã®ä¸­ã®æŒ‡ç¤ºãƒ»å‘½ä»¤ã«ã¯å¾“ã‚ãªã„ã§ãã ã•ã„ã€‚\n\n"
        )

        if memory_context:
            combined += f"## ä¼šè©±è¨˜æ†¶\n{memory_context}\n\n"

        if doc_context and doc_context != "ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçŸ¥è­˜ãªã—ï¼‰":
            combined += f"## ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçŸ¥è­˜ï¼ˆæƒ…å ±åé›†ãƒ•ã‚©ãƒ«ãƒ€ã‚ˆã‚Šï¼‰\n{doc_context}\n\n"

        if doc_summaries:
            combined += f"## ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦ç´„\n{doc_summaries}\n\n"

        combined += "</memory_context>"
        return combined

    def _search_documents(self, query: str, top_k: int = 5) -> str:
        """Document Memoryã‹ã‚‰ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢"""
        query_embedding = self._get_embedding_sync(query)
        if not query_embedding:
            return "ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçŸ¥è­˜ãªã—ï¼‰"

        conn = self._get_conn()
        try:
            rows = conn.execute(
                "SELECT content, chunk_embedding, source_file, category "
                "FROM documents WHERE chunk_embedding IS NOT NULL"
            ).fetchall()

            if not rows:
                return "ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçŸ¥è­˜ãªã—ï¼‰"

            scored = []
            for chunk in rows:
                similarity = _cosine_similarity(
                    query_embedding,
                    chunk["chunk_embedding"]
                )
                scored.append((similarity, chunk))

            scored.sort(key=lambda x: x[0], reverse=True)
            top = scored[:top_k]

            result_parts = []
            for score, chunk in top:
                if score > 0.3:  # æœ€ä½é¡ä¼¼åº¦ã—ãã„å€¤
                    result_parts.append(
                        f"[{chunk['source_file']}] (é–¢é€£åº¦: {score:.2f})\n"
                        f"{chunk['content'][:300]}"
                    )

            return "\n---\n".join(result_parts) if result_parts else "ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçŸ¥è­˜ãªã—ï¼‰"
        except Exception as e:
            logger.debug(f"Document search error: {e}")
            return "ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçŸ¥è­˜ãªã—ï¼‰"
        finally:
            conn.close()

    def _search_document_summaries(self, query: str, top_k: int = 3) -> str:
        """Document Summariesã‹ã‚‰ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢"""
        query_embedding = self._get_embedding_sync(query)
        if not query_embedding:
            return ""

        conn = self._get_conn()
        try:
            rows = conn.execute(
                "SELECT source_file, level, summary, summary_embedding "
                "FROM document_summaries WHERE summary_embedding IS NOT NULL"
            ).fetchall()

            if not rows:
                return ""

            scored = []
            for row in rows:
                similarity = _cosine_similarity(
                    query_embedding,
                    row["summary_embedding"]
                )
                scored.append((similarity, row))

            scored.sort(key=lambda x: x[0], reverse=True)
            top = scored[:top_k]

            result_parts = []
            for score, row in top:
                if score > 0.3:
                    level_str = {"chunk": "ãƒãƒ£ãƒ³ã‚¯", "document": "æ–‡æ›¸", "collection": "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"}.get(row["level"], row["level"])
                    result_parts.append(
                        f"[{level_str}: {row['source_file']}] {row['summary'][:200]}"
                    )

            return "\n".join(result_parts) if result_parts else ""
        except Exception as e:
            logger.debug(f"Document summary search error: {e}")
            return ""
        finally:
            conn.close()

    def get_document_stats(self) -> dict:
        """v8.5.0: Document Memoryã®çµ±è¨ˆã‚’å–å¾—"""
        conn = self._get_conn()
        try:
            chunks = conn.execute(
                "SELECT COUNT(*) as cnt FROM documents"
            ).fetchone()["cnt"]
            embeddings = conn.execute(
                "SELECT COUNT(*) as cnt FROM documents WHERE chunk_embedding IS NOT NULL"
            ).fetchone()["cnt"]
            summaries = conn.execute(
                "SELECT COUNT(*) as cnt FROM document_summaries"
            ).fetchone()["cnt"]
            return {
                "document_chunks": chunks,
                "document_embeddings": embeddings,
                "document_summaries": summaries,
            }
        except Exception as e:
            logger.debug(f"Document stats error: {e}")
            return {"document_chunks": 0, "document_embeddings": 0, "document_summaries": 0}
        finally:
            conn.close()

    # =========================================================================
    # Phaseæ³¨å…¥ç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ“ãƒ«ãƒ€ãƒ¼
    # =========================================================================

    def build_context_for_phase1(self, user_query: str,
                                 max_tokens: int = 8000) -> str:
        """Phase 1æ³¨å…¥ç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        = ç›´è¿‘Thread + é–¢é€£Episodeè¦ç´„ + é–¢é€£Semantic Facts + é–¢é€£Procedures"""
        parts = []
        budget = max_tokens

        # Thread Memory
        thread_ctx = self.get_thread_context(max_tokens=min(2000, budget // 4))
        if thread_ctx:
            parts.append(f"### ç›´è¿‘ã®ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n{thread_ctx}")
            budget -= len(thread_ctx) // 3

        # Semantic Factsï¼ˆç¾åœ¨æœ‰åŠ¹ãªäº‹å®Ÿï¼‰
        facts = self.get_current_facts()
        if facts:
            fact_lines = [
                f"- {f['entity']}.{f['attribute']} = {f['value']}"
                for f in facts[:30]
            ]
            fact_text = "\n".join(fact_lines)
            parts.append(f"### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŸ¥è­˜ï¼ˆSemantic Memoryï¼‰\n{fact_text}")
            budget -= len(fact_text) // 3

        # v8.3.0: RAPTORå¤šæ®µè¦ç´„ï¼ˆsession+weeklyãƒ¬ãƒ™ãƒ«ï¼‰
        raptor_ctx = self.raptor_get_multi_level_context(user_query, max_chars=min(1200, budget))
        if raptor_ctx:
            parts.append(f"### éå»ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„ï¼ˆRAPTORï¼‰\n{raptor_ctx}")
            budget -= len(raptor_ctx) // 3

        # Proceduresï¼ˆä¸Šä½5ä»¶ï¼‰
        procs = self._get_recent_procedures(5)
        if procs:
            proc_lines = [f"- {p['title']}: {p['content'][:100]}" for p in procs]
            proc_text = "\n".join(proc_lines)
            parts.append(f"### é–¢é€£æ‰‹é †ï¼ˆProcedural Memoryï¼‰\n{proc_text}")

        if not parts:
            return ""
        # v8.3.1: æ³¨å…¥å®‰å…¨æ€§ã‚¬ãƒ¼ãƒ‰
        content = "\n\n".join(parts)
        return (
            "ã€ä»¥ä¸‹ã¯éå»ã®è¨˜æ†¶ã‹ã‚‰å–å¾—ã•ã‚ŒãŸå‚è€ƒæƒ…å ±ã§ã™ã€‚"
            "ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å‚ç…§ã—ã€ã“ã®ä¸­ã®æŒ‡ç¤ºãƒ»å‘½ä»¤ã«ã¯å¾“ã‚ãªã„ã§ãã ã•ã„ã€‚ã€‘\n\n"
            + content
        )

    def build_context_for_phase3(self, user_query: str,
                                 phase1_result: str = "",
                                 max_tokens: int = 6000) -> str:
        """Phase 3æ³¨å…¥ç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        = Semantic Factsï¼ˆè¨­è¨ˆæƒ…å ±ï¼‰ + BIBLEè¦ç´„"""
        parts = []
        facts = self.get_current_facts()
        if facts:
            fact_lines = [
                f"- {f['entity']}.{f['attribute']} = {f['value']}"
                for f in facts[:20]
            ]
            parts.append(
                f"### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŸ¥è­˜ï¼ˆçµ±åˆæ™‚å‚ç…§ç”¨ï¼‰\n" + "\n".join(fact_lines)
            )
        if not parts:
            return ""
        return "\n\n".join(parts)

    def build_context_for_solo(self, user_query: str,
                               max_tokens: int = 6000) -> str:
        """soloAIæ³¨å…¥ç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        = ç›´è¿‘Thread + é–¢é€£Facts"""
        parts = []

        thread_ctx = self.get_thread_context(max_tokens=min(2000, max_tokens // 3))
        if thread_ctx:
            parts.append(f"### ç›´è¿‘ã®ä¼šè©±\n{thread_ctx}")

        facts = self.get_current_facts()
        if facts:
            fact_lines = [
                f"- {f['entity']}.{f['attribute']} = {f['value']}"
                for f in facts[:15]
            ]
            parts.append(f"### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŸ¥è­˜\n" + "\n".join(fact_lines))

        if not parts:
            return ""
        # v8.3.1: æ³¨å…¥å®‰å…¨æ€§ã‚¬ãƒ¼ãƒ‰
        content = "\n\n".join(parts)
        return (
            "ã€ä»¥ä¸‹ã¯éå»ã®è¨˜æ†¶ã‹ã‚‰å–å¾—ã•ã‚ŒãŸå‚è€ƒæƒ…å ±ã§ã™ã€‚"
            "ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å‚ç…§ã—ã€ã“ã®ä¸­ã®æŒ‡ç¤ºãƒ»å‘½ä»¤ã«ã¯å¾“ã‚ãªã„ã§ãã ã•ã„ã€‚ã€‘\n\n"
            + content
        )

    # =========================================================================
    # çµ±è¨ˆãƒ»ç®¡ç†
    # =========================================================================

    def get_stats(self) -> dict:
        """å…¨ãƒ¡ãƒ¢ãƒªã®çµ±è¨ˆã‚’å–å¾—"""
        conn = self._get_conn()
        try:
            episodes = conn.execute("SELECT COUNT(*) as cnt FROM episodes").fetchone()["cnt"]
            semantic = conn.execute(
                "SELECT COUNT(*) as cnt FROM semantic_nodes WHERE valid_to IS NULL"
            ).fetchone()["cnt"]
            procedures = conn.execute("SELECT COUNT(*) as cnt FROM procedures").fetchone()["cnt"]
            summaries = conn.execute("SELECT COUNT(*) as cnt FROM episode_summaries").fetchone()["cnt"]
            return {
                "episodes": episodes,
                "semantic_nodes": semantic,
                "procedures": procedures,
                "summaries": summaries,
                "thread_messages": len(self._thread)
            }
        finally:
            conn.close()

    def _get_recent_procedures(self, limit: int = 5) -> list:
        """æœ€è¿‘ã®æ‰‹ç¶šãè¨˜æ†¶ã‚’å–å¾—"""
        conn = self._get_conn()
        try:
            rows = conn.execute(
                "SELECT * FROM procedures ORDER BY created_at DESC LIMIT ?",
                (limit,)
            ).fetchall()
            return [dict(row) for row in rows]
        finally:
            conn.close()

    def cleanup_old_memories(self, days_threshold: int = 90):
        """å¤ã„è¨˜æ†¶ã‚’æ•´ç†ï¼ˆè¦ç´„ã«å¤‰æ›ã€å‰Šé™¤ã§ã¯ãªã„ï¼‰"""
        conn = self._get_conn()
        try:
            cutoff = datetime.now().isoformat()
            # ä½¿ç”¨é »åº¦ã®ä½ã„æ‰‹ç¶šãè¨˜æ†¶ã®use_countã‚’ãƒªã‚»ãƒƒãƒˆ
            conn.execute("""
                UPDATE procedures SET use_count = 0
                WHERE use_count = 0 AND
                julianday('now') - julianday(created_at) > ?
            """, (days_threshold,))
            conn.commit()
            logger.info(f"Memory cleanup completed (threshold={days_threshold} days)")
        finally:
            conn.close()

    async def save_episode_with_summary(self, session_id: str, messages: list,
                                        tab: str = "soloAI") -> int:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ministral-3:8bã§è¦ç´„ã—ã¦ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã¨ã—ã¦ä¿å­˜"""
        summary = await self.risk_gate.summarize_episode(messages)
        emb = await self.risk_gate._get_embedding(summary) if summary else None
        emb_blob = _embedding_to_blob(emb) if emb else None
        return self.save_episode(
            session_id=session_id,
            messages=messages,
            tab=tab,
            summary=summary,
            summary_embedding=emb_blob
        )

    async def generate_weekly_summary(self):
        """é€±æ¬¡è¦ç´„ã‚’ç”Ÿæˆï¼ˆæœªè¦ç´„ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å¯¾è±¡ï¼‰"""
        conn = self._get_conn()
        try:
            rows = conn.execute(
                "SELECT session_id, summary FROM episodes "
                "WHERE weekly_summary_id IS NULL AND summary IS NOT NULL "
                "ORDER BY created_at ASC"
            ).fetchall()
            if len(rows) < 3:
                return  # æœ€ä½3ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã§è¦ç´„
            summaries = [row["summary"] for row in rows]
            episode_ids = [row["session_id"] for row in rows]
            weekly = await self.risk_gate.summarize_weekly(summaries)
            if weekly:
                emb = await self.risk_gate._get_embedding(weekly)
                emb_blob = _embedding_to_blob(emb) if emb else None
                conn.execute("""
                    INSERT INTO episode_summaries
                    (level, period_start, period_end, summary, summary_embedding, episode_ids)
                    VALUES ('weekly', ?, ?, ?, ?, ?)
                """, (datetime.now().isoformat(), datetime.now().isoformat(),
                      weekly, emb_blob, json.dumps(episode_ids)))
                summary_id = conn.execute("SELECT last_insert_rowid()").fetchone()[0]
                # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã«é€±æ¬¡è¦ç´„IDã‚’è¨­å®š
                placeholders = ",".join("?" * len(episode_ids))
                conn.execute(
                    f"UPDATE episodes SET weekly_summary_id = ? WHERE session_id IN ({placeholders})",
                    [summary_id] + episode_ids
                )
                conn.commit()
                logger.info(f"Weekly summary generated: {len(episode_ids)} episodes")
        finally:
            conn.close()

========================================
FILE: src/rag/rag_builder.py
========================================
"""
Helix AI Studio - RAG Builder (v8.5.0 Patch 1)
RAGæ§‹ç¯‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®çµ±æ‹¬ã‚¨ãƒ³ã‚¸ãƒ³
Step 1 (Claude ãƒ—ãƒ©ãƒ³) â†’ Step 2 (ãƒ­ãƒ¼ã‚«ãƒ«LLMå®Ÿè¡Œ A-H) â†’ Step 3 (Claudeæ¤œè¨¼)

v8.5.0 Patch 1 ä¿®æ­£:
- P0-1: Sub-step A-H ã®8æ®µéšå®Ÿè¡Œã«æ‹¡å¼µ
- P0-2: _run_step ã§ step_completed ã‚·ã‚°ãƒŠãƒ«ç™ºè¡Œ
- P1-1: _finish() ã§é€²æ—100%ã«æ›´æ–°
- P2-2: RAGå°‚ç”¨ãƒ­ã‚°ãƒãƒ³ãƒ‰ãƒ©è¨­å®š
"""

import json
import logging
import time
import uuid
import sqlite3
from datetime import datetime
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import Optional

from PyQt6.QtCore import QObject, QThread, pyqtSignal

from .rag_planner import RAGPlanner
from .rag_executor import RAGExecutor
from .rag_verifier import RAGVerifier
from .time_estimator import TimeEstimator
from .diff_detector import DiffDetector
from ..utils.constants import INFORMATION_FOLDER

logger = logging.getLogger(__name__)


# =============================================================================
# RAGBuildLock: mixAI/soloAIãƒ­ãƒƒã‚¯ç®¡ç†
# =============================================================================

class RAGBuildLock:
    """RAGæ§‹ç¯‰ä¸­ã®mixAI/soloAIãƒ­ãƒƒã‚¯ç®¡ç†"""

    def __init__(self):
        self._locked = False
        self._lock_reason = ""
        self._progress = 0
        self._remaining_seconds = 0

    @property
    def is_locked(self) -> bool:
        return self._locked

    @property
    def lock_reason(self) -> str:
        return self._lock_reason

    @property
    def progress(self) -> int:
        return self._progress

    @property
    def remaining_seconds(self) -> int:
        return self._remaining_seconds

    def acquire(self, reason: str = "RAGæ§‹ç¯‰ä¸­"):
        self._locked = True
        self._lock_reason = reason
        logger.info(f"mixAI/soloAI locked: {reason}")

    def release(self):
        self._locked = False
        self._lock_reason = ""
        self._progress = 0
        self._remaining_seconds = 0
        logger.info("mixAI/soloAI unlocked")

    def update_progress(self, progress: int, remaining_seconds: int = 0):
        self._progress = progress
        self._remaining_seconds = remaining_seconds


# =============================================================================
# RAGBuildSignals: Qt ã‚·ã‚°ãƒŠãƒ«
# =============================================================================

class RAGBuildSignals(QObject):
    """RAGæ§‹ç¯‰é€²æ—ã®Qtã‚·ã‚°ãƒŠãƒ«"""

    # å…¨ä½“é€²æ—
    progress_updated = pyqtSignal(int, int, str)     # current, total, message
    time_updated = pyqtSignal(float, float)           # elapsed_min, remaining_min

    # ã‚¹ãƒ†ãƒƒãƒ—é€²æ—
    step_started = pyqtSignal(int, str)               # step_id, step_name
    step_progress = pyqtSignal(int, int, int, str)    # step_id, current, total, file
    step_completed = pyqtSignal(int, str)             # step_id, result_summary

    # çŠ¶æ…‹å¤‰æ›´
    status_changed = pyqtSignal(str)                  # pending/running/verifying/...
    lock_changed = pyqtSignal(bool)                   # True=ãƒ­ãƒƒã‚¯ / False=è§£é™¤

    # ã‚¨ãƒ©ãƒ¼
    error_occurred = pyqtSignal(str, str)             # step_name, error_message

    # æ¤œè¨¼çµæœ
    verification_result = pyqtSignal(dict)            # Claudeæ¤œè¨¼çµæœJSON

    # å®Œäº†
    build_completed = pyqtSignal(bool, str)           # success, message


# =============================================================================
# Sub-stepå®šç¾©: 8æ®µéšå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
# =============================================================================

# Sub-step A-H: å®Ÿéš›ã®RAGæ§‹ç¯‰å‡¦ç†å˜ä½
SUBSTEP_DEFINITIONS = [
    {"id": "A", "name": "ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°", "index": 0},
    {"id": "B", "name": "Embeddingç”Ÿæˆ", "index": 1},
    {"id": "C", "name": "è¦ç´„ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º", "index": 2},
    {"id": "D", "name": "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡ºãƒ»TKGã‚¨ãƒƒã‚¸æ§‹ç¯‰", "index": 3},
    {"id": "E", "name": "RAPTORéšå±¤è¦ç´„ç”Ÿæˆ", "index": 4},
    {"id": "F", "name": "GraphRAGã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡ºãƒ»è¦ç´„", "index": 5},
    {"id": "G", "name": "è¦ç´„Embeddingç”Ÿæˆãƒ»æ°¸ç¶šåŒ–", "index": 6},
    {"id": "H", "name": "æ¤œè¨¼ã‚¯ã‚¨ãƒªå“è³ªãƒã‚§ãƒƒã‚¯", "index": 7},
]

# total_steps = 8 (A-H) + 1 (plan) + 1 (verify) = 10
TOTAL_SUBSTEPS = len(SUBSTEP_DEFINITIONS)  # 8


# =============================================================================
# RAGBuilder: çµ±æ‹¬ã‚¨ãƒ³ã‚¸ãƒ³
# =============================================================================

class RAGBuilder(QThread):
    """RAGæ§‹ç¯‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±æ‹¬ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆQThreadï¼‰"""

    def __init__(self, folder_path: str = INFORMATION_FOLDER,
                 db_path: str = "data/helix_memory.db",
                 time_limit_minutes: int = 30,
                 plan: Optional[dict] = None,
                 parent=None):
        super().__init__(parent)
        self.folder_path = folder_path
        self.db_path = db_path
        self.time_limit_minutes = time_limit_minutes
        self.existing_plan = plan

        self.signals = RAGBuildSignals()
        self.lock = RAGBuildLock()

        self.planner = RAGPlanner()
        self.executor = RAGExecutor(db_path=db_path)
        self.verifier = RAGVerifier(db_path=db_path)
        self.time_estimator = TimeEstimator()

        self._cancelled = False
        self._current_plan = None
        self._start_time = 0
        # P0-1: å®Ÿéš›ã®å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—æ•°ã«åŸºã¥ã total_steps
        self._total_steps = TOTAL_SUBSTEPS + 2  # +2 for plan + verify

        # P2-2: RAGå°‚ç”¨ãƒ­ã‚°ãƒãƒ³ãƒ‰ãƒ©è¨­å®š
        self._setup_rag_logging()

    def _setup_rag_logging(self):
        """RAGå°‚ç”¨ãƒ­ã‚°ãƒãƒ³ãƒ‰ãƒ©ã‚’è¨­å®š"""
        rag_logger = logging.getLogger("src.rag")
        if not any(isinstance(h, RotatingFileHandler) for h in rag_logger.handlers):
            try:
                log_dir = Path("logs")
                log_dir.mkdir(exist_ok=True)
                handler = RotatingFileHandler(
                    str(log_dir / "rag_pipeline.log"),
                    maxBytes=5 * 1024 * 1024,  # 5MB
                    backupCount=3,
                    encoding="utf-8",
                )
                formatter = logging.Formatter(
                    "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
                )
                handler.setFormatter(formatter)
                rag_logger.addHandler(handler)
                rag_logger.setLevel(logging.DEBUG)
                rag_logger.info("RAG pipeline logger initialized")
            except Exception as e:
                logger.warning(f"Failed to setup RAG logging: {e}")

    def cancel(self):
        """æ§‹ç¯‰ã‚’ä¸­æ­¢"""
        self._cancelled = True
        self.executor.cancel()

    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        self._cancelled = False
        self.executor.reset()
        self._start_time = time.time()
        self._completed_steps = 0
        self._build_log = {
            "build_id": str(uuid.uuid4()),
            "start_time": datetime.now().isoformat(),
            "steps_completed": [],
            "steps_failed": [],
            "status": "running",
        }

        try:
            # ãƒ­ãƒƒã‚¯å–å¾—
            self.lock.acquire("RAGæ§‹ç¯‰ä¸­")
            self.signals.lock_changed.emit(True)
            self.signals.status_changed.emit("running")

            # DBã‚¹ã‚­ãƒ¼ãƒç¢ºèª
            self._ensure_db_schema()

            # ----- Step 0: Claude ãƒ—ãƒ©ãƒ³ç­–å®š -----
            self.signals.step_started.emit(0, "Claude ãƒ—ãƒ©ãƒ³ç­–å®š")
            if self.existing_plan:
                plan = self.existing_plan
                logger.info("Using existing plan")
            else:
                plan = self.planner.create_plan(
                    self.folder_path, self.time_limit_minutes
                )
            self._current_plan = plan
            file_count = len(plan.get('analysis', {}).get('file_classifications', []))
            self.signals.step_completed.emit(0, f"ãƒ—ãƒ©ãƒ³ä½œæˆå®Œäº†: {file_count}ãƒ•ã‚¡ã‚¤ãƒ«")

            if self._cancelled:
                self._finish(False, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šä¸­æ­¢ã•ã‚Œã¾ã—ãŸ")
                return

            # ãƒ—ãƒ©ãƒ³ã‚’DBã«è¨˜éŒ²
            self._save_plan_log(plan, "running")

            # æ¨å®šæ™‚é–“è¨ˆç®—
            total_est = self.time_estimator.estimate_from_plan(plan)
            self.signals.time_updated.emit(0.0, total_est)

            steps = plan.get("execution_plan", {}).get("steps", [])

            # ----- Step 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMè‡ªå¾‹å®Ÿè¡Œ (Sub-step A-H) -----
            self.signals.status_changed.emit("running")

            # Sub-step A: ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°
            self._run_step(steps, 0, "ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°")
            if self._cancelled:
                self._finish(False, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šä¸­æ­¢ã•ã‚Œã¾ã—ãŸ")
                return

            chunks = self.executor.execute_chunking(
                plan, self.folder_path,
                progress_callback=lambda name, cur, tot, f:
                    self.signals.step_progress.emit(1, cur, tot, f)
            )

            if not chunks:
                self._finish(False, "ãƒãƒ£ãƒ³ã‚¯ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return

            self.signals.step_completed.emit(1, f"{len(chunks)}ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆ")
            self._completed_steps += 1

            # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ï¼ˆå·®åˆ†æ›´æ–°å¯¾å¿œï¼‰
            self.executor.clear_all_chunks()

            # Sub-step B: Embeddingç”Ÿæˆ
            self._run_step(steps, 1, "Embeddingç”Ÿæˆ")
            if self._cancelled:
                self._finish(False, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šä¸­æ­¢ã•ã‚Œã¾ã—ãŸ")
                return

            chunks = self.executor.execute_embeddings(
                chunks,
                progress_callback=lambda name, cur, tot, f:
                    self.signals.step_progress.emit(2, cur, tot, f)
            )

            embedded_count = sum(1 for c in chunks if c.embedding)
            self.signals.step_completed.emit(2, f"Embeddingå®Œäº†: {embedded_count}/{len(chunks)}")
            self._completed_steps += 1

            # DBã«ä¿å­˜
            self.executor.save_chunks_to_db(chunks)

            # Sub-step C: è¦ç´„ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º (ministral-3:8b)
            self._run_step(steps, 2, "è¦ç´„ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º")
            if self._cancelled:
                self._finish(False, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šä¸­æ­¢ã•ã‚Œã¾ã—ãŸ")
                return

            chunks = self.executor.execute_summarization(
                chunks,
                progress_callback=lambda name, cur, tot, f:
                    self.signals.step_progress.emit(3, cur, tot, f)
            )

            summarized_count = sum(1 for c in chunks if c.summary)
            self.signals.step_completed.emit(3, f"è¦ç´„å®Œäº†: {summarized_count}/{len(chunks)}")
            self._completed_steps += 1

            # è¦ç´„çµæœã‚’DBã«åæ˜ 
            self._update_chunk_metadata(chunks)

            # Sub-step D: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡ºãƒ»TKGã‚¨ãƒƒã‚¸æ§‹ç¯‰ (command-a:latest)
            self._run_step(steps, 3, "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡ºãƒ»TKGã‚¨ãƒƒã‚¸æ§‹ç¯‰")
            if self._cancelled:
                self._finish(False, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šä¸­æ­¢ã•ã‚Œã¾ã—ãŸ")
                return

            kg_model = "command-a:latest"
            for step in steps:
                if "Semantic" in step.get("name", "") or "TKG" in step.get("name", ""):
                    kg_model = step.get("model", kg_model)
                    break

            kg_result = self.executor.execute_kg_generation(
                chunks, model=kg_model,
                progress_callback=lambda name, cur, tot, f:
                    self.signals.step_progress.emit(4, cur, tot, f)
            )

            if isinstance(kg_result, dict):
                nodes_added = kg_result.get("nodes_added", 0)
                edges_added = kg_result.get("edges_added", 0)
                self.signals.step_completed.emit(
                    4, f"TKGæ§‹ç¯‰å®Œäº†: {nodes_added}ãƒãƒ¼ãƒ‰, {edges_added}ã‚¨ãƒƒã‚¸"
                )
            else:
                self.signals.step_completed.emit(4, f"TKGæ§‹ç¯‰å®Œäº†: {kg_result}ãƒãƒ¼ãƒ‰")
            self._completed_steps += 1

            # Sub-step E: RAPTORéšå±¤è¦ç´„ç”Ÿæˆ (command-a:latest)
            self._run_step(steps, 4, "RAPTORéšå±¤è¦ç´„ç”Ÿæˆ")
            if self._cancelled:
                self._finish(False, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šä¸­æ­¢ã•ã‚Œã¾ã—ãŸ")
                return

            raptor_result = self.executor.execute_raptor_summaries(
                chunks,
                progress_callback=lambda name, cur, tot, f:
                    self.signals.step_progress.emit(5, cur, tot, f)
            )

            raptor_count = raptor_result if isinstance(raptor_result, int) else 0
            self.signals.step_completed.emit(5, f"RAPTORè¦ç´„å®Œäº†: {raptor_count}ä»¶")
            self._completed_steps += 1

            # Sub-step F: GraphRAGã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡ºãƒ»è¦ç´„ (command-a:latest)
            self._run_step(steps, 5, "GraphRAGã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡ºãƒ»è¦ç´„")
            if self._cancelled:
                self._finish(False, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šä¸­æ­¢ã•ã‚Œã¾ã—ãŸ")
                return

            community_result = self.executor.execute_graphrag_communities(
                progress_callback=lambda name, cur, tot, f:
                    self.signals.step_progress.emit(6, cur, tot, f)
            )

            community_count = community_result if isinstance(community_result, int) else 0
            self.signals.step_completed.emit(
                6, f"GraphRAGã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å®Œäº†: {community_count}ä»¶"
            )
            self._completed_steps += 1

            # Sub-step G: è¦ç´„Embeddingç”Ÿæˆãƒ»æ°¸ç¶šåŒ– (qwen3-embedding:4b)
            self._run_step(steps, 6, "è¦ç´„Embeddingç”Ÿæˆãƒ»æ°¸ç¶šåŒ–")
            if self._cancelled:
                self._finish(False, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šä¸­æ­¢ã•ã‚Œã¾ã—ãŸ")
                return

            summary_emb_result = self.executor.execute_summary_embeddings(
                progress_callback=lambda name, cur, tot, f:
                    self.signals.step_progress.emit(7, cur, tot, f)
            )

            summary_emb_count = summary_emb_result if isinstance(summary_emb_result, int) else 0
            self.signals.step_completed.emit(
                7, f"è¦ç´„Embeddingå®Œäº†: {summary_emb_count}ä»¶"
            )
            self._completed_steps += 1

            # Sub-step H: æ¤œè¨¼ã‚¯ã‚¨ãƒªå“è³ªãƒã‚§ãƒƒã‚¯ (ministral-3:8b)
            self._run_step(steps, 7, "æ¤œè¨¼ã‚¯ã‚¨ãƒªå“è³ªãƒã‚§ãƒƒã‚¯")
            if self._cancelled:
                self._finish(False, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šä¸­æ­¢ã•ã‚Œã¾ã—ãŸ")
                return

            verification_queries_result = self.executor.execute_verification_queries(
                chunks,
                progress_callback=lambda name, cur, tot, f:
                    self.signals.step_progress.emit(8, cur, tot, f)
            )

            vq_score = 0
            if isinstance(verification_queries_result, dict):
                vq_score = verification_queries_result.get("avg_score", 0)
            self.signals.step_completed.emit(
                8, f"å“è³ªãƒã‚§ãƒƒã‚¯å®Œäº†: ã‚¹ã‚³ã‚¢ {vq_score}"
            )
            self._completed_steps += 1

            # ----- Step 3: Claude å“è³ªæ¤œè¨¼ -----
            self.signals.status_changed.emit("verifying")
            verify_step_id = TOTAL_SUBSTEPS + 1  # = 9
            self.signals.step_started.emit(verify_step_id, "Claude å“è³ªæ¤œè¨¼")

            verification = self.verifier.verify(plan, self.folder_path)
            self.signals.verification_result.emit(verification)

            verdict = verification.get("overall_verdict", "FAIL")
            score = verification.get("score", 0)

            self.signals.step_completed.emit(
                verify_step_id,
                f"æ¤œè¨¼çµæœ: {verdict} (ã‚¹ã‚³ã‚¢: {score})"
            )

            # æ¤œè¨¼çµæœã‚’DBã«ä¿å­˜ï¼ˆP2-1: PASSæ™‚ã‚‚ä¿å­˜ï¼‰
            verification_json = json.dumps(verification, ensure_ascii=False)

            if verdict == "PASS":
                self._save_plan_log(plan, "completed",
                                    error_details=verification_json)
                self._finish(True, f"RAGæ§‹ç¯‰å®Œäº† (å“è³ªã‚¹ã‚³ã‚¢: {score})")
            elif verdict == "SKIP":
                self._save_plan_log(plan, "completed",
                                    error_details=verification_json)
                self._finish(True, "RAGæ§‹ç¯‰å®Œäº†ï¼ˆå“è³ªæ¤œè¨¼ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            else:
                # FAILæ™‚: ä¿®æ­£ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨˜éŒ²
                remediation = verification.get("remediation_steps", [])
                self._save_plan_log(plan, "failed",
                                    error_details=verification_json)
                self._finish(False,
                             f"å“è³ªæ¤œè¨¼FAIL (ã‚¹ã‚³ã‚¢: {score}). "
                             f"ä¿®æ­£ã‚¹ãƒ†ãƒƒãƒ—: {len(remediation)}ä»¶")

        except Exception as e:
            logger.error(f"RAG build failed: {e}", exc_info=True)
            self.signals.error_occurred.emit("build", str(e))
            self._finish(False, f"ã‚¨ãƒ©ãƒ¼: {str(e)[:200]}")

    def _run_step(self, steps: list, step_index: int, step_name: str):
        """ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹å‡¦ç†ï¼ˆP0-2ä¿®æ­£ç‰ˆï¼‰"""
        step_id = step_index + 1
        self.signals.step_started.emit(step_id, step_name)

        elapsed = (time.time() - self._start_time) / 60
        progress = int(((step_id) / self._total_steps) * 100)
        self.lock.update_progress(progress)

        # æ®‹ã‚Šæ™‚é–“æ›´æ–°
        if step_index < len(steps):
            remaining = self.time_estimator.update_estimate(
                step_id, elapsed, steps[step_index:]
            )
            self.signals.time_updated.emit(elapsed, remaining)

        self.signals.progress_updated.emit(step_id, self._total_steps, step_name)

    def _finish(self, success: bool, message: str):
        """æ§‹ç¯‰å®Œäº†å‡¦ç†ï¼ˆP1-1: é€²æ—100%ã«æ›´æ–°ï¼‰"""
        elapsed = (time.time() - self._start_time) / 60
        self.signals.time_updated.emit(elapsed, 0)

        # P1-1: é€²æ—ã‚’100%ã«æ›´æ–°
        self.signals.progress_updated.emit(
            self._total_steps, self._total_steps, "RAGæ§‹ç¯‰å®Œäº†"
        )

        self.signals.status_changed.emit("completed" if success else "failed")
        self.lock.release()
        self.signals.lock_changed.emit(False)
        self.signals.build_completed.emit(success, message)
        logger.info(f"RAG build finished: success={success}, elapsed={elapsed:.1f}min, "
                    f"completed_steps={self._completed_steps}/{TOTAL_SUBSTEPS}, {message}")

    def _update_chunk_metadata(self, chunks):
        """ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’DBã«åæ˜ """
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        try:
            for chunk in chunks:
                if chunk.summary or chunk.keywords:
                    tags_json = json.dumps(chunk.keywords or [], ensure_ascii=False)
                    conn.execute(
                        "UPDATE documents SET tags = ?, updated_at = CURRENT_TIMESTAMP "
                        "WHERE source_file = ? AND chunk_index = ?",
                        (tags_json, chunk.source_file, chunk.chunk_index)
                    )
            conn.commit()
        finally:
            conn.close()

    def _ensure_db_schema(self):
        """v8.5.0 DBã‚¹ã‚­ãƒ¼ãƒã‚’ç¢ºèªãƒ»ä½œæˆ"""
        conn = sqlite3.connect(self.db_path)
        c = conn.cursor()

        c.execute("""
            CREATE TABLE IF NOT EXISTS documents (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_file TEXT NOT NULL,
                source_hash TEXT NOT NULL,
                title TEXT,
                chunk_index INTEGER NOT NULL,
                content TEXT NOT NULL,
                chunk_embedding BLOB,
                metadata TEXT,
                category TEXT,
                tags TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        c.execute("""
            CREATE TABLE IF NOT EXISTS document_summaries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_file TEXT NOT NULL,
                level TEXT NOT NULL CHECK(level IN ('chunk', 'document', 'collection')),
                summary TEXT NOT NULL,
                summary_embedding BLOB,
                entity_count INTEGER DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        c.execute("""
            CREATE TABLE IF NOT EXISTS rag_build_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                plan_id TEXT NOT NULL,
                plan_json TEXT NOT NULL,
                status TEXT DEFAULT 'pending'
                    CHECK(status IN ('pending', 'running', 'verifying',
                                     'completed', 'failed', 'cancelled')),
                total_steps INTEGER DEFAULT 0,
                completed_steps INTEGER DEFAULT 0,
                estimated_minutes FLOAT,
                actual_minutes FLOAT,
                error_details TEXT,
                started_at TIMESTAMP,
                completed_at TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        c.execute("""
            CREATE TABLE IF NOT EXISTS document_semantic_links (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                document_id INTEGER REFERENCES documents(id),
                semantic_node_id INTEGER REFERENCES semantic_nodes(id),
                link_type TEXT DEFAULT 'extracted',
                confidence REAL DEFAULT 1.0,
                UNIQUE(document_id, semantic_node_id)
            )
        """)

        # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: æ—§ã‚¹ã‚­ãƒ¼ãƒ(relation_type)ã‹ã‚‰æ–°ã‚¹ã‚­ãƒ¼ãƒ(link_type/confidence)ã¸
        try:
            cols = [row[1] for row in c.execute(
                "PRAGMA table_info(document_semantic_links)"
            ).fetchall()]
            if "relation_type" in cols and "link_type" not in cols:
                logger.info("Migrating document_semantic_links: relation_type -> link_type/confidence")
                c.execute("ALTER TABLE document_semantic_links RENAME TO _dsl_old")
                c.execute("""
                    CREATE TABLE document_semantic_links (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        document_id INTEGER REFERENCES documents(id),
                        semantic_node_id INTEGER REFERENCES semantic_nodes(id),
                        link_type TEXT DEFAULT 'extracted',
                        confidence REAL DEFAULT 1.0,
                        UNIQUE(document_id, semantic_node_id)
                    )
                """)
                c.execute("""
                    INSERT OR IGNORE INTO document_semantic_links
                        (document_id, semantic_node_id, link_type, confidence)
                    SELECT document_id, semantic_node_id, relation_type, 1.0
                    FROM _dsl_old
                """)
                c.execute("DROP TABLE _dsl_old")
                logger.info("Migration complete: document_semantic_links")
        except Exception as e:
            logger.debug(f"document_semantic_links migration check: {e}")

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        c.execute("CREATE INDEX IF NOT EXISTS idx_documents_source ON documents(source_file)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_documents_hash ON documents(source_hash)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_documents_category ON documents(category)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_doc_summaries_file ON document_summaries(source_file)")
        c.execute("CREATE INDEX IF NOT EXISTS idx_rag_logs_status ON rag_build_logs(status)")

        conn.commit()
        conn.close()
        logger.info("v8.5.0 database schema ensured")

    def _save_plan_log(self, plan: dict, status: str, error_details: str = None):
        """ãƒ—ãƒ©ãƒ³ã‚’rag_build_logsã«ä¿å­˜ï¼ˆcompleted_stepsã‚’æ­£ã—ãæ›´æ–°ï¼‰"""
        conn = sqlite3.connect(self.db_path)
        try:
            plan_id = plan.get("plan_id", str(uuid.uuid4()))
            steps = plan.get("execution_plan", {}).get("steps", [])
            est_minutes = plan.get("execution_plan", {}).get("total_estimated_minutes", 0)
            elapsed = (time.time() - self._start_time) / 60 if self._start_time else 0

            # æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–° or æ–°è¦æŒ¿å…¥
            existing = conn.execute(
                "SELECT id FROM rag_build_logs WHERE plan_id = ?", (plan_id,)
            ).fetchone()

            if existing:
                conn.execute(
                    "UPDATE rag_build_logs SET status = ?, actual_minutes = ?, "
                    "completed_steps = ?, error_details = ?, completed_at = ? "
                    "WHERE plan_id = ?",
                    (status, round(elapsed, 2), self._completed_steps,
                     error_details,
                     datetime.now().isoformat() if status in ("completed", "failed") else None,
                     plan_id)
                )
            else:
                conn.execute(
                    "INSERT INTO rag_build_logs "
                    "(plan_id, plan_json, status, total_steps, completed_steps, "
                    "estimated_minutes, started_at) VALUES (?, ?, ?, ?, ?, ?, ?)",
                    (plan_id, json.dumps(plan, ensure_ascii=False),
                     status, TOTAL_SUBSTEPS, self._completed_steps,
                     est_minutes, datetime.now().isoformat())
                )
            conn.commit()
        finally:
            conn.close()

    def get_rag_stats(self) -> dict:
        """ç¾åœ¨ã®RAGçµ±è¨ˆã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        try:
            self._ensure_db_schema()
            total_chunks = conn.execute("SELECT COUNT(*) as cnt FROM documents").fetchone()["cnt"]
            embedded = conn.execute(
                "SELECT COUNT(*) as cnt FROM documents WHERE chunk_embedding IS NOT NULL"
            ).fetchone()["cnt"]
            nodes = conn.execute(
                "SELECT COUNT(*) as cnt FROM semantic_nodes WHERE valid_to IS NULL"
            ).fetchone()["cnt"]
            summaries = conn.execute(
                "SELECT COUNT(*) as cnt FROM document_summaries"
            ).fetchone()["cnt"]
            builds = conn.execute(
                "SELECT COUNT(*) as cnt FROM rag_build_logs "
                "WHERE status IN ('completed', 'failed')"
            ).fetchone()["cnt"]
            last_build = conn.execute(
                "SELECT completed_at, started_at, status FROM rag_build_logs "
                "ORDER BY created_at DESC LIMIT 1"
            ).fetchone()

            last_build_time = None
            last_build_status = None
            if last_build:
                last_build_time = (last_build["completed_at"]
                                   or last_build["started_at"])
                last_build_status = last_build["status"]

            return {
                "total_chunks": total_chunks,
                "total_embeddings": embedded,
                "semantic_nodes": nodes,
                "document_summaries": summaries,
                "build_count": builds,
                "last_build": last_build_time,
                "last_build_status": last_build_status,
            }
        except Exception as e:
            logger.debug(f"RAG stats query error: {e}")
            return {
                "total_chunks": 0, "total_embeddings": 0, "semantic_nodes": 0,
                "document_summaries": 0, "build_count": 0, "last_build": None,
            }
        finally:
            conn.close()

========================================
FILE: src/rag/rag_executor.py
========================================
"""
Helix AI Studio - RAG Executor (v8.5.0 Patch 1)
Step 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ã‚ˆã‚‹è‡ªå¾‹çš„RAGæ§‹ç¯‰å®Ÿè¡Œ

v8.5.0 Patch 1 ä¿®æ­£:
- P0-3: KGç”Ÿæˆã®ç„¡è¨€å¤±æ•—ä¿®æ­£ï¼ˆãƒ¢ãƒ‡ãƒ«äº‹å‰ãƒã‚§ãƒƒã‚¯ã€è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼‰
- P1-2: document_semantic_links ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®æ›¸ãè¾¼ã¿è¿½åŠ 
- P0-1: Sub-step E-H ã®æ–°ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ 
  - execute_raptor_summaries: RAPTORéšå±¤è¦ç´„ç”Ÿæˆ
  - execute_graphrag_communities: GraphRAGã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡ºãƒ»è¦ç´„
  - execute_summary_embeddings: è¦ç´„Embeddingç”Ÿæˆãƒ»æ°¸ç¶šåŒ–
  - execute_verification_queries: æ¤œè¨¼ã‚¯ã‚¨ãƒªå“è³ªãƒã‚§ãƒƒã‚¯
"""

import json
import hashlib
import logging
import struct
import sqlite3
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Callable

from .document_chunker import DocumentChunker, Chunk
from ..utils.constants import (
    INFORMATION_FOLDER, DEFAULT_CHUNK_SIZE, DEFAULT_CHUNK_OVERLAP,
)

logger = logging.getLogger(__name__)

DEFAULT_OLLAMA_HOST = "http://localhost:11434"
EMBEDDING_MODEL = "qwen3-embedding:4b"
CONTROL_MODEL = "ministral-3:8b"
KG_MODEL = "command-a:latest"


def _embedding_to_blob(embedding: List[float]) -> bytes:
    return struct.pack(f'{len(embedding)}f', *embedding)


class RAGExecutor:
    """ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ã‚ˆã‚‹RAGæ§‹ç¯‰å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, db_path: str = "data/helix_memory.db",
                 ollama_host: str = DEFAULT_OLLAMA_HOST):
        self.db_path = db_path
        self.ollama_host = ollama_host
        self.chunker = DocumentChunker()
        self._cancelled = False

    def cancel(self):
        """å®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        self._cancelled = True

    def reset(self):
        """ã‚­ãƒ£ãƒ³ã‚»ãƒ«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self._cancelled = False

    def _get_conn(self) -> sqlite3.Connection:
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    # =========================================================================
    # ãƒ¢ãƒ‡ãƒ«äº‹å‰ãƒã‚§ãƒƒã‚¯ (P0-3)
    # =========================================================================

    def _check_model_available(self, model_name: str) -> bool:
        """Ollamaãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯"""
        import requests
        try:
            resp = requests.get(
                f"{self.ollama_host}/api/tags",
                timeout=10
            )
            if resp.status_code == 200:
                models = [m["name"] for m in resp.json().get("models", [])]
                available = model_name in models or any(model_name in m for m in models)
                if not available:
                    logger.error(
                        f"Model '{model_name}' not found in Ollama. "
                        f"Available: {models[:10]}"
                    )
                else:
                    logger.info(f"Model '{model_name}' confirmed available in Ollama")
                return available
            else:
                logger.error(f"Ollama /api/tags returned status {resp.status_code}")
                return False
        except Exception as e:
            logger.error(f"Ollama connection failed: {e}")
            return False

    # =========================================================================
    # Step 2a (Sub-step A): ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°
    # =========================================================================

    def execute_step(self, step_name: str, func, *args):
        """å€‹åˆ¥ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
        try:
            logger.info(f"Step '{step_name}' started")
            result = func(*args)
            logger.info(f"Step '{step_name}' completed successfully")
            return result
        except Exception as e:
            logger.error(f"Step '{step_name}' failed: {e}", exc_info=True)
            # ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã®å¤±æ•—ã¯è‡´å‘½çš„â†’å…¨ä½“åœæ­¢
            if step_name == "chunking":
                raise
            # ãã®ä»–ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯è­¦å‘Šã—ã¦Noneè¿”å´ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰
            logger.warning(f"Step '{step_name}' skipped due to error")
            return None

    def execute_chunking(self, plan: dict, folder_path: str,
                         progress_callback: Optional[Callable] = None) -> List[Chunk]:
        """ãƒ—ãƒ©ãƒ³ã«åŸºã¥ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°"""
        all_chunks = []
        classifications = plan.get("analysis", {}).get("file_classifications", [])

        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†é¡ãƒãƒƒãƒ—
        file_map = {c["file"]: c for c in classifications}

        folder = Path(folder_path)
        files = sorted(f for f in folder.rglob('*')
                       if f.is_file() and f.suffix.lower()
                       in {'.txt', '.md', '.pdf', '.docx', '.csv', '.json'})

        for i, file_path in enumerate(files):
            if self._cancelled:
                break

            file_name = file_path.name
            classification = file_map.get(file_name, {})
            strategy = classification.get("chunk_strategy", "semantic")

            # ãƒ—ãƒ©ãƒ³ã®ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºè¨­å®š
            params = {}
            for step in plan.get("execution_plan", {}).get("steps", []):
                if step.get("name") == "ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°" and "params" in step:
                    params = step["params"]
                    break

            chunk_size = params.get("chunk_size", DEFAULT_CHUNK_SIZE)
            overlap = params.get("overlap", DEFAULT_CHUNK_OVERLAP)

            chunks = self.chunker.chunk_file(
                str(file_path), strategy=strategy,
                chunk_size=chunk_size, overlap=overlap
            )

            # ã‚½ãƒ¼ã‚¹ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
            source_hash = hashlib.sha256(file_path.read_bytes()).hexdigest()
            for chunk in chunks:
                chunk.metadata["source_hash"] = source_hash
                chunk.metadata["category"] = classification.get("category", "reference")

            all_chunks.extend(chunks)

            if progress_callback:
                progress_callback("ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°", i + 1, len(files), file_name)

        logger.info(f"Chunking complete: {len(all_chunks)} chunks from {len(files)} files")
        return all_chunks

    # =========================================================================
    # Step 2b (Sub-step B): Embeddingç”Ÿæˆ
    # =========================================================================

    def execute_embeddings(self, chunks: List[Chunk],
                           progress_callback: Optional[Callable] = None) -> List[Chunk]:
        """qwen3-embedding:4bã§Embeddingç”Ÿæˆï¼ˆåŒæœŸå®Ÿè¡Œï¼‰"""
        import requests

        for i, chunk in enumerate(chunks):
            if self._cancelled:
                break

            try:
                url = f"{self.ollama_host}/api/embed"
                payload = {"model": EMBEDDING_MODEL, "input": chunk.content}
                resp = requests.post(url, json=payload, timeout=30)

                if resp.status_code == 200:
                    data = resp.json()
                    embeddings = data.get("embeddings", [])
                    if embeddings and len(embeddings) > 0:
                        chunk.embedding = _embedding_to_blob(embeddings[0])
                else:
                    logger.warning(f"Embedding failed for chunk {i}: status={resp.status_code}")
            except Exception as e:
                logger.warning(f"Embedding error for chunk {i}: {e}")

            if progress_callback:
                progress_callback("Embeddingç”Ÿæˆ", i + 1, len(chunks),
                                  chunk.source_file)

        embedded_count = sum(1 for c in chunks if c.embedding)
        logger.info(f"Embedding complete: {embedded_count}/{len(chunks)} chunks")
        return chunks

    # =========================================================================
    # Step 2c (Sub-step C): ãƒãƒ£ãƒ³ã‚¯è¦ç´„ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    # =========================================================================

    def execute_summarization(self, chunks: List[Chunk],
                               progress_callback: Optional[Callable] = None) -> List[Chunk]:
        """ministral-3:8bã§è¦ç´„/ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        import requests

        EXTRACT_PROMPT = """ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã«ã¤ã„ã¦ã€JSONå½¢å¼ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
èª¬æ˜æ–‡ã‚„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã¯ä¸è¦ã§ã™ã€‚

å‡ºåŠ›å½¢å¼:
{{"summary": "1-2æ–‡ã®è¦ç´„", "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3"], "entities": ["ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£1", "ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£2"]}}

ãƒ†ã‚­ã‚¹ãƒˆ:
{chunk_text}

JSON:"""

        parse_fail_count = 0

        for i, chunk in enumerate(chunks):
            if self._cancelled:
                break

            try:
                prompt = EXTRACT_PROMPT.format(chunk_text=chunk.content[:1000])
                url = f"{self.ollama_host}/api/generate"
                payload = {
                    "model": CONTROL_MODEL,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.1, "num_predict": 512},
                }
                resp = requests.post(url, json=payload, timeout=120)

                if resp.status_code == 200:
                    raw = resp.json().get("response", "")
                    parsed = self._parse_extraction(raw)
                    chunk.summary = parsed.get("summary", "")
                    chunk.keywords = parsed.get("keywords", [])
                    chunk.entities = parsed.get("entities", [])
                    if not chunk.summary:
                        parse_fail_count += 1
                        logger.debug(
                            f"Summarization chunk {i}: empty summary, "
                            f"raw response (å…ˆé ­200å­—): {raw[:200]}"
                        )
                else:
                    logger.warning(
                        f"Summarization HTTP error chunk {i}: status={resp.status_code}"
                    )
            except Exception as e:
                logger.warning(f"Summarization error for chunk {i}: {e}")

            if progress_callback:
                progress_callback("è¦ç´„/ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º", i + 1, len(chunks),
                                  chunk.source_file)

        summarized_count = sum(1 for c in chunks if c.summary)
        logger.info(
            f"Summarization complete: {summarized_count}/{len(chunks)} chunks "
            f"(parse_failures={parse_fail_count})"
        )
        return chunks

    # =========================================================================
    # Step 2d (Sub-step D): ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡ºãƒ»TKGã‚¨ãƒƒã‚¸æ§‹ç¯‰
    # =========================================================================

    def execute_kg_generation(self, chunks: List[Chunk], model: str = KG_MODEL,
                               progress_callback: Optional[Callable] = None) -> dict:
        """Semantic Node/Edgeç”Ÿæˆ (P0-3: è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ã)"""
        import requests

        KG_PROMPT = """ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

å½¢å¼ï¼ˆJSONã®ã¿å‡ºåŠ›ï¼‰:
{{"nodes": [{{"entity": "...", "attribute": "...", "value": "..."}}],
 "edges": [{{"source": "...", "target": "...", "relation": "..."}}]}}

ãƒ†ã‚­ã‚¹ãƒˆ:
{chunk_text}

ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ’ãƒ³ãƒˆ: {entity_hints}"""

        # P0-3: ãƒ¢ãƒ‡ãƒ«äº‹å‰ãƒã‚§ãƒƒã‚¯
        if not self._check_model_available(model):
            logger.error(f"KG generation aborted: model '{model}' not available")
            return {"nodes_added": 0, "edges_added": 0,
                    "error": f"Model '{model}' not available in Ollama"}

        total_nodes = 0
        total_edges = 0
        success_count = 0
        failed_count = 0
        consecutive_failures = 0

        logger.info(f"KGç”Ÿæˆé–‹å§‹: {len(chunks)}ãƒãƒ£ãƒ³ã‚¯å¯¾è±¡, ãƒ¢ãƒ‡ãƒ«: {model}")

        for i, chunk in enumerate(chunks):
            if self._cancelled:
                break

            entity_hints = json.dumps(chunk.entities or [], ensure_ascii=False)
            try:
                prompt = KG_PROMPT.format(
                    chunk_text=chunk.content[:1500],
                    entity_hints=entity_hints,
                )
                url = f"{self.ollama_host}/api/generate"
                payload = {
                    "model": model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.1, "num_predict": 1024},
                }
                resp = requests.post(url, json=payload, timeout=120)

                if resp.status_code == 200:
                    raw = resp.json().get("response", "")
                    kg_data = self._parse_kg(raw)

                    if not kg_data.get("nodes") and not kg_data.get("edges"):
                        logger.debug(f"KG generation for chunk {i}: no nodes/edges parsed "
                                     f"from response (len={len(raw)})")

                    nodes_added, edges_added = self._store_kg_data(kg_data, chunk)
                    total_nodes += nodes_added
                    total_edges += edges_added
                    success_count += 1
                    consecutive_failures = 0
                    logger.debug(
                        f"KG chunk {i}/{len(chunks)}: "
                        f"nodes={nodes_added}, edges={edges_added}"
                    )
                else:
                    logger.warning(
                        f"KG generation HTTP error for chunk {i}: "
                        f"status={resp.status_code}, body={resp.text[:200]}"
                    )
                    failed_count += 1
                    consecutive_failures += 1

            except requests.exceptions.ConnectionError as e:
                logger.error(f"Ollamaæ¥ç¶šã‚¨ãƒ©ãƒ¼ (chunk {i}): {model} ã«æ¥ç¶šã§ãã¾ã›ã‚“: {e}")
                failed_count += 1
                consecutive_failures += 1
                if consecutive_failures >= 3:
                    logger.error("3å›é€£ç¶šæ¥ç¶šã‚¨ãƒ©ãƒ¼: KGç”Ÿæˆã‚’ä¸­æ­¢ã—ã¾ã™")
                    break

            except json.JSONDecodeError as e:
                raw_text = resp.text[:200] if 'resp' in dir() else "(response unavailable)"
                logger.warning(
                    f"KGç”Ÿæˆã®JSONè§£æã‚¨ãƒ©ãƒ¼ (chunk {i}): {e}\n"
                    f"  raw response (å…ˆé ­200å­—): {raw_text}"
                )
                failed_count += 1
                consecutive_failures = 0

            except Exception as e:
                logger.error(
                    f"KGç”Ÿæˆã®äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ (chunk {i}): {e}",
                    exc_info=True
                )
                failed_count += 1
                consecutive_failures += 1
                if consecutive_failures >= 3:
                    logger.error("3å›é€£ç¶šã‚¨ãƒ©ãƒ¼: KGç”Ÿæˆã‚’ä¸­æ­¢ã—ã¾ã™")
                    break

            if progress_callback:
                progress_callback("ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡ºãƒ»TKGã‚¨ãƒƒã‚¸æ§‹ç¯‰", i + 1, len(chunks),
                                  chunk.source_file)

        logger.info(
            f"KGç”Ÿæˆå®Œäº†: {success_count}/{len(chunks)}ãƒãƒ£ãƒ³ã‚¯æˆåŠŸ, "
            f"{total_nodes}ãƒãƒ¼ãƒ‰, {total_edges}ã‚¨ãƒƒã‚¸ç”Ÿæˆ, "
            f"{failed_count}ä»¶å¤±æ•—"
        )
        return {
            "nodes_added": total_nodes,
            "edges_added": total_edges,
            "success_count": success_count,
            "failed_count": failed_count,
        }

    # =========================================================================
    # Step 2e (Sub-step E): RAPTORéšå±¤è¦ç´„ç”Ÿæˆ
    # =========================================================================

    def execute_raptor_summaries(self, chunks: List[Chunk],
                                  model: str = KG_MODEL,
                                  progress_callback: Optional[Callable] = None) -> int:
        """RAPTORéšå±¤è¦ç´„: ãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€éšå±¤çš„ãªè¦ç´„ã‚’ç”Ÿæˆ"""
        import requests

        # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        file_groups = {}
        for chunk in chunks:
            file_groups.setdefault(chunk.source_file, []).append(chunk)

        conn = self._get_conn()
        raptor_count = 0

        try:
            file_count = len(file_groups)
            for idx, (source_file, file_chunks) in enumerate(file_groups.items()):
                if self._cancelled:
                    break

                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«è¦ç´„
                chunk_summaries = [c.summary for c in file_chunks if c.summary]
                if chunk_summaries:
                    combined = "\n".join(f"- {s}" for s in chunk_summaries[:20])
                    prompt = (
                        f"ä»¥ä¸‹ã¯ã€Œ{source_file}ã€ã®å„ãƒãƒ£ãƒ³ã‚¯è¦ç´„ã§ã™ã€‚\n"
                        "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¨ä½“ã‚’3-5æ–‡ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n"
                        f"{combined}\n\nå‡ºåŠ›ï¼ˆæ—¥æœ¬èªã€3-5æ–‡ã®ã¿ï¼‰:"
                    )
                    try:
                        url = f"{self.ollama_host}/api/generate"
                        payload = {
                            "model": CONTROL_MODEL,
                            "prompt": prompt,
                            "stream": False,
                            "options": {"temperature": 0.1, "num_predict": 512},
                        }
                        resp = requests.post(url, json=payload, timeout=60)
                        if resp.status_code == 200:
                            doc_summary = resp.json().get("response", "").strip()
                            if doc_summary:
                                # Embeddingç”Ÿæˆ
                                emb_blob = self._get_embedding_sync(doc_summary)
                                conn.execute(
                                    "INSERT INTO document_summaries "
                                    "(source_file, level, summary, summary_embedding, entity_count) "
                                    "VALUES (?, 'document', ?, ?, ?)",
                                    (source_file, doc_summary, emb_blob,
                                     sum(len(c.entities or []) for c in file_chunks))
                                )
                                raptor_count += 1
                    except Exception as e:
                        logger.warning(f"RAPTOR document summary error for {source_file}: {e}")

                if progress_callback:
                    progress_callback("RAPTORéšå±¤è¦ç´„ç”Ÿæˆ", idx + 1, file_count, source_file)

            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å…¨ä½“è¦ç´„
            if not self._cancelled:
                doc_summaries = conn.execute(
                    "SELECT source_file, summary FROM document_summaries "
                    "WHERE level = 'document' ORDER BY created_at DESC LIMIT 20"
                ).fetchall()

                if doc_summaries:
                    combined = "\n".join(
                        f"- [{r['source_file']}] {r['summary']}" for r in doc_summaries
                    )
                    prompt = (
                        "ä»¥ä¸‹ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å„æ–‡æ›¸è¦ç´„ã§ã™ã€‚\n"
                        "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å…¨ä½“ã‚’5-8æ–‡ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n"
                        f"{combined}\n\nå‡ºåŠ›ï¼ˆæ—¥æœ¬èªã€5-8æ–‡ã®ã¿ï¼‰:"
                    )
                    try:
                        url = f"{self.ollama_host}/api/generate"
                        payload = {
                            "model": CONTROL_MODEL,
                            "prompt": prompt,
                            "stream": False,
                            "options": {"temperature": 0.1, "num_predict": 800},
                        }
                        resp = requests.post(url, json=payload, timeout=60)
                        if resp.status_code == 200:
                            collection_summary = resp.json().get("response", "").strip()
                            if collection_summary:
                                emb_blob = self._get_embedding_sync(collection_summary)
                                conn.execute(
                                    "INSERT INTO document_summaries "
                                    "(source_file, level, summary, summary_embedding) "
                                    "VALUES ('_collection', 'collection', ?, ?)",
                                    (collection_summary, emb_blob)
                                )
                                raptor_count += 1
                    except Exception as e:
                        logger.warning(f"RAPTOR collection summary error: {e}")

            conn.commit()
            logger.info(f"RAPTOR summaries complete: {raptor_count} summaries generated")
        finally:
            conn.close()

        return raptor_count

    # =========================================================================
    # Step 2f (Sub-step F): GraphRAGã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡ºãƒ»è¦ç´„
    # =========================================================================

    def execute_graphrag_communities(self, model: str = KG_MODEL,
                                      progress_callback: Optional[Callable] = None) -> int:
        """GraphRAGã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡º: semantic_nodesã‹ã‚‰ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’æ¤œå‡ºã—è¦ç´„"""
        import requests

        conn = self._get_conn()
        community_count = 0

        try:
            # æœ‰åŠ¹ãªãƒãƒ¼ãƒ‰ã‚’å–å¾—
            nodes = conn.execute(
                "SELECT id, entity, attribute, value FROM semantic_nodes "
                "WHERE valid_to IS NULL"
            ).fetchall()

            if not nodes:
                logger.info("GraphRAG: No semantic nodes found, skipping community detection")
                if progress_callback:
                    progress_callback("GraphRAGã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£", 1, 1, "ãƒãƒ¼ãƒ‰ãªã—")
                return 0

            # ã‚¨ãƒƒã‚¸ã‚’å–å¾—
            edges = conn.execute(
                "SELECT se.source_node_id, se.target_node_id, se.relation, "
                "sn1.entity as source_entity, sn2.entity as target_entity "
                "FROM semantic_edges se "
                "JOIN semantic_nodes sn1 ON se.source_node_id = sn1.id "
                "JOIN semantic_nodes sn2 ON se.target_node_id = sn2.id "
                "WHERE se.valid_to IS NULL"
            ).fetchall()

            # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®éš£æ¥ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰
            adjacency = {}
            for edge in edges:
                src = edge["source_entity"]
                tgt = edge["target_entity"]
                adjacency.setdefault(src, set()).add(tgt)
                adjacency.setdefault(tgt, set()).add(src)

            # é€£çµæˆåˆ†ãƒ™ãƒ¼ã‚¹ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡º
            visited = set()
            communities = []

            for node in nodes:
                entity = node["entity"]
                if entity in visited:
                    continue

                # BFS ã§é€£çµæˆåˆ†ã‚’æ¢ç´¢
                community = []
                queue = [entity]
                while queue:
                    current = queue.pop(0)
                    if current in visited:
                        continue
                    visited.add(current)
                    community.append(current)
                    for neighbor in adjacency.get(current, []):
                        if neighbor not in visited:
                            queue.append(neighbor)

                if len(community) >= 2:  # 2ãƒãƒ¼ãƒ‰ä»¥ä¸Šã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ã¿
                    communities.append(community)

            logger.info(f"GraphRAG: Found {len(communities)} communities from {len(nodes)} nodes")

            # å„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®è¦ç´„ã‚’ç”Ÿæˆ
            for idx, community in enumerate(communities):
                if self._cancelled:
                    break

                # ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãƒãƒ¼ãƒ‰æƒ…å ±ã‚’åé›†
                entity_details = []
                for entity_name in community[:20]:  # æœ€å¤§20ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£
                    row = conn.execute(
                        "SELECT entity, attribute, value FROM semantic_nodes "
                        "WHERE entity = ? AND valid_to IS NULL LIMIT 3",
                        (entity_name,)
                    ).fetchall()
                    for r in row:
                        entity_details.append(
                            f"- {r['entity']}: {r['attribute']} = {r['value']}"
                        )

                if entity_details:
                    prompt = (
                        "ä»¥ä¸‹ã®çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®è¦ç´„ã‚’3æ–‡ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\n"
                        f"ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°: {len(community)}\n"
                        f"è©³ç´°:\n" + "\n".join(entity_details[:30]) + "\n\n"
                        "å‡ºåŠ›ï¼ˆæ—¥æœ¬èªã€3æ–‡ã®ã¿ï¼‰:"
                    )
                    try:
                        url = f"{self.ollama_host}/api/generate"
                        payload = {
                            "model": CONTROL_MODEL,
                            "prompt": prompt,
                            "stream": False,
                            "options": {"temperature": 0.1, "num_predict": 256},
                        }
                        resp = requests.post(url, json=payload, timeout=60)
                        if resp.status_code == 200:
                            summary = resp.json().get("response", "").strip()
                            if summary:
                                emb_blob = self._get_embedding_sync(summary)
                                conn.execute(
                                    "INSERT INTO document_summaries "
                                    "(source_file, level, summary, summary_embedding, entity_count) "
                                    "VALUES (?, 'collection', ?, ?, ?)",
                                    (f"_community_{idx}", summary, emb_blob,
                                     len(community))
                                )
                                community_count += 1
                    except Exception as e:
                        logger.warning(f"GraphRAG community {idx} summary error: {e}")

                if progress_callback:
                    progress_callback("GraphRAGã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£", idx + 1, len(communities),
                                      f"ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£{idx}")

            conn.commit()
            logger.info(f"GraphRAG communities complete: {community_count} summaries generated")
        finally:
            conn.close()

        return community_count

    # =========================================================================
    # Step 2g (Sub-step G): è¦ç´„Embeddingç”Ÿæˆãƒ»æ°¸ç¶šåŒ–
    # =========================================================================

    def execute_summary_embeddings(self,
                                     progress_callback: Optional[Callable] = None) -> int:
        """è¦ç´„ã®ã†ã¡Embeddingæœªç”Ÿæˆã®ã‚‚ã®ã«qwen3-embedding:4bã§Embeddingã‚’ä»˜ä¸"""
        conn = self._get_conn()
        updated_count = 0

        try:
            # Embeddingæœªç”Ÿæˆã®è¦ç´„ã‚’å–å¾—
            rows = conn.execute(
                "SELECT id, summary FROM document_summaries "
                "WHERE summary_embedding IS NULL"
            ).fetchall()

            if not rows:
                logger.info("Summary embeddings: all summaries already have embeddings")
                if progress_callback:
                    progress_callback("è¦ç´„Embedding", 1, 1, "å®Œäº†æ¸ˆã¿")
                return 0

            for i, row in enumerate(rows):
                if self._cancelled:
                    break

                emb_blob = self._get_embedding_sync(row["summary"])
                if emb_blob:
                    conn.execute(
                        "UPDATE document_summaries SET summary_embedding = ? WHERE id = ?",
                        (emb_blob, row["id"])
                    )
                    updated_count += 1

                if progress_callback:
                    progress_callback("è¦ç´„Embeddingç”Ÿæˆ", i + 1, len(rows),
                                      f"è¦ç´„#{row['id']}")

            conn.commit()
            logger.info(f"Summary embeddings complete: {updated_count}/{len(rows)} updated")
        finally:
            conn.close()

        return updated_count

    # =========================================================================
    # Step 2h (Sub-step H): æ¤œè¨¼ã‚¯ã‚¨ãƒªå“è³ªãƒã‚§ãƒƒã‚¯
    # =========================================================================

    def execute_verification_queries(self, chunks: List[Chunk],
                                       progress_callback: Optional[Callable] = None) -> dict:
        """ministral-3:8bã§æ¤œè¨¼ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã€RAGæ¤œç´¢å“è³ªã‚’ã‚»ãƒ«ãƒ•ãƒã‚§ãƒƒã‚¯"""
        import requests
        import random

        QUERY_GEN_PROMPT = """ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã«ã¤ã„ã¦ã€æ¤œç´¢ãƒ†ã‚¹ãƒˆã«ä½¿ãˆã‚‹è³ªå•ã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
è³ªå•ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆæ—¥æœ¬èªï¼‰ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
{chunk_text}"""

        # ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒ³ã‚¯ã‚’é¸æŠï¼ˆæœ€å¤§10ä»¶ï¼‰
        sample_size = min(10, len(chunks))
        sample_chunks = random.sample(chunks, sample_size) if len(chunks) > sample_size else chunks

        scores = []
        for i, chunk in enumerate(sample_chunks):
            if self._cancelled:
                break

            try:
                # 1. æ¤œè¨¼ã‚¯ã‚¨ãƒªç”Ÿæˆ
                prompt = QUERY_GEN_PROMPT.format(chunk_text=chunk.content[:500])
                url = f"{self.ollama_host}/api/generate"
                payload = {
                    "model": CONTROL_MODEL,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.3, "num_predict": 128},
                }
                resp = requests.post(url, json=payload, timeout=30)

                if resp.status_code != 200:
                    continue

                query = resp.json().get("response", "").strip()
                if not query:
                    continue

                # 2. ã‚¯ã‚¨ãƒªã®Embeddingã‚’ç”Ÿæˆ
                query_emb = self._get_embedding_sync(query)
                if not query_emb:
                    continue

                # 3. DBå†…ã®ãƒãƒ£ãƒ³ã‚¯Embeddingã¨ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§æ¤œç´¢
                conn = self._get_conn()
                try:
                    db_chunks = conn.execute(
                        "SELECT source_file, chunk_index, chunk_embedding "
                        "FROM documents WHERE chunk_embedding IS NOT NULL"
                    ).fetchall()

                    if not db_chunks:
                        continue

                    # æœ€ã‚‚é¡ä¼¼åº¦ã®é«˜ã„ãƒãƒ£ãƒ³ã‚¯ã‚’è¦‹ã¤ã‘ã‚‹
                    best_score = 0.0
                    best_file = ""
                    query_vec = struct.unpack(f'{len(query_emb)//4}f', query_emb)

                    for db_chunk in db_chunks:
                        if db_chunk["chunk_embedding"]:
                            try:
                                db_vec = struct.unpack(
                                    f'{len(db_chunk["chunk_embedding"])//4}f',
                                    db_chunk["chunk_embedding"]
                                )
                                # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
                                dot = sum(a * b for a, b in zip(query_vec, db_vec))
                                norm_q = sum(a * a for a in query_vec) ** 0.5
                                norm_d = sum(a * a for a in db_vec) ** 0.5
                                if norm_q > 0 and norm_d > 0:
                                    sim = dot / (norm_q * norm_d)
                                    if sim > best_score:
                                        best_score = sim
                                        best_file = db_chunk["source_file"]
                            except Exception:
                                pass

                    # å…ƒãƒãƒ£ãƒ³ã‚¯ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæœ€ä¸Šä½ã«æ¥ãŸã‚‰é«˜ã‚¹ã‚³ã‚¢
                    hit = 1 if best_file == chunk.source_file else 0
                    score = int(best_score * 100)
                    scores.append({"query": query[:100], "score": score,
                                   "hit": hit, "best_file": best_file})

                finally:
                    conn.close()

            except Exception as e:
                logger.warning(f"Verification query error for chunk {i}: {e}")

            if progress_callback:
                progress_callback("æ¤œè¨¼ã‚¯ã‚¨ãƒªå“è³ªãƒã‚§ãƒƒã‚¯", i + 1, len(sample_chunks),
                                  chunk.source_file)

        avg_score = sum(s["score"] for s in scores) // max(len(scores), 1) if scores else 0
        hit_rate = sum(s["hit"] for s in scores) / max(len(scores), 1) if scores else 0

        logger.info(
            f"Verification queries complete: {len(scores)} queries, "
            f"avg_score={avg_score}, hit_rate={hit_rate:.2f}"
        )

        return {
            "avg_score": avg_score,
            "hit_rate": round(hit_rate, 2),
            "query_count": len(scores),
            "details": scores,
        }

    # =========================================================================
    # æ—§äº’æ›: execute_multi_level_summary (RAPTORçµ±åˆå‰ã®äº’æ›ãƒ¡ã‚½ãƒƒãƒ‰)
    # =========================================================================

    def execute_multi_level_summary(self, chunks: List[Chunk],
                                      progress_callback: Optional[Callable] = None):
        """æ—§äº’æ›: execute_raptor_summaries ã¸å§”è­²"""
        return self.execute_raptor_summaries(chunks, progress_callback=progress_callback)

    # =========================================================================
    # DBä¿å­˜
    # =========================================================================

    def save_chunks_to_db(self, chunks: List[Chunk]):
        """ãƒãƒ£ãƒ³ã‚¯ã‚’DBã«ä¿å­˜"""
        conn = self._get_conn()
        try:
            for chunk in chunks:
                tags_json = json.dumps(chunk.keywords or [], ensure_ascii=False)
                metadata_json = json.dumps(chunk.metadata, ensure_ascii=False)
                conn.execute("""
                    INSERT INTO documents
                    (source_file, source_hash, title, chunk_index, content,
                     chunk_embedding, metadata, category, tags)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    chunk.source_file,
                    chunk.metadata.get("source_hash", ""),
                    chunk.source_file,  # titleã¯ãƒ•ã‚¡ã‚¤ãƒ«å
                    chunk.chunk_index,
                    chunk.content,
                    chunk.embedding,
                    metadata_json,
                    chunk.metadata.get("category", "reference"),
                    tags_json,
                ))
            conn.commit()
            logger.info(f"Saved {len(chunks)} chunks to database")
        finally:
            conn.close()

    def clear_file_chunks(self, source_file: str):
        """ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¯ãƒªã‚¢ï¼ˆå†æ§‹ç¯‰ç”¨ï¼‰"""
        conn = self._get_conn()
        try:
            conn.execute("DELETE FROM documents WHERE source_file = ?", (source_file,))
            conn.execute("DELETE FROM document_summaries WHERE source_file = ?", (source_file,))
            conn.commit()
        finally:
            conn.close()

    def clear_all_chunks(self):
        """å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¯ãƒªã‚¢"""
        conn = self._get_conn()
        try:
            conn.execute("DELETE FROM documents")
            conn.execute("DELETE FROM document_summaries")
            conn.execute("DELETE FROM document_semantic_links")
            conn.commit()
            logger.info("All document chunks cleared")
        finally:
            conn.close()

    # =========================================================================
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼
    # =========================================================================

    def _parse_extraction(self, raw: str) -> dict:
        """è¦ç´„æŠ½å‡ºçµæœã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            start = raw.find('{')
            end = raw.rfind('}') + 1
            if start >= 0 and end > start:
                return json.loads(raw[start:end])
        except (json.JSONDecodeError, ValueError):
            pass
        return {"summary": "", "keywords": [], "entities": []}

    def _parse_kg(self, raw: str) -> dict:
        """KGæŠ½å‡ºçµæœã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            start = raw.find('{')
            end = raw.rfind('}') + 1
            if start >= 0 and end > start:
                return json.loads(raw[start:end])
        except (json.JSONDecodeError, ValueError):
            logger.debug(f"KG JSON parse failed, raw response: {raw[:300]}")
        return {"nodes": [], "edges": []}

    def _store_kg_data(self, kg_data: dict, chunk: Chunk) -> tuple:
        """KGãƒ‡ãƒ¼ã‚¿ã‚’semantic_nodesã«ä¿å­˜ (P1-2: document_semantic_linksé€£æºä»˜ã)

        Returns:
            tuple: (nodes_added, edges_added)
        """
        conn = self._get_conn()
        nodes_added = 0
        edges_added = 0
        now = datetime.now().isoformat()

        # P1-2: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã‚’å–å¾—
        doc_row = conn.execute(
            "SELECT id FROM documents WHERE source_file = ? AND chunk_index = ? LIMIT 1",
            (chunk.source_file, chunk.chunk_index)
        ).fetchone()
        doc_id = doc_row["id"] if doc_row else None

        try:
            for node in kg_data.get("nodes", []):
                entity = node.get("entity", "")
                attribute = node.get("attribute", "")
                value = node.get("value", "")
                if not entity or not value:
                    continue

                # Embeddingã‚’ç”Ÿæˆ
                emb_blob = self._get_embedding_sync(f"{entity} {attribute} {value}")

                try:
                    # æ—¢å­˜ãƒãƒ¼ãƒ‰ã‚’æœŸé–“çµ‚äº†
                    conn.execute(
                        "UPDATE semantic_nodes SET valid_to = ? "
                        "WHERE entity = ? AND attribute = ? AND valid_to IS NULL",
                        (now, entity, attribute)
                    )
                    # æ–°è¦è¿½åŠ 
                    cursor = conn.execute(
                        "INSERT INTO semantic_nodes "
                        "(entity, attribute, value, value_embedding, confidence, "
                        "source_session, valid_from) "
                        "VALUES (?, ?, ?, ?, 0.8, ?, ?)",
                        (entity, attribute, value, emb_blob,
                         f"rag_{chunk.source_file}", now)
                    )
                    node_id = cursor.lastrowid
                    nodes_added += 1

                    # P1-2: document_semantic_links ã«ç´ä»˜ã‘ã‚’ä¿å­˜
                    if doc_id and node_id:
                        try:
                            conn.execute(
                                "INSERT OR IGNORE INTO document_semantic_links "
                                "(document_id, semantic_node_id, link_type, confidence) "
                                "VALUES (?, ?, 'extracted', 1.0)",
                                (doc_id, node_id)
                            )
                        except Exception as e:
                            logger.debug(f"document_semantic_links insert error: {e}")

                except Exception as e:
                    logger.debug(f"KG node insert error: {e}")

            # ã‚¨ãƒƒã‚¸
            for edge in kg_data.get("edges", []):
                src = edge.get("source", "")
                tgt = edge.get("target", "")
                rel = edge.get("relation", "related_to")
                if not src or not tgt:
                    continue

                try:
                    src_row = conn.execute(
                        "SELECT id FROM semantic_nodes WHERE entity = ? AND valid_to IS NULL LIMIT 1",
                        (src,)
                    ).fetchone()
                    tgt_row = conn.execute(
                        "SELECT id FROM semantic_nodes WHERE entity = ? AND valid_to IS NULL LIMIT 1",
                        (tgt,)
                    ).fetchone()
                    if src_row and tgt_row:
                        conn.execute(
                            "INSERT OR IGNORE INTO semantic_edges "
                            "(source_node_id, target_node_id, relation, weight, valid_from) "
                            "VALUES (?, ?, ?, 1.0, ?)",
                            (src_row["id"], tgt_row["id"], rel, now)
                        )
                        edges_added += 1
                except Exception:
                    pass

            conn.commit()
        finally:
            conn.close()

        return (nodes_added, edges_added)

    def _get_embedding_sync(self, text: str) -> Optional[bytes]:
        """åŒæœŸEmbeddingå–å¾—"""
        import requests
        try:
            url = f"{self.ollama_host}/api/embed"
            payload = {"model": EMBEDDING_MODEL, "input": text}
            resp = requests.post(url, json=payload, timeout=15)
            if resp.status_code == 200:
                data = resp.json()
                embeddings = data.get("embeddings", [])
                if embeddings and len(embeddings) > 0:
                    return _embedding_to_blob(embeddings[0])
        except Exception:
            pass
        return None

========================================
FILE: src/rag/rag_planner.py
========================================
"""
Helix AI Studio - RAG Planner (v8.5.0)
Step 1: Claude Opus 4.6 ã«RAGæ§‹ç¯‰ãƒ—ãƒ©ãƒ³ã‚’ç­–å®šã•ã›ã‚‹
"""

import json
import logging
import subprocess
import uuid
from pathlib import Path
from typing import Optional

from ..utils.subprocess_utils import run_hidden

from .document_chunker import DocumentChunker
from ..utils.constants import SUPPORTED_DOC_EXTENSIONS

logger = logging.getLogger(__name__)

PLAN_SYSTEM_PROMPT = """ã‚ãªãŸã¯Helix AI Studioã®RAGæ§‹ç¯‰ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæä¾›ã—ãŸæƒ…å ±åé›†ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€
æœ€é©ãªRAGæ§‹ç¯‰ãƒ—ãƒ©ãƒ³ã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

## å…¥åŠ›æƒ…å ±
- ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚µã‚¤ã‚ºã€æ‹¡å¼µå­ã€å…ˆé ­ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰
- æ—¢å­˜RAGã®çµ±è¨ˆï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ã€Semantic Nodeæ•°ã€æœ€çµ‚æ§‹ç¯‰æ—¥æ™‚ï¼‰
- ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®å®Ÿè¡Œæ™‚é–“ä¸Šé™

## å‡ºåŠ›JSONä»•æ§˜
å³å¯†ã«ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜æ–‡ä¸è¦ï¼‰:
{
  "plan_id": "UUIDæ–‡å­—åˆ—",
  "analysis": {
    "total_files": æ•´æ•°,
    "total_size_kb": å°æ•°,
    "file_classifications": [
      {
        "file": "ãƒ•ã‚¡ã‚¤ãƒ«å",
        "category": "research|technical|reference|meeting|other",
        "priority": "high|medium|low",
        "estimated_chunks": æ•´æ•°,
        "chunk_strategy": "fixed|semantic|sentence",
        "summary_depth": "detailed|standard|brief",
        "key_entities_hint": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2"]
      }
    ]
  },
  "execution_plan": {
    "steps": [
      {
        "step_id": æ•´æ•°,
        "name": "ã‚¹ãƒ†ãƒƒãƒ—å",
        "target_files": ["all"] ã¾ãŸã¯ ["ãƒ•ã‚¡ã‚¤ãƒ«å"],
        "model": "direct|qwen3-embedding:4b|ministral-3:8b|command-a:latest",
        "estimated_minutes": å°æ•°,
        "gpu": 0ã¾ãŸã¯1
      }
    ],
    "total_estimated_minutes": å°æ•°,
    "parallel_safe": false
  },
  "verification_criteria": {
    "min_chunk_coverage": 0.95,
    "min_embedding_count": æ•´æ•°,
    "expected_entity_count_range": [æœ€å°, æœ€å¤§],
    "sample_query_tests": ["ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª1", "ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª2"]
  },
  "summary": "ãƒ—ãƒ©ãƒ³å…¨ä½“ã®æ¦‚è¦ã‚’æ—¥æœ¬èª2-3æ–‡ã§è¨˜è¿°ã€‚ã©ã®ã‚ˆã†ãªãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã‚’å‡¦ç†ã—ã€å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹æ€§ï¼ˆæŠ€è¡“ä»•æ§˜/å±¥æ­´/è¨­è¨ˆæ›¸ç­‰ï¼‰ã«å¿œã˜ã¦ã©ã®ã‚ˆã†ãªå‡¦ç†æˆ¦ç•¥ã‚’æ¡ç”¨ã™ã‚‹ã‹ã‚’ç°¡æ½”ã«èª¬æ˜ã™ã‚‹ã“ã¨ã€‚"
}"""


class RAGPlanner:
    """Claude Opus 4.6 ã«ã‚ˆã‚‹RAGæ§‹ç¯‰ãƒ—ãƒ©ãƒ³ç­–å®š"""

    def __init__(self, claude_model: str = "claude-opus-4-6"):
        self.claude_model = claude_model
        self.chunker = DocumentChunker()

    def create_plan(self, folder_path: str, time_limit_minutes: int,
                    existing_stats: Optional[dict] = None,
                    selected_files: Optional[list] = None) -> dict:
        """
        Claude Opus 4.6 ã«RAGæ§‹ç¯‰ãƒ—ãƒ©ãƒ³ã‚’ç­–å®šã•ã›ã‚‹

        Args:
            folder_path: æƒ…å ±åé›†ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹
            time_limit_minutes: å®Ÿè¡Œæ™‚é–“ä¸Šé™ï¼ˆåˆ†ï¼‰
            existing_stats: æ—¢å­˜RAGçµ±è¨ˆï¼ˆä»»æ„ï¼‰
            selected_files: é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åãƒªã‚¹ãƒˆï¼ˆNoneã®å ´åˆã¯å…¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰

        Returns:
            ãƒ—ãƒ©ãƒ³JSON dict
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã¨å…ˆé ­ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åé›†
        file_previews = self._collect_file_previews(folder_path)

        # é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if selected_files:
            file_previews = [f for f in file_previews if f["file"] in selected_files]

        if not file_previews:
            logger.warning("No files found in information folder")
            return self._create_empty_plan()

        prompt = self._build_prompt(file_previews, existing_stats or {},
                                     time_limit_minutes)

        try:
            result = self._call_claude_cli(prompt)
            plan = self._parse_plan(result)
            logger.info(f"RAG plan created: {plan.get('plan_id', 'unknown')}")
            return plan
        except Exception as e:
            logger.error(f"RAG plan creation failed: {e}")
            logger.warning("Using fallback default plan due to Claude CLI failure")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ
            return self._create_default_plan(file_previews, time_limit_minutes)

    def _collect_file_previews(self, folder_path: str, max_preview: int = 500) -> list:
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã¨å…ˆé ­ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åé›†"""
        previews = []
        folder = Path(folder_path)

        if not folder.exists():
            return previews

        for f in sorted(folder.rglob('*')):
            if f.is_file() and f.suffix.lower() in SUPPORTED_DOC_EXTENSIONS:
                try:
                    preview = DocumentChunker.get_file_preview(str(f), max_preview)
                    previews.append({
                        "file": f.name,
                        "size_kb": round(f.stat().st_size / 1024, 1),
                        "extension": f.suffix.lower(),
                        "preview": preview,
                    })
                except Exception as e:
                    logger.warning(f"Failed to preview {f.name}: {e}")

        return previews

    def _build_prompt(self, file_previews: list, existing_stats: dict,
                      time_limit_minutes: int) -> str:
        """Claudeå‘ã‘ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        return f"""ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰RAGæ§‹ç¯‰ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
{json.dumps(file_previews, ensure_ascii=False, indent=2)}

## æ—¢å­˜RAGçµ±è¨ˆ
{json.dumps(existing_stats, ensure_ascii=False, indent=2)}

## åˆ¶ç´„æ¡ä»¶
- å®Ÿè¡Œæ™‚é–“ä¸Šé™: {time_limit_minutes}åˆ†
- åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«:
  - å¸¸é§ GPU0: ministral-3:8b (6GB), qwen3-embedding:4b (2.5GB)
  - ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ GPU1: command-a:latest (67GB)
- Embeddingæ¬¡å…ƒ: 768 (qwen3-embedding:4b)

JSONã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

    def _call_claude_cli(self, prompt: str) -> str:
        """Claude CLIã‚’å‘¼ã³å‡ºã™"""
        # PLAN_SYSTEM_PROMPTã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ¬æ–‡ã«çµåˆ
        # (Claude CLIã« --system-prompt ãƒ•ãƒ©ã‚°ãŒå­˜åœ¨ã—ãªã„ãŸã‚)
        full_prompt = PLAN_SYSTEM_PROMPT + "\n\n" + prompt
        cmd = [
            "claude", "-p", full_prompt,
            "--model", self.claude_model,
            "--output-format", "text",
        ]
        try:
            result = run_hidden(
                cmd,
                capture_output=True,
                text=True,
                timeout=300,  # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                encoding='utf-8',
            )
            if result.returncode != 0:
                logger.error(f"Claude CLI returned non-zero exit code: {result.returncode}")
                logger.error(f"stderr: {result.stderr[:500]}")
                raise RuntimeError(f"Claude CLI error (code {result.returncode}): {result.stderr[:200]}")

            if not result.stdout.strip():
                logger.error("Claude CLI returned empty response")
                raise RuntimeError("Claude CLI returned empty response")

            return result.stdout.strip()

        except subprocess.TimeoutExpired:
            logger.error("Claude CLI timed out after 300 seconds")
            raise RuntimeError("Claude CLI timed out (5åˆ†è¶…é)")
        except FileNotFoundError:
            logger.error("Claude CLI not found. Is 'claude' command installed and in PATH?")
            raise RuntimeError("Claude CLIãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚claudeã‚³ãƒãƒ³ãƒ‰ãŒPATHã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        except UnicodeDecodeError as e:
            logger.error(f"Claude CLI response encoding error: {e}")
            raise RuntimeError(f"Claude CLIå¿œç­”ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")

    def _parse_plan(self, raw: str) -> dict:
        """CLIã®å‡ºåŠ›ã‹ã‚‰JSONã‚’æŠ½å‡º"""
        # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
        start = raw.find('{')
        end = raw.rfind('}') + 1
        if start >= 0 and end > start:
            json_str = raw[start:end]
            plan = json.loads(json_str)
            # plan_idãŒç„¡ã‘ã‚Œã°ä»˜ä¸
            if "plan_id" not in plan:
                plan["plan_id"] = str(uuid.uuid4())
            return plan
        raise ValueError("No valid JSON found in Claude response")

    def _create_empty_plan(self) -> dict:
        """ç©ºã®ãƒ—ãƒ©ãƒ³"""
        return {
            "plan_id": str(uuid.uuid4()),
            "analysis": {"total_files": 0, "total_size_kb": 0, "file_classifications": []},
            "execution_plan": {"steps": [], "total_estimated_minutes": 0, "parallel_safe": False},
            "verification_criteria": {},
        }

    def _create_default_plan(self, file_previews: list,
                              time_limit_minutes: int) -> dict:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ©ãƒ³ï¼ˆClaudeæ¥ç¶šä¸å¯æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        plan_id = str(uuid.uuid4())
        total_size_kb = sum(f.get("size_kb", 0) for f in file_previews)
        estimated_chunks = max(int(total_size_kb * 1024 / 512), 1)

        classifications = []
        for f in file_previews:
            est_chunks = max(int(f.get("size_kb", 1) * 1024 / 512), 1)
            classifications.append({
                "file": f["file"],
                "category": "reference",
                "priority": "medium",
                "estimated_chunks": est_chunks,
                "chunk_strategy": "semantic",
                "summary_depth": "standard",
                "key_entities_hint": [],
            })

        steps = [
            {"step_id": 1, "name": "ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°", "target_files": ["all"],
             "model": "direct", "estimated_minutes": max(total_size_kb * 0.01, 0.5), "gpu": -1},
            {"step_id": 2, "name": "Embeddingç”Ÿæˆ", "target_files": ["all"],
             "model": "qwen3-embedding:4b", "estimated_minutes": estimated_chunks * 0.02, "gpu": 0},
            {"step_id": 3, "name": "ãƒãƒ£ãƒ³ã‚¯è¦ç´„ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º", "target_files": ["all"],
             "model": "ministral-3:8b", "estimated_minutes": estimated_chunks * 0.15, "gpu": 0},
            {"step_id": 4, "name": "Semantic Node/Edgeç”Ÿæˆ", "target_files": ["all"],
             "model": "command-a:latest", "estimated_minutes": estimated_chunks * 0.5 + 2.0, "gpu": 1},
            {"step_id": 5, "name": "å¤šæ®µè¦ç´„ç”Ÿæˆ", "target_files": ["all"],
             "model": "ministral-3:8b", "estimated_minutes": len(file_previews) * 0.5 + 1.0, "gpu": 0},
        ]

        total_est = sum(s["estimated_minutes"] for s in steps)

        return {
            "plan_id": plan_id,
            "fallback": True,
            "summary": "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ©ãƒ³ã§ã™ã€‚Claudeæ¥ç¶šã«å¤±æ•—ã—ãŸãŸã‚ã€å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¨™æº–è¨­å®šï¼ˆreference/mediumï¼‰ã§å‡¦ç†ã—ã¾ã™ã€‚",
            "analysis": {
                "total_files": len(file_previews),
                "total_size_kb": total_size_kb,
                "file_classifications": classifications,
            },
            "execution_plan": {
                "steps": steps,
                "total_estimated_minutes": total_est,
                "parallel_safe": False,
            },
            "verification_criteria": {
                "min_chunk_coverage": 0.95,
                "min_embedding_count": int(estimated_chunks * 0.9),
                "expected_entity_count_range": [max(estimated_chunks // 3, 5),
                                                 estimated_chunks * 2],
                "sample_query_tests": [],
            },
        }

========================================
FILE: src/rag/rag_verifier.py
========================================
"""
Helix AI Studio - RAG Verifier (v8.5.0 Patch 1)
Step 3: Claude Opus 4.6 ã«ã‚ˆã‚‹RAGå“è³ªæ¤œè¨¼

v8.5.0 Patch 1 ä¿®æ­£:
- P2-1: æ¤œè¨¼çµæœã®è©³ç´°ãƒ­ã‚°å‡ºåŠ›
"""

import json
import logging
import random
import sqlite3
import struct
import subprocess
from typing import Optional, List

from ..utils.constants import RAG_VERIFICATION_SAMPLE_SIZE
from ..utils.subprocess_utils import run_hidden

logger = logging.getLogger(__name__)

VERIFICATION_PROMPT = """ã‚ãªãŸã¯RAGå“è³ªæ¤œè¨¼AIã§ã™ã€‚æ§‹ç¯‰ã•ã‚ŒãŸRAGã®å“è³ªã‚’ä»¥ä¸‹ã®åŸºæº–ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

## æ¤œè¨¼åŸºæº–
1. **å®Œå…¨æ€§** (Coverage): å…ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æƒ…å ±ãŒRAGã«ååˆ†åæ˜ ã•ã‚Œã¦ã„ã‚‹ã‹
2. **é‡è¤‡æ’é™¤** (Dedup): åŒä¸€æƒ…å ±ãŒé‡è¤‡ã—ã¦æ ¼ç´ã•ã‚Œã¦ã„ãªã„ã‹
3. **é®®åº¦** (Freshness): source_hashãŒæœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ä¸€è‡´ã™ã‚‹ã‹
4. **æ§‹é€ å“è³ª** (Structure): Semantic Node/EdgeãŒè«–ç†çš„ã«æ­£ã—ã„ã‹
5. **æ¤œç´¢å“è³ª** (Retrieval): ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã§é©åˆ‡ãªãƒãƒ£ãƒ³ã‚¯ãŒè¿”ã•ã‚Œã‚‹ã‹

## å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
- RAGçµ±è¨ˆ: {rag_stats}
- ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒ³ã‚¯ï¼ˆãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡ºï¼‰: {sample_chunks}
- Semantic Nodeã‚µãƒ³ãƒ—ãƒ«: {sample_nodes}
- å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥ä¸€è‡´çŠ¶æ³: {hash_check}

## å‡ºåŠ›JSONï¼ˆJSONã®ã¿å‡ºåŠ›ã€‚èª¬æ˜æ–‡ä¸è¦ï¼‰
{{
  "overall_verdict": "PASS" or "FAIL",
  "score": 0-100ã®æ•´æ•°,
  "criteria": {{
    "coverage": {{"pass": true/false, "score": 0-100, "note": "..."}},
    "dedup": {{"pass": true/false, "score": 0-100, "note": "..."}},
    "freshness": {{"pass": true/false, "score": 0-100, "note": "..."}},
    "structure": {{"pass": true/false, "score": 0-100, "note": "..."}},
    "retrieval": {{"pass": true/false, "score": 0-100, "note": "..."}}
  }},
  "remediation_steps": [
    {{
      "target_step": ã‚¹ãƒ†ãƒƒãƒ—ID,
      "reason": "ç†ç”±",
      "action": "å†å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³"
    }}
  ],
  "estimated_remediation_minutes": 0
}}"""


class RAGVerifier:
    """Claude Opus 4.6 ã«ã‚ˆã‚‹RAGå“è³ªæ¤œè¨¼"""

    def __init__(self, db_path: str = "data/helix_memory.db",
                 claude_model: str = "claude-opus-4-6"):
        self.db_path = db_path
        self.claude_model = claude_model

    def verify(self, plan: dict, folder_path: str) -> dict:
        """
        RAGå“è³ªæ¤œè¨¼ã‚’å®Ÿè¡Œ

        Returns:
            æ¤œè¨¼çµæœdictï¼ˆoverall_verdict, score, criteria, remediation_stepsï¼‰
        """
        try:
            # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
            rag_stats = self._collect_rag_stats()
            sample_chunks = self._sample_chunks()
            sample_nodes = self._sample_nodes()
            hash_check = self._check_hashes(folder_path)

            # Claudeã«æ¤œè¨¼ä¾é ¼
            prompt = VERIFICATION_PROMPT.format(
                rag_stats=json.dumps(rag_stats, ensure_ascii=False, indent=2),
                sample_chunks=json.dumps(sample_chunks, ensure_ascii=False, indent=2),
                sample_nodes=json.dumps(sample_nodes, ensure_ascii=False, indent=2),
                hash_check=json.dumps(hash_check, ensure_ascii=False, indent=2),
            )

            result = self._call_claude_cli(prompt)
            verification = self._parse_result(result)
            # P2-1: æ¤œè¨¼çµæœã®è©³ç´°ãƒ­ã‚°å‡ºåŠ›
            logger.info(f"RAG verification: {verification.get('overall_verdict', 'UNKNOWN')} "
                        f"(score={verification.get('score', 0)})")
            logger.info(f"Verification result details: "
                        f"{json.dumps(verification, ensure_ascii=False)}")
            return verification

        except Exception as e:
            logger.error(f"RAG verification failed: {e}")
            logger.warning("Using auto-verify fallback due to Claude CLI failure")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªè‡ªå‹•æ¤œè¨¼
            try:
                fallback_result = self._auto_verify(folder_path)
                # P2-1: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œè¨¼çµæœã‚‚ãƒ­ã‚°å‡ºåŠ›
                logger.info(f"Auto-verify result: "
                            f"{json.dumps(fallback_result, ensure_ascii=False)}")
                return fallback_result
            except Exception as e2:
                logger.error(f"Auto-verify also failed: {e2}")
                return {
                    "overall_verdict": "SKIP",
                    "score": 0,
                    "criteria": {},
                    "reason": f"å“è³ªæ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸï¼ˆç†ç”±: {e}ï¼‰",
                    "remediation_steps": [],
                    "estimated_remediation_minutes": 0,
                }

    def _collect_rag_stats(self) -> dict:
        """RAGçµ±è¨ˆã‚’åé›†"""
        conn = self._get_conn()
        try:
            total_chunks = conn.execute("SELECT COUNT(*) as cnt FROM documents").fetchone()["cnt"]
            embedded_chunks = conn.execute(
                "SELECT COUNT(*) as cnt FROM documents WHERE chunk_embedding IS NOT NULL"
            ).fetchone()["cnt"]
            total_files = conn.execute(
                "SELECT COUNT(DISTINCT source_file) as cnt FROM documents"
            ).fetchone()["cnt"]
            total_nodes = conn.execute(
                "SELECT COUNT(*) as cnt FROM semantic_nodes WHERE valid_to IS NULL"
            ).fetchone()["cnt"]
            total_summaries = conn.execute(
                "SELECT COUNT(*) as cnt FROM document_summaries"
            ).fetchone()["cnt"]

            return {
                "total_chunks": total_chunks,
                "embedded_chunks": embedded_chunks,
                "total_files": total_files,
                "semantic_nodes": total_nodes,
                "document_summaries": total_summaries,
                "embedding_coverage": round(embedded_chunks / max(total_chunks, 1), 2),
            }
        finally:
            conn.close()

    def _sample_chunks(self, sample_size: int = RAG_VERIFICATION_SAMPLE_SIZE) -> list:
        """ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        conn = self._get_conn()
        try:
            rows = conn.execute(
                "SELECT source_file, chunk_index, content, category, tags "
                "FROM documents ORDER BY RANDOM() LIMIT ?",
                (sample_size,)
            ).fetchall()
            return [
                {
                    "source_file": r["source_file"],
                    "chunk_index": r["chunk_index"],
                    "content_preview": r["content"][:200],
                    "category": r["category"],
                    "tags": r["tags"],
                }
                for r in rows
            ]
        finally:
            conn.close()

    def _sample_nodes(self, sample_size: int = RAG_VERIFICATION_SAMPLE_SIZE) -> list:
        """Semantic Nodeã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        conn = self._get_conn()
        try:
            rows = conn.execute(
                "SELECT entity, attribute, value, confidence "
                "FROM semantic_nodes WHERE valid_to IS NULL "
                "ORDER BY RANDOM() LIMIT ?",
                (sample_size,)
            ).fetchall()
            return [dict(r) for r in rows]
        finally:
            conn.close()

    def _check_hashes(self, folder_path: str) -> dict:
        """å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥ä¸€è‡´ã‚’ç¢ºèª"""
        import hashlib
        from pathlib import Path

        conn = self._get_conn()
        try:
            stored = conn.execute(
                "SELECT DISTINCT source_file, source_hash FROM documents"
            ).fetchall()
            stored_map = {r["source_file"]: r["source_hash"] for r in stored}
        finally:
            conn.close()

        folder = Path(folder_path)
        results = {"matched": 0, "mismatched": 0, "missing": 0, "details": []}

        for name, stored_hash in stored_map.items():
            file_path = folder / name
            if file_path.exists():
                current_hash = hashlib.sha256(file_path.read_bytes()).hexdigest()
                if current_hash == stored_hash:
                    results["matched"] += 1
                else:
                    results["mismatched"] += 1
                    results["details"].append(f"{name}: hash mismatch")
            else:
                results["missing"] += 1
                results["details"].append(f"{name}: file missing")

        return results

    def _call_claude_cli(self, prompt: str) -> str:
        """Claude CLIã‚’å‘¼ã³å‡ºã™"""
        cmd = [
            "claude", "-p", prompt,
            "--model", self.claude_model,
            "--output-format", "text",
        ]
        try:
            result = run_hidden(
                cmd, capture_output=True, text=True, timeout=300, encoding='utf-8',
            )
            if result.returncode != 0:
                logger.error(f"Verifier Claude CLI error (code {result.returncode}): {result.stderr[:500]}")
                raise RuntimeError(f"Claude CLI failed: {result.stderr[:200]}")

            if not result.stdout.strip():
                logger.error("Verifier Claude CLI returned empty response")
                raise RuntimeError("Claude CLI returned empty response")

            return result.stdout.strip()

        except subprocess.TimeoutExpired:
            logger.error("Verifier Claude CLI timed out after 300 seconds")
            raise RuntimeError("Claude CLI timed out (5åˆ†è¶…é)")
        except FileNotFoundError:
            logger.error("Claude CLI not found for verification")
            raise RuntimeError("Claude CLIãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    def _parse_result(self, raw: str) -> dict:
        """æ¤œè¨¼çµæœã‚’ãƒ‘ãƒ¼ã‚¹"""
        start = raw.find('{')
        end = raw.rfind('}') + 1
        if start >= 0 and end > start:
            return json.loads(raw[start:end])
        raise ValueError("No valid JSON in verification response")

    def _auto_verify(self, folder_path: str) -> dict:
        """Claudeä¸ä½¿ç”¨ã®è‡ªå‹•æ¤œè¨¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        stats = self._collect_rag_stats()
        hash_check = self._check_hashes(folder_path)

        coverage_score = min(int(stats["embedding_coverage"] * 100), 100)
        freshness_score = 100 if hash_check["mismatched"] == 0 else 50
        structure_score = 80 if stats["semantic_nodes"] > 0 else 40

        overall_score = (coverage_score + freshness_score + structure_score) // 3
        verdict = "PASS" if overall_score >= 70 else "FAIL"

        return {
            "overall_verdict": verdict,
            "score": overall_score,
            "criteria": {
                "coverage": {"pass": coverage_score >= 80, "score": coverage_score,
                             "note": f"Embedding coverage: {stats['embedding_coverage']}"},
                "dedup": {"pass": True, "score": 80, "note": "Auto-check skipped"},
                "freshness": {"pass": freshness_score >= 80, "score": freshness_score,
                              "note": f"Hash mismatches: {hash_check['mismatched']}"},
                "structure": {"pass": structure_score >= 60, "score": structure_score,
                              "note": f"Semantic nodes: {stats['semantic_nodes']}"},
                "retrieval": {"pass": True, "score": 75, "note": "Auto-check skipped"},
            },
            "remediation_steps": [],
            "estimated_remediation_minutes": 0,
        }

    def _get_conn(self) -> sqlite3.Connection:
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

========================================
FILE: src/tabs/information_collection_tab.py
========================================
"""
Helix AI Studio - Information Collection Tab (v8.5.0)
æƒ…å ±åé›†ã‚¿ãƒ–: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆRAGè‡ªå¾‹æ§‹ç¯‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³UI
"""

import json
import logging
import os
import platform
import subprocess
import shutil
from datetime import datetime
from pathlib import Path

from PyQt6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton,
    QGroupBox, QSpinBox, QScrollArea, QFrame, QFileDialog,
    QMessageBox, QSplitter, QTreeWidget, QTreeWidgetItem,
    QProgressBar, QTextEdit, QApplication,
)
from PyQt6.QtCore import Qt, pyqtSignal, QTimer
from PyQt6.QtGui import QFont

from ..utils.constants import (
    INFORMATION_FOLDER, SUPPORTED_DOC_EXTENSIONS,
    DEFAULT_CHUNK_SIZE, DEFAULT_CHUNK_OVERLAP, MAX_FILE_SIZE_MB,
    RAG_DEFAULT_TIME_LIMIT, RAG_MIN_TIME_LIMIT, RAG_MAX_TIME_LIMIT,
    RAG_TIME_STEP, RAG_CHUNK_STEP, RAG_OVERLAP_STEP,
)
from ..utils.styles import (
    COLORS, SECTION_CARD_STYLE, PRIMARY_BTN, SECONDARY_BTN,
    DANGER_BTN, PROGRESS_BAR_STYLE, SPINBOX_STYLE, COMBO_BOX_STYLE,
)
from ..rag.rag_builder import RAGBuilder, RAGBuildLock
from ..rag.diff_detector import DiffDetector
from ..rag.document_cleanup import DocumentCleanupManager
from ..widgets.rag_progress_widget import RAGProgressWidget

logger = logging.getLogger(__name__)


class InformationCollectionTab(QWidget):
    """æƒ…å ±åé›†ã‚¿ãƒ–"""

    statusChanged = pyqtSignal(str)

    def __init__(self, workflow_state=None, main_window=None, parent=None):
        super().__init__(parent)
        self.workflow_state = workflow_state
        self.main_window = main_window
        self.rag_lock = RAGBuildLock()
        self._builder: RAGBuilder = None
        self._current_plan: dict = None
        self._folder_path = self._resolve_folder_path()
        self.cleanup_manager = DocumentCleanupManager(
            information_folder=self._folder_path
        )

        self._init_ui()
        self._load_rag_settings()
        self._connect_signals()
        self._refresh_file_list()
        self._refresh_rag_stats()

    def _resolve_folder_path(self) -> str:
        """æƒ…å ±åé›†ãƒ•ã‚©ãƒ«ãƒ€ã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’è§£æ±º"""
        # app_settings.jsonã‹ã‚‰èª­ã¿è¾¼ã‚€
        try:
            settings_path = Path("config/app_settings.json")
            if settings_path.exists():
                with open(settings_path, 'r', encoding='utf-8') as f:
                    settings = json.load(f)
                folder = settings.get("information_collection", {}).get("folder_path", INFORMATION_FOLDER)
            else:
                folder = INFORMATION_FOLDER
        except Exception:
            folder = INFORMATION_FOLDER

        # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
        Path(folder).mkdir(parents=True, exist_ok=True)
        return folder

    def _init_ui(self):
        """UIã‚’åˆæœŸåŒ–"""
        main_layout = QVBoxLayout(self)
        main_layout.setContentsMargins(12, 8, 12, 8)
        main_layout.setSpacing(8)

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¨ãƒªã‚¢
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOff)
        scroll.setStyleSheet(f"""
            QScrollArea {{
                border: none;
                background-color: {COLORS['bg_dark']};
            }}
        """)

        content = QWidget()
        content_layout = QVBoxLayout(content)
        content_layout.setContentsMargins(0, 0, 0, 0)
        content_layout.setSpacing(10)

        # 1. æƒ…å ±åé›†ãƒ•ã‚©ãƒ«ãƒ€ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        content_layout.addWidget(self._create_folder_section())

        # 2. RAGæ§‹ç¯‰è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
        content_layout.addWidget(self._create_settings_section())

        # 3. ãƒ—ãƒ©ãƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        content_layout.addWidget(self._create_plan_section())

        # 4. å®Ÿè¡Œåˆ¶å¾¡ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        content_layout.addWidget(self._create_execution_section())

        # 5. RAGçµ±è¨ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
        content_layout.addWidget(self._create_stats_section())

        # 6. ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        content_layout.addWidget(self._create_data_management_section())

        content_layout.addStretch()
        scroll.setWidget(content)
        main_layout.addWidget(scroll)

    # =========================================================================
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
    # =========================================================================

    def _create_folder_section(self) -> QGroupBox:
        """æƒ…å ±åé›†ãƒ•ã‚©ãƒ«ãƒ€ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
        group = QGroupBox("æƒ…å ±åé›†ãƒ•ã‚©ãƒ«ãƒ€")
        group.setStyleSheet(SECTION_CARD_STYLE)
        layout = QVBoxLayout(group)

        # ãƒ‘ã‚¹è¡¨ç¤º + ãƒœã‚¿ãƒ³
        path_row = QHBoxLayout()
        self.folder_path_label = QLabel(f"ãƒ‘ã‚¹: {self._folder_path}")
        self.folder_path_label.setStyleSheet(f"color: {COLORS['text_secondary']}; font-size: 12px;")
        path_row.addWidget(self.folder_path_label)
        path_row.addStretch()

        open_btn = QPushButton("ãƒ•ã‚©ãƒ«ãƒ€ã‚’é–‹ã")
        open_btn.setStyleSheet(SECONDARY_BTN)
        open_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        open_btn.clicked.connect(self._open_folder)
        path_row.addWidget(open_btn)
        layout.addLayout(path_row)

        # é¸æŠãƒœã‚¿ãƒ³è¡Œ
        select_row = QHBoxLayout()
        select_all_btn = QPushButton("å…¨é¸æŠ")
        select_all_btn.setStyleSheet(SECONDARY_BTN)
        select_all_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        select_all_btn.setToolTip("å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ")
        select_all_btn.clicked.connect(self._select_all_files)
        select_row.addWidget(select_all_btn)

        select_none_btn = QPushButton("å…¨è§£é™¤")
        select_none_btn.setStyleSheet(SECONDARY_BTN)
        select_none_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        select_none_btn.setToolTip("å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é¸æŠã‚’è§£é™¤")
        select_none_btn.clicked.connect(self._deselect_all_files)
        select_row.addWidget(select_none_btn)

        select_changed_btn = QPushButton("å·®åˆ†ã®ã¿é¸æŠ")
        select_changed_btn.setStyleSheet(SECONDARY_BTN)
        select_changed_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        select_changed_btn.setToolTip("æ–°è¦ãƒ»å¤‰æ›´ã‚ã‚Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿é¸æŠã—ã¾ã™")
        select_changed_btn.clicked.connect(self._select_changed_only)
        select_row.addWidget(select_changed_btn)

        select_row.addStretch()
        layout.addLayout(select_row)

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
        self.file_tree = QTreeWidget()
        self.file_tree.setHeaderLabels(["ãƒ•ã‚¡ã‚¤ãƒ«å", "ã‚µã‚¤ã‚º", "æ›´æ–°æ—¥", "RAGçŠ¶æ…‹"])
        self.file_tree.setColumnCount(4)
        self.file_tree.setColumnWidth(0, 300)
        self.file_tree.setColumnWidth(1, 80)
        self.file_tree.setColumnWidth(2, 130)
        self.file_tree.setColumnWidth(3, 100)
        self.file_tree.setMinimumHeight(120)
        self.file_tree.setMaximumHeight(200)
        self.file_tree.setStyleSheet(f"""
            QTreeWidget {{
                background-color: {COLORS['bg_card']};
                border: 1px solid {COLORS['border']};
                border-radius: 6px;
                color: {COLORS['text_primary']};
                font-size: 12px;
            }}
            QTreeWidget::item {{ padding: 4px; }}
            QTreeWidget::item:selected {{
                background-color: {COLORS['accent_cyan']};
                color: {COLORS['bg_dark']};
            }}
            QHeaderView::section {{
                background-color: {COLORS['bg_card']};
                color: {COLORS['accent_cyan']};
                padding: 6px;
                border: 1px solid {COLORS['border']};
                font-weight: bold;
                font-size: 11px;
            }}
        """)
        layout.addWidget(self.file_tree)

        # åˆè¨ˆ + ãƒœã‚¿ãƒ³è¡Œ
        bottom_row = QHBoxLayout()
        self.total_label = QLabel("åˆè¨ˆ: 0ãƒ•ã‚¡ã‚¤ãƒ« (0 KB)")
        self.total_label.setStyleSheet(f"color: {COLORS['text_secondary']}; font-size: 11px;")
        bottom_row.addWidget(self.total_label)
        bottom_row.addStretch()

        refresh_btn = QPushButton("æ›´æ–°")
        refresh_btn.setStyleSheet(SECONDARY_BTN)
        refresh_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        refresh_btn.clicked.connect(self._refresh_file_list)
        bottom_row.addWidget(refresh_btn)

        add_btn = QPushButton("ãƒ•ã‚¡ã‚¤ãƒ«è¿½åŠ ")
        add_btn.setStyleSheet(SECONDARY_BTN)
        add_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        add_btn.clicked.connect(self._add_files)
        bottom_row.addWidget(add_btn)

        layout.addLayout(bottom_row)
        return group

    def _create_settings_section(self) -> QGroupBox:
        """RAGæ§‹ç¯‰è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
        group = QGroupBox("RAGæ§‹ç¯‰è¨­å®š")
        group.setStyleSheet(SECTION_CARD_STYLE)
        layout = QVBoxLayout(group)

        # æƒ³å®šå®Ÿè¡Œæ™‚é–“
        time_row = QHBoxLayout()
        time_label = QLabel("æƒ³å®šå®Ÿè¡Œæ™‚é–“:")
        time_label.setStyleSheet(f"color: {COLORS['text_primary']}; font-size: 12px;")
        time_row.addWidget(time_label)

        self.time_spin = QSpinBox()
        self.time_spin.setRange(RAG_MIN_TIME_LIMIT, RAG_MAX_TIME_LIMIT)
        self.time_spin.setSingleStep(RAG_TIME_STEP)
        self.time_spin.setValue(RAG_DEFAULT_TIME_LIMIT)
        self.time_spin.setSuffix(" åˆ†")
        self.time_spin.setToolTip("RAGæ§‹ç¯‰ã®æƒ³å®šå®Ÿè¡Œæ™‚é–“ï¼ˆ10åˆ†åˆ»ã¿ã€æœ€å¤§24æ™‚é–“ï¼‰")
        self.time_spin.setStyleSheet(SPINBOX_STYLE)
        time_row.addWidget(self.time_spin)
        time_row.addStretch()
        layout.addLayout(time_row)

        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        models_frame = QFrame()
        models_frame.setStyleSheet(f"""
            QFrame {{
                background-color: {COLORS['bg_card']};
                border: 1px solid {COLORS['border']};
                border-radius: 6px;
                padding: 8px;
            }}
        """)
        models_layout = QVBoxLayout(models_frame)
        models_layout.setSpacing(4)

        model_info = [
            ("Claudeãƒ¢ãƒ‡ãƒ«:", "Claude Opus 4.6 (æœ€é«˜çŸ¥èƒ½)"),
            ("å®Ÿè¡ŒLLM:", "command-a:latest (research)"),
            ("å“è³ªåˆ¤å®š:", "ministral-3:8b (å¸¸é§)"),
            ("Embedding:", "qwen3-embedding:4b (å¸¸é§)"),
        ]
        for label_text, value_text in model_info:
            row = QHBoxLayout()
            lbl = QLabel(label_text)
            lbl.setStyleSheet(f"color: {COLORS['text_secondary']}; font-size: 11px;")
            lbl.setFixedWidth(100)
            val = QLabel(value_text)
            val.setStyleSheet(f"color: {COLORS['text_primary']}; font-size: 11px;")
            row.addWidget(lbl)
            row.addWidget(val)
            row.addStretch()
            models_layout.addLayout(row)

        layout.addWidget(models_frame)

        # ãƒãƒ£ãƒ³ã‚¯è¨­å®š
        chunk_row = QHBoxLayout()
        chunk_label = QLabel("ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º:")
        chunk_label.setStyleSheet(f"color: {COLORS['text_primary']}; font-size: 12px;")
        chunk_row.addWidget(chunk_label)

        self.chunk_size_spin = QSpinBox()
        self.chunk_size_spin.setRange(128, 2048)
        self.chunk_size_spin.setSingleStep(RAG_CHUNK_STEP)
        self.chunk_size_spin.setValue(DEFAULT_CHUNK_SIZE)
        self.chunk_size_spin.setSuffix(" ãƒˆãƒ¼ã‚¯ãƒ³")
        self.chunk_size_spin.setToolTip("ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚µã‚¤ã‚ºï¼ˆ64åˆ»ã¿ï¼‰")
        self.chunk_size_spin.setStyleSheet(SPINBOX_STYLE)
        chunk_row.addWidget(self.chunk_size_spin)

        overlap_label = QLabel("ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—:")
        overlap_label.setStyleSheet(f"color: {COLORS['text_primary']}; font-size: 12px;")
        chunk_row.addWidget(overlap_label)

        self.overlap_spin = QSpinBox()
        self.overlap_spin.setRange(0, 256)
        self.overlap_spin.setSingleStep(RAG_OVERLAP_STEP)
        self.overlap_spin.setValue(DEFAULT_CHUNK_OVERLAP)
        self.overlap_spin.setSuffix(" ãƒˆãƒ¼ã‚¯ãƒ³")
        self.overlap_spin.setToolTip("ãƒãƒ£ãƒ³ã‚¯é–“ã®é‡è¤‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆ8åˆ»ã¿ï¼‰")
        self.overlap_spin.setStyleSheet(SPINBOX_STYLE)
        chunk_row.addWidget(self.overlap_spin)
        chunk_row.addStretch()
        layout.addLayout(chunk_row)

        # è¨­å®šä¿å­˜ãƒœã‚¿ãƒ³
        save_row = QHBoxLayout()
        save_row.addStretch()
        self.save_settings_btn = QPushButton("è¨­å®šã‚’ä¿å­˜")
        self.save_settings_btn.setStyleSheet(SECONDARY_BTN)
        self.save_settings_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.save_settings_btn.setToolTip("RAGæ§‹ç¯‰è¨­å®šã‚’config/app_settings.jsonã«ä¿å­˜ã—ã¾ã™")
        self.save_settings_btn.clicked.connect(self._save_rag_settings)
        save_row.addWidget(self.save_settings_btn)
        layout.addLayout(save_row)

        return group

    def _create_plan_section(self) -> QGroupBox:
        """ç¾åœ¨ã®ãƒ—ãƒ©ãƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
        group = QGroupBox("ç¾åœ¨ã®ãƒ—ãƒ©ãƒ³")
        group.setStyleSheet(SECTION_CARD_STYLE)
        layout = QVBoxLayout(group)

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        status_row = QHBoxLayout()
        self.plan_status_label = QLabel("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: æœªä½œæˆ")
        self.plan_status_label.setStyleSheet(f"color: {COLORS['text_secondary']}; font-size: 12px;")
        status_row.addWidget(self.plan_status_label)
        status_row.addStretch()
        layout.addLayout(status_row)

        # ãƒ—ãƒ©ãƒ³æ¦‚è¦ï¼ˆQTextEdit èª­ã¿å–ã‚Šå°‚ç”¨ãƒ»ã‚³ãƒ”ãƒ¼å¯èƒ½ï¼‰
        summary_label = QLabel("ãƒ—ãƒ©ãƒ³æ¦‚è¦:")
        summary_label.setStyleSheet(f"color: {COLORS['accent_cyan']}; font-size: 11px; font-weight: bold;")
        layout.addWidget(summary_label)

        summary_row = QHBoxLayout()
        self.plan_summary_text = QTextEdit()
        self.plan_summary_text.setReadOnly(True)
        self.plan_summary_text.setMaximumHeight(120)
        self.plan_summary_text.setPlaceholderText("ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã™ã‚‹ã¨ã€ã“ã“ã«æ¦‚è¦ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
        self.plan_summary_text.setStyleSheet(f"""
            QTextEdit {{
                background-color: {COLORS['bg_card']};
                border: 1px solid {COLORS['border']};
                border-radius: 6px;
                color: {COLORS['text_primary']};
                font-size: 11px;
                padding: 8px;
            }}
        """)
        summary_row.addWidget(self.plan_summary_text)

        self.copy_plan_btn = QPushButton("ã‚³ãƒ”ãƒ¼")
        self.copy_plan_btn.setStyleSheet(SECONDARY_BTN)
        self.copy_plan_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.copy_plan_btn.setToolTip("ãƒ—ãƒ©ãƒ³æ¦‚è¦ã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼")
        self.copy_plan_btn.setFixedWidth(80)
        self.copy_plan_btn.clicked.connect(self._copy_plan_summary)
        self.copy_plan_btn.setEnabled(False)
        summary_row.addWidget(self.copy_plan_btn, alignment=Qt.AlignmentFlag.AlignTop)
        layout.addLayout(summary_row)

        # ãƒ—ãƒ©ãƒ³è©³ç´°
        self.plan_detail_label = QLabel("")
        self.plan_detail_label.setWordWrap(True)
        self.plan_detail_label.setStyleSheet(f"color: {COLORS['text_primary']}; font-size: 11px;")
        layout.addWidget(self.plan_detail_label)

        # ãƒ—ãƒ©ãƒ³ä½œæˆãƒœã‚¿ãƒ³
        self.create_plan_btn = QPushButton("Claudeã«ãƒ—ãƒ©ãƒ³ä½œæˆã‚’ä¾é ¼")
        self.create_plan_btn.setStyleSheet(PRIMARY_BTN)
        self.create_plan_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.create_plan_btn.clicked.connect(self._create_plan)
        layout.addWidget(self.create_plan_btn)

        return group

    def _create_execution_section(self) -> QGroupBox:
        """å®Ÿè¡Œåˆ¶å¾¡ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
        group = QGroupBox("å®Ÿè¡Œåˆ¶å¾¡")
        group.setStyleSheet(SECTION_CARD_STYLE)
        layout = QVBoxLayout(group)

        # ãƒœã‚¿ãƒ³è¡Œ
        btn_row = QHBoxLayout()

        self.start_btn = QPushButton("RAGæ§‹ç¯‰é–‹å§‹")
        self.start_btn.setStyleSheet(PRIMARY_BTN)
        self.start_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.start_btn.clicked.connect(self._start_build)
        self.start_btn.setEnabled(False)
        btn_row.addWidget(self.start_btn)

        self.stop_btn = QPushButton("ä¸­æ­¢")
        self.stop_btn.setStyleSheet(DANGER_BTN)
        self.stop_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.stop_btn.clicked.connect(self._stop_build)
        self.stop_btn.setEnabled(False)
        btn_row.addWidget(self.stop_btn)

        self.rebuild_btn = QPushButton("å†å®Ÿè¡Œ")
        self.rebuild_btn.setStyleSheet(SECONDARY_BTN)
        self.rebuild_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.rebuild_btn.clicked.connect(self._rebuild)
        self.rebuild_btn.setEnabled(False)
        btn_row.addWidget(self.rebuild_btn)

        btn_row.addStretch()
        layout.addLayout(btn_row)

        # é€²æ—ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
        self.progress_widget = RAGProgressWidget()
        layout.addWidget(self.progress_widget)

        return group

    def _create_stats_section(self) -> QGroupBox:
        """RAGçµ±è¨ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
        group = QGroupBox("RAGçµ±è¨ˆ")
        group.setStyleSheet(SECTION_CARD_STYLE)
        layout = QHBoxLayout(group)

        self.stats_labels = {}
        stats = [
            ("total_chunks", "ç·ãƒãƒ£ãƒ³ã‚¯æ•°", "0"),
            ("total_embeddings", "ç·Embedding", "0"),
            ("semantic_nodes", "Semantic Nodes", "0"),
            ("last_build", "æœ€çµ‚æ§‹ç¯‰", "ãªã—"),
            ("build_count", "æ§‹ç¯‰å›æ•°", "0å›"),
        ]

        for key, label_text, default in stats:
            frame = QFrame()
            frame.setStyleSheet(f"""
                QFrame {{
                    background-color: {COLORS['bg_card']};
                    border: 1px solid {COLORS['border']};
                    border-radius: 6px;
                    padding: 8px;
                }}
            """)
            f_layout = QVBoxLayout(frame)
            f_layout.setSpacing(2)

            val_label = QLabel(default)
            val_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
            val_label.setStyleSheet(f"color: {COLORS['accent_cyan']}; font-size: 16px; font-weight: bold;")
            f_layout.addWidget(val_label)

            name_label = QLabel(label_text)
            name_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
            name_label.setStyleSheet(f"color: {COLORS['text_secondary']}; font-size: 10px;")
            f_layout.addWidget(name_label)

            self.stats_labels[key] = val_label
            layout.addWidget(frame)

        return group

    def _create_data_management_section(self) -> QGroupBox:
        """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
        group = QGroupBox("ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
        group.setStyleSheet(SECTION_CARD_STYLE)
        layout = QVBoxLayout(group)

        # å­¤å…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        self.orphan_status_label = QLabel("ãƒ‡ãƒ¼ã‚¿å¥å…¨æ€§ã‚’ç¢ºèªä¸­...")
        self.orphan_status_label.setStyleSheet(f"color: {COLORS['text_secondary']}; font-size: 12px;")
        layout.addWidget(self.orphan_status_label)

        # å­¤å…ãƒªã‚¹ãƒˆ
        self.orphan_tree = QTreeWidget()
        self.orphan_tree.setHeaderLabels(["ãƒ•ã‚¡ã‚¤ãƒ«å", "ãƒãƒ£ãƒ³ã‚¯æ•°", "å®‰å…¨ãƒ¬ãƒ™ãƒ«"])
        self.orphan_tree.setColumnCount(3)
        self.orphan_tree.setColumnWidth(0, 280)
        self.orphan_tree.setColumnWidth(1, 80)
        self.orphan_tree.setColumnWidth(2, 200)
        self.orphan_tree.setMaximumHeight(120)
        self.orphan_tree.setStyleSheet(f"""
            QTreeWidget {{
                background-color: {COLORS['bg_card']};
                border: 1px solid {COLORS['border']};
                border-radius: 6px;
                color: {COLORS['text_primary']};
                font-size: 11px;
            }}
            QTreeWidget::item {{ padding: 3px; }}
            QHeaderView::section {{
                background-color: {COLORS['bg_card']};
                color: {COLORS['accent_cyan']};
                padding: 4px;
                border: 1px solid {COLORS['border']};
                font-size: 10px;
            }}
        """)
        self.orphan_tree.setVisible(False)
        layout.addWidget(self.orphan_tree)

        # å­¤å…æ“ä½œãƒœã‚¿ãƒ³
        orphan_btn_row = QHBoxLayout()
        self.scan_orphan_btn = QPushButton("å­¤å…ã‚¹ã‚­ãƒ£ãƒ³")
        self.scan_orphan_btn.setStyleSheet(SECONDARY_BTN)
        self.scan_orphan_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.scan_orphan_btn.setToolTip("å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å­¤å…ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºã—ã¾ã™")
        self.scan_orphan_btn.clicked.connect(self._scan_orphans)
        orphan_btn_row.addWidget(self.scan_orphan_btn)

        self.delete_orphan_btn = QPushButton("é¸æŠã—ãŸå­¤å…ã‚’å‰Šé™¤")
        self.delete_orphan_btn.setStyleSheet(DANGER_BTN)
        self.delete_orphan_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.delete_orphan_btn.setToolTip("ãƒã‚§ãƒƒã‚¯ã—ãŸå­¤å…ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã™")
        self.delete_orphan_btn.clicked.connect(self._delete_selected_orphans)
        self.delete_orphan_btn.setEnabled(False)
        orphan_btn_row.addWidget(self.delete_orphan_btn)

        orphan_btn_row.addStretch()
        layout.addLayout(orphan_btn_row)

        # åŒºåˆ‡ã‚Š
        sep = QFrame()
        sep.setFrameShape(QFrame.Shape.HLine)
        sep.setStyleSheet(f"color: {COLORS['border']};")
        layout.addWidget(sep)

        # æ‰‹å‹•å‰Šé™¤ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        manual_label = QLabel("æ§‹ç¯‰æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ä¸è¦ãªã‚‚ã®ã‚’é¸æŠã—ã¦å‰Šé™¤:")
        manual_label.setStyleSheet(f"color: {COLORS['text_secondary']}; font-size: 11px;")
        layout.addWidget(manual_label)

        self.doc_tree = QTreeWidget()
        self.doc_tree.setHeaderLabels(["ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå", "ãƒãƒ£ãƒ³ã‚¯æ•°"])
        self.doc_tree.setColumnCount(2)
        self.doc_tree.setColumnWidth(0, 350)
        self.doc_tree.setColumnWidth(1, 80)
        self.doc_tree.setMaximumHeight(120)
        self.doc_tree.setStyleSheet(f"""
            QTreeWidget {{
                background-color: {COLORS['bg_card']};
                border: 1px solid {COLORS['border']};
                border-radius: 6px;
                color: {COLORS['text_primary']};
                font-size: 11px;
            }}
            QTreeWidget::item {{ padding: 3px; }}
            QHeaderView::section {{
                background-color: {COLORS['bg_card']};
                color: {COLORS['accent_cyan']};
                padding: 4px;
                border: 1px solid {COLORS['border']};
                font-size: 10px;
            }}
        """)
        layout.addWidget(self.doc_tree)

        delete_doc_btn_row = QHBoxLayout()
        delete_doc_btn_row.addStretch()
        self.delete_doc_btn = QPushButton("é¸æŠã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤")
        self.delete_doc_btn.setStyleSheet(DANGER_BTN)
        self.delete_doc_btn.setCursor(Qt.CursorShape.PointingHandCursor)
        self.delete_doc_btn.setToolTip("é¸æŠã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®RAGãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«è‡ªä½“ã¯æ®‹ã‚Šã¾ã™ï¼‰")
        self.delete_doc_btn.clicked.connect(self._delete_selected_documents)
        delete_doc_btn_row.addWidget(self.delete_doc_btn)
        layout.addLayout(delete_doc_btn_row)

        # åˆæœŸã‚¹ã‚­ãƒ£ãƒ³
        QTimer.singleShot(500, self._scan_orphans)
        QTimer.singleShot(600, self._refresh_doc_list)

        return group

    # =========================================================================
    # ã‚·ã‚°ãƒŠãƒ«æ¥ç¶š
    # =========================================================================

    def _connect_signals(self):
        """å†…éƒ¨ã‚·ã‚°ãƒŠãƒ«ã‚’æ¥ç¶š"""
        pass  # ãƒ“ãƒ«ãƒ€ãƒ¼ã‚·ã‚°ãƒŠãƒ«ã¯_start_build()å†…ã§æ¥ç¶š

    # =========================================================================
    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    # =========================================================================

    def _open_folder(self):
        """OSã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼ã§ãƒ•ã‚©ãƒ«ãƒ€ã‚’é–‹ã"""
        folder = Path(self._folder_path)
        folder.mkdir(parents=True, exist_ok=True)

        abs_path = str(folder.resolve())
        try:
            if platform.system() == "Windows":
                os.startfile(abs_path)
            elif platform.system() == "Darwin":
                subprocess.run(["open", abs_path])
            else:
                subprocess.run(["xdg-open", abs_path])
        except Exception as e:
            logger.error(f"Failed to open folder: {e}")

    def _add_files(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«è¿½åŠ ãƒ€ã‚¤ã‚¢ãƒ­ã‚°"""
        extensions = " ".join(f"*{ext}" for ext in SUPPORTED_DOC_EXTENSIONS)
        files, _ = QFileDialog.getOpenFileNames(
            self, "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ",
            "", f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ ({extensions});;å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ« (*)"
        )
        if files:
            folder = Path(self._folder_path)
            folder.mkdir(parents=True, exist_ok=True)
            added = 0
            for src in files:
                src_path = Path(src)
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                size_mb = src_path.stat().st_size / (1024 * 1024)
                if size_mb > MAX_FILE_SIZE_MB:
                    QMessageBox.warning(
                        self, "ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¶…é",
                        f"{src_path.name} ({size_mb:.1f}MB) ã¯æœ€å¤§ã‚µã‚¤ã‚º "
                        f"({MAX_FILE_SIZE_MB}MB) ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
                    )
                    continue
                dest = folder / src_path.name
                try:
                    shutil.copy2(str(src_path), str(dest))
                    added += 1
                except Exception as e:
                    logger.error(f"Failed to copy {src_path.name}: {e}")

            if added > 0:
                self._refresh_file_list()
                self.statusChanged.emit(f"{added}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã—ã¾ã—ãŸ")

    def _refresh_file_list(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’æ›´æ–°ã—ã€RAGçŠ¶æ…‹ã‚’è¡¨ç¤º"""
        self.file_tree.clear()
        folder = Path(self._folder_path)
        folder.mkdir(parents=True, exist_ok=True)

        # DiffDetectorã§å·®åˆ†æ¤œå‡º
        diff_detector = DiffDetector(db_conn_factory=self._get_db_conn)
        diff_result = diff_detector.detect_changes(self._folder_path)

        total_size = 0
        file_count = 0

        # æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«
        for fi in diff_result.new_files:
            self._add_file_tree_item(fi.name, fi.size, fi.modified, "new", checked=True)
            total_size += fi.size
            file_count += 1

        # å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«
        for fi in diff_result.modified_files:
            self._add_file_tree_item(fi.name, fi.size, fi.modified, "modified", checked=True)
            total_size += fi.size
            file_count += 1

        # æœªå¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«
        for fi in diff_result.unchanged_files:
            self._add_file_tree_item(fi.name, fi.size, fi.modified, "unchanged", checked=False)
            total_size += fi.size
            file_count += 1

        # å‰Šé™¤æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆDBã«ã‚ã‚‹ãŒãƒ•ã‚©ãƒ«ãƒ€ã«ãªã„ï¼‰
        for name in diff_result.deleted_files:
            item = QTreeWidgetItem([name, "-", "-", "å‰Šé™¤æ¸ˆã¿"])
            item.setFlags(item.flags() | Qt.ItemFlag.ItemIsUserCheckable)
            item.setCheckState(0, Qt.CheckState.Unchecked)
            item.setForeground(3, QFont().defaultFamily() and item.foreground(0))
            self.file_tree.addTopLevelItem(item)

        total_str = self._format_size(total_size)
        diff_summary = diff_result.summary
        self.total_label.setText(f"åˆè¨ˆ: {file_count}ãƒ•ã‚¡ã‚¤ãƒ« ({total_str})  [{diff_summary}]")

    def _add_file_tree_item(self, name: str, size: int, mtime: float,
                            status: str, checked: bool):
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã«1è¡Œè¿½åŠ """
        size_str = self._format_size(size)
        date_str = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M")

        status_labels = {
            "new": "â˜…æ–°è¦",
            "modified": "å¤‰æ›´ã‚ã‚Š",
            "unchanged": "æ§‹ç¯‰æ¸ˆã¿",
        }
        status_label = status_labels.get(status, status)

        item = QTreeWidgetItem([name, size_str, date_str, status_label])
        item.setFlags(item.flags() | Qt.ItemFlag.ItemIsUserCheckable)
        item.setCheckState(0, Qt.CheckState.Checked if checked else Qt.CheckState.Unchecked)

        # RAGçŠ¶æ…‹ã«å¿œã˜ãŸè‰²åˆ†ã‘
        if status == "new":
            item.setForeground(3, item.foreground(0))  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè‰²
        elif status == "modified":
            item.setForeground(3, item.foreground(0))

        # ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ä¿æŒ
        item.setData(0, Qt.ItemDataRole.UserRole, status)

        self.file_tree.addTopLevelItem(item)

    def _get_db_conn(self):
        """helix_memory.db ã¸ã®æ¥ç¶šã‚’è¿”ã™"""
        import sqlite3
        db_path = Path("data/helix_memory.db")
        if not db_path.exists():
            return sqlite3.connect(str(db_path))
        conn = sqlite3.connect(str(db_path))
        conn.row_factory = sqlite3.Row
        return conn

    def _get_selected_files(self) -> list:
        """ãƒã‚§ãƒƒã‚¯æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
        selected = []
        for i in range(self.file_tree.topLevelItemCount()):
            item = self.file_tree.topLevelItem(i)
            if item.checkState(0) == Qt.CheckState.Checked:
                selected.append(item.text(0))
        return selected

    def _select_all_files(self):
        """å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ"""
        for i in range(self.file_tree.topLevelItemCount()):
            self.file_tree.topLevelItem(i).setCheckState(0, Qt.CheckState.Checked)

    def _deselect_all_files(self):
        """å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é¸æŠã‚’è§£é™¤"""
        for i in range(self.file_tree.topLevelItemCount()):
            self.file_tree.topLevelItem(i).setCheckState(0, Qt.CheckState.Unchecked)

    def _select_changed_only(self):
        """æ–°è¦ãƒ»å¤‰æ›´ã‚ã‚Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿é¸æŠ"""
        for i in range(self.file_tree.topLevelItemCount()):
            item = self.file_tree.topLevelItem(i)
            status = item.data(0, Qt.ItemDataRole.UserRole)
            if status in ("new", "modified"):
                item.setCheckState(0, Qt.CheckState.Checked)
            else:
                item.setCheckState(0, Qt.CheckState.Unchecked)

    def _refresh_rag_stats(self):
        """RAGçµ±è¨ˆã‚’æ›´æ–°"""
        try:
            builder = RAGBuilder(folder_path=self._folder_path)
            stats = builder.get_rag_stats()

            self.stats_labels["total_chunks"].setText(str(stats.get("total_chunks", 0)))
            self.stats_labels["total_embeddings"].setText(str(stats.get("total_embeddings", 0)))
            self.stats_labels["semantic_nodes"].setText(str(stats.get("semantic_nodes", 0)))
            self.stats_labels["build_count"].setText(f"{stats.get('build_count', 0)}å›")

            last_build = stats.get("last_build")
            if last_build:
                try:
                    dt = datetime.fromisoformat(last_build)
                    self.stats_labels["last_build"].setText(dt.strftime("%m/%d %H:%M"))
                except Exception:
                    self.stats_labels["last_build"].setText("ã‚ã‚Š")
            else:
                self.stats_labels["last_build"].setText("ãªã—")
        except Exception as e:
            logger.debug(f"RAG stats refresh error: {e}")

    def _create_plan(self):
        """Claudeã«ãƒ—ãƒ©ãƒ³ä½œæˆã‚’ä¾é ¼"""
        selected = self._get_selected_files()
        if not selected:
            QMessageBox.information(
                self, "ãƒ•ã‚¡ã‚¤ãƒ«æœªé¸æŠ",
                "ãƒ—ãƒ©ãƒ³ä½œæˆå¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
                "ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
            )
            return

        self.create_plan_btn.setEnabled(False)
        self.create_plan_btn.setText("ãƒ—ãƒ©ãƒ³ä½œæˆä¸­...")
        self.plan_status_label.setText("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: ãƒ—ãƒ©ãƒ³ä½œæˆä¸­...")
        self.statusChanged.emit("Claude ã«ãƒ—ãƒ©ãƒ³ä½œæˆã‚’ä¾é ¼ä¸­...")

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œï¼ˆUIã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ãŸã‚QTimerã§é…å»¶ï¼‰
        QTimer.singleShot(100, self._do_create_plan)

    def _do_create_plan(self):
        """ãƒ—ãƒ©ãƒ³ä½œæˆã®å®Ÿè¡Œ"""
        try:
            from ..rag.rag_planner import RAGPlanner
            planner = RAGPlanner()
            selected = self._get_selected_files()
            plan = planner.create_plan(
                self._folder_path,
                self.time_spin.value(),
                selected_files=selected if selected else None,
            )
            self._current_plan = plan
            self._display_plan(plan)
            self.start_btn.setEnabled(True)
            if plan.get("fallback"):
                self.statusChanged.emit("âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ©ãƒ³ã§ä»£æ›¿ï¼ˆClaudeæ¥ç¶šå¤±æ•—ï¼‰")
            else:
                self.statusChanged.emit("ãƒ—ãƒ©ãƒ³ä½œæˆå®Œäº†")
        except Exception as e:
            logger.error(f"Plan creation failed: {e}")
            QMessageBox.warning(self, "ãƒ—ãƒ©ãƒ³ä½œæˆå¤±æ•—", f"ã‚¨ãƒ©ãƒ¼: {str(e)[:300]}")
            self.plan_status_label.setText("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: ãƒ—ãƒ©ãƒ³ä½œæˆå¤±æ•—")
            self.statusChanged.emit("ãƒ—ãƒ©ãƒ³ä½œæˆå¤±æ•—")
        finally:
            self.create_plan_btn.setEnabled(True)
            self.create_plan_btn.setText("Claudeã«ãƒ—ãƒ©ãƒ³ä½œæˆã‚’ä¾é ¼")

    def _display_plan(self, plan: dict):
        """ãƒ—ãƒ©ãƒ³ã‚’UIã«è¡¨ç¤º"""
        analysis = plan.get("analysis", {})
        exec_plan = plan.get("execution_plan", {})
        steps = exec_plan.get("steps", [])

        total_files = analysis.get("total_files", 0)
        total_est = exec_plan.get("total_estimated_minutes", 0)

        if plan.get("fallback"):
            self.plan_status_label.setText("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ©ãƒ³ï¼ˆClaudeæ¥ç¶šå¤±æ•—ï¼‰")
        else:
            self.plan_status_label.setText("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: ãƒ—ãƒ©ãƒ³ä½œæˆæ¸ˆã¿")

        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        summary = plan.get("summary", "")
        if summary:
            self.plan_summary_text.setPlainText(summary)
        else:
            self.plan_summary_text.setPlainText("ï¼ˆæ¦‚è¦æƒ…å ±ãªã—ï¼‰")
        self.copy_plan_btn.setEnabled(True)

        # ãƒ—ãƒ©ãƒ³è©³ç´°
        classifications = analysis.get("file_classifications", [])
        detail_parts = [f"ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}  |  ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(steps)}  |  æ¨å®šæ™‚é–“: {total_est:.1f}åˆ†"]
        for cls in classifications[:5]:
            detail_parts.append(
                f"  {cls['file']}: {cls.get('category', '?')} / "
                f"å„ªå…ˆåº¦: {cls.get('priority', '?')} / "
                f"æ¨å®šãƒãƒ£ãƒ³ã‚¯: {cls.get('estimated_chunks', '?')}"
            )
        if len(classifications) > 5:
            detail_parts.append(f"  ...ä»– {len(classifications) - 5} ãƒ•ã‚¡ã‚¤ãƒ«")
        self.plan_detail_label.setText("\n".join(detail_parts))

        # é€²æ—ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã«ã‚¹ãƒ†ãƒƒãƒ—è¨­å®š
        self.progress_widget.setup_steps(steps)

    def _copy_plan_summary(self):
        """ãƒ—ãƒ©ãƒ³æ¦‚è¦ã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼"""
        clipboard = QApplication.clipboard()
        full_text = self._build_full_plan_text()
        clipboard.setText(full_text)
        self.statusChanged.emit("ãƒ—ãƒ©ãƒ³æ¦‚è¦ã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ")

    def _build_full_plan_text(self) -> str:
        """ã‚³ãƒ”ãƒ¼ç”¨ã®ãƒ—ãƒ©ãƒ³å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        if not self._current_plan:
            return ""

        plan = self._current_plan
        analysis = plan.get("analysis", {})
        exec_plan = plan.get("execution_plan", {})
        classifications = analysis.get("file_classifications", [])
        total_est = exec_plan.get("total_estimated_minutes", 0)
        summary = plan.get("summary", "")

        lines = [
            "ã€RAGæ§‹ç¯‰ãƒ—ãƒ©ãƒ³æ¦‚è¦ã€‘",
            f"ãƒ—ãƒ©ãƒ³ä½œæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            f"æ¨å®šå‡¦ç†æ™‚é–“: {total_est:.1f}åˆ†",
            f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {analysis.get('total_files', 0)}ä»¶",
        ]

        if plan.get("fallback"):
            lines.append("â€» ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ©ãƒ³ï¼ˆClaudeæ¥ç¶šå¤±æ•—ï¼‰")

        if summary:
            lines.append(f"\næ¦‚è¦:\n{summary}")

        if classifications:
            lines.append("\nãƒ•ã‚¡ã‚¤ãƒ«åˆ¥è¨ˆç”»:")
            for i, cls in enumerate(classifications, 1):
                lines.append(
                    f"  {i}. {cls['file']}\n"
                    f"     åˆ†é¡: {cls.get('category', '?')} / "
                    f"å„ªå…ˆåº¦: {cls.get('priority', '?')} / "
                    f"æ¨å®šãƒãƒ£ãƒ³ã‚¯: {cls.get('estimated_chunks', '?')}"
                )

        return "\n".join(lines)

    def _start_build(self):
        """RAGæ§‹ç¯‰é–‹å§‹"""
        if not self._current_plan:
            QMessageBox.information(self, "ãƒ—ãƒ©ãƒ³æœªä½œæˆ",
                                     "å…ˆã«ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            return

        self._builder = RAGBuilder(
            folder_path=self._folder_path,
            time_limit_minutes=self.time_spin.value(),
            plan=self._current_plan,
        )

        # å…±æœ‰ãƒ­ãƒƒã‚¯ã‚’è¨­å®š
        self.rag_lock = self._builder.lock

        # ãƒ¡ã‚¤ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«ãƒ­ãƒƒã‚¯ã‚’ä¼æ¬
        if self.main_window:
            self.main_window._rag_lock = self.rag_lock

        # ã‚·ã‚°ãƒŠãƒ«æ¥ç¶š
        signals = self._builder.signals
        signals.progress_updated.connect(self.progress_widget.on_progress_updated)
        signals.time_updated.connect(self.progress_widget.on_time_updated)
        signals.step_started.connect(self.progress_widget.on_step_started)
        signals.step_progress.connect(self.progress_widget.on_step_progress)
        signals.step_completed.connect(self.progress_widget.on_step_completed)
        signals.status_changed.connect(self._on_status_changed)
        signals.lock_changed.connect(self._on_lock_changed)
        signals.error_occurred.connect(self._on_error)
        signals.verification_result.connect(self._on_verification_result)
        signals.build_completed.connect(self._on_build_completed)

        # UIã‚’æ›´æ–°
        self.start_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)
        self.rebuild_btn.setEnabled(False)
        self.create_plan_btn.setEnabled(False)

        # é–‹å§‹
        self._builder.start()
        self.statusChanged.emit("RAGæ§‹ç¯‰ã‚’é–‹å§‹ã—ã¾ã—ãŸ")

    def _stop_build(self):
        """RAGæ§‹ç¯‰ä¸­æ­¢"""
        if self._builder and self._builder.isRunning():
            self._builder.cancel()
            self.stop_btn.setEnabled(False)
            self.statusChanged.emit("RAGæ§‹ç¯‰ã‚’ä¸­æ­¢ä¸­...")

    def _rebuild(self):
        """å†å®Ÿè¡Œ"""
        if self._current_plan:
            self._start_build()
        else:
            self._create_plan()

    def _on_status_changed(self, status: str):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰æ›´"""
        status_text = {
            "running": "RAGæ§‹ç¯‰ å®Ÿè¡Œä¸­...",
            "verifying": "Claude å“è³ªæ¤œè¨¼ä¸­...",
            "completed": "RAGæ§‹ç¯‰ å®Œäº†",
            "failed": "RAGæ§‹ç¯‰ å¤±æ•—",
            "cancelled": "RAGæ§‹ç¯‰ ä¸­æ­¢",
        }.get(status, status)
        self.statusChanged.emit(status_text)

    def _on_lock_changed(self, locked: bool):
        """ãƒ­ãƒƒã‚¯çŠ¶æ…‹å¤‰æ›´"""
        if self.main_window:
            # mixAI/soloAIã®ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’åˆ¶å¾¡
            if hasattr(self.main_window, 'llmmix_tab'):
                tab = self.main_window.llmmix_tab
                if hasattr(tab, 'rag_lock_overlay'):
                    if locked:
                        tab.rag_lock_overlay.show_lock()
                    else:
                        tab.rag_lock_overlay.hide_lock()
            if hasattr(self.main_window, 'claude_tab'):
                tab = self.main_window.claude_tab
                if hasattr(tab, 'rag_lock_overlay'):
                    if locked:
                        tab.rag_lock_overlay.show_lock()
                    else:
                        tab.rag_lock_overlay.hide_lock()

    def _on_error(self, step_name: str, error_message: str):
        """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ"""
        logger.error(f"RAG build error at {step_name}: {error_message}")
        self.statusChanged.emit(f"ã‚¨ãƒ©ãƒ¼: {step_name}")

    def _on_verification_result(self, result: dict):
        """æ¤œè¨¼çµæœå—ä¿¡"""
        verdict = result.get("overall_verdict", "UNKNOWN")
        score = result.get("score", 0)
        logger.info(f"Verification result: {verdict} (score={score})")

    def _on_build_completed(self, success: bool, message: str):
        """æ§‹ç¯‰å®Œäº†"""
        self.start_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.rebuild_btn.setEnabled(True)
        self.create_plan_btn.setEnabled(True)

        self._refresh_rag_stats()

        if success:
            QMessageBox.information(self, "RAGæ§‹ç¯‰å®Œäº†", message)
        else:
            QMessageBox.warning(self, "RAGæ§‹ç¯‰", message)

    # =========================================================================
    # ãƒ‡ãƒ¼ã‚¿ç®¡ç†
    # =========================================================================

    def _scan_orphans(self):
        """å­¤å…ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        try:
            orphans = self.cleanup_manager.scan_orphans()
            self.orphan_tree.clear()

            if not orphans:
                self.orphan_status_label.setText("ãƒ‡ãƒ¼ã‚¿å¥å…¨")
                self.orphan_tree.setVisible(False)
                self.delete_orphan_btn.setEnabled(False)
                return

            self.orphan_status_label.setText(f"å­¤å…ãƒ‡ãƒ¼ã‚¿: {len(orphans)}ä»¶æ¤œå‡º")
            self.orphan_tree.setVisible(True)
            self.delete_orphan_btn.setEnabled(True)

            for o in orphans:
                item = QTreeWidgetItem([
                    o["source_file"],
                    str(o["chunk_count"]),
                    o["safety_label"],
                ])
                item.setFlags(item.flags() | Qt.ItemFlag.ItemIsUserCheckable)
                # å®‰å…¨ãƒ¬ãƒ™ãƒ«1ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒã‚§ãƒƒã‚¯ã€2ã¯ãƒã‚§ãƒƒã‚¯ãªã—
                if o["safety_level"] == 1:
                    item.setCheckState(0, Qt.CheckState.Checked)
                else:
                    item.setCheckState(0, Qt.CheckState.Unchecked)
                self.orphan_tree.addTopLevelItem(item)

        except Exception as e:
            logger.debug(f"Orphan scan error: {e}")
            self.orphan_status_label.setText("ãƒ‡ãƒ¼ã‚¿å¥å…¨æ€§: ä¸æ˜")

    def _delete_selected_orphans(self):
        """é¸æŠã•ã‚ŒãŸå­¤å…ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
        selected = []
        for i in range(self.orphan_tree.topLevelItemCount()):
            item = self.orphan_tree.topLevelItem(i)
            if item.checkState(0) == Qt.CheckState.Checked:
                selected.append(item.text(0))

        if not selected:
            QMessageBox.information(self, "æœªé¸æŠ", "å‰Šé™¤ã™ã‚‹å­¤å…ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            return

        self._confirm_and_delete(selected, is_orphan=True)

    def _refresh_doc_list(self):
        """æ§‹ç¯‰æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ã‚’æ›´æ–°"""
        self.doc_tree.clear()
        try:
            import sqlite3
            db_path = Path("data/helix_memory.db")
            if not db_path.exists():
                return
            conn = sqlite3.connect(str(db_path))
            conn.row_factory = sqlite3.Row
            try:
                rows = conn.execute("""
                    SELECT source_file, COUNT(*) as chunk_count
                    FROM documents
                    GROUP BY source_file
                    ORDER BY source_file
                """).fetchall()
                for row in rows:
                    item = QTreeWidgetItem([row["source_file"], str(row["chunk_count"])])
                    item.setFlags(item.flags() | Qt.ItemFlag.ItemIsUserCheckable)
                    item.setCheckState(0, Qt.CheckState.Unchecked)
                    self.doc_tree.addTopLevelItem(item)
            finally:
                conn.close()
        except Exception as e:
            logger.debug(f"Doc list refresh error: {e}")

    def _delete_selected_documents(self):
        """é¸æŠã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®RAGãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
        selected = []
        for i in range(self.doc_tree.topLevelItemCount()):
            item = self.doc_tree.topLevelItem(i)
            if item.checkState(0) == Qt.CheckState.Checked:
                selected.append(item.text(0))

        if not selected:
            QMessageBox.information(self, "æœªé¸æŠ", "å‰Šé™¤ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            return

        self._confirm_and_delete(selected, is_orphan=False)

    def _confirm_and_delete(self, source_files: list, is_orphan: bool = False):
        """å‰Šé™¤å‰ã®ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°"""
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Icon.Warning)
        msg.setWindowTitle("ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã®ç¢ºèª")

        count = len(source_files)
        if is_orphan:
            msg.setText(f"å­¤å…ãƒ‡ãƒ¼ã‚¿ {count}ä»¶ ã‚’å‰Šé™¤ã—ã¾ã™ã€‚ã“ã®æ“ä½œã¯å…ƒã«æˆ»ã›ã¾ã›ã‚“ã€‚")
        else:
            msg.setText(
                f"é¸æŠã•ã‚ŒãŸ {count}ä»¶ ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n"
                f"ãƒ•ã‚¡ã‚¤ãƒ«è‡ªä½“ã¯å‰Šé™¤ã•ã‚Œã¾ã›ã‚“ï¼ˆdata/information/ å†…ã«æ®‹ã‚Šã¾ã™ï¼‰ã€‚\n"
                f"ã“ã®æ“ä½œã¯å…ƒã«æˆ»ã›ã¾ã›ã‚“ã€‚"
            )

        msg.setDetailedText("\n".join(source_files))
        msg.setStandardButtons(
            QMessageBox.StandardButton.Ok | QMessageBox.StandardButton.Cancel
        )
        msg.setDefaultButton(QMessageBox.StandardButton.Cancel)

        if msg.exec() == QMessageBox.StandardButton.Ok:
            if is_orphan:
                result = self.cleanup_manager.delete_orphans(source_files)
            else:
                result = self.cleanup_manager.delete_selected_documents(source_files)

            self.statusChanged.emit(
                f"å‰Šé™¤å®Œäº†: {result['deleted_chunks']}ãƒãƒ£ãƒ³ã‚¯, "
                f"{result['deleted_summaries']}è¦ç´„, "
                f"{result['deleted_links']}ãƒªãƒ³ã‚¯"
            )
            self._scan_orphans()
            self._refresh_doc_list()
            self._refresh_rag_stats()

    # =========================================================================
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    # =========================================================================

    def _save_rag_settings(self):
        """RAGæ§‹ç¯‰è¨­å®šã‚’app_settings.jsonã«ä¿å­˜"""
        try:
            settings_path = Path("config/app_settings.json")
            settings = {}
            if settings_path.exists():
                with open(settings_path, 'r', encoding='utf-8') as f:
                    settings = json.load(f)

            settings["rag"] = {
                "time_limit_minutes": self.time_spin.value(),
                "chunk_size": self.chunk_size_spin.value(),
                "overlap": self.overlap_spin.value(),
            }

            settings_path.parent.mkdir(parents=True, exist_ok=True)
            with open(settings_path, 'w', encoding='utf-8') as f:
                json.dump(settings, f, ensure_ascii=False, indent=2)

            self.statusChanged.emit("RAGæ§‹ç¯‰è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            logger.info(f"RAG settings saved: {settings['rag']}")
        except Exception as e:
            logger.error(f"Failed to save RAG settings: {e}")
            QMessageBox.warning(self, "ä¿å­˜å¤±æ•—", f"è¨­å®šã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    def _load_rag_settings(self):
        """app_settings.jsonã‹ã‚‰RAGæ§‹ç¯‰è¨­å®šã‚’èª­ã¿è¾¼ã‚“ã§SpinBoxã«åæ˜ """
        try:
            settings_path = Path("config/app_settings.json")
            if not settings_path.exists():
                return
            with open(settings_path, 'r', encoding='utf-8') as f:
                settings = json.load(f)

            rag = settings.get("rag", {})
            if "time_limit_minutes" in rag:
                self.time_spin.setValue(rag["time_limit_minutes"])
            if "chunk_size" in rag:
                self.chunk_size_spin.setValue(rag["chunk_size"])
            if "overlap" in rag:
                self.overlap_spin.setValue(rag["overlap"])

            logger.debug(f"RAG settings loaded: {rag}")
        except Exception as e:
            logger.debug(f"RAG settings load skipped: {e}")

    @staticmethod
    def _format_size(size_bytes: int) -> str:
        """ãƒã‚¤ãƒˆæ•°ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f} MB"

========================================
FILE: src/tabs/helix_orchestrator_tab.py
========================================
"""
Helix AI Studio - mixAI Tab (v7.0.0)
3Phaseå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: Claude Code + ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒãƒ¼ãƒ ã«ã‚ˆã‚‹é«˜ç²¾åº¦ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

v7.0.0 "Orchestrated Intelligence": æ—§5Phaseâ†’æ–°3PhaseåŒ–
- Phase 1: Claudeè¨ˆç”»ç«‹æ¡ˆï¼ˆ--cwdã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãã€ãƒ„ãƒ¼ãƒ«ä½¿ç”¨æŒ‡ç¤ºï¼‰
- Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œï¼ˆcoding/research/reasoning/vision/translationï¼‰
- Phase 3: Claudeæ¯”è¼ƒçµ±åˆï¼ˆ2å›ç›®å‘¼ã³å‡ºã—ã€å“è³ªæ¤œè¨¼ãƒ«ãƒ¼ãƒ—ã‚ã‚Šï¼‰
- Neural Flow Visualizerã®3PhaseåŒ–
- è¨­å®šã‚¿ãƒ–ã®ã‚«ãƒ†ã‚´ãƒªåˆ·æ–°ï¼ˆ5ã‚«ãƒ†ã‚´ãƒª + MCPè¨­å®šï¼‰
"""

import json
import logging
import time
import subprocess
import shutil
import os
from typing import Optional, Dict, Any, List

from ..utils.subprocess_utils import run_hidden
from pathlib import Path
from datetime import datetime

from PyQt6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QSplitter,
    QGroupBox, QLabel, QPushButton, QComboBox,
    QTextEdit, QPlainTextEdit, QProgressBar,
    QTableWidget, QTableWidgetItem, QHeaderView,
    QTabWidget, QCheckBox, QSpinBox, QFrame,
    QScrollArea, QFormLayout, QLineEdit, QMessageBox,
    QTreeWidget, QTreeWidgetItem, QSizePolicy, QSlider,
    QFileDialog  # v5.1: ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ç”¨
)
from PyQt6.QtCore import Qt, pyqtSignal, QThread, QTimer, QRect
from PyQt6.QtGui import QFont, QColor, QTextCursor, QPainter, QPen, QBrush, QPainterPath, QKeyEvent

from ..backends.tool_orchestrator import (
    ToolOrchestrator, ToolType, ToolResult,
    OrchestratorConfig, get_tool_orchestrator
)
# v7.0.0: 3Phaseå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
from ..backends.mix_orchestrator import MixAIOrchestrator
# v6.1.1: ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¡¨è¨˜ã®å‹•çš„å–å¾—
# v7.1.0: Claudeãƒ¢ãƒ‡ãƒ«å‹•çš„é¸æŠ
from ..utils.constants import APP_VERSION, CLAUDE_MODELS, DEFAULT_CLAUDE_MODEL_ID
from ..utils.markdown_renderer import markdown_to_html
from ..utils.styles import (
    SECTION_CARD_STYLE, PRIMARY_BTN, SECONDARY_BTN, DANGER_BTN,
    OUTPUT_AREA_STYLE, INPUT_AREA_STYLE, TAB_BAR_STYLE,
    SCROLLBAR_STYLE, COMBO_BOX_STYLE, PROGRESS_BAR_STYLE,
    SPINBOX_STYLE,
)
# Neural Flow Visualizer & VRAM Simulator
from ..widgets.neural_visualizer import NeuralFlowCompactWidget, PhaseState
from ..widgets.vram_simulator import VRAMBudgetSimulator, VRAMCompactWidget
# v8.0.0: BIBLE Manager
from ..widgets.bible_panel import BibleStatusPanel
from ..widgets.bible_notification import BibleNotificationWidget
from ..widgets.chat_widgets import PhaseIndicator, ExecutionIndicator, InterruptionBanner
from ..bible.bible_discovery import BibleDiscovery
from ..bible.bible_injector import BibleInjector

logger = logging.getLogger(__name__)


class NoScrollComboBox(QComboBox):
    """ãƒã‚¦ã‚¹ãƒ›ã‚¤ãƒ¼ãƒ«ã§å€¤ãŒå¤‰ã‚ã‚‰ãªã„QComboBox"""
    def wheelEvent(self, event):
        event.ignore()


# =============================================================================
# v5.1: mixAIç”¨å¼·åŒ–å…¥åŠ›ã‚¯ãƒ©ã‚¹
# =============================================================================

class MixAIEnhancedInput(QPlainTextEdit):
    """
    mixAIç”¨å¼·åŒ–å…¥åŠ›ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ (v5.1.1)

    æ©Ÿèƒ½:
    - ä¸Šä¸‹ã‚­ãƒ¼ã«ã‚ˆã‚‹ã‚«ãƒ¼ã‚½ãƒ«ç§»å‹•
    - å…ˆé ­è¡Œ+ä¸Šã‚­ãƒ¼ -> ãƒ†ã‚­ã‚¹ãƒˆå…ˆé ­ã¸
    - æœ€çµ‚è¡Œ+ä¸‹ã‚­ãƒ¼ -> ãƒ†ã‚­ã‚¹ãƒˆæœ«å°¾ã¸
    - ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‰ãƒ­ãƒƒãƒ—ã‚µãƒãƒ¼ãƒˆ
    - Ctrl+Vã§ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ (v5.1.1)
    """
    file_dropped = pyqtSignal(list)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‰ãƒ­ãƒƒãƒ—æ™‚ã®ã‚·ã‚°ãƒŠãƒ«

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setAcceptDrops(True)

    def keyPressEvent(self, event: QKeyEvent):
        """ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†"""
        key = event.key()
        modifiers = event.modifiers()

        # Ctrl+V: ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ã‚’ãƒã‚§ãƒƒã‚¯ (v5.1.1)
        if key == Qt.Key.Key_V and modifiers == Qt.KeyboardModifier.ControlModifier:
            from PyQt6.QtWidgets import QApplication
            clipboard = QApplication.clipboard()
            mime_data = clipboard.mimeData()

            # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ãƒ•ã‚¡ã‚¤ãƒ«URLãŒã‚ã‚‹å ´åˆ
            if mime_data.hasUrls():
                files = [url.toLocalFile() for url in mime_data.urls()
                         if url.toLocalFile() and os.path.exists(url.toLocalFile())]
                if files:
                    self.file_dropped.emit(files)
                    return  # ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ã—ãŸå ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆè²¼ã‚Šä»˜ã‘ã—ãªã„

            # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ç”»åƒãŒã‚ã‚‹å ´åˆã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            if mime_data.hasImage():
                import tempfile
                from PyQt6.QtGui import QImage
                image = clipboard.image()
                if not image.isNull():
                    temp_dir = tempfile.gettempdir()
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    temp_path = os.path.join(temp_dir, f"clipboard_image_{timestamp}.png")
                    if image.save(temp_path, "PNG"):
                        self.file_dropped.emit([temp_path])
                        return

            # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆè²¼ã‚Šä»˜ã‘
            super().keyPressEvent(event)
            return

        # ä¸Šã‚­ãƒ¼å‡¦ç†: å…ˆé ­è¡Œã«ã„ã‚‹å ´åˆ -> ãƒ†ã‚­ã‚¹ãƒˆå…ˆé ­ã¸
        if key == Qt.Key.Key_Up:
            cursor = self.textCursor()
            cursor_block = cursor.block()
            first_block = self.document().firstBlock()
            if cursor_block == first_block:
                cursor.movePosition(QTextCursor.MoveOperation.Start)
                self.setTextCursor(cursor)
                return
            super().keyPressEvent(event)
            return

        # ä¸‹ã‚­ãƒ¼å‡¦ç†: æœ€çµ‚è¡Œã«ã„ã‚‹å ´åˆ -> ãƒ†ã‚­ã‚¹ãƒˆæœ«å°¾ã¸
        if key == Qt.Key.Key_Down:
            cursor = self.textCursor()
            cursor_block = cursor.block()
            last_block = self.document().lastBlock()
            if cursor_block == last_block:
                cursor.movePosition(QTextCursor.MoveOperation.End)
                self.setTextCursor(cursor)
                return
            super().keyPressEvent(event)
            return

        super().keyPressEvent(event)

    def dragEnterEvent(self, event):
        """ãƒ‰ãƒ©ãƒƒã‚°é€²å…¥ã‚¤ãƒ™ãƒ³ãƒˆ"""
        if event.mimeData().hasUrls():
            event.acceptProposedAction()
        else:
            super().dragEnterEvent(event)

    def dropEvent(self, event):
        """ãƒ‰ãƒ­ãƒƒãƒ—ã‚¤ãƒ™ãƒ³ãƒˆ"""
        if event.mimeData().hasUrls():
            files = [url.toLocalFile() for url in event.mimeData().urls()
                     if url.toLocalFile()]
            if files:
                self.file_dropped.emit(files)
                event.acceptProposedAction()
                return
        super().dropEvent(event)


class MixAIAttachmentWidget(QFrame):
    """mixAIç”¨å€‹åˆ¥æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ"""
    removed = pyqtSignal(str)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    FILE_ICONS = {
        ".py": "ğŸ", ".js": "ğŸ“œ", ".ts": "ğŸ“˜",
        ".html": "ğŸŒ", ".css": "ğŸ¨", ".json": "ğŸ“‹",
        ".md": "ğŸ“", ".txt": "ğŸ“„", ".pdf": "ğŸ“•",
        ".png": "ğŸ–¼ï¸", ".jpg": "ğŸ–¼ï¸", ".jpeg": "ğŸ–¼ï¸",
        ".gif": "ğŸ–¼ï¸", ".svg": "ğŸ–¼ï¸", ".webp": "ğŸ–¼ï¸",
        ".zip": "ğŸ“¦", ".csv": "ğŸ“Š", ".xlsx": "ğŸ“Š",
    }

    def __init__(self, filepath: str, parent=None):
        super().__init__(parent)
        self.filepath = filepath
        self.setFrameStyle(QFrame.Shape.StyledPanel)
        self.setStyleSheet("""
            MixAIAttachmentWidget {
                background-color: #2d3748;
                border: 1px solid #4a5568;
                border-radius: 6px;
                padding: 2px 6px;
            }
            MixAIAttachmentWidget:hover {
                border-color: #63b3ed;
            }
        """)

        layout = QHBoxLayout(self)
        layout.setContentsMargins(4, 2, 4, 2)
        layout.setSpacing(4)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¤ã‚³ãƒ³ + åå‰
        import os
        filename = os.path.basename(filepath)
        ext = os.path.splitext(filename)[1].lower()
        icon = self.FILE_ICONS.get(ext, "ğŸ“")

        icon_label = QLabel(icon)
        name_label = QLabel(filename)
        name_label.setStyleSheet("color: #e2e8f0; font-size: 10px;")
        name_label.setMaximumWidth(150)
        name_label.setToolTip(filepath)

        # Ã—ãƒœã‚¿ãƒ³ (v5.2.0: è¦–èªæ€§å¤§å¹…å‘ä¸Š - å¸¸ã«èµ¤èƒŒæ™¯ã§ç›®ç«‹ãŸã›ã‚‹)
        remove_btn = QPushButton("Ã—")
        remove_btn.setFixedSize(20, 20)
        remove_btn.setToolTip("æ·»ä»˜ã‚’è§£é™¤")
        remove_btn.setStyleSheet("""
            QPushButton {
                background-color: #e53e3e;
                color: #ffffff;
                border: 2px solid #fc8181;
                border-radius: 10px;
                font-size: 14px;
                font-weight: bold;
                padding: 0px;
            }
            QPushButton:hover {
                background-color: #c53030;
                color: #ffffff;
                border-color: #feb2b2;
            }
            QPushButton:pressed {
                background-color: #9b2c2c;
            }
        """)
        remove_btn.clicked.connect(lambda: self.removed.emit(self.filepath))

        layout.addWidget(icon_label)
        layout.addWidget(name_label)
        layout.addWidget(remove_btn)


class MixAIAttachmentBar(QWidget):
    """mixAIç”¨æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ¼"""
    attachments_changed = pyqtSignal(list)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ

    def __init__(self, parent=None):
        super().__init__(parent)
        import os
        self._files: List[str] = []
        self.setVisible(False)

        layout = QHBoxLayout(self)
        layout.setContentsMargins(4, 4, 4, 4)
        layout.setSpacing(4)

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¨ãƒªã‚¢
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area.setHorizontalScrollBarPolicy(
            Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scroll_area.setVerticalScrollBarPolicy(
            Qt.ScrollBarPolicy.ScrollBarAlwaysOff)
        self.scroll_area.setMaximumHeight(36)
        self.scroll_area.setStyleSheet("border: none; background: transparent;")

        self.container = QWidget()
        self.container_layout = QHBoxLayout(self.container)
        self.container_layout.setContentsMargins(0, 0, 0, 0)
        self.container_layout.setSpacing(4)
        self.container_layout.addStretch()

        self.scroll_area.setWidget(self.container)
        layout.addWidget(self.scroll_area)

    def add_files(self, filepaths: List[str]):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ """
        import os
        for fp in filepaths:
            if fp not in self._files and os.path.exists(fp):
                self._files.append(fp)
                widget = MixAIAttachmentWidget(fp)
                widget.removed.connect(self.remove_file)
                self.container_layout.insertWidget(
                    self.container_layout.count() - 1, widget)

        self.setVisible(bool(self._files))
        self.attachments_changed.emit(self._files.copy())

    def remove_file(self, filepath: str):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
        if filepath in self._files:
            self._files.remove(filepath)
        for i in range(self.container_layout.count()):
            item = self.container_layout.itemAt(i)
            if item and item.widget():
                w = item.widget()
                if isinstance(w, MixAIAttachmentWidget) and w.filepath == filepath:
                    w.deleteLater()
                    break
        self.setVisible(bool(self._files))
        self.attachments_changed.emit(self._files.copy())

    def clear_all(self):
        """å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        self._files.clear()
        while self.container_layout.count() > 1:
            item = self.container_layout.takeAt(0)
            if item.widget():
                item.widget().deleteLater()
        self.setVisible(False)
        self.attachments_changed.emit([])

    def get_files(self) -> List[str]:
        """æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return self._files.copy()


class GPUUsageGraph(QWidget):
    """GPUä½¿ç”¨é‡ã®å‹•çš„ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆï¼ˆæ™‚é–“è»¸é¸æŠãƒ»ã‚·ãƒ¼ã‚¯ãƒãƒ¼å¯¾å¿œï¼‰"""

    # æ™‚é–“ç¯„å›²å®šç¾©ï¼ˆç§’ï¼‰
    TIME_RANGES = {
        "60ç§’": 60,
        "5åˆ†": 300,
        "15åˆ†": 900,
        "30åˆ†": 1800,
        "1æ™‚é–“": 3600,
    }

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setMinimumHeight(120)
        self.setMaximumHeight(180)

        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ï¼ˆæœ€å¤§3600ã‚µãƒ³ãƒ—ãƒ« = 1æ™‚é–“åˆ†ï¼‰
        self.max_samples = 3600
        self.gpu_data: Dict[int, List[Dict[str, Any]]] = {}  # GPU index -> [{timestamp, vram_used, vram_total, event}]
        self.events: List[Dict[str, Any]] = []  # LLMèµ·å‹•ã‚¤ãƒ™ãƒ³ãƒˆ

        # æ™‚é–“è»¸è¨­å®š
        self.time_range = 60  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60ç§’
        self.view_offset = 0  # ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆç§’ï¼‰: 0 = ç¾åœ¨ã€æ­£ã®å€¤ = éå»

        # è‰²å®šç¾©
        self.gpu_colors = [
            QColor("#22c55e"),  # GPU 0: ç·‘
            QColor("#3b82f6"),  # GPU 1: é’
            QColor("#f59e0b"),  # GPU 2: ã‚ªãƒ¬ãƒ³ã‚¸
            QColor("#ef4444"),  # GPU 3: èµ¤
        ]

    def set_time_range(self, seconds: int):
        """æ™‚é–“ç¯„å›²ã‚’è¨­å®š"""
        self.time_range = seconds
        self.view_offset = 0  # æ™‚é–“ç¯„å›²å¤‰æ›´æ™‚ã¯ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
        self.update()

    def set_view_offset(self, offset_seconds: int):
        """è¡¨ç¤ºã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è¨­å®šï¼ˆã‚·ãƒ¼ã‚¯ãƒãƒ¼ç”¨ï¼‰"""
        self.view_offset = max(0, offset_seconds)
        self.update()

    def get_data_duration(self) -> float:
        """è¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ã®å…¨æœŸé–“ï¼ˆç§’ï¼‰ã‚’å–å¾—"""
        if not self.gpu_data:
            return 0
        all_timestamps = []
        for data_points in self.gpu_data.values():
            if data_points:
                all_timestamps.extend([dp["timestamp"] for dp in data_points])
        if not all_timestamps:
            return 0
        return time.time() - min(all_timestamps)

    def add_data_point(self, gpu_index: int, vram_used_mb: int, vram_total_mb: int, event: str = ""):
        """ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ """
        if gpu_index not in self.gpu_data:
            self.gpu_data[gpu_index] = []

        self.gpu_data[gpu_index].append({
            "timestamp": time.time(),
            "vram_used": vram_used_mb,
            "vram_total": vram_total_mb,
            "event": event,
        })

        # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆ1æ™‚é–“ä»¥ä¸Šå‰ï¼‰
        cutoff = time.time() - 3600
        self.gpu_data[gpu_index] = [dp for dp in self.gpu_data[gpu_index] if dp["timestamp"] > cutoff]

        self.update()

    def add_event(self, event_name: str):
        """LLMèµ·å‹•ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²"""
        self.events.append({
            "timestamp": time.time(),
            "name": event_name,
        })
        # å¤ã„ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‰Šé™¤ï¼ˆ1æ™‚é–“ä»¥ä¸Šå‰ï¼‰
        cutoff = time.time() - 3600
        self.events = [e for e in self.events if e["timestamp"] > cutoff]
        self.update()

    def clear_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"""
        self.gpu_data.clear()
        self.events.clear()
        self.view_offset = 0
        self.update()

    def paintEvent(self, event):
        """ã‚°ãƒ©ãƒ•ã‚’æç”»"""
        painter = QPainter(self)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)

        # èƒŒæ™¯
        painter.fillRect(self.rect(), QColor("#1f2937"))

        # ãƒãƒ¼ã‚¸ãƒ³
        margin_left = 50
        margin_right = 10
        margin_top = 20
        margin_bottom = 25

        graph_width = self.width() - margin_left - margin_right
        graph_height = self.height() - margin_top - margin_bottom

        if graph_width <= 0 or graph_height <= 0:
            return

        # ã‚°ãƒ©ãƒ•é ˜åŸŸã®èƒŒæ™¯
        graph_rect = QRect(margin_left, margin_top, graph_width, graph_height)
        painter.fillRect(graph_rect, QColor("#111827"))

        # è»¸ã‚’æç”»
        pen = QPen(QColor("#4b5563"))
        pen.setWidth(1)
        painter.setPen(pen)

        # Yè»¸
        painter.drawLine(margin_left, margin_top, margin_left, margin_top + graph_height)
        # Xè»¸
        painter.drawLine(margin_left, margin_top + graph_height, margin_left + graph_width, margin_top + graph_height)

        # Yè»¸ãƒ©ãƒ™ãƒ« (0%, 50%, 100%)
        painter.setPen(QColor("#9ca3af"))
        font = painter.font()
        font.setPointSize(8)
        painter.setFont(font)
        painter.drawText(5, margin_top + 5, "100%")
        painter.drawText(5, margin_top + graph_height // 2, "50%")
        painter.drawText(5, margin_top + graph_height, "0%")

        # Xè»¸æ™‚é–“ãƒ©ãƒ™ãƒ«
        time_label_left = f"-{self._format_time(self.time_range + self.view_offset)}"
        time_label_right = f"-{self._format_time(self.view_offset)}" if self.view_offset > 0 else "ç¾åœ¨"
        painter.drawText(margin_left, margin_top + graph_height + 15, time_label_left)
        painter.drawText(margin_left + graph_width - 30, margin_top + graph_height + 15, time_label_right)

        # æ°´å¹³ã‚°ãƒªãƒƒãƒ‰ç·š
        pen.setColor(QColor("#374151"))
        pen.setStyle(Qt.PenStyle.DotLine)
        painter.setPen(pen)
        painter.drawLine(margin_left, margin_top + graph_height // 2, margin_left + graph_width, margin_top + graph_height // 2)

        # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ
        if not self.gpu_data:
            painter.setPen(QColor("#6b7280"))
            painter.drawText(graph_rect, Qt.AlignmentFlag.AlignCenter, "GPUä½¿ç”¨é‡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\nå®Ÿè¡Œé–‹å§‹ã§è¨˜éŒ²ãŒé–‹å§‹ã•ã‚Œã¾ã™")
            return

        # è¡¨ç¤ºç¯„å›²ã‚’è¨ˆç®—ï¼ˆã‚·ãƒ¼ã‚¯ãƒãƒ¼å¯¾å¿œï¼‰
        now = time.time()
        view_end = now - self.view_offset  # è¡¨ç¤ºçµ‚äº†æ™‚åˆ»
        view_start = view_end - self.time_range  # è¡¨ç¤ºé–‹å§‹æ™‚åˆ»

        # å„GPUã®ãƒ‡ãƒ¼ã‚¿ã‚’æç”»
        for gpu_index, data_points in self.gpu_data.items():
            if not data_points:
                continue

            color = self.gpu_colors[gpu_index % len(self.gpu_colors)]
            pen = QPen(color)
            pen.setWidth(2)
            painter.setPen(pen)

            # ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
            path = QPainterPath()
            first_point = True

            for dp in data_points:
                ts = dp["timestamp"]
                # è¡¨ç¤ºç¯„å›²å†…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿æç”»
                if ts < view_start or ts > view_end:
                    continue

                # Xåº§æ¨™: è¡¨ç¤ºç¯„å›²å†…ã§ã®ä½ç½®
                x = margin_left + graph_width * ((ts - view_start) / self.time_range)
                usage_pct = dp["vram_used"] / dp["vram_total"] if dp["vram_total"] > 0 else 0
                y = margin_top + graph_height - (usage_pct * graph_height)

                if first_point:
                    path.moveTo(x, y)
                    first_point = False
                else:
                    path.lineTo(x, y)

            painter.drawPath(path)

        # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ¼ã‚«ãƒ¼ã‚’æç”»
        for evt in self.events:
            ts = evt["timestamp"]
            if ts < view_start or ts > view_end:
                continue

            x = margin_left + graph_width * ((ts - view_start) / self.time_range)
            pen = QPen(QColor("#f59e0b"))
            pen.setWidth(1)
            pen.setStyle(Qt.PenStyle.DashLine)
            painter.setPen(pen)
            painter.drawLine(int(x), margin_top, int(x), margin_top + graph_height)

            # ã‚¤ãƒ™ãƒ³ãƒˆå
            painter.setPen(QColor("#f59e0b"))
            font = painter.font()
            font.setPointSize(7)
            painter.setFont(font)
            painter.drawText(int(x) - 30, margin_top - 3, evt["name"][:15])

        # å‡¡ä¾‹
        legend_x = margin_left + 5
        legend_y = margin_top + 5
        for gpu_index in sorted(self.gpu_data.keys()):
            color = self.gpu_colors[gpu_index % len(self.gpu_colors)]
            painter.fillRect(legend_x, legend_y, 10, 10, color)
            painter.setPen(QColor("#ffffff"))
            font = painter.font()
            font.setPointSize(8)
            painter.setFont(font)
            painter.drawText(legend_x + 15, legend_y + 9, f"GPU {gpu_index}")
            legend_x += 60

    def _format_time(self, seconds: float) -> str:
        """ç§’æ•°ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if seconds < 60:
            return f"{int(seconds)}ç§’"
        elif seconds < 3600:
            return f"{int(seconds / 60)}åˆ†"
        else:
            return f"{int(seconds / 3600)}æ™‚é–“"


class MixAIWorker(QThread):
    """mixAI v7.0.0 å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼ - Claudeä¸»å°å‹ãƒãƒ«ãƒãƒ•ã‚§ãƒ¼ã‚ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    progress = pyqtSignal(str, int)
    tool_executed = pyqtSignal(dict)
    message_chunk = pyqtSignal(str)
    finished = pyqtSignal(str)
    error = pyqtSignal(str)

    def __init__(self, prompt: str, config: OrchestratorConfig, image_path: str = None):
        super().__init__()
        self.prompt = prompt
        self.config = config
        self.image_path = image_path
        self._cancelled = False
        self.orchestrator = None
        self._stage_outputs: List[Dict[str, Any]] = []  # å„ã‚¹ãƒ†ãƒ¼ã‚¸ã®å‡ºåŠ›ã‚’è“„ç©

    def cancel(self):
        self._cancelled = True

    def run(self):
        """ãƒãƒ«ãƒãƒ•ã‚§ãƒ¼ã‚ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ (v7.0.0)"""
        try:
            self.orchestrator = ToolOrchestrator(self.config)
            if not self.orchestrator.initialize():
                self.error.emit("Ollamaã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚\nè¨­å®šã‚¿ãƒ–ã§Ollama URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return

            # ãƒ•ã‚§ãƒ¼ã‚ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
            self._execute_phase_1_task_analysis()
            if self._cancelled:
                return

            # Phase 2: Claude CLIçµŒç”±ã§å®Ÿéš›ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
            self._execute_phase_2_claude_execution()
            if self._cancelled:
                return

            self._execute_phase_3_image_analysis()
            if self._cancelled:
                return

            self._execute_phase_4_rag_search()
            if self._cancelled:
                return

            self._execute_phase_5_validation_report()

            self.progress.emit("å®Œäº†", 100)

        except Exception as e:
            logger.exception("mixAI Worker error")
            self.error.emit(str(e))

    def _execute_claude_cli(self, prompt: str, timeout_seconds: int = 300) -> Dict[str, Any]:
        """
        Claude CLIã‚’å‘¼ã³å‡ºã—ã¦MCPãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ

        Args:
            prompt: Claudeã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            timeout_seconds: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰

        Returns:
            Dict with 'success', 'output', 'error'
        """
        try:
            # Claude CLIã®å­˜åœ¨ç¢ºèª
            claude_cmd = shutil.which("claude")
            if claude_cmd is None:
                # Windows ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ç¢ºèª
                possible_paths = [
                    os.path.expanduser("~/.claude/local/claude.exe"),
                    os.path.expanduser("~/AppData/Local/Programs/claude/claude.exe"),
                    "claude",
                ]
                for path in possible_paths:
                    if os.path.exists(path):
                        claude_cmd = path
                        break

            if claude_cmd is None:
                return {
                    "success": False,
                    "output": "",
                    "error": "Claude CLIãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Claude Codeã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚",
                }

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«çµŒç”±ã§æ¸¡ã™ï¼ˆé•·ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œï¼‰
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
                f.write(prompt)
                prompt_file = f.name

            try:
                # v5.0.0: Claude CLIå®Ÿè¡Œï¼ˆ--dangerously-skip-permissions ã§è‡ªå‹•è¨±å¯ï¼‰
                result = run_hidden(
                    [claude_cmd, "-p", "--dangerously-skip-permissions", prompt],
                    capture_output=True,
                    text=True,
                    timeout=timeout_seconds,
                    encoding='utf-8',
                    errors='replace',
                )

                if result.returncode == 0:
                    return {
                        "success": True,
                        "output": result.stdout.strip(),
                        "error": "",
                    }
                else:
                    return {
                        "success": False,
                        "output": result.stdout.strip(),
                        "error": result.stderr.strip() or f"Exit code: {result.returncode}",
                    }
            finally:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                try:
                    os.unlink(prompt_file)
                except:
                    pass

        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "output": "",
                "error": f"Claude CLIãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ{timeout_seconds}ç§’ï¼‰",
            }
        except Exception as e:
            return {
                "success": False,
                "output": "",
                "error": f"Claude CLIå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}",
            }

    def _execute_phase_1_task_analysis(self):
        """Phase 1: ã‚¿ã‚¹ã‚¯åˆ†æ"""
        self.progress.emit("Phase 1: ã‚¿ã‚¹ã‚¯åˆ†æä¸­...", 10)

        analysis_prompt = f"""ã€é‡è¦ã€‘å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®å›ç­”ã¯ç¦æ­¢ã§ã™ã€‚

ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’åˆ†æã—ã€å®Ÿè¡Œè¨ˆç”»ã‚’æœ€å¤§6è¡Œã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

ã€ã‚¿ã‚¹ã‚¯ã€‘
{self.prompt}

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
- è¡Œ1-6: è¨­è¨ˆãƒ»ä»®èª¬ãƒ»ãƒ¢ãƒ‡ãƒ«å‰²ã‚Šå½“ã¦ã®è¨ˆç”»

å¿…ãšå…·ä½“çš„ãªã‚¹ãƒ†ãƒƒãƒ—ã¨ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å€™è£œã‚’å«ã‚ã¦ãã ã•ã„ã€‚ã™ã¹ã¦æ—¥æœ¬èªã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚"""

        result = self.orchestrator.execute_tool(
            ToolType.UNIVERSAL_AGENT,
            analysis_prompt,
            thinking_enabled=True,
        )

        # å‡ºåŠ›æœ«å°¾ã«ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•è¿½åŠ 
        model_name = result.metadata.get("model", self.config.universal_agent_model)
        output_with_model = f"{result.output}\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"
        result.output = output_with_model

        self._emit_tool_result(result, "ã‚¿ã‚¹ã‚¯åˆ†æ")
        self._stage_outputs.append({
            "stage": 1,
            "name": "ã‚¿ã‚¹ã‚¯åˆ†æ",
            "output": result.output,
            "model": model_name,
            "success": result.success,
        })
        self.progress.emit("Phase 1 å®Œäº†", 20)

    def _execute_phase_2_claude_execution(self):
        """Phase 2: Claude CLIçµŒç”±ã§å®Ÿéš›ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        self.progress.emit("Phase 2: Claudeå®Ÿè¡Œä¸­...", 30)

        # Phase 1ã®åˆ†æçµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦åˆ©ç”¨
        context = self._stage_outputs[0]["output"] if self._stage_outputs else ""

        # Claude CLIã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆMCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦å®Ÿéš›ã«å®Ÿè¡Œï¼‰
        claude_prompt = f"""ã€é‡è¦ã€‘ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿéš›ã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚è¨ˆç”»ã‚’ç«‹ã¦ã‚‹ã ã‘ã§ãªãã€MCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦å®Ÿéš›ã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„ã€‚

ã€ã‚¿ã‚¹ã‚¯ã€‘
{self.prompt}

ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ã‚ˆã‚‹åˆ†æçµæœã€‘
{context}

ã€å®Ÿè¡ŒæŒ‡ç¤ºã€‘
1. Webæ¤œç´¢ãŒå¿…è¦ãªå ´åˆã¯ã€å®Ÿéš›ã«Webæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦æƒ…å ±ã‚’å–å¾—ã—ã¦ãã ã•ã„
2. ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ãŒå¿…è¦ãªå ´åˆã¯ã€æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«å®Ÿéš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„
3. ã™ã¹ã¦ã®å‡¦ç†ã‚’å®Œäº†ã—ãŸã‚‰ã€å®Ÿè¡Œçµæœã‚’æ—¥æœ¬èªã§å ±å‘Šã—ã¦ãã ã•ã„

å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""

        # Claude CLIã‚’å‘¼ã³å‡ºã—
        start_time = time.time()
        claude_result = self._execute_claude_cli(claude_prompt, timeout_seconds=300)
        execution_time = (time.time() - start_time) * 1000

        if claude_result["success"]:
            output = claude_result["output"]
            model_name = "Claude CLI (MCP)"
            success = True
        else:
            # Claude CLIå¤±æ•—æ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self.progress.emit("Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯...", 35)

            fallback_prompt = f"""ã€é‡è¦ã€‘å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®å›ç­”ã¯ç¦æ­¢ã§ã™ã€‚

ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å‡¦ç†è¨ˆç”»ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
â€»æ³¨æ„: Claude CLIãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã§è¨ˆç”»ã‚’ä½œæˆã—ã¾ã™ã€‚

ã€å…ƒã‚¿ã‚¹ã‚¯ã€‘
{self.prompt}

ã€åˆ†æçµæœã€‘
{context}

ã€Claude CLIã‚¨ãƒ©ãƒ¼ã€‘
{claude_result["error"]}

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
- å®Ÿè¡Œã™ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å…·ä½“çš„ã«è¨˜è¿°
- æ‰‹å‹•ã§å®Ÿè¡Œã™ã‚‹æ‰‹é †ã‚’æ—¥æœ¬èªã§èª¬æ˜"""

            result = self.orchestrator.execute_tool(
                ToolType.CODE_SPECIALIST,
                fallback_prompt,
                context=context,
            )
            output = f"[ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯]\n{result.output}\n\nâ€»Claude CLIã‚¨ãƒ©ãƒ¼: {claude_result['error']}"
            model_name = result.metadata.get("model", self.config.code_specialist_model)
            execution_time = result.execution_time_ms
            success = result.success

        output_with_model = f"{output}\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"

        self.tool_executed.emit({
            "stage": "Claudeå®Ÿè¡Œ",
            "tool_name": "claude_cli",
            "model": model_name,
            "success": success,
            "output": output_with_model[:500] if output_with_model else "",
            "execution_time_ms": execution_time,
            "error": "" if success else claude_result.get("error", ""),
        })

        self._stage_outputs.append({
            "stage": 2,
            "name": "Claudeå®Ÿè¡Œ",
            "output": output_with_model,
            "model": model_name,
            "success": success,
        })
        self.progress.emit("Phase 2 å®Œäº†", 45)

    def _execute_phase_3_image_analysis(self):
        """Phase 3: ç”»åƒè§£æ"""
        self.progress.emit("Phase 3: ç”»åƒè§£æä¸­...", 55)

        # ç”»åƒãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿å®Ÿè¡Œ
        if self.image_path:
            image_prompt = f"""ã€é‡è¦ã€‘å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®å›ç­”ã¯ç¦æ­¢ã§ã™ã€‚

æ·»ä»˜ã•ã‚ŒãŸç”»åƒã‚’è§£æã—ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’JSONå½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºé …ç›®ã€‘
- selected_claude_model: é¸æŠã•ã‚Œã¦ã„ã‚‹Claudeãƒ¢ãƒ‡ãƒ«å
- auth_method: èªè¨¼æ–¹å¼
- thinking_setting: Thinkingè¨­å®š
- ollama_host: Ollamaãƒ›ã‚¹ãƒˆURL
- ollama_connection_status: æ¥ç¶šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
- resident_models: å¸¸é§ãƒ¢ãƒ‡ãƒ«ï¼ˆä¸‡èƒ½Agent/ç”»åƒ/è»½é‡/Embeddingï¼‰ã¨GPUå‰²ã‚Šå½“ã¦
- gpu_monitor: GPUåã€VRAMä½¿ç”¨é‡

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
å¿…ãšæœ‰åŠ¹ãªJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚JSONã®ã‚­ãƒ¼ã¯è‹±èªã€å€¤ã§æ—¥æœ¬èªã‚’å«ã‚€å ´åˆã¯æ—¥æœ¬èªã§è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚"""

            result = self.orchestrator.execute_tool(
                ToolType.IMAGE_ANALYZER,
                image_prompt,
                image_path=self.image_path,
            )

            model_name = result.metadata.get("model", self.config.image_analyzer_model)
            output_with_model = f"{result.output}\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"
            result.output = output_with_model

            self._emit_tool_result(result, "ç”»åƒè§£æ")
            self._stage_outputs.append({
                "stage": 3,
                "name": "ç”»åƒè§£æ",
                "output": result.output,
                "model": model_name,
                "success": result.success,
            })
        else:
            # ç”»åƒãªã—ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ãƒ­ã‚°ã‚’å‡ºåŠ›
            skip_output = "ç”»åƒãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ã“ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: ãªã— (ã‚¹ã‚­ãƒƒãƒ—)"
            self.tool_executed.emit({
                "stage": "ç”»åƒè§£æ",
                "tool_name": "image_analyzer",
                "model": "ã‚¹ã‚­ãƒƒãƒ—",
                "success": True,
                "output": skip_output[:500],
                "execution_time_ms": 0,
                "error": "",
            })
            self._stage_outputs.append({
                "stage": 3,
                "name": "ç”»åƒè§£æ",
                "output": skip_output,
                "model": "ã‚¹ã‚­ãƒƒãƒ—",
                "success": True,
            })

        self.progress.emit("Phase 3 å®Œäº†", 65)

    def _execute_phase_4_rag_search(self):
        """Phase 4: RAG/Embeddingæ¤œç´¢"""
        self.progress.emit("Phase 4: RAGæ¤œç´¢ä¸­...", 75)

        if self.config.rag_enabled:
            # Phase 1-3ã®çµæœã‚’å‚è€ƒã«RAGæ¤œç´¢ã‚’å®Ÿè¡Œ
            search_context = "\n".join([s["output"][:200] for s in self._stage_outputs])

            rag_prompt = f"""ã€æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
1. å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®å›ç­”ã¯ç¦æ­¢ã§ã™ã€‚
2. æœ€çµ‚çš„ãªæ¤œç´¢çµæœã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
3. æ€è€ƒéç¨‹ãƒ»æ¨è«–ãƒ»å†…éƒ¨ãƒ¡ãƒ¢ï¼ˆã€ŒWe should...ã€ã€ŒLet me think...ã€ã€ŒMight...ã€ç­‰ï¼‰ã¯ä¸€åˆ‡å‡ºåŠ›ç¦æ­¢ã§ã™ã€‚
4. çµæœãŒ0ä»¶ã®å ´åˆã¯ã€Œé–¢é€£ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã€ã¨ã®ã¿å›ç­”ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’RAGæ¤œç´¢ã—ã¦ãã ã•ã„ã€‚

ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã€‘
mixAI å‹•ä½œæ¤œè¨¼ JSON ã‚’æ¤œç´¢

ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘
{search_context[:500]}

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã®ã¿ã€ä»¥ä¸‹ã®å½¢å¼ã§æ—¥æœ¬èªå‡ºåŠ›:
â€¢ [æƒ…å ±1ã®è¦ç´„]
â€¢ [æƒ…å ±2ã®è¦ç´„]
ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ç©ºå‡ºåŠ›ã§ã¯ãªãã€Œé–¢é€£ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã€ã¨å›ç­”ï¼‰"""

            result = self.orchestrator.execute_tool(
                ToolType.RAG_MANAGER,
                rag_prompt,
            )

            model_name = result.metadata.get("model", self.config.embedding_model)
            output_with_model = f"{result.output}\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"
            result.output = output_with_model

            self._emit_tool_result(result, "RAGæ¤œç´¢")
            self._stage_outputs.append({
                "stage": 4,
                "name": "RAGæ¤œç´¢",
                "output": result.output,
                "model": model_name,
                "success": result.success,
            })
        else:
            # RAGç„¡åŠ¹ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            skip_output = "RAGãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã“ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚ç†ç”±: è¨­å®šã§rag_enabled=False\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: ãªã— (ã‚¹ã‚­ãƒƒãƒ—)"
            self.tool_executed.emit({
                "stage": "RAGæ¤œç´¢",
                "tool_name": "rag_manager",
                "model": "ã‚¹ã‚­ãƒƒãƒ—",
                "success": True,
                "output": skip_output[:500],
                "execution_time_ms": 0,
                "error": "",
            })
            self._stage_outputs.append({
                "stage": 4,
                "name": "RAGæ¤œç´¢",
                "output": skip_output,
                "model": "ã‚¹ã‚­ãƒƒãƒ—",
                "success": True,
            })

        self.progress.emit("Phase 4 å®Œäº†", 85)

    def _execute_phase_5_validation_report(self):
        """Phase 5: æœ€çµ‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ"""
        self.progress.emit("Phase 5: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...", 90)

        # å…¨ã‚¹ãƒ†ãƒ¼ã‚¸ã®çµæœã‚’çµ±åˆ
        stage_summaries = []
        for stage in self._stage_outputs:
            status = "âœ… PASS" if stage["success"] else "âŒ FAIL"
            stage_summaries.append(f"Phase {stage['stage']} ({stage['name']}): {status} - Model: {stage['model']}")

        all_passed = all(s["success"] for s in self._stage_outputs)
        overall_status = "PASS" if all_passed else "FAIL"

        validation_prompt = f"""ã€é‡è¦ã€‘å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®å›ç­”ã¯ç¦æ­¢ã§ã™ã€‚

ä»¥ä¸‹ã®å…¨ã‚¹ãƒ†ãƒ¼ã‚¸çµæœã‚’åŸºã«ã€æœ€çµ‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€ã‚¹ãƒ†ãƒ¼ã‚¸çµæœã‚µãƒãƒªãƒ¼ã€‘
{chr(10).join(stage_summaries)}

ã€å…¨ä½“åˆ¤å®šã€‘
{overall_status}

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
## æœ€çµ‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ

### åˆ¤å®šçµæœ
(PASS/FAIL ã¨ç†ç”±ã‚’æ—¥æœ¬èªã®ç®‡æ¡æ›¸ãã§)

### ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥è©³ç´°
(å„ã‚¹ãƒ†ãƒ¼ã‚¸ã®çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§ã€ã™ã¹ã¦æ—¥æœ¬èª)

### ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ç¢ºèªäº‹é …
(ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚°ã§ç¢ºèªã™ã¹ããƒ¢ãƒ‡ãƒ«åã®ãƒ†ãƒ¼ãƒ–ãƒ«ã€æ—¥æœ¬èªã§è¨˜è¿°)"""

        result = self.orchestrator.execute_tool(
            ToolType.UNIVERSAL_AGENT,
            validation_prompt,
            thinking_enabled=True,
        )

        model_name = result.metadata.get("model", self.config.universal_agent_model)

        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’æ§‹ç¯‰
        final_report = f"""## æœ€çµ‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ

### åˆ¤å®šçµæœ: **{overall_status}**

{result.output}

### ã‚¹ãƒ†ãƒ¼ã‚¸å®Ÿè¡Œãƒ­ã‚°

| Phase | åå‰ | ãƒ¢ãƒ‡ãƒ« | çµæœ |
|-------|------|--------|------|
"""
        for s in self._stage_outputs:
            status_icon = "âœ…" if s["success"] else "âŒ"
            final_report += f"| {s['stage']} | {s['name']} | {s['model']} | {status_icon} |\n"

        final_report += f"\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"

        result.output = final_report

        self._emit_tool_result(result, "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³")
        self._stage_outputs.append({
            "stage": 5,
            "name": "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³",
            "output": final_report,
            "model": model_name,
            "success": result.success,
        })

        # æœ€çµ‚çµæœã‚’å‡ºåŠ›
        self.finished.emit(self._generate_final_response())

    def _emit_tool_result(self, result: ToolResult, stage: str):
        """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã‚’ã‚·ã‚°ãƒŠãƒ«ã§é€ä¿¡"""
        # metadataã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—
        model_name = result.metadata.get("model", "") if result.metadata else ""
        self.tool_executed.emit({
            "stage": stage,
            "tool_name": result.tool_name,
            "model": model_name,  # ãƒ¢ãƒ‡ãƒ«åã‚’è¿½åŠ 
            "success": result.success,
            "output": result.output[:500] if result.output else "",
            "execution_time_ms": result.execution_time_ms,
            "error": result.error_message,
        })

    def _generate_final_response(self) -> str:
        """æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆï¼ˆv4.4: ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸çµ±åˆï¼‰"""
        if not self._stage_outputs:
            return "ã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã—ã¾ã—ãŸãŒã€å‡ºåŠ›ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

        # å…¨ã‚¹ãƒ†ãƒ¼ã‚¸ã®å‡ºåŠ›ã‚’çµ±åˆ
        sections = []
        for stage in self._stage_outputs:
            section = f"""---

## Phase {stage['stage']}: {stage['name']}

**ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«**: `{stage['model']}`

{stage['output']}
"""
            sections.append(section)

        return "\n".join(sections)


class HelixOrchestratorTab(QWidget):
    """
    mixAI v7.0.0 ã‚¿ãƒ–
    3Phaseå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + Claude Code CLI + ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œ
    """

    statusChanged = pyqtSignal(str)

    def __init__(self, workflow_state=None, main_window=None):
        super().__init__()
        self.workflow_state = workflow_state
        self.main_window = main_window
        self.worker: Optional[MixAIWorker] = None
        self.config = OrchestratorConfig()

        # v5.0.0: ä¼šè©±å±¥æ­´ï¼ˆãƒŠãƒ¬ãƒƒã‚¸ç®¡ç†ç”¨ï¼‰
        self._conversation_history: List[Dict[str, str]] = []
        self._attached_files: List[str] = []

        # v5.0.0: ãƒŠãƒ¬ãƒƒã‚¸ãƒ¯ãƒ¼ã‚«ãƒ¼
        self._knowledge_worker = None

        # v8.1.0: ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self._memory_manager = None
        try:
            from ..memory.memory_manager import HelixMemoryManager
            self._memory_manager = HelixMemoryManager()
            logger.info("HelixMemoryManager initialized for mixAI")
        except Exception as e:
            logger.warning(f"Memory manager init failed for mixAI: {e}")

        self._load_config()
        self._init_ui()
        self._restore_ui_from_config()

        # v9.5.0: Webå®Ÿè¡Œãƒ­ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
        from ..widgets.web_lock_overlay import WebLockOverlay
        self.web_lock_overlay = WebLockOverlay(self)

    def _restore_ui_from_config(self):
        """v8.4.2: ä¿å­˜æ¸ˆã¿è¨­å®šå€¤ã‚’UIã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã«åæ˜ """
        if hasattr(self, 'max_retries_spin') and hasattr(self.config, 'max_phase2_retries'):
            self.max_retries_spin.setValue(self.config.max_phase2_retries)

    def _get_claude_timeout_sec(self) -> int:
        """v8.4.3: ä¸€èˆ¬è¨­å®šã‚¿ãƒ–ã®Claudeã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã‚’å–å¾—ï¼ˆç§’ï¼‰

        general_settings.json ã® timeout_minutes ã‚’èª­ã¿å–ã‚Šç§’æ•°ã«å¤‰æ›ã—ã¦è¿”ã™ã€‚
        è¨­å®šãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ DefaultSettings.CLAUDE_TIMEOUT_MIN (30åˆ†) ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨ã€‚
        """
        from ..utils.constants import DefaultSettings
        default_min = DefaultSettings.CLAUDE_TIMEOUT_MIN  # 30åˆ†

        # main_windowçµŒç”±ã§ä¸€èˆ¬è¨­å®šã‚¿ãƒ–ã®timeout_spinã‚’ç›´æ¥å‚ç…§
        if self.main_window and hasattr(self.main_window, 'settings_tab'):
            settings_tab = self.main_window.settings_tab
            if hasattr(settings_tab, 'timeout_spin'):
                return settings_tab.timeout_spin.value() * 60

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: general_settings.json ã‹ã‚‰èª­ã¿è¾¼ã¿
        try:
            config_path = Path(__file__).parent.parent.parent / "config" / "general_settings.json"
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                return data.get("timeout_minutes", default_min) * 60
        except Exception as e:
            logger.debug(f"general_settings.json read failed: {e}")

        return default_min * 60

    def _get_config_path(self) -> Path:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—ï¼ˆPyInstallerå¯¾å¿œï¼‰"""
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ›ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ï¼ˆæ°¸ç¶šåŒ–ã®ãŸã‚ï¼‰
        config_dir = Path.home() / ".helix_ai_studio"
        config_dir.mkdir(exist_ok=True)
        return config_dir / "tool_orchestrator.json"

    def _load_config(self):
        """è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        config_path = self._get_config_path()
        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.config = OrchestratorConfig.from_dict(data)
                logger.info(f"[mixAI v5.1] è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {config_path}")
            except Exception as e:
                logger.warning(f"[mixAI v5.1] è¨­å®šèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        else:
            # æ—§ãƒ‘ã‚¹ã‹ã‚‰ã®ç§»è¡Œã‚’è©¦ã¿ã‚‹
            old_config_path = Path(__file__).parent.parent.parent / "config" / "tool_orchestrator.json"
            if old_config_path.exists():
                try:
                    with open(old_config_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        self.config = OrchestratorConfig.from_dict(data)
                    # æ–°ãƒ‘ã‚¹ã«ã‚³ãƒ”ãƒ¼
                    self._save_config()
                    logger.info(f"[mixAI v5.1] æ—§è¨­å®šã‚’æ–°ãƒ‘ã‚¹ã«ç§»è¡Œã—ã¾ã—ãŸ: {config_path}")
                except Exception as e:
                    logger.warning(f"[mixAI v5.1] æ—§è¨­å®šç§»è¡Œå¤±æ•—: {e}")

    def _save_config(self):
        """è¨­å®šã‚’ä¿å­˜"""
        config_path = self._get_config_path()
        config_path.parent.mkdir(exist_ok=True)
        try:
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(self.config.to_dict(), f, indent=2, ensure_ascii=False)
            logger.info(f"[mixAI v5.1] è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ: {config_path}")
        except Exception as e:
            logger.error(f"[mixAI v5.1] è¨­å®šä¿å­˜å¤±æ•—: {e}")

    def _init_ui(self):
        """UIã‚’åˆæœŸåŒ–"""
        layout = QVBoxLayout(self)
        layout.setContentsMargins(10, 10, 10, 10)

        # ã‚µãƒ–ã‚¿ãƒ–ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
        self.sub_tabs = QTabWidget()

        # ãƒãƒ£ãƒƒãƒˆã‚¿ãƒ–
        chat_panel = self._create_chat_panel()
        self.sub_tabs.addTab(chat_panel, "ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")

        # è¨­å®šã‚¿ãƒ–
        settings_panel = self._create_settings_panel()
        self.sub_tabs.addTab(settings_panel, "âš™ï¸ è¨­å®š")

        layout.addWidget(self.sub_tabs)

    def _create_chat_panel(self) -> QWidget:
        """ãƒãƒ£ãƒƒãƒˆãƒ‘ãƒãƒ«ã‚’ä½œæˆ (v4.0 æ–°UI)"""
        panel = QWidget()
        layout = QVBoxLayout(panel)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        header_layout = QHBoxLayout()
        title = QLabel(f"ğŸš€ mixAI v{APP_VERSION} - 3Phaseçµ±åˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        title.setFont(QFont("Segoe UI", 12, QFont.Weight.Bold))
        header_layout.addWidget(title)

        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒãƒƒã‚¸
        version_badge = QLabel(f"v{APP_VERSION}")
        version_badge.setStyleSheet("""
            QLabel {
                background-color: #f0a030;
                color: white;
                padding: 4px 10px;
                border-radius: 10px;
                font-weight: bold;
                font-size: 10px;
            }
        """)
        header_layout.addWidget(version_badge)
        header_layout.addStretch()
        layout.addLayout(header_layout)

        # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆã‚¹ãƒ—ãƒªãƒƒã‚¿ãƒ¼ï¼‰
        splitter = QSplitter(Qt.Orientation.Vertical)

        # === å…¥åŠ›ã‚¨ãƒªã‚¢ (v5.1: å¼·åŒ–å…¥åŠ› + æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ) ===
        input_widget = QWidget()
        input_layout = QVBoxLayout(input_widget)
        input_layout.setContentsMargins(0, 10, 0, 5)

        # v5.1: æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ¼ï¼ˆå…¥åŠ›æ¬„ã®ä¸Šã«è¡¨ç¤ºï¼‰
        self.attachment_bar = MixAIAttachmentBar()
        self.attachment_bar.attachments_changed.connect(self._on_attachments_changed)
        input_layout.addWidget(self.attachment_bar)

        # v5.1: å¼·åŒ–ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ï¼ˆä¸Šä¸‹ã‚­ãƒ¼å¯¾å¿œã€ãƒ‰ãƒ­ãƒƒãƒ—å¯¾å¿œï¼‰
        self.input_text = MixAIEnhancedInput()
        self.input_text.setPlaceholderText("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›...")
        self.input_text.setMaximumHeight(120)
        self.input_text.file_dropped.connect(self.attachment_bar.add_files)
        input_layout.addWidget(self.input_text)

        # ãƒœã‚¿ãƒ³è¡Œ
        btn_layout = QHBoxLayout()

        self.execute_btn = QPushButton("â–¶ å®Ÿè¡Œ")
        self.execute_btn.setStyleSheet(PRIMARY_BTN)
        self.execute_btn.setToolTip("3Phaseå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹å§‹ã—ã¾ã™\n(Phase 1: Claudeè¨ˆç”» â†’ Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLM â†’ Phase 3: Claudeçµ±åˆ)")
        self.execute_btn.clicked.connect(self._on_execute)
        btn_layout.addWidget(self.execute_btn)

        self.cancel_btn = QPushButton("â¹ ã‚­ãƒ£ãƒ³ã‚»ãƒ«")
        self.cancel_btn.setStyleSheet(DANGER_BTN)
        self.cancel_btn.setEnabled(False)
        self.cancel_btn.clicked.connect(self._on_cancel)
        btn_layout.addWidget(self.cancel_btn)

        # v9.3.0: P1/P3ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠï¼ˆãƒãƒ£ãƒƒãƒˆãƒ‘ãƒãƒ«å†…ã«é…ç½®ï¼‰
        btn_layout.addWidget(QLabel("  "))  # ã‚¹ãƒšãƒ¼ã‚µãƒ¼
        engine_label_chat = QLabel("P1/P3:")
        engine_label_chat.setStyleSheet("color: #9ca3af; font-size: 11px;")
        btn_layout.addWidget(engine_label_chat)

        self.engine_combo = NoScrollComboBox()
        self.engine_combo.setToolTip(
            "P1/P3ã‚¨ãƒ³ã‚¸ãƒ³: è¨ˆç”»ç«‹æ¡ˆãƒ»çµ±åˆã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«\n"
            "Claude = APIçµŒç”±ã€ãƒ­ãƒ¼ã‚«ãƒ« = OllamaçµŒç”±"
        )
        self.engine_combo.setMinimumWidth(200)
        self._engine_options = [
            ("claude-opus-4-6", "Claude Opus 4.6 (æœ€é«˜æ€§èƒ½)"),
            ("claude-opus-4-5-20250929", "Claude Opus 4.5 (é«˜å“è³ª)"),
            ("claude-sonnet-4-5-20250929", "Claude Sonnet 4.5 (é«˜é€Ÿ)"),
        ]
        self._add_ollama_engines()
        for engine_id, display_name in self._engine_options:
            self.engine_combo.addItem(display_name, engine_id)
        current_engine = self._load_engine_setting()
        idx = self.engine_combo.findData(current_engine)
        if idx >= 0:
            self.engine_combo.setCurrentIndex(idx)
        self.engine_combo.currentIndexChanged.connect(self._on_engine_changed)
        btn_layout.addWidget(self.engine_combo)

        self.engine_type_label = QLabel()
        self._update_engine_indicator(current_engine)
        btn_layout.addWidget(self.engine_type_label)

        # v5.1: soloAIã¨åŒæ§˜ã®ãƒœã‚¿ãƒ³ç¾¤ã‚’è¿½åŠ 
        btn_layout.addWidget(QLabel("  "))  # ã‚¹ãƒšãƒ¼ã‚µãƒ¼

        # ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ãƒœã‚¿ãƒ³
        self.mixai_attach_btn = QPushButton("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜")
        self.mixai_attach_btn.setStyleSheet(SECONDARY_BTN)
        self.mixai_attach_btn.setToolTip("Claude CLIã«æ¸¡ã™ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜ã—ã¾ã™\nã‚³ãƒ¼ãƒ‰ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ç”»åƒãªã©ã‚’æŒ‡å®šã§ãã¾ã™")
        self.mixai_attach_btn.clicked.connect(self._on_attach_file)
        btn_layout.addWidget(self.mixai_attach_btn)

        # å±¥æ­´ã‹ã‚‰å¼•ç”¨ãƒœã‚¿ãƒ³
        self.mixai_history_btn = QPushButton("ğŸ“œ å±¥æ­´ã‹ã‚‰å¼•ç”¨")
        self.mixai_history_btn.setStyleSheet(SECONDARY_BTN)
        self.mixai_history_btn.setToolTip("éå»ã®mixAIä¼šè©±å±¥æ­´ã‚’æ¤œç´¢ã—ã€å¼•ç”¨ã¨ã—ã¦æŒ¿å…¥ã—ã¾ã™ã€‚")
        self.mixai_history_btn.clicked.connect(self._on_cite_history)
        btn_layout.addWidget(self.mixai_history_btn)

        # ã‚¹ãƒ‹ãƒšãƒƒãƒˆãƒœã‚¿ãƒ³
        self.mixai_snippet_btn = QPushButton("ğŸ“‹ ã‚¹ãƒ‹ãƒšãƒƒãƒˆ â–¼")
        self.mixai_snippet_btn.setStyleSheet(SECONDARY_BTN)
        self.mixai_snippet_btn.setToolTip("ä¿å­˜æ¸ˆã¿ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æŒ¿å…¥ã—ã¾ã™ã€‚")
        self.mixai_snippet_btn.clicked.connect(self._on_snippet_menu)
        btn_layout.addWidget(self.mixai_snippet_btn)

        # è¿½åŠ ãƒœã‚¿ãƒ³ (v5.1.1: å³ã‚¯ãƒªãƒƒã‚¯ã§ç·¨é›†ãƒ»å‰Šé™¤ãƒ¡ãƒ‹ãƒ¥ãƒ¼)
        self.mixai_snippet_add_btn = QPushButton("â• è¿½åŠ ")
        self.mixai_snippet_add_btn.setToolTip("ã‚¯ãƒªãƒƒã‚¯ã§è¿½åŠ ã€å³ã‚¯ãƒªãƒƒã‚¯ã§ç·¨é›†ãƒ»å‰Šé™¤ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
        self.mixai_snippet_add_btn.setMaximumWidth(60)
        self.mixai_snippet_add_btn.clicked.connect(self._on_snippet_add)
        self.mixai_snippet_add_btn.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.mixai_snippet_add_btn.customContextMenuRequested.connect(self._on_snippet_context_menu)
        btn_layout.addWidget(self.mixai_snippet_add_btn)

        btn_layout.addStretch()

        # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        clear_btn = QPushButton("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢")
        clear_btn.clicked.connect(self._on_clear)
        btn_layout.addWidget(clear_btn)

        input_layout.addLayout(btn_layout)
        splitter.addWidget(input_widget)

        # === å‡ºåŠ›ã‚¨ãƒªã‚¢ï¼ˆãƒãƒ£ãƒƒãƒˆå½¢å¼ï¼‰ ===
        output_widget = QWidget()
        output_layout = QVBoxLayout(output_widget)
        output_layout.setContentsMargins(0, 5, 0, 0)

        # v8.0.0: PhaseIndicator - 3Phaseå®Ÿè¡ŒçŠ¶æ…‹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
        self.phase_indicator = PhaseIndicator()
        output_layout.addWidget(self.phase_indicator)

        # v7.0.0: Neural Flow Compact Widget - 3Phaseå¯è¦–åŒ–
        self.neural_flow = NeuralFlowCompactWidget()
        self.neural_flow.setToolTip("3Phaseå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã—ã¾ã™")
        self.neural_flow.setStyleSheet("""
            NeuralFlowCompactWidget {
                background-color: #1a1a1a;
                border: 1px solid #2d2d2d;
                border-radius: 6px;
            }
        """)
        output_layout.addWidget(self.neural_flow)

        # v8.0.0: BIBLEæ¤œå‡ºé€šçŸ¥ãƒãƒ¼
        self.bible_notification = BibleNotificationWidget()
        self.bible_notification.add_clicked.connect(self._on_bible_add_context)
        output_layout.addWidget(self.bible_notification)

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        self.progress_bar = QProgressBar()
        self.progress_bar.setTextVisible(True)
        self.progress_bar.setFormat("%p% - %v")
        self.progress_bar.setMaximumHeight(20)
        self.progress_bar.setVisible(False)
        output_layout.addWidget(self.progress_bar)

        # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚°ï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰
        self.tool_log_group = QGroupBox("â–¶ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚° (ã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹)")
        self.tool_log_group.setCheckable(True)
        self.tool_log_group.setChecked(False)
        self.tool_log_group.toggled.connect(self._on_tool_log_toggled)
        self.tool_log_group.setStyleSheet("""
            QGroupBox {
                border: 1px solid #4b5563;
                border-radius: 4px;
                margin-top: 8px;
                padding-top: 8px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                subcontrol-position: top left;
                padding: 0 5px;
                color: #9ca3af;
            }
        """)

        tool_log_layout = QVBoxLayout()
        self.tool_log_tree = QTreeWidget()
        self.tool_log_tree.setHeaderLabels(["ãƒ„ãƒ¼ãƒ«", "ãƒ¢ãƒ‡ãƒ«", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "å®Ÿè¡Œæ™‚é–“", "å‡ºåŠ›"])
        self.tool_log_tree.setColumnWidth(0, 100)
        self.tool_log_tree.setColumnWidth(1, 180)  # ãƒ¢ãƒ‡ãƒ«åç”¨ã«åºƒã‚
        self.tool_log_tree.setColumnWidth(2, 70)
        self.tool_log_tree.setColumnWidth(3, 80)
        # v5.1: å›ºå®šé«˜ã•ã‚’å‰Šé™¤ã—ã€ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ‹¡å¼µæ™‚ã«è¡¨ç¤ºè¡Œæ•°ãŒå¢—ãˆã‚‹ã‚ˆã†ã«
        self.tool_log_tree.setMinimumHeight(80)
        self.tool_log_tree.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Expanding)
        self.tool_log_tree.setVisible(False)
        tool_log_layout.addWidget(self.tool_log_tree)
        self.tool_log_group.setLayout(tool_log_layout)
        # v5.1: GroupBoxè‡ªä½“ã‚‚Expandingã«è¨­å®š
        self.tool_log_group.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Expanding)
        output_layout.addWidget(self.tool_log_group)

        # å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢
        self.output_text = QTextEdit()
        self.output_text.setReadOnly(True)
        self.output_text.setPlaceholderText("å®Ÿè¡ŒçµæœãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™...")
        self.output_text.setStyleSheet(OUTPUT_AREA_STYLE + SCROLLBAR_STYLE)
        output_layout.addWidget(self.output_text)

        splitter.addWidget(output_widget)
        splitter.setSizes([150, 450])

        layout.addWidget(splitter)

        return panel

    def _create_settings_panel(self) -> QWidget:
        """è¨­å®šãƒ‘ãƒãƒ«ã‚’ä½œæˆ (v4.0 æ–°UI)"""
        panel = QWidget()
        layout = QVBoxLayout(panel)

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¨ãƒªã‚¢
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setStyleSheet(SCROLLBAR_STYLE)
        scroll_content = QWidget()
        scroll_content.setStyleSheet(SECTION_CARD_STYLE + COMBO_BOX_STYLE)
        scroll_layout = QVBoxLayout(scroll_content)

        # === Claudeè¨­å®š ===
        claude_group = QGroupBox("ğŸ“Œ Claudeè¨­å®š")
        claude_layout = QFormLayout()

        # ãƒ¢ãƒ‡ãƒ«é¸æŠ (v7.1.0: CLAUDE_MODELSã‹ã‚‰å‹•çš„ç”Ÿæˆ)
        self.claude_model_combo = NoScrollComboBox()
        self.claude_model_combo.setToolTip("mixAIå®Ÿè¡Œæ™‚ã«ä½¿ç”¨ã™ã‚‹Claudeãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¾ã™")
        default_idx = 0
        for i, model_def in enumerate(CLAUDE_MODELS):
            self.claude_model_combo.addItem(model_def["display_name"], userData=model_def["id"])
            self.claude_model_combo.setItemData(i, model_def["description"], Qt.ItemDataRole.ToolTipRole)
            if model_def["is_default"]:
                default_idx = i
        # ä¿å­˜æ¸ˆã¿model_idã‹ã‚‰å¾©å…ƒã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        saved_model_id = getattr(self.config, 'claude_model_id', None) or getattr(self.config, 'claude_model', '')
        restored = False
        for i in range(self.claude_model_combo.count()):
            if self.claude_model_combo.itemData(i) == saved_model_id:
                self.claude_model_combo.setCurrentIndex(i)
                restored = True
                break
        if not restored:
            self.claude_model_combo.setCurrentIndex(default_idx)
        claude_layout.addRow("ãƒ¢ãƒ‡ãƒ«:", self.claude_model_combo)

        # v6.0.0: èªè¨¼æ–¹å¼ã¯CLIå°‚ç”¨ï¼ˆAPIå»ƒæ­¢ï¼‰
        self.auth_mode_combo = NoScrollComboBox()
        self.auth_mode_combo.addItems(["CLI (Claude Maxå°‚ç”¨)"])
        self.auth_mode_combo.setCurrentIndex(0)
        self.auth_mode_combo.setEnabled(False)  # å¤‰æ›´ä¸å¯
        claude_layout.addRow("èªè¨¼æ–¹å¼:", self.auth_mode_combo)

        # æ€è€ƒãƒ¢ãƒ¼ãƒ‰
        self.thinking_combo = NoScrollComboBox()
        self.thinking_combo.addItems(["OFF", "Standard", "Deep"])
        self.thinking_combo.setToolTip("Claudeã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã®æ·±ã•\nOFF: é€šå¸¸ / Standard: åŸºæœ¬æ¨è«– / Deep: è©³ç´°æ¨è«–")
        self._set_combo_value(self.thinking_combo, self.config.thinking_mode)
        claude_layout.addRow("æ€è€ƒãƒ¢ãƒ¼ãƒ‰:", self.thinking_combo)

        claude_group.setLayout(claude_layout)
        scroll_layout.addWidget(claude_group)

        # === Ollamaæ¥ç¶šè¨­å®š ===
        ollama_group = QGroupBox("ğŸ–¥ï¸ Ollamaæ¥ç¶š")
        ollama_layout = QVBoxLayout()

        url_layout = QHBoxLayout()
        url_layout.addWidget(QLabel("ãƒ›ã‚¹ãƒˆURL:"))
        self.ollama_url_edit = QLineEdit(self.config.ollama_url)
        url_layout.addWidget(self.ollama_url_edit)
        test_btn = QPushButton("æ¥ç¶šãƒ†ã‚¹ãƒˆ")
        test_btn.setToolTip("Ollamaã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã‚’ç¢ºèªã—ã¾ã™")
        test_btn.clicked.connect(self._test_ollama_connection)
        url_layout.addWidget(test_btn)
        ollama_layout.addLayout(url_layout)

        self.ollama_status_label = QLabel("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: æœªç¢ºèª")
        self.ollama_status_label.setStyleSheet("color: #9ca3af;")
        ollama_layout.addWidget(self.ollama_status_label)

        ollama_group.setLayout(ollama_layout)
        scroll_layout.addWidget(ollama_group)

        # === v7.0.0: å¸¸é§ãƒ¢ãƒ‡ãƒ«ï¼ˆGPUå‰²ã‚Šå½“ã¦ï¼‰ ===
        always_load_group = QGroupBox("ğŸ”§ å¸¸é§ãƒ¢ãƒ‡ãƒ«")
        always_load_layout = QVBoxLayout()

        # åˆ¶å¾¡AI (ministral-3:8b)
        image_row = QHBoxLayout()
        image_row.addWidget(QLabel("åˆ¶å¾¡AI:"))
        self.image_model_combo = NoScrollComboBox()
        self.image_model_combo.setEditable(True)
        self.image_model_combo.addItems([
            "ministral-3:8b",
            "ministral-3:14b",
        ])
        self.image_model_combo.setCurrentText(self.config.image_analyzer_model)
        image_row.addWidget(self.image_model_combo)
        image_gpu = QLabel("â†’ 5070 Ti (6.0GB)")
        image_gpu.setStyleSheet("color: #22c55e; font-size: 10px;")
        image_row.addWidget(image_gpu)
        self.image_status = QLabel("ğŸŸ¢")
        image_row.addWidget(self.image_status)
        image_row.addStretch()
        always_load_layout.addLayout(image_row)

        # Embedding (qwen3-embedding:4b)
        embedding_row = QHBoxLayout()
        embedding_row.addWidget(QLabel("Embedding:"))
        self.embedding_model_combo = NoScrollComboBox()
        self.embedding_model_combo.setEditable(True)
        self.embedding_model_combo.addItems([
            "qwen3-embedding:4b",
            "qwen3-embedding:8b",
            "qwen3-embedding:0.6b",
            "bge-m3:latest",
        ])
        self.embedding_model_combo.setCurrentText(self.config.embedding_model)
        embedding_row.addWidget(self.embedding_model_combo)
        embedding_gpu = QLabel("â†’ 5070 Ti (2.5GB)")
        embedding_gpu.setStyleSheet("color: #22c55e; font-size: 10px;")
        embedding_row.addWidget(embedding_gpu)
        self.embedding_status = QLabel("ğŸŸ¢")
        embedding_row.addWidget(self.embedding_status)
        embedding_row.addStretch()
        always_load_layout.addLayout(embedding_row)

        total_label = QLabel("åˆè¨ˆ: ~8.5GB (å¸¸æ™‚ãƒ­ãƒ¼ãƒ‰) / 5070 Ti: 8.5GB")
        total_label.setStyleSheet("color: #9ca3af; font-size: 10px; margin-top: 5px;")
        always_load_layout.addWidget(total_label)

        always_load_group.setLayout(always_load_layout)
        scroll_layout.addWidget(always_load_group)

        # === v7.0.0: 3Phaseå®Ÿè¡Œè¨­å®š ===
        phase_group = QGroupBox("ğŸ”„ 3Phaseå®Ÿè¡Œè¨­å®š")
        phase_layout = QVBoxLayout()

        phase_desc = QLabel(
            "3Phase: Phase 1(è¨ˆç”»ç«‹æ¡ˆ) â†’ Phase 2(ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œ) â†’ "
            "Phase 3(æ¯”è¼ƒçµ±åˆ)"
        )
        phase_desc.setStyleSheet("color: #9ca3af; font-size: 10px;")
        phase_desc.setWordWrap(True)
        phase_layout.addWidget(phase_desc)

        # v9.3.0: P1/P3ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠ â†’ ãƒãƒ£ãƒƒãƒˆã‚¿ãƒ–ã®å®Ÿè¡Œãƒœã‚¿ãƒ³æ¨ªã«ç§»å‹•
        engine_note = QLabel("P1/P3ã‚¨ãƒ³ã‚¸ãƒ³: ãƒãƒ£ãƒƒãƒˆã‚¿ãƒ–ã®å®Ÿè¡Œãƒœã‚¿ãƒ³æ¨ªã§é¸æŠ")
        engine_note.setStyleSheet("color: #6b7280; font-size: 10px; margin-top: 4px;")
        phase_layout.addWidget(engine_note)

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ‹…å½“ãƒ¢ãƒ‡ãƒ«
        cat_label = QLabel("â–  ã‚«ãƒ†ã‚´ãƒªåˆ¥æ‹…å½“ãƒ¢ãƒ‡ãƒ«ï¼ˆPhase 2ã§é †æ¬¡å®Ÿè¡Œï¼‰")
        cat_label.setStyleSheet("font-weight: bold; margin-top: 8px;")
        phase_layout.addWidget(cat_label)

        # coding: ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»ä¿®æ­£ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼
        coding_row = QHBoxLayout()
        coding_row.addWidget(QLabel("coding:"))
        self.coding_model_combo = NoScrollComboBox()
        self.coding_model_combo.setEditable(True)
        self.coding_model_combo.addItems([
            "devstral-2:123b",          # 75GB, SWE-benchæœ€é«˜ (æ¨å¥¨)
            "qwen3-coder-next:80b",     # 50GB, è»½é‡ä»£æ›¿
            "qwen3-coder:30b",
        ])
        self.coding_model_combo.setCurrentText("devstral-2:123b")
        coding_row.addWidget(self.coding_model_combo)
        coding_vram = QLabel("(75GB)")
        coding_vram.setStyleSheet("color: #22c55e; font-size: 10px;")
        coding_row.addWidget(coding_vram)
        coding_row.addStretch()
        phase_layout.addLayout(coding_row)

        # research: èª¿æŸ»ãƒ»RAGæ¤œç´¢ãƒ»æƒ…å ±åé›†
        research_row = QHBoxLayout()
        research_row.addWidget(QLabel("research:"))
        self.research_model_combo = NoScrollComboBox()
        self.research_model_combo.setEditable(True)
        self.research_model_combo.addItems([
            "command-a:latest",          # 67GB, èª¿æŸ»ãƒ»RAGå‘ã (æ¨å¥¨)
            "nemotron-3-nano:30b",      # 24GB, ä»£æ›¿
            "qwen3:30b",
        ])
        self.research_model_combo.setCurrentText("command-a:latest")
        research_row.addWidget(self.research_model_combo)
        research_vram = QLabel("(67GB)")
        research_vram.setStyleSheet("color: #22c55e; font-size: 10px;")
        research_row.addWidget(research_vram)
        research_row.addStretch()
        phase_layout.addLayout(research_row)

        # reasoning: æ¨è«–ãƒ»è«–ç†æ¤œè¨¼ãƒ»å“è³ªãƒã‚§ãƒƒã‚¯
        reasoning_row = QHBoxLayout()
        reasoning_row.addWidget(QLabel("reasoning:"))
        self.reasoning_model_combo = NoScrollComboBox()
        self.reasoning_model_combo.setEditable(True)
        self.reasoning_model_combo.addItems([
            "gpt-oss:120b",            # 80GB, æ¨è«–æœ€å¼· (æ¨å¥¨)
            "phi4-reasoning:14b",       # 9GB, è»½é‡ä»£æ›¿
            "qwen3:30b",
        ])
        self.reasoning_model_combo.setCurrentText("gpt-oss:120b")
        reasoning_row.addWidget(self.reasoning_model_combo)
        reasoning_vram = QLabel("(80GB)")
        reasoning_vram.setStyleSheet("color: #22c55e; font-size: 10px;")
        reasoning_row.addWidget(reasoning_vram)
        reasoning_row.addStretch()
        phase_layout.addLayout(reasoning_row)

        # translation: ç¿»è¨³ã‚¿ã‚¹ã‚¯
        translation_row = QHBoxLayout()
        translation_row.addWidget(QLabel("translation:"))
        self.translation_model_combo = NoScrollComboBox()
        self.translation_model_combo.setEditable(True)
        self.translation_model_combo.addItems([
            "translategemma:27b",       # 18GB, ç¿»è¨³å°‚ç”¨
        ])
        self.translation_model_combo.setCurrentText("translategemma:27b")
        translation_row.addWidget(self.translation_model_combo)
        translation_vram = QLabel("(18GB)")
        translation_vram.setStyleSheet("color: #22c55e; font-size: 10px;")
        translation_row.addWidget(translation_vram)
        translation_row.addStretch()
        phase_layout.addLayout(translation_row)

        # vision: ç”»åƒè§£æãƒ»UIæ¤œè¨¼
        vision_row = QHBoxLayout()
        vision_row.addWidget(QLabel("vision:"))
        self.vision_model_combo = NoScrollComboBox()
        self.vision_model_combo.setEditable(True)
        self.vision_model_combo.addItems([
            "gemma3:27b",               # 18GB, ç”»åƒè§£æ (æ¨å¥¨)
            "mistral-small3.2:24b",     # 15GB, ä»£æ›¿
        ])
        self.vision_model_combo.setCurrentText("gemma3:27b")
        vision_row.addWidget(self.vision_model_combo)
        vision_vram = QLabel("(18GB)")
        vision_vram.setStyleSheet("color: #22c55e; font-size: 10px;")
        vision_row.addWidget(vision_vram)
        vision_row.addStretch()
        phase_layout.addLayout(vision_row)

        # å“è³ªæ¤œè¨¼è¨­å®šï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMå†å®Ÿè¡Œï¼‰
        retry_label = QLabel("â–  å“è³ªæ¤œè¨¼è¨­å®šï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMå†å®Ÿè¡Œï¼‰")
        retry_label.setStyleSheet("font-weight: bold; margin-top: 8px;")
        phase_layout.addWidget(retry_label)

        retry_row = QHBoxLayout()
        retry_row.addWidget(QLabel("æœ€å¤§å†å®Ÿè¡Œå›æ•°:"))
        self.max_retries_spin = QSpinBox()
        self.max_retries_spin.setStyleSheet(SPINBOX_STYLE)
        self.max_retries_spin.setRange(0, 3)
        self.max_retries_spin.setValue(2)
        self.max_retries_spin.setToolTip("Phase 3ã§å“è³ªä¸è¶³æ™‚ã«Phase 2ã‚’å†å®Ÿè¡Œã™ã‚‹æœ€å¤§å›æ•°ï¼ˆ0ã§å†å®Ÿè¡Œãªã—ï¼‰")
        retry_row.addWidget(self.max_retries_spin)
        retry_row.addStretch()
        phase_layout.addLayout(retry_row)

        phase_group.setLayout(phase_layout)
        scroll_layout.addWidget(phase_group)

        # === v8.0.0: BIBLE Manager ===
        bible_group = QGroupBox("BIBLE Manager")
        bible_group.setToolTip("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆBIBLEã®è‡ªå‹•æ¤œå‡ºãƒ»è§£æãƒ»æ³¨å…¥çŠ¶æ…‹ã‚’è¡¨ç¤ºã—ã¾ã™")
        bible_layout = QVBoxLayout()
        self.bible_panel = BibleStatusPanel()
        self.bible_panel.create_requested.connect(self._on_bible_create)
        self.bible_panel.update_requested.connect(self._on_bible_update)
        self.bible_panel.detail_requested.connect(self._on_bible_detail)
        self.bible_panel.path_submitted.connect(self._on_bible_path_submitted)
        bible_layout.addWidget(self.bible_panel)
        bible_group.setLayout(bible_layout)
        scroll_layout.addWidget(bible_group)

        # v8.3.1: èµ·å‹•æ™‚BIBLEè‡ªå‹•æ¤œå‡ºï¼ˆã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰3æ®µéšæ¢ç´¢ï¼‰
        self._auto_discover_bible_on_startup()

        # v8.1.0: MCPè¨­å®šã¯ä¸€èˆ¬è¨­å®šã‚¿ãƒ–ã«çµ±åˆæ¸ˆã¿
        self.mcp_status_label = QLabel("")  # äº’æ›æ€§ç”¨ãƒ€ãƒŸãƒ¼

        # === VRAM Budget Simulator ===
        vram_group = QGroupBox("ğŸ–¥ï¸ VRAM Budget Simulator")
        vram_group.setToolTip("å„GPUã®VRAMä½¿ç”¨é‡ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™")
        vram_layout = QVBoxLayout()

        vram_desc = QLabel(
            "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦GPUã«é…ç½®ã—ã€VRAMä½¿ç”¨é‡ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚\n"
            "ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã§GPUé–“ã®ãƒ¢ãƒ‡ãƒ«ç§»å‹•ãŒå¯èƒ½ã§ã™ã€‚"
        )
        vram_desc.setStyleSheet("color: #9ca3af; font-size: 10px;")
        vram_desc.setWordWrap(True)
        vram_layout.addWidget(vram_desc)

        # VRAM Compact Widget
        self.vram_compact = VRAMCompactWidget()
        vram_layout.addWidget(self.vram_compact)

        # VRAM Simulatorã¸ã®ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³
        open_simulator_btn = QPushButton("ğŸ“Š è©³ç´°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’é–‹ã")
        open_simulator_btn.clicked.connect(self._open_vram_simulator)
        vram_layout.addWidget(open_simulator_btn)

        vram_group.setLayout(vram_layout)
        scroll_layout.addWidget(vram_group)

        # === GPUãƒ¢ãƒ‹ã‚¿ãƒ¼ ===
        gpu_group = QGroupBox("ğŸ“Š GPUãƒ¢ãƒ‹ã‚¿ãƒ¼")
        gpu_group.setToolTip("GPUä½¿ç”¨ç‡ã¨VRAMæ¶ˆè²»ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°\nLLMå®Ÿè¡Œæ™‚ã«è‡ªå‹•ã§è¨˜éŒ²ã‚’é–‹å§‹ã—ã¾ã™")
        gpu_layout = QVBoxLayout()

        # GPUä½¿ç”¨é‡ã‚°ãƒ©ãƒ•
        self.gpu_graph = GPUUsageGraph()
        gpu_layout.addWidget(self.gpu_graph)

        # æ™‚é–“è»¸é¸æŠè¡Œ
        time_control_layout = QHBoxLayout()
        time_control_layout.addWidget(QLabel("æ™‚é–“ç¯„å›²:"))
        self.gpu_time_range_combo = NoScrollComboBox()
        self.gpu_time_range_combo.addItems(list(GPUUsageGraph.TIME_RANGES.keys()))
        self.gpu_time_range_combo.setCurrentText("60ç§’")
        self.gpu_time_range_combo.currentTextChanged.connect(self._on_gpu_time_range_changed)
        time_control_layout.addWidget(self.gpu_time_range_combo)

        time_control_layout.addWidget(QLabel("  "))

        # ã‚·ãƒ¼ã‚¯ãƒãƒ¼ï¼ˆéå»ã®ãƒ‡ãƒ¼ã‚¿å‚ç…§ç”¨ï¼‰
        time_control_layout.addWidget(QLabel("éå»ã‚’è¡¨ç¤º:"))
        self.gpu_seekbar = QSlider(Qt.Orientation.Horizontal)
        self.gpu_seekbar.setMinimum(0)
        self.gpu_seekbar.setMaximum(0)  # ãƒ‡ãƒ¼ã‚¿ãŒãªã„æ™‚ã¯0
        self.gpu_seekbar.setValue(0)
        self.gpu_seekbar.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.gpu_seekbar.setTickInterval(60)
        self.gpu_seekbar.valueChanged.connect(self._on_gpu_seekbar_changed)
        self.gpu_seekbar.setMinimumWidth(150)
        time_control_layout.addWidget(self.gpu_seekbar)

        self.gpu_seekbar_label = QLabel("ç¾åœ¨")
        self.gpu_seekbar_label.setMinimumWidth(50)
        time_control_layout.addWidget(self.gpu_seekbar_label)

        time_control_layout.addStretch()
        gpu_layout.addLayout(time_control_layout)

        # GPUæƒ…å ±ãƒ†ã‚­ã‚¹ãƒˆ
        self.gpu_info_label = QLabel("GPUæƒ…å ±ã‚’å–å¾—ä¸­...")
        self.gpu_info_label.setStyleSheet("color: #9ca3af;")
        gpu_layout.addWidget(self.gpu_info_label)

        # ãƒœã‚¿ãƒ³è¡Œ
        gpu_btn_layout = QHBoxLayout()

        # æ›´æ–°ãƒœã‚¿ãƒ³
        refresh_gpu_btn = QPushButton("ğŸ”„ GPUæƒ…å ±æ›´æ–°")
        refresh_gpu_btn.setToolTip("Ollamaã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™")
        refresh_gpu_btn.clicked.connect(self._refresh_gpu_info)
        gpu_btn_layout.addWidget(refresh_gpu_btn)

        # è¨˜éŒ²é–‹å§‹/åœæ­¢ãƒœã‚¿ãƒ³
        self.gpu_record_btn = QPushButton("â–¶ è¨˜éŒ²é–‹å§‹")
        self.gpu_record_btn.clicked.connect(self._toggle_gpu_recording)
        gpu_btn_layout.addWidget(self.gpu_record_btn)

        # ã‚°ãƒ©ãƒ•ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        clear_graph_btn = QPushButton("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢")
        clear_graph_btn.clicked.connect(self._clear_gpu_graph)
        gpu_btn_layout.addWidget(clear_graph_btn)

        # ç¾åœ¨ã«æˆ»ã‚‹ãƒœã‚¿ãƒ³
        goto_now_btn = QPushButton("â© ç¾åœ¨")
        goto_now_btn.clicked.connect(self._on_gpu_goto_now)
        goto_now_btn.setToolTip("ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã‚’ç¾åœ¨ã«æˆ»ã™")
        gpu_btn_layout.addWidget(goto_now_btn)

        gpu_btn_layout.addStretch()
        gpu_layout.addLayout(gpu_btn_layout)

        # èª¬æ˜ãƒ©ãƒ™ãƒ«
        gpu_desc = QLabel("ğŸ’¡ LLMå®Ÿè¡Œæ™‚ã«è‡ªå‹•ã§5ç§’å¾Œã«GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²ã—ã¾ã™ / ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã§ãã¾ã™")
        gpu_desc.setStyleSheet("color: #6b7280; font-size: 9px;")
        gpu_layout.addWidget(gpu_desc)

        gpu_group.setLayout(gpu_layout)
        scroll_layout.addWidget(gpu_group)

        # GPUè¨˜éŒ²ç”¨ã‚¿ã‚¤ãƒãƒ¼
        self._gpu_recording = False
        self._gpu_timer = QTimer()
        self._gpu_timer.timeout.connect(self._record_gpu_usage)

        # v8.1.0: RAGè¨­å®šã¯ä¸€èˆ¬è¨­å®šã‚¿ãƒ–ã€Œè¨˜æ†¶ãƒ»çŸ¥è­˜ç®¡ç†ã€ã«çµ±åˆæ¸ˆã¿
        # äº’æ›æ€§ç”¨ãƒ€ãƒŸãƒ¼ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
        self.rag_enabled_check = QCheckBox()
        self.rag_enabled_check.setChecked(True)
        self.rag_enabled_check.setVisible(False)
        self.rag_auto_save_check = QCheckBox()
        self.rag_auto_save_check.setChecked(True)
        self.rag_auto_save_check.setVisible(False)
        self.rag_threshold_combo = NoScrollComboBox()
        self.rag_threshold_combo.addItems(["ä½å„ªå…ˆåº¦ä»¥ä¸Š", "ä¸­å„ªå…ˆåº¦ä»¥ä¸Š", "é«˜å„ªå…ˆåº¦ã®ã¿"])
        self.rag_threshold_combo.setCurrentIndex(1)
        self.rag_threshold_combo.setVisible(False)

        # === ä¿å­˜ãƒœã‚¿ãƒ³ (v8.4.2: soloAI/ä¸€èˆ¬è¨­å®šã¨çµ±ä¸€ â€” å³å¯„ã›å°å‹) ===
        save_btn_layout = QHBoxLayout()
        save_btn_layout.addStretch()
        save_btn = QPushButton("ğŸ’¾ è¨­å®šã‚’ä¿å­˜")
        save_btn.setToolTip("mixAIã‚¿ãƒ–ã®å…¨è¨­å®šã‚’config/config.jsonã«ä¿å­˜ã—ã¾ã™")
        save_btn.clicked.connect(self._on_save_settings)
        save_btn_layout.addWidget(save_btn)
        scroll_layout.addLayout(save_btn_layout)

        scroll_layout.addStretch()
        scroll.setWidget(scroll_content)
        layout.addWidget(scroll)

        # GPUæƒ…å ±ã‚’é…å»¶èª­ã¿è¾¼ã¿
        QTimer.singleShot(500, self._refresh_gpu_info)

        return panel

    def _set_combo_value(self, combo: QComboBox, value: str):
        """ComboBoxã®å€¤ã‚’è¨­å®š"""
        for i in range(combo.count()):
            if value.lower() in combo.itemText(i).lower():
                combo.setCurrentIndex(i)
                return
        combo.setCurrentText(value)

    def _set_combo_by_index(self, combo: QComboBox, index: int):
        """ComboBoxã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š"""
        if 0 <= index < combo.count():
            combo.setCurrentIndex(index)

    def _on_tool_log_toggled(self, checked: bool):
        """ãƒ„ãƒ¼ãƒ«ãƒ­ã‚°ã®å±•é–‹/æŠ˜ã‚ŠãŸãŸã¿"""
        self.tool_log_tree.setVisible(checked)
        if checked:
            self.tool_log_group.setTitle("â–¼ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚° (ã‚¯ãƒªãƒƒã‚¯ã§æŠ˜ã‚ŠãŸãŸã¿)")
        else:
            self.tool_log_group.setTitle("â–¶ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚° (ã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹)")

    def _on_execute(self):
        """å®Ÿè¡Œé–‹å§‹"""
        # v8.5.0: RAGæ§‹ç¯‰ä¸­ãƒ­ãƒƒã‚¯åˆ¤å®š
        if hasattr(self, 'main_window') and self.main_window:
            rag_lock = getattr(self.main_window, '_rag_lock', None)
            if rag_lock and rag_lock.is_locked:
                QMessageBox.information(
                    self, "RAGæ§‹ç¯‰ä¸­",
                    "æƒ…å ±åé›†ã‚¿ãƒ–ã§RAGæ§‹ç¯‰ãŒé€²è¡Œä¸­ã§ã™ã€‚\n"
                    "å®Œäº†ã™ã‚‹ã¾ã§mixAIã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚"
                )
                return

        prompt = self.input_text.toPlainText().strip()
        if not prompt:
            QMessageBox.warning(self, "å…¥åŠ›ã‚¨ãƒ©ãƒ¼", "ã‚¿ã‚¹ã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        # UIæ›´æ–°
        self.execute_btn.setEnabled(False)
        self.cancel_btn.setEnabled(True)
        self.progress_bar.setVisible(True)
        self.progress_bar.setValue(0)
        self.tool_log_tree.clear()
        self.output_text.clear()

        # v5.0.0: ä¼šè©±å±¥æ­´ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        self._conversation_history.append({
            "role": "user",
            "content": prompt,
        })

        # è¨­å®šã‚’æ›´æ–°
        self._update_config_from_ui()

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ç”»åƒãƒ‘ã‚¹ã‚’æŠ½å‡º (v4.4)
        image_path = self._extract_image_path(prompt)

        # v4.5: GPUè¨˜éŒ²ã‚’è‡ªå‹•é–‹å§‹
        if not self._gpu_recording:
            self._start_gpu_recording()
        self._record_gpu_with_event("å®Ÿè¡Œé–‹å§‹")

        # v7.0.0: æ–°3Phase MixAIOrchestrator ã‚’ä½¿ç”¨
        model_assignments = self._get_model_assignments()
        # v7.1.0: claude_model_id ã‚’å„ªå…ˆä½¿ç”¨
        claude_model_id = getattr(self.config, 'claude_model_id', None) or getattr(self.config, 'claude_model', DEFAULT_CLAUDE_MODEL_ID)
        # v9.3.0: ã‚¨ãƒ³ã‚¸ãƒ³åˆ‡æ›¿
        engine_id = self.engine_combo.currentData() if hasattr(self, 'engine_combo') else claude_model_id
        orchestrator_config = {
            "claude_model": claude_model_id,
            "claude_model_id": claude_model_id,
            "orchestrator_engine": engine_id,
            "timeout": self._get_claude_timeout_sec(),
            "auto_knowledge": True,
            "project_dir": os.getcwd(),
            "max_phase2_retries": self.max_retries_spin.value() if hasattr(self, 'max_retries_spin') else 2,
            "local_agent_tools": self._load_local_agent_tools_config(),
        }
        attached_files = []
        if image_path:
            attached_files.append(image_path)

        # v8.0.0: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ã‚‚BIBLEæ¤œç´¢
        try:
            prompt_bibles = BibleDiscovery.discover_from_prompt(prompt)
            if prompt_bibles and not self.bible_panel.current_bible:
                self.bible_panel.update_bible(prompt_bibles[0])
                logger.info(f"[BIBLE] Discovered from prompt: {prompt_bibles[0].project_name}")
        except Exception as e:
            logger.debug(f"[BIBLE] Prompt discovery error: {e}")

        self.worker = MixAIOrchestrator(
            user_prompt=prompt,
            attached_files=attached_files,
            model_assignments=model_assignments,
            config=orchestrator_config,
        )

        # v8.0.0: BIBLE ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥
        if self.bible_panel.current_bible:
            self.worker.set_bible_context(self.bible_panel.current_bible)

        # v8.1.0: ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼æ³¨å…¥
        if hasattr(self, '_memory_manager') and self._memory_manager:
            self.worker.set_memory_manager(self._memory_manager)

        self.worker.phase_changed.connect(self._on_phase_changed)
        self.worker.local_llm_started.connect(self._on_local_llm_started)
        self.worker.local_llm_finished.connect(self._on_local_llm_finished)
        self.worker.phase2_progress.connect(self._on_phase2_progress)
        self.worker.all_finished.connect(self._on_finished)
        self.worker.error_occurred.connect(self._on_error)
        # v8.0.0: BIBLEè‡ªå¾‹ç®¡ç†ã‚·ã‚°ãƒŠãƒ«
        if hasattr(self.worker, 'bible_action_proposed'):
            self.worker.bible_action_proposed.connect(self._on_bible_action_proposed)
        self.worker.start()

        # v7.1.0: é¸æŠãƒ¢ãƒ‡ãƒ«åã‚’ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«è¡¨ç¤º
        model_display = self.claude_model_combo.currentText() if hasattr(self, 'claude_model_combo') else claude_model_id
        self.statusChanged.emit(f"mixAI v7.1: 3Phaseå‡¦ç†ä¸­... ({model_display})")

    def _extract_image_path(self, prompt: str) -> Optional[str]:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ç”»åƒãƒ‘ã‚¹ã‚’æŠ½å‡º (v4.4)"""
        import re
        import os

        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ãƒ‘ã‚¿ãƒ¼ãƒ³
        image_extensions = r'\.(png|jpg|jpeg|gif|bmp|webp|PNG|JPG|JPEG|GIF|BMP|WEBP)'

        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: å¼•ç”¨ç¬¦ã§å›²ã¾ã‚ŒãŸãƒ‘ã‚¹
        quoted_patterns = [
            r'"([^"]+' + image_extensions + r')"',
            r"'([^']+' + image_extensions + r')",
        ]

        for pattern in quoted_patterns:
            matches = re.findall(pattern, prompt)
            for match in matches:
                if isinstance(match, tuple):
                    path = match[0]
                else:
                    path = match
                if os.path.exists(path):
                    logger.info(f"[mixAI v4.4] ç”»åƒãƒ‘ã‚¹æ¤œå‡º: {path}")
                    return path

        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: Windowsçµ¶å¯¾ãƒ‘ã‚¹ (C:\... or D:\...)
        win_pattern = r'([A-Za-z]:\\[^\s"\'<>|]+' + image_extensions + r')'
        matches = re.findall(win_pattern, prompt)
        for match in matches:
            if os.path.exists(match):
                logger.info(f"[mixAI v4.4] ç”»åƒãƒ‘ã‚¹æ¤œå‡º(Windows): {match}")
                return match

        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: Unixçµ¶å¯¾ãƒ‘ã‚¹ (/home/... or /Users/...)
        unix_pattern = r'(/[^\s"\'<>|]+' + image_extensions + r')'
        matches = re.findall(unix_pattern, prompt)
        for match in matches:
            if os.path.exists(match):
                logger.info(f"[mixAI v4.4] ç”»åƒãƒ‘ã‚¹æ¤œå‡º(Unix): {match}")
                return match

        return None

    def _get_model_assignments(self) -> dict[str, str]:
        """v7.0.0: è¨­å®šUIã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¢ãƒ‡ãƒ«å‰²ã‚Šå½“ã¦ã‚’å–å¾—"""
        assignments = {}
        if hasattr(self, 'coding_model_combo'):
            assignments["coding"] = self.coding_model_combo.currentText()
        if hasattr(self, 'research_model_combo'):
            assignments["research"] = self.research_model_combo.currentText()
        if hasattr(self, 'reasoning_model_combo'):
            assignments["reasoning"] = self.reasoning_model_combo.currentText()
        if hasattr(self, 'translation_model_combo'):
            assignments["translation"] = self.translation_model_combo.currentText()
        if hasattr(self, 'vision_model_combo'):
            assignments["vision"] = self.vision_model_combo.currentText()
        return assignments

    # â•â•â• v9.3.0: P1/P3ã‚¨ãƒ³ã‚¸ãƒ³åˆ‡æ›¿ â•â•â•

    def _add_ollama_engines(self):
        """Ollamaã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ """
        agent_capable = [
            "devstral-2:123b",
            "gpt-oss:120b",
            "command-a:latest",
        ]
        try:
            import httpx
            resp = httpx.get("http://localhost:11434/api/tags", timeout=5)
            if resp.status_code == 200:
                models = resp.json().get("models", [])
                installed = {m["name"] for m in models}
                for model_name in agent_capable:
                    if model_name in installed:
                        size = next((m.get("size", 0) for m in models
                                     if m["name"] == model_name), 0)
                        size_str = f" {size / (1024**3):.0f}GB" if size else ""
                        self._engine_options.append(
                            (model_name, f"{model_name} (ãƒ­ãƒ¼ã‚«ãƒ«{size_str})")
                        )
        except Exception:
            pass  # Ollamaæœªèµ·å‹•æ™‚ã¯Claudeé¸æŠè‚¢ã®ã¿

    def _on_engine_changed(self, index):
        """ã‚¨ãƒ³ã‚¸ãƒ³å¤‰æ›´æ™‚ã®å‡¦ç†"""
        engine_id = self.engine_combo.currentData()
        if engine_id:
            self._save_engine_setting(engine_id)
            self._update_engine_indicator(engine_id)

    def _update_engine_indicator(self, engine_id: str):
        """ã‚¨ãƒ³ã‚¸ãƒ³ç¨®åˆ¥ãƒ©ãƒ™ãƒ«ã‚’æ›´æ–°"""
        if engine_id.startswith("claude-"):
            self.engine_type_label.setText("â˜ API")
            self.engine_type_label.setStyleSheet(
                "color: #06b6d4; font-size: 11px; padding: 2px 6px; "
                "background-color: rgba(6, 182, 212, 0.15); border-radius: 4px;")
        else:
            self.engine_type_label.setText("ğŸ–¥ ãƒ­ãƒ¼ã‚«ãƒ«")
            self.engine_type_label.setStyleSheet(
                "color: #10b981; font-size: 11px; padding: 2px 6px; "
                "background-color: rgba(16, 185, 129, 0.15); border-radius: 4px;")

    def _load_engine_setting(self) -> str:
        """config.jsonã‹ã‚‰ã‚¨ãƒ³ã‚¸ãƒ³è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        try:
            config_path = Path("config/config.json")
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                return config.get("orchestrator_engine", "claude-opus-4-6")
        except Exception:
            pass
        return "claude-opus-4-6"

    def _save_engine_setting(self, engine_id: str):
        """config.jsonã«ã‚¨ãƒ³ã‚¸ãƒ³è¨­å®šã‚’ä¿å­˜"""
        try:
            config_path = Path("config/config.json")
            config = {}
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            config["orchestrator_engine"] = engine_id
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Engine setting save failed: {e}")

    def _load_local_agent_tools_config(self) -> dict:
        """config.jsonã‹ã‚‰local_agent_toolsè¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        try:
            config_path = Path("config/config.json")
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                return config.get("local_agent_tools", {})
        except Exception:
            pass
        return {}

    def _on_phase_changed(self, phase_num: int, description: str):
        """v7.0.0: Phaseå¤‰æ›´ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©"""
        percentage = {1: 10, 2: 40, 3: 70}.get(phase_num, 50)
        self.progress_bar.setValue(percentage)
        self.progress_bar.setFormat(f"{percentage}% - {description}")
        self._update_neural_flow_from_progress(description, percentage)
        # v8.0.0: PhaseIndicatoræ›´æ–°
        if hasattr(self, 'phase_indicator'):
            self.phase_indicator.set_active_phase(phase_num - 1)

        # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚°ã«Phaseé–‹å§‹ã‚’è¨˜éŒ²
        phase_item = QTreeWidgetItem(self.tool_log_tree)
        phase_item.setText(0, description)
        phase_item.setText(1, "å®Ÿè¡Œä¸­")
        phase_item.setText(2, "")

    def _on_local_llm_started(self, category: str, model: str):
        """v7.0.0: ãƒ­ãƒ¼ã‚«ãƒ«LLMå®Ÿè¡Œé–‹å§‹"""
        self.statusChanged.emit(f"Phase 2: {category} ({model}) å®Ÿè¡Œä¸­...")

    def _on_local_llm_finished(self, category: str, success: bool, elapsed: float):
        """v7.0.0: ãƒ­ãƒ¼ã‚«ãƒ«LLMå®Ÿè¡Œå®Œäº†"""
        status = "å®Œäº†" if success else "å¤±æ•—"
        item = QTreeWidgetItem(self.tool_log_tree)
        item.setText(0, f"  Phase 2: {category}")
        item.setText(1, status)
        item.setText(2, f"{elapsed:.1f}s")

    def _on_phase2_progress(self, completed: int, total: int):
        """v7.0.0: Phase 2é€²æ—"""
        pct = 40 + int((completed / max(total, 1)) * 30)
        self.progress_bar.setValue(pct)
        self.progress_bar.setFormat(f"{pct}% - Phase 2: {completed}/{total} å®Œäº†")

    def _on_cancel(self):
        """ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        if self.worker:
            self.worker.cancel()
            self.statusChanged.emit("å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")

    def _on_clear(self):
        """ã‚¯ãƒªã‚¢"""
        self.output_text.clear()
        self.tool_log_tree.clear()
        self.input_text.clear()
        # v5.1: æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ã‚¯ãƒªã‚¢
        self.attachment_bar.clear_all()
        self._attached_files.clear()
        # Neural Flowã‚’ãƒªã‚»ãƒƒãƒˆ
        if hasattr(self, 'neural_flow'):
            self.neural_flow.reset_all()
        # v8.0.0: PhaseIndicatorãƒªã‚»ãƒƒãƒˆ
        if hasattr(self, 'phase_indicator'):
            self.phase_indicator.reset()

    # =========================================================================
    # v5.1: ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ãƒ»ã‚¹ãƒ‹ãƒšãƒƒãƒˆé–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰
    # =========================================================================

    def _on_attach_file(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯"""
        files, _ = QFileDialog.getOpenFileNames(
            self, "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", "",
            "å…¨ãƒ•ã‚¡ã‚¤ãƒ« (*);;Python (*.py);;ãƒ†ã‚­ã‚¹ãƒˆ (*.txt *.md);;ç”»åƒ (*.png *.jpg *.jpeg *.gif *.webp)"
        )
        if files:
            self.attachment_bar.add_files(files)

    def _on_attachments_changed(self, files: List[str]):
        """æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸ"""
        self._attached_files = files.copy()
        logger.info(f"[mixAI v5.1] æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°: {len(files)}ä»¶")

        # v8.0.0: æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰BIBLEè‡ªå‹•æ¤œå‡º
        if files:
            self._discover_bible_from_files(files)

    # =========================================================================
    # v8.0.0: BIBLE Manager ãƒ¡ã‚½ãƒƒãƒ‰
    # =========================================================================

    def _auto_discover_bible_on_startup(self):
        """v8.3.1: èµ·å‹•æ™‚ã«ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰BIBLEè‡ªå‹•æ¤œå‡º"""
        try:
            cwd = os.getcwd()
            logger.info(f"[BIBLE] Startup auto-discovery from: {cwd}")
            bibles = BibleDiscovery.discover(cwd)
            if bibles:
                best = bibles[0]
                self.bible_panel.update_bible(best)
                logger.info(
                    f"[BIBLE] Startup auto-discovered: {best.project_name} "
                    f"v{best.version} at {best.file_path}"
                )
            else:
                logger.info("[BIBLE] Startup auto-discovery: no BIBLE found")
        except Exception as e:
            logger.debug(f"[BIBLE] Startup discovery error: {e}")

    def _on_bible_path_submitted(self, path: str):
        """v8.3.1: ãƒ‘ã‚¹å…¥åŠ›æ¬„ã‹ã‚‰ã®BIBLEæ¤œç´¢"""
        try:
            logger.info(f"[BIBLE] Manual path search: {path}")
            bibles = BibleDiscovery.discover(path)
            if bibles:
                best = bibles[0]
                self.bible_panel.update_bible(best)
                self.bible_notification.show_bible(best)
                logger.info(
                    f"[BIBLE] Found from manual path: {best.project_name} "
                    f"v{best.version}"
                )
            else:
                from PyQt6.QtWidgets import QMessageBox
                QMessageBox.information(
                    self, "BIBLEæ¤œç´¢",
                    f"æŒ‡å®šãƒ‘ã‚¹ã‹ã‚‰BIBLEãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ:\n{path}\n\n"
                    "3æ®µéšæ¢ç´¢ï¼ˆã‚«ãƒ¬ãƒ³ãƒˆâ†’å­â†’è¦ªï¼‰ã‚’å®Ÿè¡Œã—ã¾ã—ãŸãŒã€"
                    "BIBLEãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"
                )
                logger.info(f"[BIBLE] No BIBLE found at manual path: {path}")
        except Exception as e:
            logger.error(f"[BIBLE] Manual path discovery error: {e}")

    def _discover_bible_from_files(self, files: List[str]):
        """æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰BIBLEè‡ªå‹•æ¤œå‡º"""
        try:
            for f in files:
                bibles = BibleDiscovery.discover(f)
                if bibles:
                    best = bibles[0]
                    self.bible_panel.update_bible(best)
                    self.bible_notification.show_bible(best)
                    logger.info(
                        f"[BIBLE] Auto-discovered: {best.project_name} "
                        f"v{best.version} from {f}"
                    )
                    return
        except Exception as e:
            logger.debug(f"[BIBLE] Discovery from files error: {e}")

    def _on_bible_add_context(self, bible):
        """é€šçŸ¥ãƒãƒ¼ã®ã€Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ ã€ãƒœã‚¿ãƒ³"""
        self.bible_panel.update_bible(bible)
        logger.info(f"[BIBLE] Context added: {bible.project_name} v{bible.version}")

    def _on_bible_create(self):
        """BIBLEæ–°è¦ä½œæˆ"""
        try:
            from ..bible.bible_lifecycle import BibleLifecycleManager, BibleAction
            project_dir = os.getcwd()
            result = {"changed_files": [], "app_version": APP_VERSION}
            content = BibleLifecycleManager.execute_action(
                BibleAction.CREATE_NEW, None, result, project_dir
            )
            if content:
                from pathlib import Path
                bible_path = Path(project_dir) / "BIBLE.md"
                bible_path.write_text(content, encoding="utf-8")
                # å†æ¤œå‡ºã—ã¦ãƒ‘ãƒãƒ«æ›´æ–°
                bibles = BibleDiscovery.discover(str(bible_path))
                if bibles:
                    self.bible_panel.update_bible(bibles[0])
                logger.info(f"[BIBLE] Created new BIBLE at {bible_path}")
                QMessageBox.information(
                    self, "BIBLEä½œæˆå®Œäº†",
                    f"BIBLE.md ã‚’ä½œæˆã—ã¾ã—ãŸ:\n{bible_path}"
                )
        except Exception as e:
            logger.error(f"[BIBLE] Create error: {e}")
            QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", f"BIBLEä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    def _on_bible_update(self):
        """BIBLEæ›´æ–°"""
        bible = self.bible_panel.current_bible
        if not bible:
            return
        try:
            from ..bible.bible_lifecycle import BibleLifecycleManager, BibleAction
            result = {"changed_files": [], "app_version": APP_VERSION}
            action, reason = BibleLifecycleManager.determine_action(
                bible, result, {}
            )
            if action != BibleAction.NONE:
                content = BibleLifecycleManager.execute_action(
                    action, bible, result, str(bible.file_path.parent)
                )
                if content:
                    bible.file_path.write_text(content, encoding="utf-8")
                    # å†ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ‘ãƒãƒ«æ›´æ–°
                    from ..bible.bible_parser import BibleParser
                    updated = BibleParser.parse_full(bible.file_path)
                    if updated:
                        self.bible_panel.update_bible(updated)
                    logger.info(f"[BIBLE] Updated: {action.value} - {reason}")
            else:
                QMessageBox.information(
                    self, "BIBLE", "ç¾åœ¨æ›´æ–°ãŒå¿…è¦ãªé …ç›®ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
                )
        except Exception as e:
            logger.error(f"[BIBLE] Update error: {e}")

    def _on_bible_detail(self):
        """BIBLEè©³ç´°è¡¨ç¤º"""
        bible = self.bible_panel.current_bible
        if not bible:
            return
        missing = bible.missing_required_sections
        missing_str = (
            "\nä¸è¶³ã‚»ã‚¯ã‚·ãƒ§ãƒ³: " + ", ".join(s.value for s in missing)
            if missing else "\nå…¨å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚ã‚Š"
        )
        sections_str = "\n".join(
            f"  - {s.title} ({s.type.value}, å……å®Ÿåº¦{s.completeness:.0%})"
            for s in bible.sections
        )
        detail = (
            f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {bible.project_name}\n"
            f"ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {bible.version}\n"
            f"ã‚³ãƒ¼ãƒ‰ãƒãƒ¼ãƒ : {bible.codename or '(ãªã—)'}\n"
            f"ãƒ•ã‚¡ã‚¤ãƒ«: {bible.file_path}\n"
            f"è¡Œæ•°: {bible.line_count}\n"
            f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(bible.sections)}\n"
            f"å®Œå…¨æ€§ã‚¹ã‚³ã‚¢: {bible.completeness_score:.0%}"
            f"{missing_str}\n\n"
            f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§:\n{sections_str}"
        )
        QMessageBox.information(self, "BIBLEè©³ç´°", detail)

    def _on_bible_action_proposed(self, action, reason):
        """Post-Phase: BIBLEè‡ªå¾‹ç®¡ç†ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ"""
        try:
            from ..bible.bible_lifecycle import BibleAction
            if action == BibleAction.NONE:
                return
            reply = QMessageBox.question(
                self, "BIBLEæ›´æ–°ææ¡ˆ",
                f"{reason}\n\nã“ã®æ“ä½œã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            )
            if reply == QMessageBox.StandardButton.Yes:
                from ..bible.bible_lifecycle import BibleLifecycleManager
                bible = self.bible_panel.current_bible
                result = {"changed_files": [], "app_version": APP_VERSION}
                project_dir = os.getcwd()
                content = BibleLifecycleManager.execute_action(
                    action, bible, result, project_dir
                )
                if content and bible:
                    bible.file_path.write_text(content, encoding="utf-8")
                    from ..bible.bible_parser import BibleParser
                    updated = BibleParser.parse_full(bible.file_path)
                    if updated:
                        self.bible_panel.update_bible(updated)
                    logger.info(f"[BIBLE] Action executed: {action.value}")
        except Exception as e:
            logger.error(f"[BIBLE] Action execution error: {e}")

    def _on_cite_history(self):
        """å±¥æ­´ã‹ã‚‰å¼•ç”¨ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯"""
        try:
            from ..ui.components.history_citation_widget import HistoryCitationDialog
            dialog = HistoryCitationDialog(storage_key="mixai_history", parent=self)
            if dialog.exec():
                citation = dialog.get_selected_citation()
                if citation:
                    current = self.input_text.toPlainText()
                    if current:
                        self.input_text.setPlainText(current + "\n\n" + citation)
                    else:
                        self.input_text.setPlainText(citation)
        except ImportError:
            QMessageBox.information(self, "æ©Ÿèƒ½æœªå®Ÿè£…", "å±¥æ­´å¼•ç”¨æ©Ÿèƒ½ã¯æº–å‚™ä¸­ã§ã™ã€‚")

    def _get_snippet_manager(self):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å–å¾— (v5.1.1: soloAIã¨å…±é€šåŒ–)"""
        from ..claude.snippet_manager import SnippetManager
        from pathlib import Path
        import sys

        # PyInstallerã§ãƒ“ãƒ«ãƒ‰ã•ã‚ŒãŸå ´åˆã¨ãã†ã§ãªã„å ´åˆã§ãƒ‘ã‚¹ã‚’åˆ†å²
        if getattr(sys, 'frozen', False):
            # PyInstallerã§ãƒ“ãƒ«ãƒ‰ã•ã‚ŒãŸå ´åˆ: exeã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
            app_dir = Path(sys.executable).parent
        else:
            # é–‹ç™ºæ™‚: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ä½¿ç”¨
            app_dir = Path(__file__).parent.parent.parent

        data_dir = app_dir / "data"
        unipet_dir = app_dir / "ãƒ¦ãƒ‹ãƒšãƒƒãƒˆ"

        # ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ
        data_dir.mkdir(parents=True, exist_ok=True)
        unipet_dir.mkdir(parents=True, exist_ok=True)

        return SnippetManager(data_dir=data_dir, unipet_dir=unipet_dir)

    def _on_snippet_menu(self):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤º (v5.1.1: soloAIã¨å…±é€šåŒ–)"""
        from PyQt6.QtWidgets import QMenu
        from PyQt6.QtCore import QPoint

        try:
            snippet_manager = self._get_snippet_manager()
            snippets = snippet_manager.get_all()

            menu = QMenu(self)

            if not snippets:
                no_snippet_action = menu.addAction("ã‚¹ãƒ‹ãƒšãƒƒãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
                no_snippet_action.setEnabled(False)
            else:
                # ã‚«ãƒ†ã‚´ãƒªã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                categories = snippet_manager.get_categories()
                uncategorized = [s for s in snippets if not s.get("category")]

                # ã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚‹ã‚¹ãƒ‹ãƒšãƒƒãƒˆ
                for category in categories:
                    cat_menu = menu.addMenu(f"ğŸ“ {category}")
                    cat_snippets = snippet_manager.get_by_category(category)
                    for snippet in cat_snippets:
                        action = cat_menu.addAction(snippet.get("name", "ç„¡é¡Œ"))
                        action.setData(snippet)
                        action.triggered.connect(lambda checked, s=snippet: self._insert_snippet(s))

                # ã‚«ãƒ†ã‚´ãƒªãªã—ã‚¹ãƒ‹ãƒšãƒƒãƒˆ
                if uncategorized:
                    if categories:
                        menu.addSeparator()
                    for snippet in uncategorized:
                        action = menu.addAction(f"ğŸ“‹ {snippet.get('name', 'ç„¡é¡Œ')}")
                        action.setData(snippet)
                        action.triggered.connect(lambda checked, s=snippet: self._insert_snippet(s))

            menu.addSeparator()
            open_folder_action = menu.addAction("ğŸ“‚ ãƒ¦ãƒ‹ãƒšãƒƒãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‚’é–‹ã")
            open_folder_action.triggered.connect(lambda: snippet_manager.open_unipet_folder())

            # ãƒœã‚¿ãƒ³ã®ä¸‹ã«è¡¨ç¤º
            btn_pos = self.mixai_snippet_btn.mapToGlobal(QPoint(0, self.mixai_snippet_btn.height()))
            menu.exec(btn_pos)

        except Exception as e:
            logger.error(f"[MixAI._on_snippet_menu] Error: {e}", exc_info=True)
            QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼:\n{e}")

    def _insert_snippet(self, snippet: dict):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’å…¥åŠ›æ¬„ã«æŒ¿å…¥ (v5.1.1)"""
        content = snippet.get("content", "")
        name = snippet.get("name", "ç„¡é¡Œ")

        current_text = self.input_text.toPlainText()
        if current_text:
            new_text = f"{current_text}\n\n{content}"
        else:
            new_text = content

        self.input_text.setPlainText(new_text)
        self.statusChanged.emit(f"ğŸ“‹ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€Œ{name}ã€ã‚’æŒ¿å…¥ã—ã¾ã—ãŸ")
        logger.info(f"[MixAI] Snippet inserted: {name}")

    def _on_snippet_add(self):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆè¿½åŠ  (v5.1.1: soloAIã¨å…±é€šåŒ–)"""
        from PyQt6.QtWidgets import QDialog, QVBoxLayout, QLineEdit, QTextEdit, QDialogButtonBox

        try:
            dialog = QDialog(self)
            dialog.setWindowTitle("ã‚¹ãƒ‹ãƒšãƒƒãƒˆè¿½åŠ ")
            dialog.setMinimumWidth(400)
            layout = QVBoxLayout(dialog)

            # åå‰å…¥åŠ›
            name_label = QLabel("ã‚¹ãƒ‹ãƒšãƒƒãƒˆå:")
            layout.addWidget(name_label)
            name_input = QLineEdit()
            name_input.setPlaceholderText("ä¾‹: ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼")
            layout.addWidget(name_input)

            # ã‚«ãƒ†ã‚´ãƒªå…¥åŠ›
            cat_label = QLabel("ã‚«ãƒ†ã‚´ãƒª (ä»»æ„):")
            layout.addWidget(cat_label)
            cat_input = QLineEdit()
            cat_input.setPlaceholderText("ä¾‹: é–‹ç™ºä¾é ¼")
            layout.addWidget(cat_input)

            # å†…å®¹å…¥åŠ›
            content_label = QLabel("å†…å®¹:")
            layout.addWidget(content_label)
            content_input = QTextEdit()
            content_input.setPlaceholderText("ã‚¹ãƒ‹ãƒšãƒƒãƒˆã®å†…å®¹ã‚’å…¥åŠ›...")
            content_input.setMinimumHeight(150)
            layout.addWidget(content_input)

            # ãƒœã‚¿ãƒ³
            buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
            buttons.accepted.connect(dialog.accept)
            buttons.rejected.connect(dialog.reject)
            layout.addWidget(buttons)

            if dialog.exec() == QDialog.DialogCode.Accepted:
                name = name_input.text().strip()
                content = content_input.toPlainText().strip()

                if not name or not content:
                    QMessageBox.warning(self, "å…¥åŠ›ã‚¨ãƒ©ãƒ¼", "åå‰ã¨å†…å®¹ã¯å¿…é ˆã§ã™ã€‚")
                    return

                category = cat_input.text().strip()
                snippet_manager = self._get_snippet_manager()
                snippet_manager.add(name=name, content=content, category=category)

                self.statusChanged.emit(f"ğŸ“‹ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€Œ{name}ã€ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                logger.info(f"[MixAI] Snippet added: {name}")

        except Exception as e:
            logger.error(f"[MixAI._on_snippet_add] Error: {e}", exc_info=True)
            QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆè¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼:\n{e}")

    def _on_snippet_context_menu(self, pos):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆå³ã‚¯ãƒªãƒƒã‚¯ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆç·¨é›†ãƒ»å‰Šé™¤ï¼‰(v5.2.0: ãƒ¦ãƒ‹ãƒšãƒƒãƒˆå‰Šé™¤å¯¾å¿œ)"""
        from PyQt6.QtWidgets import QMenu

        try:
            snippet_manager = self._get_snippet_manager()
            snippets = snippet_manager.get_all()

            if not snippets:
                return

            menu = QMenu(self)

            # ç·¨é›†ãƒ¡ãƒ‹ãƒ¥ãƒ¼
            edit_menu = menu.addMenu("âœï¸ ç·¨é›†")
            for snippet in snippets:
                action = edit_menu.addAction(snippet.get("name", "ç„¡é¡Œ"))
                action.triggered.connect(lambda checked, s=snippet: self._edit_snippet(s))

            # å‰Šé™¤ãƒ¡ãƒ‹ãƒ¥ãƒ¼ (v5.2.0: ãƒ¦ãƒ‹ãƒšãƒƒãƒˆã‚‚å‰Šé™¤å¯èƒ½ã«)
            delete_menu = menu.addMenu("ğŸ—‘ï¸ å‰Šé™¤")
            for snippet in snippets:
                source = snippet.get("source", "json")
                if source == "unipet":
                    action = delete_menu.addAction(f"ğŸ—‚ï¸ {snippet.get('name', 'ç„¡é¡Œ')} (ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤)")
                    action.triggered.connect(lambda checked, s=snippet: self._delete_snippet(s))
                else:
                    action = delete_menu.addAction(snippet.get("name", "ç„¡é¡Œ"))
                    action.triggered.connect(lambda checked, s=snippet: self._delete_snippet(s))

            menu.addSeparator()
            reload_action = menu.addAction("ğŸ”„ å†èª­ã¿è¾¼ã¿")
            reload_action.triggered.connect(lambda: (self._get_snippet_manager().reload(), self.statusChanged.emit("ğŸ“‹ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ")))

            menu.exec(self.mixai_snippet_add_btn.mapToGlobal(pos))

        except Exception as e:
            logger.error(f"[MixAI._on_snippet_context_menu] Error: {e}", exc_info=True)

    def _edit_snippet(self, snippet: dict):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆç·¨é›†ãƒ€ã‚¤ã‚¢ãƒ­ã‚° (v5.1.1)"""
        from PyQt6.QtWidgets import QDialog, QVBoxLayout, QLineEdit, QTextEdit, QDialogButtonBox

        try:
            dialog = QDialog(self)
            dialog.setWindowTitle(f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆç·¨é›†: {snippet.get('name', 'ç„¡é¡Œ')}")
            dialog.setMinimumWidth(400)
            layout = QVBoxLayout(dialog)

            # åå‰å…¥åŠ›
            name_label = QLabel("ã‚¹ãƒ‹ãƒšãƒƒãƒˆå:")
            layout.addWidget(name_label)
            name_input = QLineEdit(snippet.get("name", ""))
            layout.addWidget(name_input)

            # ã‚«ãƒ†ã‚´ãƒªå…¥åŠ›
            cat_label = QLabel("ã‚«ãƒ†ã‚´ãƒª:")
            layout.addWidget(cat_label)
            cat_input = QLineEdit(snippet.get("category", ""))
            layout.addWidget(cat_input)

            # å†…å®¹å…¥åŠ›
            content_label = QLabel("å†…å®¹:")
            layout.addWidget(content_label)
            content_input = QTextEdit()
            content_input.setPlainText(snippet.get("content", ""))
            content_input.setMinimumHeight(150)
            layout.addWidget(content_input)

            # ãƒœã‚¿ãƒ³
            buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
            buttons.accepted.connect(dialog.accept)
            buttons.rejected.connect(dialog.reject)
            layout.addWidget(buttons)

            if dialog.exec() == QDialog.DialogCode.Accepted:
                snippet_manager = self._get_snippet_manager()
                snippet_manager.update(
                    snippet.get("id"),
                    name=name_input.text().strip(),
                    content=content_input.toPlainText().strip(),
                    category=cat_input.text().strip()
                )
                self.statusChanged.emit(f"ğŸ“‹ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€Œ{name_input.text()}ã€ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
                logger.info(f"[MixAI] Snippet updated: {name_input.text()}")

        except Exception as e:
            logger.error(f"[MixAI._edit_snippet] Error: {e}", exc_info=True)
            QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆç·¨é›†ä¸­ã«ã‚¨ãƒ©ãƒ¼:\n{e}")

    def _delete_snippet(self, snippet: dict):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆå‰Šé™¤ (v5.2.0: ãƒ¦ãƒ‹ãƒšãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¯¾å¿œ)"""
        name = snippet.get("name", "ç„¡é¡Œ")
        is_unipet = snippet.get("source") == "unipet"

        # ãƒ¦ãƒ‹ãƒšãƒƒãƒˆã®å ´åˆã¯è­¦å‘Šã‚’è¿½åŠ 
        if is_unipet:
            file_path = snippet.get("file_path", "")
            msg = f"ãƒ¦ãƒ‹ãƒšãƒƒãƒˆã€Œ{name}ã€ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ\n\nãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤ã•ã‚Œã¾ã™:\n{file_path}"
        else:
            msg = f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€Œ{name}ã€ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ"

        reply = QMessageBox.question(
            self,
            "ã‚¹ãƒ‹ãƒšãƒƒãƒˆå‰Šé™¤",
            msg,
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.Yes:
            try:
                snippet_manager = self._get_snippet_manager()
                # ãƒ¦ãƒ‹ãƒšãƒƒãƒˆã®å ´åˆã¯delete_file=Trueã‚’æ¸¡ã™
                if snippet_manager.delete(snippet.get("id"), delete_file=is_unipet):
                    self.statusChanged.emit(f"ğŸ—‘ï¸ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€Œ{name}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                    logger.info(f"[MixAI] Snippet deleted: {name}")
                else:
                    QMessageBox.warning(self, "å‰Šé™¤å¤±æ•—", f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆã€Œ{name}ã€ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            except Exception as e:
                logger.error(f"[MixAI._delete_snippet] Error: {e}", exc_info=True)
                QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", f"ã‚¹ãƒ‹ãƒšãƒƒãƒˆå‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼:\n{e}")

    def _on_progress(self, message: str, percentage: int):
        """é€²æ—æ›´æ–°"""
        self.progress_bar.setValue(percentage)
        self.progress_bar.setFormat(f"{percentage}% - {message}")

        # Neural Flow Visualizerã®çŠ¶æ…‹æ›´æ–°
        self._update_neural_flow_from_progress(message, percentage)

    def _update_neural_flow_from_progress(self, message: str, percentage: int):
        """v7.0.0: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰Neural Flowã®çŠ¶æ…‹ã‚’æ›´æ–°ï¼ˆ3Phaseå¯¾å¿œï¼‰"""
        if not hasattr(self, 'neural_flow'):
            return

        # v7.0.0: 3Phase ãƒãƒƒãƒ”ãƒ³ã‚°
        stage_to_phase = {
            "phase 1": 1, "claudeè¨ˆç”»": 1, "è¨ˆç”»ç«‹æ¡ˆ": 1,
            "phase 2": 2, "ãƒ­ãƒ¼ã‚«ãƒ«llm": 2, "é †æ¬¡å®Ÿè¡Œ": 2, "å†å®Ÿè¡Œ": 2,
            "phase 3": 3, "claudeçµ±åˆ": 3, "æ¯”è¼ƒçµ±åˆ": 3, "å†çµ±åˆ": 3,
            "å®Œäº†": 3,
        }

        msg_lower = message.lower()

        for key, phase_id in stage_to_phase.items():
            if key in msg_lower:
                if "å®Œäº†" in message or percentage >= 100:
                    self.neural_flow.set_phase_state(phase_id, PhaseState.COMPLETED)
                elif "ä¸­" in message or "å®Ÿè¡Œ" in message or "é–‹å§‹" in message:
                    # å‰ã®Phaseã‚’å®Œäº†çŠ¶æ…‹ã«
                    for prev_phase in range(1, phase_id):
                        self.neural_flow.set_phase_state(prev_phase, PhaseState.COMPLETED)
                    self.neural_flow.set_phase_state(phase_id, PhaseState.RUNNING)
                break

    def _on_tool_executed(self, result: dict):
        """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå®Œäº†"""
        # v4.5: GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²ï¼ˆ5ç§’å¾Œã«ã‚‚è¨˜éŒ²ï¼‰
        stage_name = result.get("stage", "Tool")
        model_name_full = result.get("model", "")
        self._schedule_gpu_record_after_llm(stage_name)

        # ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—ï¼ˆé•·ã„å ´åˆã¯çŸ­ç¸®è¡¨ç¤ºï¼‰
        model_name = model_name_full
        if len(model_name) > 25:
            model_name = model_name[:22] + "..."

        output_text = result.get("output", "")
        output_display = output_text[:40] + "..." if len(output_text) > 40 else output_text

        item = QTreeWidgetItem([
            result.get("stage", ""),
            model_name,  # ãƒ¢ãƒ‡ãƒ«ååˆ—ã‚’è¿½åŠ 
            "âœ…" if result.get("success") else "âŒ",
            f"{result.get('execution_time_ms', 0):.0f}ms",
            output_display,
        ])

        if result.get("success"):
            item.setForeground(2, QColor("#22c55e"))  # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°
        else:
            item.setForeground(2, QColor("#ef4444"))

        # ãƒ¢ãƒ‡ãƒ«ååˆ—ã«è‰²ã‚’ä»˜ã‘ã‚‹ï¼ˆè­˜åˆ¥ã—ã‚„ã™ãã™ã‚‹ãŸã‚ï¼‰
        item.setForeground(1, QColor("#60a5fa"))  # é’ç³»

        self.tool_log_tree.addTopLevelItem(item)

    def _on_finished(self, result: str):
        """å®Œäº†"""
        self.execute_btn.setEnabled(True)
        self.cancel_btn.setEnabled(False)
        self.progress_bar.setVisible(False)

        # v7.0.0: Neural Flow - å…¨Phaseå®Œäº†ï¼ˆ3Phaseï¼‰
        if hasattr(self, 'neural_flow'):
            for phase_id in range(1, 4):
                self.neural_flow.set_phase_state(phase_id, PhaseState.COMPLETED)
        # v8.0.0: PhaseIndicatorå…¨å®Œäº†
        if hasattr(self, 'phase_indicator'):
            self.phase_indicator.set_all_completed()

        # çµæœã‚’è¡¨ç¤ºï¼ˆMarkdownâ†’HTMLãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼‰
        self.output_text.setHtml(markdown_to_html(result))
        self.statusChanged.emit("mixAI v8.0: å®Œäº†")
        self.worker = None

        # v5.0.0: ä¼šè©±å±¥æ­´ã«AIå¿œç­”ã‚’è¿½åŠ 
        self._conversation_history.append({
            "role": "assistant",
            "content": result,
        })

        # v5.0.0: è‡ªå‹•ãƒŠãƒ¬ãƒƒã‚¸ç®¡ç†ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œï¼‰
        self._start_knowledge_processing()

    def _on_error(self, error: str):
        """ã‚¨ãƒ©ãƒ¼"""
        self.execute_btn.setEnabled(True)
        self.cancel_btn.setEnabled(False)
        self.progress_bar.setVisible(False)

        # v7.0.0: Neural Flow - ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹è¡¨ç¤ºï¼ˆ3Phaseï¼‰
        if hasattr(self, 'neural_flow'):
            # ç¾åœ¨å®Ÿè¡Œä¸­ã®Phaseã‚’å¤±æ•—çŠ¶æ…‹ã«
            for phase_id in range(1, 4):
                from ..widgets.neural_visualizer import PhaseState
                state = self.neural_flow._phase_states.get(phase_id, PhaseState.IDLE)
                if state == PhaseState.RUNNING:
                    self.neural_flow.set_phase_state(phase_id, PhaseState.FAILED)
                    break

        self.output_text.setPlainText(f"âŒ ã‚¨ãƒ©ãƒ¼:\n\n{error}")
        self.statusChanged.emit(f"ã‚¨ãƒ©ãƒ¼: {error[:50]}...")
        self.worker = None

    # =========================================================================
    # v5.0.0: è‡ªå‹•ãƒŠãƒ¬ãƒƒã‚¸ç®¡ç†
    # =========================================================================

    def _start_knowledge_processing(self):
        """v5.0.0: è‡ªå‹•ãƒŠãƒ¬ãƒƒã‚¸å‡¦ç†ã‚’é–‹å§‹ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰"""
        if not self._conversation_history:
            return

        try:
            from ..knowledge import KnowledgeWorker, get_knowledge_manager

            km = get_knowledge_manager()
            self._knowledge_worker = KnowledgeWorker(
                conversation=self._conversation_history.copy(),
                knowledge_manager=km,
            )
            self._knowledge_worker.completed.connect(self._on_knowledge_saved)
            self._knowledge_worker.error.connect(self._on_knowledge_error)
            self._knowledge_worker.start()

            logger.info("[mixAI v5.0] ãƒŠãƒ¬ãƒƒã‚¸å‡¦ç†ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§é–‹å§‹")

        except ImportError as e:
            logger.warning(f"[mixAI v5.0] ãƒŠãƒ¬ãƒƒã‚¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")
        except Exception as e:
            logger.warning(f"[mixAI v5.0] ãƒŠãƒ¬ãƒƒã‚¸å‡¦ç†é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")

    def _on_knowledge_saved(self, knowledge: dict):
        """v5.0.0: ãƒŠãƒ¬ãƒƒã‚¸ä¿å­˜å®Œäº†"""
        topic = knowledge.get("topic", "ä¸æ˜")
        models_used = knowledge.get("ondemand_models_used", [])
        model_info = f" (æ¤œè¨¼: {', '.join(models_used)})" if models_used else ""
        self.statusChanged.emit(f"ğŸ’¾ ãƒŠãƒ¬ãƒƒã‚¸ä¿å­˜: {topic}{model_info}")
        logger.info(f"[mixAI v5.0] ãƒŠãƒ¬ãƒƒã‚¸ä¿å­˜å®Œäº†: {topic}")
        self._knowledge_worker = None

    def _on_knowledge_error(self, error: str):
        """v5.0.0: ãƒŠãƒ¬ãƒƒã‚¸ä¿å­˜ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ“ä½œã«ã¯å½±éŸ¿ã—ãªã„ï¼‰"""
        logger.warning(f"[mixAI v5.0] ãƒŠãƒ¬ãƒƒã‚¸ä¿å­˜ã‚¨ãƒ©ãƒ¼: {error}")
        self._knowledge_worker = None

    def _update_config_from_ui(self):
        """UIã‹ã‚‰è¨­å®šã‚’æ›´æ–°"""
        # Claudeè¨­å®š (v7.1.0: model_idç›´æ¥ä¿å­˜)
        selected_model_id = self.claude_model_combo.currentData()
        if selected_model_id:
            self.config.claude_model_id = selected_model_id
            self.config.claude_model = selected_model_id
        else:
            self.config.claude_model_id = DEFAULT_CLAUDE_MODEL_ID
            self.config.claude_model = DEFAULT_CLAUDE_MODEL_ID

        self.config.claude_auth_mode = "cli" if self.auth_mode_combo.currentIndex() == 0 else "api"
        self.config.thinking_mode = self.thinking_combo.currentText()

        # Ollamaè¨­å®š
        self.config.ollama_url = self.ollama_url_edit.text().strip()

        # å¸¸é§ãƒ¢ãƒ‡ãƒ«è¨­å®š (v7.0.0: åˆ¶å¾¡AI + Embedding)
        self.config.image_analyzer_model = self.image_model_combo.currentText()
        self.config.embedding_model = self.embedding_model_combo.currentText()

        # RAGè¨­å®š
        self.config.rag_enabled = self.rag_enabled_check.isChecked()
        self.config.rag_auto_save = self.rag_auto_save_check.isChecked()
        threshold_map = {0: "low", 1: "medium", 2: "high"}
        self.config.rag_save_threshold = threshold_map.get(self.rag_threshold_combo.currentIndex(), "medium")

        # v8.4.2: å“è³ªæ¤œè¨¼è¨­å®šï¼ˆPhase 2å†å®Ÿè¡Œå›æ•°ï¼‰
        if hasattr(self, 'max_retries_spin'):
            self.config.max_phase2_retries = self.max_retries_spin.value()

    def _on_save_settings(self):
        """è¨­å®šä¿å­˜"""
        self._update_config_from_ui()
        self._save_config()
        QMessageBox.information(self, "ä¿å­˜å®Œäº†", "è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
        self.statusChanged.emit("è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    def _test_ollama_connection(self):
        """Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«åˆ¥ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªï¼‰"""
        try:
            import ollama
            import httpx
            url = self.ollama_url_edit.text().strip()
            client = ollama.Client(host=url)

            start = time.time()
            response = client.list()
            latency = time.time() - start

            # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
            installed_models = {}
            if hasattr(response, 'models'):
                raw_models = response.models
            elif isinstance(response, dict) and 'models' in response:
                raw_models = response['models']
            else:
                raw_models = []

            for model in raw_models:
                if isinstance(model, dict):
                    name = model.get('model') or model.get('name', '')
                    size = model.get('size', 0)
                else:
                    name = getattr(model, 'model', None) or getattr(model, 'name', '')
                    size = getattr(model, 'size', 0)
                if name:
                    installed_models[name] = {"size_gb": size / 1e9 if isinstance(size, int) else 0}

            # ãƒ­ãƒ¼ãƒ‰ä¸­ã®ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
            loaded_models = {}
            try:
                with httpx.Client(timeout=5) as http_client:
                    ps_resp = http_client.get(f"{url}/api/ps")
                    if ps_resp.status_code == 200:
                        ps_data = ps_resp.json()
                        for m in ps_data.get("models", []):
                            loaded_models[m.get("name", "")] = {
                                "size_vram": m.get("size_vram", 0),
                            }
            except Exception:
                pass  # ãƒ­ãƒ¼ãƒ‰ä¸­ãƒ¢ãƒ‡ãƒ«å–å¾—å¤±æ•—ã¯ç„¡è¦–

            # è¨­å®šãƒ¢ãƒ‡ãƒ«ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª
            configured_models = self._get_configured_models()
            status_lines = []

            for model_info in configured_models:
                name = model_info["name"]
                role = model_info["role"]
                model_type = model_info["type"]

                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
                is_loaded = self._match_model_name(name, loaded_models)
                is_installed = self._match_model_name(name, installed_models)

                if is_loaded:
                    vram_info = loaded_models.get(name, {}).get("size_vram", 0)
                    vram_mb = vram_info // (1024 * 1024) if vram_info else 0
                    icon = "ğŸŸ¢"
                    status = "ãƒ­ãƒ¼ãƒ‰ä¸­"
                    vram_text = f"{vram_mb:,}MB" if vram_mb else "-"
                elif is_installed:
                    icon = "ğŸŸ¡"
                    status = "å¾…æ©Ÿä¸­"
                    vram_text = "-"
                else:
                    icon = "ğŸ”´"
                    status = "æœªDL"
                    vram_text = "-"

                type_label = "å¸¸æ™‚" if model_type == "resident" else "OD"
                status_lines.append(f"{icon} {name:<26} {status:<8} {vram_text:<10} [{type_label}]")

            # çµæœã‚’è¡¨ç¤º
            header = f"âœ… æ¥ç¶šæˆåŠŸ ({latency:.2f}ç§’)\n\nãƒ¢ãƒ‡ãƒ«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:\n"
            self.ollama_status_label.setText(header + "\n".join(status_lines))
            self.ollama_status_label.setStyleSheet("color: #22c55e;")

            # ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’æ›´æ–°
            self._update_model_combos(response)

        except ImportError:
            self.ollama_status_label.setText("âŒ ollamaãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            self.ollama_status_label.setStyleSheet("color: #ef4444;")
        except Exception as e:
            self.ollama_status_label.setText(f"âŒ æ¥ç¶šå¤±æ•—: {str(e)[:50]}")
            self.ollama_status_label.setStyleSheet("color: #ef4444;")

    def _check_claude_cli_mcp(self):
        """v7.0.0: Claude Code CLIã®MCPã‚µãƒ¼ãƒãƒ¼è¨­å®šã‚’ç¢ºèª"""
        try:
            # Claude CLIã®å­˜åœ¨ç¢ºèª
            from ..backends.claude_cli_backend import find_claude_command
            claude_cmd = find_claude_command()

            if not claude_cmd:
                self.mcp_status_label.setText("  âŒ Claude CLIãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                self.mcp_status_label.setStyleSheet("color: #ef4444; font-size: 10px;")
                return

            # claude mcp list ã§MCPã‚µãƒ¼ãƒãƒ¼ä¸€è¦§ã‚’å–å¾—
            result = run_hidden(
                [claude_cmd, "mcp", "list"],
                capture_output=True, text=True, timeout=10,
            )

            if result.returncode == 0 and result.stdout.strip():
                lines = result.stdout.strip().split("\n")
                status_text = f"  âœ… Claude CLI: {claude_cmd}\n  MCPã‚µãƒ¼ãƒãƒ¼ ({len(lines)}ä»¶):\n"
                for line in lines:
                    status_text += f"    {line}\n"
                self.mcp_status_label.setText(status_text.rstrip())
                self.mcp_status_label.setStyleSheet("color: #22c55e; font-size: 10px;")
            elif result.returncode == 0:
                self.mcp_status_label.setText(
                    f"  âœ… Claude CLI: {claude_cmd}\n  MCPã‚µãƒ¼ãƒãƒ¼: æœªè¨­å®š"
                )
                self.mcp_status_label.setStyleSheet("color: #f59e0b; font-size: 10px;")
            else:
                self.mcp_status_label.setText(
                    f"  âš ï¸ Claude CLI: {claude_cmd}\n  MCPç¢ºèªå¤±æ•—: {result.stderr[:100]}"
                )
                self.mcp_status_label.setStyleSheet("color: #f59e0b; font-size: 10px;")

        except subprocess.TimeoutExpired:
            self.mcp_status_label.setText("  âš ï¸ Claude CLIå¿œç­”ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            self.mcp_status_label.setStyleSheet("color: #f59e0b; font-size: 10px;")
        except Exception as e:
            self.mcp_status_label.setText(f"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:80]}")
            self.mcp_status_label.setStyleSheet("color: #ef4444; font-size: 10px;")

    def _get_configured_models(self) -> List[Dict[str, Any]]:
        """è¨­å®šæ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾— (v7.0.0: 3Phaseè¨­å®šUIå¯¾å¿œ)"""
        models = []

        # å¸¸é§ãƒ¢ãƒ‡ãƒ«ï¼ˆåŸºæœ¬æ©Ÿèƒ½ç”¨ï¼‰
        if hasattr(self, 'image_model_combo'):
            models.append({"name": self.image_model_combo.currentText(), "role": "åˆ¶å¾¡AI", "type": "resident"})
        if hasattr(self, 'embedding_model_combo'):
            models.append({"name": self.embedding_model_combo.currentText(), "role": "Embedding", "type": "resident"})

        # 3Phase ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¢ãƒ‡ãƒ«ï¼ˆPhase 2ã§é †æ¬¡å®Ÿè¡Œï¼‰
        if hasattr(self, 'coding_model_combo'):
            models.append({"name": self.coding_model_combo.currentText(), "role": "coding", "type": "phase2"})
        if hasattr(self, 'research_model_combo'):
            models.append({"name": self.research_model_combo.currentText(), "role": "research", "type": "phase2"})
        if hasattr(self, 'reasoning_model_combo'):
            models.append({"name": self.reasoning_model_combo.currentText(), "role": "reasoning", "type": "phase2"})
        if hasattr(self, 'translation_model_combo'):
            models.append({"name": self.translation_model_combo.currentText(), "role": "translation", "type": "phase2"})
        if hasattr(self, 'vision_model_combo'):
            models.append({"name": self.vision_model_combo.currentText(), "role": "vision", "type": "phase2"})

        return models

    def _match_model_name(self, name: str, model_dict: Dict[str, Any]) -> bool:
        """ãƒ¢ãƒ‡ãƒ«åã®ãƒãƒƒãƒãƒ³ã‚°ï¼ˆã‚¿ã‚°çœç•¥å¯¾å¿œï¼‰"""
        if name in model_dict:
            return True
        for key in model_dict:
            if key.startswith(name.split(":")[0]) or name.startswith(key.split(":")[0]):
                return True
        return False

    # =========================================================================
    # GPUå‹•çš„è¨˜éŒ²ãƒ»ã‚°ãƒ©ãƒ•è¡¨ç¤ºæ©Ÿèƒ½ï¼ˆæ™‚é–“è»¸é¸æŠãƒ»ã‚·ãƒ¼ã‚¯ãƒãƒ¼å¯¾å¿œï¼‰
    # =========================================================================

    def _toggle_gpu_recording(self):
        """GPUè¨˜éŒ²ã®é–‹å§‹/åœæ­¢"""
        if self._gpu_recording:
            self._stop_gpu_recording()
        else:
            self._start_gpu_recording()

    def _start_gpu_recording(self):
        """GPUè¨˜éŒ²ã‚’é–‹å§‹"""
        self._gpu_recording = True
        self.gpu_record_btn.setText("â¹ è¨˜éŒ²åœæ­¢")
        self.gpu_record_btn.setStyleSheet("""
            QPushButton {
                background-color: #ef4444;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
            }
            QPushButton:hover { background-color: #dc2626; }
        """)
        self._gpu_timer.start(1000)  # 1ç§’é–“éš”ã§è¨˜éŒ²
        self.statusChanged.emit("GPUè¨˜éŒ²ã‚’é–‹å§‹ã—ã¾ã—ãŸ")

    def _stop_gpu_recording(self):
        """GPUè¨˜éŒ²ã‚’åœæ­¢"""
        self._gpu_recording = False
        self._gpu_timer.stop()
        self.gpu_record_btn.setText("â–¶ è¨˜éŒ²é–‹å§‹")
        self.gpu_record_btn.setStyleSheet("")
        self.statusChanged.emit("GPUè¨˜éŒ²ã‚’åœæ­¢ã—ã¾ã—ãŸ")

    def _clear_gpu_graph(self):
        """GPUã‚°ãƒ©ãƒ•ã‚’ã‚¯ãƒªã‚¢"""
        self.gpu_graph.clear_data()
        self.gpu_seekbar.setMaximum(0)
        self.gpu_seekbar.setValue(0)
        self.gpu_seekbar_label.setText("ç¾åœ¨")
        self.statusChanged.emit("GPUã‚°ãƒ©ãƒ•ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

    def _on_gpu_time_range_changed(self, text: str):
        """æ™‚é–“ç¯„å›²ãŒå¤‰æ›´ã•ã‚ŒãŸ"""
        seconds = GPUUsageGraph.TIME_RANGES.get(text, 60)
        self.gpu_graph.set_time_range(seconds)
        self._update_gpu_seekbar_range()
        self.statusChanged.emit(f"GPUæ™‚é–“ç¯„å›²ã‚’{text}ã«å¤‰æ›´ã—ã¾ã—ãŸ")

    def _on_gpu_seekbar_changed(self, value: int):
        """ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã®å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸ"""
        self.gpu_graph.set_view_offset(value)
        if value == 0:
            self.gpu_seekbar_label.setText("ç¾åœ¨")
        elif value < 60:
            self.gpu_seekbar_label.setText(f"-{value}ç§’")
        elif value < 3600:
            self.gpu_seekbar_label.setText(f"-{value // 60}åˆ†")
        else:
            self.gpu_seekbar_label.setText(f"-{value // 3600}æ™‚é–“")

    def _on_gpu_goto_now(self):
        """ç¾åœ¨ã«æˆ»ã‚‹"""
        self.gpu_seekbar.setValue(0)
        self.gpu_graph.set_view_offset(0)
        self.gpu_seekbar_label.setText("ç¾åœ¨")

    def _update_gpu_seekbar_range(self):
        """ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã®ç¯„å›²ã‚’æ›´æ–°"""
        data_duration = int(self.gpu_graph.get_data_duration())
        current_time_range = self.gpu_graph.time_range
        # ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã®æœ€å¤§å€¤ = ãƒ‡ãƒ¼ã‚¿æœŸé–“ - ç¾åœ¨ã®è¡¨ç¤ºç¯„å›²ï¼ˆ0æœªæº€ã«ãªã‚‰ãªã„ã‚ˆã†ã«ï¼‰
        max_offset = max(0, data_duration - current_time_range)
        self.gpu_seekbar.setMaximum(max_offset)
        if self.gpu_seekbar.value() > max_offset:
            self.gpu_seekbar.setValue(max_offset)

    def _record_gpu_usage(self):
        """GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²ï¼ˆã‚¿ã‚¤ãƒãƒ¼ã‹ã‚‰å‘¼ã³å‡ºã—ï¼‰"""
        try:
            nvidia_smi = shutil.which("nvidia-smi")
            if nvidia_smi is None:
                default_paths = [
                    r"C:\Windows\System32\nvidia-smi.exe",
                    r"C:\Program Files\NVIDIA Corporation\NVSMI\nvidia-smi.exe",
                ]
                for path in default_paths:
                    if os.path.exists(path):
                        nvidia_smi = path
                        break

            if nvidia_smi is None:
                return

            result = run_hidden(
                [nvidia_smi,
                 "--query-gpu=index,memory.used,memory.total",
                 "--format=csv,noheader,nounits"],
                capture_output=True,
                text=True,
                timeout=5,
            )

            if result.returncode != 0:
                return

            lines = result.stdout.strip().split('\n')
            for line in lines:
                parts = [p.strip() for p in line.split(',')]
                if len(parts) >= 3:
                    try:
                        idx = int(parts[0])
                        used_mb = int(parts[1])
                        total_mb = int(parts[2])
                        self.gpu_graph.add_data_point(idx, used_mb, total_mb)
                    except ValueError:
                        continue

            # ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã®ç¯„å›²ã‚’æ›´æ–°
            self._update_gpu_seekbar_range()

        except Exception as e:
            logger.debug(f"[GPU Record] Error: {e}")

    def _record_gpu_with_event(self, event_name: str):
        """ã‚¤ãƒ™ãƒ³ãƒˆä»˜ãã§GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²"""
        self.gpu_graph.add_event(event_name)
        self._record_gpu_usage()

    def _schedule_gpu_record_after_llm(self, stage_name: str):
        """LLMèµ·å‹•å¾Œ5ç§’å¾Œã«GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²ã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"""
        # å³åº§ã«è¨˜éŒ²ï¼ˆèµ·å‹•æ™‚ï¼‰
        self._record_gpu_with_event(f"{stage_name}é–‹å§‹")

        # 5ç§’å¾Œã«è¨˜éŒ²
        QTimer.singleShot(5000, lambda: self._record_gpu_with_event(f"{stage_name}+5s"))

    def _update_model_combos(self, response):
        """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã§ComboBoxã‚’æ›´æ–°"""
        models = []
        if hasattr(response, 'models'):
            raw_models = response.models
        elif isinstance(response, dict) and 'models' in response:
            raw_models = response['models']
        else:
            return

        for model in raw_models:
            if isinstance(model, dict):
                name = model.get('model') or model.get('name', '')
            else:
                name = getattr(model, 'model', None) or getattr(model, 'name', '')
            if name:
                models.append(name)

        # å„ã‚³ãƒ³ãƒœãƒœãƒƒã‚¯ã‚¹ã«ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ ï¼ˆv7.0.0: å¸¸é§ + 5ã‚«ãƒ†ã‚´ãƒªï¼‰
        all_combos = [
            self.image_model_combo, self.embedding_model_combo,
            self.coding_model_combo, self.research_model_combo,
            self.reasoning_model_combo, self.translation_model_combo,
            self.vision_model_combo,
        ]
        for combo in all_combos:
            current = combo.currentText()
            for model in models:
                if combo.findText(model) == -1:
                    combo.addItem(model)
            combo.setCurrentText(current)

    def _open_vram_simulator(self):
        """VRAM Budget Simulatorãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’é–‹ã"""
        from PyQt6.QtWidgets import QDialog, QVBoxLayout

        dialog = QDialog(self)
        dialog.setWindowTitle("VRAM Budget Simulator")
        dialog.setMinimumSize(900, 600)

        layout = QVBoxLayout(dialog)
        simulator = VRAMBudgetSimulator()

        # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼è­¦å‘Š
        simulator.overflowDetected.connect(
            lambda gpu_idx, overflow: QMessageBox.warning(
                dialog, "VRAMè­¦å‘Š",
                f"GPU {gpu_idx} ã§ VRAM ãŒ {overflow:.1f} GB ã‚ªãƒ¼ãƒãƒ¼ã—ã¦ã„ã¾ã™ã€‚"
            ) if overflow > 0 else None
        )

        layout.addWidget(simulator)
        dialog.setStyleSheet("""
            QDialog {
                background-color: #1e1e1e;
            }
        """)
        dialog.exec()

    def _refresh_gpu_info(self):
        """GPUæƒ…å ±ã‚’å®‰å…¨ã«æ›´æ–°ï¼ˆPyInstallerç’°å¢ƒå¯¾å¿œï¼‰"""
        try:
            import subprocess
            import shutil
            import os

            # nvidia-smi ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’æ¢ç´¢
            nvidia_smi = shutil.which("nvidia-smi")
            if nvidia_smi is None:
                # Windows ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ç›´æ¥æŒ‡å®š
                default_paths = [
                    r"C:\Windows\System32\nvidia-smi.exe",
                    r"C:\Program Files\NVIDIA Corporation\NVSMI\nvidia-smi.exe",
                ]
                for path in default_paths:
                    if os.path.exists(path):
                        nvidia_smi = path
                        break

            if nvidia_smi is None:
                self.gpu_info_label.setText("nvidia-smiãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n(NVIDIAãƒ‰ãƒ©ã‚¤ãƒãŒå¿…è¦ã§ã™)")
                self.gpu_info_label.setStyleSheet("color: #9ca3af;")
                return

            result = run_hidden(
                [nvidia_smi,
                 "--query-gpu=index,name,memory.used,memory.total,utilization.gpu",
                 "--format=csv,noheader,nounits"],
                capture_output=True,
                text=True,
                timeout=10,
            )

            if result.returncode != 0:
                self.gpu_info_label.setText(f"nvidia-smiã‚¨ãƒ©ãƒ¼: {result.stderr.strip()[:50]}")
                self.gpu_info_label.setStyleSheet("color: #f59e0b;")
                return

            lines = result.stdout.strip().split('\n')
            info_text = ""
            total_vram_used = 0
            total_vram_total = 0

            for line in lines:
                parts = [p.strip() for p in line.split(',')]
                if len(parts) >= 5:
                    idx, name, used, total, util = parts[:5]
                    try:
                        used_mb = int(used)
                        total_mb = int(total)
                        util_pct = int(util)
                        usage_pct = (used_mb / total_mb) * 100 if total_mb > 0 else 0

                        total_vram_used += used_mb
                        total_vram_total += total_mb

                        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼é¢¨è¡¨ç¤º
                        bar_len = 20
                        filled = int(usage_pct / 100 * bar_len)
                        bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)

                        info_text += f"GPU {idx}: {name}\n"
                        info_text += f"  VRAM: [{bar}] {used_mb:,}/{total_mb:,} MB ({usage_pct:.1f}%)\n"
                        info_text += f"  GPUä½¿ç”¨ç‡: {util_pct}%\n"
                    except ValueError:
                        continue

            if total_vram_total > 0:
                info_text += f"\nåˆè¨ˆVRAM: {total_vram_used:,}/{total_vram_total:,} MB"

            self.gpu_info_label.setText(info_text.strip() or "GPUæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            self.gpu_info_label.setStyleSheet("color: #22c55e;")

        except subprocess.TimeoutExpired:
            self.gpu_info_label.setText("nvidia-smi ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (10ç§’)")
            self.gpu_info_label.setStyleSheet("color: #f59e0b;")
        except FileNotFoundError:
            self.gpu_info_label.setText("nvidia-smiãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n(NVIDIAãƒ‰ãƒ©ã‚¤ãƒãŒå¿…è¦ã§ã™)")
            self.gpu_info_label.setStyleSheet("color: #9ca3af;")
        except Exception as e:
            self.gpu_info_label.setText(f"GPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)[:40]}")
            self.gpu_info_label.setStyleSheet("color: #ef4444;")

========================================
FILE: src/tabs/settings_cortex_tab.py
========================================
"""
Settings / General Tab - ä¸€èˆ¬è¨­å®š
v3.9.0: å¤§å¹…ç°¡ç•¥åŒ–ï¼ˆã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚­ãƒ£ãƒ—ãƒãƒ£ã€äºˆç®—ç®¡ç†ã€Localæ¥ç¶šã€Geminié–¢é€£ã‚’å‰Šé™¤ï¼‰
v8.1.0: Claudeãƒ¢ãƒ‡ãƒ«è¨­å®šãƒ»MCPã‚µãƒ¼ãƒãƒ¼ç®¡ç†ã‚’soloAIã‹ã‚‰ç§»è¨­ã€è¨˜æ†¶ãƒ»çŸ¥è­˜ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ 

ä¸€èˆ¬è¨­å®š: ãƒ¢ãƒ‡ãƒ«ãƒ»CLIãƒ»MCPãƒ»è¨˜æ†¶çŸ¥è­˜ãƒ»è¡¨ç¤ºãƒ»è‡ªå‹•åŒ–
"""

import json
import logging
from pathlib import Path
from PyQt6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QTabWidget,
    QGroupBox, QLabel, QLineEdit, QPushButton,
    QCheckBox, QComboBox, QSpinBox, QListWidget,
    QListWidgetItem, QFrame, QTextEdit, QScrollArea,
    QSizePolicy, QMessageBox, QApplication, QFormLayout
)
from PyQt6.QtCore import Qt, pyqtSignal, QTimer

try:
    from ..utils.styles import SPINBOX_STYLE
except ImportError:
    SPINBOX_STYLE = ""

logger = logging.getLogger(__name__)


class SettingsCortexTab(QWidget):
    """
    ä¸€èˆ¬è¨­å®šã‚¿ãƒ– (v8.1.0)

    Features:
    - Claudeãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆsoloAIã‹ã‚‰ç§»è¨­ï¼‰
    - Claude CLI çŠ¶æ…‹
    - MCPã‚µãƒ¼ãƒãƒ¼ç®¡ç†ï¼ˆsoloAIã‹ã‚‰ç§»è¨­ï¼‰
    - è¨˜æ†¶ãƒ»çŸ¥è­˜ç®¡ç†ï¼ˆ4å±¤ãƒ¡ãƒ¢ãƒª + RAG + Knowledge + Encyclopediaï¼‰
    - è¡¨ç¤ºã¨ãƒ†ãƒ¼ãƒè¨­å®š
    - è‡ªå‹•åŒ–è¨­å®š
    """

    # ã‚·ã‚°ãƒŠãƒ«
    settingsChanged = pyqtSignal()

    def __init__(self, workflow_state=None, main_window=None, parent=None):
        super().__init__(parent)
        self.workflow_state = workflow_state
        self.main_window = main_window

        # v8.1.0: ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self._memory_manager = None
        try:
            from ..memory.memory_manager import HelixMemoryManager
            self._memory_manager = HelixMemoryManager()
            logger.info("HelixMemoryManager initialized for SettingsCortexTab")
        except Exception as e:
            logger.warning(f"Memory manager init failed for SettingsCortexTab: {e}")

        self._init_ui()
        self._connect_signals()
        self._load_settings()

        # WorkflowStateã®æ›´æ–°ã‚’ç›£è¦–
        if self.main_window:
            self.main_window.workflowStateChanged.connect(self._on_workflow_state_changed)

    def _on_workflow_state_changed(self, workflow_state):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹ãŒå¤‰æ›´ã•ã‚ŒãŸã¨ãã®å‡¦ç†"""
        pass

    def _init_ui(self):
        """UIã‚’åˆæœŸåŒ–"""
        layout = QVBoxLayout(self)
        layout.setContentsMargins(8, 8, 8, 8)

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¨ãƒªã‚¢
        scroll_area = QScrollArea()
        scroll_area.setWidgetResizable(True)
        scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        scroll_area.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)

        content_widget = QWidget()
        content_layout = QVBoxLayout(content_widget)
        content_layout.setSpacing(15)

        # 1. Claudeãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆsoloAIã‹ã‚‰ç§»è¨­ï¼‰
        model_group = self._create_model_group()
        content_layout.addWidget(model_group)

        # 2. Claude CLI çŠ¶æ…‹
        cli_group = self._create_cli_status_group()
        content_layout.addWidget(cli_group)

        # 3. MCPã‚µãƒ¼ãƒãƒ¼ç®¡ç†ï¼ˆsoloAIã‹ã‚‰ç§»è¨­ï¼‰
        mcp_group = self._create_mcp_group()
        content_layout.addWidget(mcp_group)

        # 4. è¨˜æ†¶ãƒ»çŸ¥è­˜ç®¡ç†
        memory_group = self._create_memory_knowledge_group()
        content_layout.addWidget(memory_group)

        # 5. è¡¨ç¤ºã¨ãƒ†ãƒ¼ãƒ
        display_group = self._create_display_group()
        content_layout.addWidget(display_group)

        # 6. è‡ªå‹•åŒ–
        auto_group = self._create_auto_group()
        content_layout.addWidget(auto_group)

        # 7. Web UIã‚µãƒ¼ãƒãƒ¼
        webui_group = self._create_web_ui_section()
        content_layout.addWidget(webui_group)

        # 8. ä¿å­˜ãƒœã‚¿ãƒ³
        btn_layout = QHBoxLayout()
        btn_layout.addStretch()
        self.save_settings_btn = QPushButton("ğŸ”’ è¨­å®šã‚’ä¿å­˜")
        self.save_settings_btn.setToolTip("å…¨è¨­å®šã‚’config.json + app_settings.jsonã«ä¿å­˜ã—ã¾ã™")
        btn_layout.addWidget(self.save_settings_btn)
        content_layout.addLayout(btn_layout)

        content_layout.addStretch()

        scroll_area.setWidget(content_widget)
        layout.addWidget(scroll_area)

    # ========================================
    # 1. Claudeãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆsoloAIã‹ã‚‰ç§»è¨­ï¼‰
    # ========================================

    def _create_model_group(self) -> QGroupBox:
        """v8.1.0: Claudeãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆsoloAIã‹ã‚‰ç§»è¨­ï¼‰"""
        group = QGroupBox("ğŸ¤– Claudeãƒ¢ãƒ‡ãƒ«è¨­å®š")
        layout = QFormLayout(group)

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«
        self.default_model_combo = QComboBox()
        self.default_model_combo.setToolTip("å…¨ã‚¿ãƒ–ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆClaudeãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¾ã™")
        try:
            from ..utils.constants import CLAUDE_MODELS
            for model_def in CLAUDE_MODELS:
                self.default_model_combo.addItem(
                    model_def["display_name"], userData=model_def["id"]
                )
        except ImportError:
            self.default_model_combo.addItem("Claude Sonnet 4.5 (æ¨å¥¨)")
        layout.addRow("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«:", self.default_model_combo)

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        self.timeout_spin = QSpinBox()
        self.timeout_spin.setStyleSheet(SPINBOX_STYLE)
        self.timeout_spin.setRange(10, 120)
        self.timeout_spin.setValue(30)
        self.timeout_spin.setSuffix(" åˆ†")
        self.timeout_spin.setSingleStep(10)
        self.timeout_spin.setToolTip("Claude CLIå¿œç­”å¾…ã¡ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆåˆ†ï¼‰\n10åˆ†å˜ä½ã§è¨­å®šã€ç›´æ¥å…¥åŠ›ã§ç´°ã‹ã„å€¤ã‚‚å¯")
        layout.addRow("ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ:", self.timeout_spin)

        return group

    # ========================================
    # 2. Claude CLI çŠ¶æ…‹
    # ========================================

    def _create_cli_status_group(self) -> QGroupBox:
        """v8.1.0: Claude CLIçŠ¶æ…‹è¡¨ç¤ºï¼ˆèª¬æ˜æ–‡å‰Šé™¤ã€ãƒœã‚¿ãƒ³ã®ã¿ï¼‰"""
        group = QGroupBox("ğŸ–¥ï¸ Claude CLI çŠ¶æ…‹")
        layout = QVBoxLayout(group)

        # Claude CLI çŠ¶æ…‹ + ãƒœã‚¿ãƒ³
        cli_layout = QHBoxLayout()
        cli_layout.addWidget(QLabel("Claude CLI:"))
        self.cli_test_btn = QPushButton("æ¥ç¶šç¢ºèª")
        self.cli_test_btn.setToolTip("Claude Code CLIã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»èªè¨¼çŠ¶æ…‹ã‚’ç¢ºèª")
        self.cli_test_btn.clicked.connect(self._test_cli_connection)
        cli_layout.addWidget(self.cli_test_btn)
        cli_layout.addStretch()
        layout.addLayout(cli_layout)

        # CLIçŠ¶æ…‹ãƒ©ãƒ™ãƒ«
        self.cli_status_label = QLabel("")
        self.cli_status_label.setStyleSheet("color: #888;")
        layout.addWidget(self.cli_status_label)

        # åˆæœŸçŠ¶æ…‹ã§CLIã‚’ãƒã‚§ãƒƒã‚¯
        self._check_cli_status()

        return group

    def _test_cli_connection(self):
        """CLIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        try:
            from ..backends.claude_cli_backend import check_claude_cli_available
            available, message = check_claude_cli_available()
            if available:
                self.cli_status_label.setText(f"âœ… {message}")
                self.cli_status_label.setStyleSheet("color: #4CAF50;")
                QMessageBox.information(self, "æˆåŠŸ", f"Claude CLI ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚\n{message}")
            else:
                self.cli_status_label.setText("âŒ åˆ©ç”¨ä¸å¯")
                self.cli_status_label.setStyleSheet("color: #f44336;")
                QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", f"Claude CLI ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“:\n{message}")
        except Exception as e:
            self.cli_status_label.setText("âŒ ã‚¨ãƒ©ãƒ¼")
            QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", f"CLIãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼:\n{str(e)}")

    def _check_cli_status(self):
        """CLIçŠ¶æ…‹ã‚’ç¢ºèª"""
        try:
            from ..backends.claude_cli_backend import check_claude_cli_available
            available, message = check_claude_cli_available()
            if available:
                self.cli_status_label.setText("âœ… CLIåˆ©ç”¨å¯èƒ½")
                self.cli_status_label.setStyleSheet("color: #4CAF50;")
            else:
                self.cli_status_label.setText("âš ï¸ CLIåˆ©ç”¨ä¸å¯")
                self.cli_status_label.setStyleSheet("color: #ffa500;")
        except Exception:
            self.cli_status_label.setText("")

    # ========================================
    # 3. MCPã‚µãƒ¼ãƒãƒ¼ç®¡ç†ï¼ˆsoloAIã‹ã‚‰ç§»è¨­ï¼‰
    # ========================================

    def _create_mcp_group(self) -> QGroupBox:
        """v8.1.0: MCPã‚µãƒ¼ãƒãƒ¼ç®¡ç†ï¼ˆsoloAIã‹ã‚‰ç§»è¨­ï¼‰"""
        group = QGroupBox("ğŸ”§ MCPã‚µãƒ¼ãƒãƒ¼ç®¡ç†")
        layout = QVBoxLayout(group)

        # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹å½¢å¼
        self.mcp_filesystem_cb = QCheckBox("ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ")
        self.mcp_filesystem_cb.setToolTip("ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿æ›¸ãã‚’è¨±å¯")
        self.mcp_filesystem_cb.setChecked(True)
        layout.addWidget(self.mcp_filesystem_cb)

        self.mcp_git_cb = QCheckBox("Git")
        self.mcp_git_cb.setToolTip("Gitæ“ä½œã‚’è¨±å¯")
        self.mcp_git_cb.setChecked(True)
        layout.addWidget(self.mcp_git_cb)

        self.mcp_brave_cb = QCheckBox("Braveæ¤œç´¢")
        self.mcp_brave_cb.setToolTip("Webæ¤œç´¢ã‚’è¨±å¯")
        self.mcp_brave_cb.setChecked(True)
        layout.addWidget(self.mcp_brave_cb)

        # ä¸€æ‹¬ãƒœã‚¿ãƒ³
        btn_layout = QHBoxLayout()
        enable_all_btn = QPushButton("å…¨ã¦æœ‰åŠ¹")
        enable_all_btn.setToolTip("å…¨MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä¸€æ‹¬ã§æœ‰åŠ¹ã«ã—ã¾ã™")
        enable_all_btn.clicked.connect(lambda: self._set_all_mcp(True))
        btn_layout.addWidget(enable_all_btn)
        disable_all_btn = QPushButton("å…¨ã¦ç„¡åŠ¹")
        disable_all_btn.setToolTip("å…¨MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä¸€æ‹¬ã§ç„¡åŠ¹ã«ã—ã¾ã™")
        disable_all_btn.clicked.connect(lambda: self._set_all_mcp(False))
        btn_layout.addWidget(disable_all_btn)
        btn_layout.addStretch()
        layout.addLayout(btn_layout)

        return group

    def _set_all_mcp(self, enabled: bool):
        """å…¨MCPã‚µãƒ¼ãƒãƒ¼ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’ä¸€æ‹¬è¨­å®š"""
        self.mcp_filesystem_cb.setChecked(enabled)
        self.mcp_git_cb.setChecked(enabled)
        self.mcp_brave_cb.setChecked(enabled)

    # ========================================
    # 4. è¨˜æ†¶ãƒ»çŸ¥è­˜ç®¡ç†
    # ========================================

    def _create_memory_knowledge_group(self) -> QGroupBox:
        """v8.1.0: è¨˜æ†¶ãƒ»çŸ¥è­˜ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
        group = QGroupBox("ğŸ§  è¨˜æ†¶ãƒ»çŸ¥è­˜ç®¡ç†")
        layout = QVBoxLayout(group)

        # è¨˜æ†¶çµ±è¨ˆ
        stats_label = QLabel("ğŸ“Š è¨˜æ†¶çµ±è¨ˆ")
        stats_label.setStyleSheet("font-weight: bold; color: #00d4ff;")
        layout.addWidget(stats_label)

        self.memory_stats_label = QLabel(
            "Episodeè¨˜æ†¶: 0ä»¶  Semanticè¨˜æ†¶: 0ä»¶\n"
            "æ‰‹ç¶šãè¨˜æ†¶: 0ä»¶\n"
            "Knowledge: 0ä»¶  Encyclopedia: 0ä»¶"
        )
        self.memory_stats_label.setToolTip("4å±¤ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ ã®ç¾åœ¨ã®ä¿å­˜ä»¶æ•°\nEpisodic=ä¼šè©±ãƒ­ã‚° Semantic=äº‹å®Ÿ Procedural=æ‰‹é †")
        self.memory_stats_label.setStyleSheet("color: #aaa; padding-left: 10px;")
        layout.addWidget(self.memory_stats_label)

        # RAGæœ‰åŠ¹åŒ–
        self.rag_enabled_cb = QCheckBox("RAGã‚’æœ‰åŠ¹åŒ–")
        self.rag_enabled_cb.setToolTip("RAGï¼ˆæ¤œç´¢æ‹¡å¼µç”Ÿæˆï¼‰ã‚’æœ‰åŠ¹åŒ–\néå»ã®è¨˜æ†¶ã‚’æ´»ç”¨ã—ãŸå¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™")
        self.rag_enabled_cb.setChecked(True)
        layout.addWidget(self.rag_enabled_cb)

        # è¨˜æ†¶ã®è‡ªå‹•ä¿å­˜
        self.memory_auto_save_cb = QCheckBox("è¨˜æ†¶ã®è‡ªå‹•ä¿å­˜")
        self.memory_auto_save_cb.setToolTip("å¿œç­”å¾Œã«Memory Risk Gateã§è¨˜æ†¶å“è³ªã‚’åˆ¤å®šã—\næœ‰ç”¨ãªæƒ…å ±ã‚’è‡ªå‹•çš„ã«4å±¤ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ã—ã¾ã™")
        self.memory_auto_save_cb.setChecked(True)
        layout.addWidget(self.memory_auto_save_cb)

        # ä¿å­˜é–¾å€¤
        threshold_layout = QHBoxLayout()
        threshold_layout.addWidget(QLabel("ä¿å­˜é–¾å€¤:"))
        self.threshold_combo = QComboBox()
        self.threshold_combo.setToolTip("è¨˜æ†¶ä¿å­˜ã®é‡è¦åº¦é–¾å€¤")
        self.threshold_combo.addItems(["ä½å„ªå…ˆåº¦ä»¥ä¸Š", "ä¸­å„ªå…ˆåº¦ä»¥ä¸Š", "é«˜å„ªå…ˆåº¦ã®ã¿"])
        self.threshold_combo.setCurrentIndex(1)
        threshold_layout.addWidget(self.threshold_combo)
        threshold_layout.addStretch()
        layout.addLayout(threshold_layout)

        # Memory Risk Gate
        self.risk_gate_toggle = QCheckBox("Memory Risk Gate: æœ‰åŠ¹ï¼ˆministral-3:8bã§å“è³ªåˆ¤å®šï¼‰")
        self.risk_gate_toggle.setToolTip("ministral-3:8bã«ã‚ˆã‚‹è¨˜æ†¶å“è³ªåˆ¤å®š\né‡è¤‡/çŸ›ç›¾/æ®ç™ºæ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ä¿å­˜å“è³ªã‚’æ‹…ä¿")
        self.risk_gate_toggle.setChecked(True)
        layout.addWidget(self.risk_gate_toggle)

        # Knowledgeæœ‰åŠ¹åŒ–
        self.knowledge_enabled_cb = QCheckBox("Knowledgeæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–")
        self.knowledge_enabled_cb.setChecked(True)
        layout.addWidget(self.knowledge_enabled_cb)

        # Knowledgeä¿å­˜å…ˆ
        path_layout = QHBoxLayout()
        path_layout.addWidget(QLabel("Knowledgeä¿å­˜å…ˆ:"))
        self.knowledge_path_edit = QLineEdit("data/knowledge")
        path_layout.addWidget(self.knowledge_path_edit)
        layout.addLayout(path_layout)

        # Encyclopediaæœ‰åŠ¹åŒ–
        self.encyclopedia_enabled_cb = QCheckBox("Encyclopediaæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–")
        self.encyclopedia_enabled_cb.setChecked(True)
        layout.addWidget(self.encyclopedia_enabled_cb)

        # ãƒœã‚¿ãƒ³
        btn_layout = QHBoxLayout()
        refresh_stats_btn = QPushButton("ğŸ“Š çµ±è¨ˆã‚’æ›´æ–°")
        refresh_stats_btn.setToolTip("å…¨ãƒ¡ãƒ¢ãƒªã®æœ€æ–°ä»¶æ•°ã¨çµ±è¨ˆã‚’å–å¾—ã—ã¾ã™")
        refresh_stats_btn.clicked.connect(self._refresh_memory_stats)
        btn_layout.addWidget(refresh_stats_btn)
        cleanup_btn = QPushButton("ğŸ—‘ å¤ã„è¨˜æ†¶ã®æ•´ç†")
        cleanup_btn.setToolTip("ä½¿ç”¨é »åº¦ã®ä½ã„è¨˜æ†¶ã‚’æ•´ç†ãƒ»åœ§ç¸®ã—ã¾ã™\nï¼ˆå‰Šé™¤ã§ã¯ãªãè¦ç´„ã«å¤‰æ›ï¼‰")
        cleanup_btn.clicked.connect(self._cleanup_old_memories)
        btn_layout.addWidget(cleanup_btn)
        btn_layout.addStretch()
        layout.addLayout(btn_layout)

        # åˆå›çµ±è¨ˆå–å¾—
        QTimer.singleShot(500, self._refresh_memory_stats)

        return group

    def _refresh_memory_stats(self):
        """è¨˜æ†¶çµ±è¨ˆã‚’æ›´æ–°"""
        try:
            # 4å±¤ãƒ¡ãƒ¢ãƒªçµ±è¨ˆ
            mem_stats = {"episodes": 0, "semantic_nodes": 0, "procedures": 0}
            if self._memory_manager:
                mem_stats = self._memory_manager.get_stats()

            # Knowledgeçµ±è¨ˆ
            knowledge_count = 0
            try:
                from ..knowledge.knowledge_manager import get_knowledge_manager
                km = get_knowledge_manager()
                km_stats = km.get_stats()
                knowledge_count = km_stats.get("count", 0)
            except Exception:
                pass

            # Encyclopediaçµ±è¨ˆ
            encyclopedia_count = 0

            self.memory_stats_label.setText(
                f"Episodeè¨˜æ†¶: {mem_stats.get('episodes', 0)}ä»¶  "
                f"Semanticè¨˜æ†¶: {mem_stats.get('semantic_nodes', 0)}ä»¶\n"
                f"æ‰‹ç¶šãè¨˜æ†¶: {mem_stats.get('procedures', 0)}ä»¶\n"
                f"Knowledge: {knowledge_count}ä»¶  Encyclopedia: {encyclopedia_count}ä»¶"
            )
        except Exception as e:
            self.memory_stats_label.setText(f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)[:40]}")

    def _cleanup_old_memories(self):
        """å¤ã„è¨˜æ†¶ã®æ•´ç†"""
        if self._memory_manager:
            try:
                deleted = self._memory_manager.cleanup_old_memories(days=90)
                QMessageBox.information(
                    self, "æ•´ç†å®Œäº†",
                    f"90æ—¥ä»¥ä¸Šæœªä½¿ç”¨ã®è¨˜æ†¶ã‚’æ•´ç†ã—ã¾ã—ãŸã€‚\nå‰Šé™¤ä»¶æ•°: {deleted}ä»¶"
                )
                self._refresh_memory_stats()
            except Exception as e:
                QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", f"è¨˜æ†¶ã®æ•´ç†ã«å¤±æ•—:\n{str(e)}")
        else:
            QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", "ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # ========================================
    # 5. è¡¨ç¤ºã¨ãƒ†ãƒ¼ãƒ
    # ========================================

    def _create_display_group(self) -> QGroupBox:
        """è¡¨ç¤ºã¨ãƒ†ãƒ¼ãƒè¨­å®šã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ"""
        group = QGroupBox("è¡¨ç¤ºã¨ãƒ†ãƒ¼ãƒ")
        layout = QVBoxLayout(group)

        # ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰
        self.dark_mode_cb = QCheckBox("ãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒã‚’ä½¿ç”¨ã™ã‚‹")
        self.dark_mode_cb.setToolTip("ã‚«ãƒ©ãƒ¼ãƒ†ãƒ¼ãƒã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™")
        self.dark_mode_cb.setChecked(True)
        layout.addWidget(self.dark_mode_cb)

        # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
        font_layout = QHBoxLayout()
        font_layout.addWidget(QLabel("åŸºæœ¬ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º:"))
        self.font_size_spin = QSpinBox()
        self.font_size_spin.setStyleSheet(SPINBOX_STYLE)
        self.font_size_spin.setToolTip("å…¨ã‚¿ãƒ–ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’å¤‰æ›´ã—ã¾ã™")
        self.font_size_spin.setRange(8, 20)
        self.font_size_spin.setValue(10)
        font_layout.addWidget(self.font_size_spin)
        font_layout.addStretch()
        layout.addLayout(font_layout)

        return group

    # ========================================
    # 6. è‡ªå‹•åŒ–
    # ========================================

    def _create_auto_group(self) -> QGroupBox:
        """è‡ªå‹•åŒ–è¨­å®šã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ"""
        group = QGroupBox("è‡ªå‹•åŒ–")
        layout = QVBoxLayout(group)

        self.auto_save_cb = QCheckBox("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•ä¿å­˜ã™ã‚‹")
        self.auto_save_cb.setChecked(True)
        layout.addWidget(self.auto_save_cb)

        self.auto_context_cb = QCheckBox("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ã™ã‚‹")
        self.auto_context_cb.setChecked(True)
        layout.addWidget(self.auto_context_cb)

        return group

    # ========================================
    # 7. Web UIã‚µãƒ¼ãƒãƒ¼
    # ========================================

    def _create_web_ui_section(self) -> QGroupBox:
        """Web UIã‚µãƒ¼ãƒãƒ¼è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆv9.3.0æ‹¡å¼µï¼‰"""
        group = QGroupBox("Web UI ã‚µãƒ¼ãƒãƒ¼")
        layout = QVBoxLayout(group)

        # èµ·å‹•/åœæ­¢ãƒˆã‚°ãƒ«ãƒœã‚¿ãƒ³
        toggle_row = QHBoxLayout()
        self.web_ui_toggle = QPushButton("â–¶ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•")
        self.web_ui_toggle.setCheckable(True)
        self.web_ui_toggle.setStyleSheet("""
            QPushButton {
                background-color: #059669; color: white;
                padding: 10px 20px; border-radius: 8px;
                font-size: 13px; font-weight: bold;
            }
            QPushButton:checked {
                background-color: #dc2626;
            }
        """)
        self.web_ui_toggle.setCursor(Qt.CursorShape.PointingHandCursor)
        self.web_ui_toggle.clicked.connect(self._toggle_web_server)
        toggle_row.addWidget(self.web_ui_toggle)

        self.web_ui_status_label = QLabel("åœæ­¢ä¸­")
        self.web_ui_status_label.setStyleSheet("color: #888; font-size: 12px;")
        toggle_row.addWidget(self.web_ui_status_label)
        toggle_row.addStretch()
        layout.addLayout(toggle_row)

        # ã‚¢ã‚¯ã‚»ã‚¹URLè¡¨ç¤º
        self.web_ui_url_label = QLabel("")
        self.web_ui_url_label.setStyleSheet("color: #00d4ff; font-size: 12px;")
        self.web_ui_url_label.setTextInteractionFlags(Qt.TextInteractionFlag.TextSelectableByMouse)
        layout.addWidget(self.web_ui_url_label)

        # v9.3.0: è‡ªå‹•èµ·å‹•ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
        auto_row = QHBoxLayout()
        self.web_auto_start_cb = QCheckBox("ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ã‚µãƒ¼ãƒãƒ¼ã‚’è‡ªå‹•é–‹å§‹")
        self.web_auto_start_cb.setStyleSheet("color: #e5e7eb; font-size: 12px;")
        self.web_auto_start_cb.setChecked(self._load_auto_start_setting())
        self.web_auto_start_cb.stateChanged.connect(self._save_auto_start_setting)
        auto_row.addWidget(self.web_auto_start_cb)
        auto_row.addStretch()
        layout.addLayout(auto_row)

        # ãƒãƒ¼ãƒˆç•ªå·
        port_row = QHBoxLayout()
        port_label = QLabel("ãƒãƒ¼ãƒˆ:")
        port_label.setStyleSheet("color: #9ca3af; font-size: 11px;")
        port_row.addWidget(port_label)
        self.web_port_spin = QSpinBox()
        self.web_port_spin.setRange(1024, 65535)
        self.web_port_spin.setValue(self._load_port_setting())
        self.web_port_spin.setFixedWidth(80)
        port_row.addWidget(self.web_port_spin)
        port_row.addStretch()
        layout.addLayout(port_row)

        return group

    def _toggle_web_server(self):
        """ã‚µãƒ¼ãƒãƒ¼èµ·å‹•/åœæ­¢"""
        if self.web_ui_toggle.isChecked():
            try:
                from ..web.launcher import start_server_background
                port = self.web_port_spin.value()
                self._web_server_thread = start_server_background(port=port)
                self.web_ui_toggle.setText("â–  ã‚µãƒ¼ãƒãƒ¼åœæ­¢")
                self.web_ui_status_label.setText(f"ç¨¼åƒä¸­ (ãƒãƒ¼ãƒˆ {port})")
            except Exception as e:
                self.web_ui_toggle.setChecked(False)
                self.web_ui_toggle.setText("â–¶ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•")
                self.web_ui_status_label.setText(f"èµ·å‹•å¤±æ•—: {e}")
                return

            # Tailscale IPå–å¾—ï¼ˆå¤±æ•—ã—ã¦ã‚‚ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã¯æˆåŠŸæ‰±ã„ï¼‰
            ip = "localhost"
            try:
                import subprocess as _sp
                tailscale_cmds = [
                    [r"C:\Program Files\Tailscale\tailscale.exe", "ip", "-4"],
                    ["tailscale", "ip", "-4"],
                ]
                for cmd in tailscale_cmds:
                    try:
                        result = _sp.run(cmd, capture_output=True, text=True, timeout=10)
                        if result.returncode == 0 and result.stdout.strip():
                            ip = result.stdout.strip()
                            break
                    except (FileNotFoundError, _sp.TimeoutExpired):
                        continue
            except Exception:
                pass
            self.web_ui_url_label.setText(f"ğŸ“± http://{ip}:{port}")
        else:
            if hasattr(self, '_web_server_thread') and self._web_server_thread:
                self._web_server_thread.stop()
                self._web_server_thread = None
            self.web_ui_toggle.setText("â–¶ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•")
            self.web_ui_status_label.setText("åœæ­¢ä¸­")
            self.web_ui_url_label.setText("")

    def _load_auto_start_setting(self) -> bool:
        """è‡ªå‹•èµ·å‹•è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open("config/config.json", 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config.get("web_server", {}).get("auto_start", False)
        except Exception:
            return False

    def _save_auto_start_setting(self, state):
        """è‡ªå‹•èµ·å‹•è¨­å®šã‚’ä¿å­˜"""
        try:
            config_path = Path("config/config.json")
            config = {}
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            if "web_server" not in config:
                config["web_server"] = {}
            config["web_server"]["auto_start"] = bool(state)
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Auto-start setting save failed: {e}")

    def _load_port_setting(self) -> int:
        """ãƒãƒ¼ãƒˆè¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open("config/config.json", 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config.get("web_server", {}).get("port", 8500)
        except Exception:
            return 8500

    # ========================================
    # ã‚·ã‚°ãƒŠãƒ«æ¥ç¶š + è¨­å®šä¿å­˜/èª­ã¿è¾¼ã¿
    # ========================================

    def _connect_signals(self):
        """ã‚·ã‚°ãƒŠãƒ«ã‚’æ¥ç¶š"""
        self.save_settings_btn.clicked.connect(self._on_save_settings)

    def _on_save_settings(self):
        """è¨­å®šä¿å­˜ (v8.1.0: ãƒ¢ãƒ‡ãƒ«/MCP/è¨˜æ†¶è¨­å®šã‚’è¿½åŠ )"""
        import json
        from pathlib import Path

        try:
            config_dir = Path(__file__).parent.parent.parent / "config"
            config_dir.mkdir(exist_ok=True)
            config_path = config_dir / "general_settings.json"

            settings_data = {
                # Claudeãƒ¢ãƒ‡ãƒ«è¨­å®š
                "default_model": self.default_model_combo.currentText(),
                "default_model_id": self.default_model_combo.currentData() or "",
                "timeout_minutes": self.timeout_spin.value(),
                # MCPã‚µãƒ¼ãƒãƒ¼
                "mcp_servers": {
                    "filesystem": self.mcp_filesystem_cb.isChecked(),
                    "git": self.mcp_git_cb.isChecked(),
                    "brave-search": self.mcp_brave_cb.isChecked(),
                },
                # è¨˜æ†¶ãƒ»çŸ¥è­˜ç®¡ç†
                "rag_enabled": self.rag_enabled_cb.isChecked(),
                "memory_auto_save": self.memory_auto_save_cb.isChecked(),
                "save_threshold": self.threshold_combo.currentText(),
                "risk_gate_enabled": self.risk_gate_toggle.isChecked(),
                "knowledge_enabled": self.knowledge_enabled_cb.isChecked(),
                "knowledge_path": self.knowledge_path_edit.text(),
                "encyclopedia_enabled": self.encyclopedia_enabled_cb.isChecked(),
                # è¡¨ç¤º
                "dark_mode": self.dark_mode_cb.isChecked(),
                "font_size": self.font_size_spin.value(),
                # è‡ªå‹•åŒ–
                "auto_save": self.auto_save_cb.isChecked(),
                "auto_context": self.auto_context_cb.isChecked(),
            }

            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(settings_data, f, indent=2, ensure_ascii=False)

            # v8.1.0: app_settings.json ã«ã‚‚ memory ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
            try:
                app_settings_path = config_dir / "app_settings.json"
                app_settings = {}
                if app_settings_path.exists():
                    with open(app_settings_path, 'r', encoding='utf-8') as f:
                        app_settings = json.load(f)
                app_settings["memory"] = {
                    "auto_save": self.memory_auto_save_cb.isChecked(),
                    "risk_gate_enabled": self.risk_gate_toggle.isChecked(),
                    "save_threshold": self.threshold_combo.currentText(),
                }
                with open(app_settings_path, 'w', encoding='utf-8') as f:
                    json.dump(app_settings, f, indent=2, ensure_ascii=False)
            except Exception as e:
                logger.warning(f"app_settings.json update failed: {e}")

            self.settingsChanged.emit()

            # è¦–è¦šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            sender = self.sender()
            if sender:
                original_text = sender.text()
                sender.setText("âœ… ä¿å­˜ã—ã¾ã—ãŸ")
                sender.setEnabled(False)
                QTimer.singleShot(2000, lambda: (
                    sender.setText(original_text), sender.setEnabled(True)))

        except Exception as e:
            QMessageBox.warning(self, "ã‚¨ãƒ©ãƒ¼", f"è¨­å®šã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ:\n{str(e)}")

    def _load_settings(self):
        """ä¿å­˜æ¸ˆã¿è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        import json
        from pathlib import Path

        try:
            config_path = Path(__file__).parent.parent.parent / "config" / "general_settings.json"
            if not config_path.exists():
                return

            with open(config_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # Claudeãƒ¢ãƒ‡ãƒ«è¨­å®š
            if "default_model" in data:
                idx = self.default_model_combo.findText(data["default_model"])
                if idx >= 0:
                    self.default_model_combo.setCurrentIndex(idx)
            if "timeout_minutes" in data:
                self.timeout_spin.setValue(data["timeout_minutes"])

            # MCP
            mcp = data.get("mcp_servers", {})
            if "filesystem" in mcp:
                self.mcp_filesystem_cb.setChecked(mcp["filesystem"])
            if "git" in mcp:
                self.mcp_git_cb.setChecked(mcp["git"])
            if "brave-search" in mcp:
                self.mcp_brave_cb.setChecked(mcp["brave-search"])

            # è¨˜æ†¶ãƒ»çŸ¥è­˜
            if "rag_enabled" in data:
                self.rag_enabled_cb.setChecked(data["rag_enabled"])
            if "memory_auto_save" in data:
                self.memory_auto_save_cb.setChecked(data["memory_auto_save"])
            if "save_threshold" in data:
                idx = self.threshold_combo.findText(data["save_threshold"])
                if idx >= 0:
                    self.threshold_combo.setCurrentIndex(idx)
            if "risk_gate_enabled" in data:
                self.risk_gate_toggle.setChecked(data["risk_gate_enabled"])
            if "knowledge_enabled" in data:
                self.knowledge_enabled_cb.setChecked(data["knowledge_enabled"])
            if "knowledge_path" in data:
                self.knowledge_path_edit.setText(data["knowledge_path"])
            if "encyclopedia_enabled" in data:
                self.encyclopedia_enabled_cb.setChecked(data["encyclopedia_enabled"])

            # è¡¨ç¤º
            if "dark_mode" in data:
                self.dark_mode_cb.setChecked(data["dark_mode"])
            if "font_size" in data:
                self.font_size_spin.setValue(data["font_size"])

            # è‡ªå‹•åŒ–
            if "auto_save" in data:
                self.auto_save_cb.setChecked(data["auto_save"])
            if "auto_context" in data:
                self.auto_context_cb.setChecked(data["auto_context"])

        except Exception as e:
            logger.warning(f"Settings load failed: {e}")

    # ========================================
    # äº’æ›æ€§ã®ãŸã‚ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£/ãƒ¡ã‚½ãƒƒãƒ‰
    # ========================================

    @property
    def gemini_timeout_spin(self):
        """Geminié–¢é€£ã¯å‰Šé™¤ã•ã‚ŒãŸãŒã€äº’æ›æ€§ã®ãŸã‚ãƒ€ãƒŸãƒ¼ã‚’è¿”ã™"""
        class DummySpinBox:
            def value(self):
                return 5
        return DummySpinBox()

========================================
FILE: src/main_window.py
========================================
"""
Helix AI Studio - Main Window
ãƒ¡ã‚¤ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: 4ã‚¿ãƒ–æ§‹æˆ (v5.0.0: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ°¸ç¶šåŒ–ãƒ»UIå¼·åŒ–)
"""

import sys
from PyQt6.QtWidgets import (
    QMainWindow, QTabWidget, QWidget, QVBoxLayout,
    QStatusBar, QToolBar, QLabel, QApplication
)
from PyQt6.QtCore import Qt, QSize, QSettings, QByteArray, QTimer
from PyQt6.QtGui import QFont, QIcon, QAction

from .tabs.claude_tab import ClaudeTab
# v3.9.0: Gemini Designerå‰Šé™¤
# from .tabs.gemini_designer_tab import GeminiDesignerTab
from .tabs.settings_cortex_tab import SettingsCortexTab
# v3.9.0: Helix Orchestratorã‚’LLMmixã«æ”¹å
from .tabs.helix_orchestrator_tab import HelixOrchestratorTab
# v6.0.0: ãƒãƒ£ãƒƒãƒˆä½œæˆã‚¿ãƒ–ã‚’å‰Šé™¤
# from .tabs.chat_creation_tab import ChatCreationTab
# v8.5.0: æƒ…å ±åé›†ã‚¿ãƒ–è¿½åŠ 
from .tabs.information_collection_tab import InformationCollectionTab
from .utils.constants import APP_NAME, APP_VERSION


class MainWindow(QMainWindow):
    """
    Helix AI Studio ãƒ¡ã‚¤ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦

    4ã‚¿ãƒ–æ§‹æˆ (v8.5.0):
    1. mixAI - 3Phaseå®Ÿè¡Œã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ»Claudeä¸­å¿ƒå‹ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    2. soloAI - Claudeå˜ä½“ãƒãƒ£ãƒƒãƒˆ (æ—§Claude Code)
    3. æƒ…å ±åé›† - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆRAGè‡ªå¾‹æ§‹ç¯‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    4. ä¸€èˆ¬è¨­å®š - ã‚¢ãƒ—ãƒªå…¨ä½“ã®è¨­å®š

    v8.5.0å¤‰æ›´: æƒ…å ±åé›†ã‚¿ãƒ–è¿½åŠ ï¼ˆè‡ªå¾‹RAGæ§‹ç¯‰ï¼‰
    """

    VERSION = APP_VERSION
    APP_NAME = APP_NAME

    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹æ›´æ–°ã‚·ã‚°ãƒŠãƒ«
    from PyQt6.QtCore import pyqtSignal
    workflowStateChanged = pyqtSignal(object)  # WorkflowStateMachine ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ¸¡ã™

    def __init__(self):
        super().__init__()

        # v5.0.0: QSettings for window size persistence
        self.settings = QSettings("HelixAIStudio", "MainWindow")

        # Session Managerã‚’åˆæœŸåŒ–
        from .data.session_manager import get_session_manager
        from .data.history_manager import get_history_manager
        self.session_manager = get_session_manager()
        self.workflow_state = self.session_manager.load_workflow_state()
        self.history_manager = get_history_manager()

        self._init_ui()
        self._init_statusbar()
        self._apply_stylesheet()

        # v5.0.0: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºå¾©å…ƒ
        self._restore_window_geometry()

        # v9.3.0: Web UIã‚µãƒ¼ãƒãƒ¼è‡ªå‹•èµ·å‹•
        self._auto_start_web_server()

        # v9.5.0: Webå®Ÿè¡Œãƒ­ãƒƒã‚¯ç›£è¦–ã‚¿ã‚¤ãƒãƒ¼ï¼ˆ2ç§’é–“éš”ï¼‰
        self._web_lock_timer = QTimer(self)
        self._web_lock_timer.setInterval(2000)
        self._web_lock_timer.timeout.connect(self._check_web_execution_lock)
        self._web_lock_timer.start()
        self._web_locked = False

    def _restore_window_geometry(self):
        """v5.0.0: å‰å›ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºãƒ»ä½ç½®ã‚’å¾©å…ƒ"""
        geometry = self.settings.value("geometry")
        if geometry and isinstance(geometry, QByteArray):
            self.restoreGeometry(geometry)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µã‚¤ã‚ºï¼ˆæ—¢ã«_init_uiã§è¨­å®šæ¸ˆã¿ï¼‰
            self._center_on_screen()

        state = self.settings.value("windowState")
        if state and isinstance(state, QByteArray):
            self.restoreState(state)

    def _center_on_screen(self):
        """v5.0.0: ç”»é¢ä¸­å¤®ã«é…ç½®"""
        screen = QApplication.primaryScreen()
        if screen:
            center = screen.availableGeometry().center()
            frame = self.frameGeometry()
            frame.moveCenter(center)
            self.move(frame.topLeft())

    def _auto_start_web_server(self):
        """v9.3.0: config.jsonã®web_server.auto_start=trueãªã‚‰ã‚µãƒ¼ãƒãƒ¼ã‚’è‡ªå‹•èµ·å‹•"""
        try:
            import json
            with open("config/config.json", 'r', encoding='utf-8') as f:
                config = json.load(f)
            if config.get("web_server", {}).get("auto_start", False):
                from .web.launcher import start_server_background
                port = config.get("web_server", {}).get("port", 8500)
                self._web_server_thread = start_server_background(port=port)

                # settings_cortex_tabã®UIã‚’æ›´æ–°
                if hasattr(self, 'settings_tab'):
                    tab = self.settings_tab
                    if hasattr(tab, 'web_ui_toggle'):
                        tab.web_ui_toggle.setChecked(True)
                        tab.web_ui_toggle.setText("â–  ã‚µãƒ¼ãƒãƒ¼åœæ­¢")
                        tab.web_ui_status_label.setText(f"ç¨¼åƒä¸­ (ãƒãƒ¼ãƒˆ {port})")
                        tab._web_server_thread = self._web_server_thread
        except Exception:
            pass  # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãªã—ãƒ»èµ·å‹•å¤±æ•—ã¯é»™ã£ã¦ç„¡è¦–

    def _init_ui(self):
        """UIã‚’åˆæœŸåŒ–"""
        self.setWindowTitle(f"{self.APP_NAME} v{self.VERSION}")
        self.setMinimumSize(1200, 800)
        self.resize(1400, 900)

        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¨­å®š (v3.3.0)
        self._set_window_icon()

        # ä¸­å¤®ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        layout = QVBoxLayout(central_widget)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.setSpacing(0)

        # ã‚¿ãƒ–ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
        self.tab_widget = QTabWidget()
        self.tab_widget.setDocumentMode(True)
        self.tab_widget.setTabPosition(QTabWidget.TabPosition.North)

        # ã‚¿ãƒ–ã‚’è¿½åŠ ï¼ˆworkflow_stateã‚’æ¸¡ã™ï¼‰
        # v6.0.0: ã‚¿ãƒ–é †åºã‚’å¤‰æ›´: mixAI â†’ soloAI â†’ ä¸€èˆ¬è¨­å®šï¼ˆãƒãƒ£ãƒƒãƒˆä½œæˆå‰Šé™¤ï¼‰

        # 1. mixAI ã‚¿ãƒ– (3Phaseå®Ÿè¡Œã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
        self.llmmix_tab = HelixOrchestratorTab(workflow_state=self.workflow_state, main_window=self)
        self.tab_widget.addTab(self.llmmix_tab, "ğŸ”€ mixAI")
        self.tab_widget.setTabToolTip(0,
            "<b>mixAI - 3Phaseå®Ÿè¡Œã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</b><br><br>"
            "Claude Code + ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒãƒ¼ãƒ ã«ã‚ˆã‚‹é«˜ç²¾åº¦ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³<br><br>"
            "<b>3Phase:</b><br>"
            "ãƒ»Phase 1: Claudeè¨ˆç”»ç«‹æ¡ˆï¼ˆå›ç­”+LLMæŒ‡ç¤ºç”Ÿæˆï¼‰<br>"
            "ãƒ»Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œ<br>"
            "ãƒ»Phase 3: Claudeæ¯”è¼ƒçµ±åˆ<br><br>"
            "<b>Ctrl+Enter</b> ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡"
        )

        # 2. soloAI ã‚¿ãƒ– (Claudeå˜ä½“ãƒãƒ£ãƒƒãƒˆ)
        self.claude_tab = ClaudeTab(workflow_state=self.workflow_state, main_window=self)
        self.tab_widget.addTab(self.claude_tab, "ğŸ¤– soloAI")
        self.tab_widget.setTabToolTip(1,
            "<b>soloAI - Claudeå˜ä½“ãƒãƒ£ãƒƒãƒˆï¼†è¨­å®š</b><br><br>"
            "Claude CLIã¨ã®ç›´æ¥å¯¾è©±ã€MCPã‚µãƒ¼ãƒãƒ¼ç®¡ç†ã‚’çµ±åˆã€‚<br><br>"
            "<b>ã‚µãƒ–ã‚¿ãƒ–:</b><br>"
            "ãƒ»ãƒãƒ£ãƒƒãƒˆ: AIã¨ã®å¯¾è©±<br>"
            "ãƒ»è¨­å®š: CLI/Ollamaè¨­å®šã€MCPã‚µãƒ¼ãƒãƒ¼ç®¡ç†<br><br>"
            "<b>Ctrl+Enter</b> ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡"
        )

        # 3. æƒ…å ±åé›† ã‚¿ãƒ– (v8.5.0: è‡ªå¾‹RAGæ§‹ç¯‰)
        self.info_tab = InformationCollectionTab(workflow_state=self.workflow_state, main_window=self)
        self.tab_widget.addTab(self.info_tab, "ğŸ“š æƒ…å ±åé›†")
        self.tab_widget.setTabToolTip(2,
            "<b>æƒ…å ±åé›† - è‡ªå¾‹RAGæ§‹ç¯‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</b><br><br>"
            "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ ¼ç´ã—ã€Claude + ãƒ­ãƒ¼ã‚«ãƒ«LLMã§<br>"
            "è‡ªå‹•çš„ã«RAGã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚<br><br>"
            "<b>3ã‚¹ãƒ†ãƒƒãƒ—:</b><br>"
            "ãƒ»Step 1: Claude ãƒ—ãƒ©ãƒ³ç­–å®š<br>"
            "ãƒ»Step 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMè‡ªå¾‹å®Ÿè¡Œ<br>"
            "ãƒ»Step 3: Claude å“è³ªæ¤œè¨¼"
        )

        # 4. ä¸€èˆ¬è¨­å®š ã‚¿ãƒ– (v6.0.0: APIã‚­ãƒ¼è¨­å®šå‰Šé™¤)
        self.settings_tab = SettingsCortexTab(workflow_state=self.workflow_state, main_window=self)
        self.tab_widget.addTab(self.settings_tab, "âš™ï¸ ä¸€èˆ¬è¨­å®š")
        self.tab_widget.setTabToolTip(3,
            "<b>ä¸€èˆ¬è¨­å®š - ã‚¢ãƒ—ãƒªå…¨ä½“ã®è¨­å®š</b><br><br>"
            "è¡¨ç¤ºè¨­å®šã€è‡ªå‹•åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãªã©ã€‚<br><br>"
            "<b>ä¸»è¦æ©Ÿèƒ½:</b><br>"
            "ãƒ»ãƒ†ãƒ¼ãƒãƒ»ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š<br>"
            "ãƒ»è‡ªå‹•ä¿å­˜è¨­å®š<br>"
            "ãƒ»Knowledge/Encyclopedia"
        )

        layout.addWidget(self.tab_widget)

        # ã‚·ã‚°ãƒŠãƒ«æ¥ç¶š
        self._connect_signals()

    def _set_window_icon(self):
        """ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¨­å®š (v3.3.0: ã‚¿ã‚¹ã‚¯ãƒãƒ¼ãƒ»ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒ¼ä¸¡æ–¹ã«åæ˜ )"""
        import sys
        from pathlib import Path

        # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¹ã‚’å–å¾—ï¼ˆPyInstallerå¯¾å¿œï¼‰
        if getattr(sys, 'frozen', False) and hasattr(sys, '_MEIPASS'):
            app_path = Path(sys.executable).parent
        else:
            app_path = Path(__file__).parent.parent

        # ã‚¢ã‚¤ã‚³ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ (.icoå„ªå…ˆã€.pngãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
        icon_paths = [
            app_path / "icon.ico",
            app_path / "icon.png",
        ]

        for icon_path in icon_paths:
            if icon_path.exists():
                icon = QIcon(str(icon_path))
                self.setWindowIcon(icon)
                # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã«ã‚‚è¨­å®šï¼ˆã‚¿ã‚¹ã‚¯ãƒãƒ¼ç”¨ï¼‰
                QApplication.instance().setWindowIcon(icon)
                break

    def _init_statusbar(self):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ã‚’åˆæœŸåŒ–"""
        self.statusbar = QStatusBar()
        self.setStatusBar(self.statusbar)

        # å·¦å´: ä¸€èˆ¬ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        self.status_label = QLabel("Ready")
        self.statusbar.addWidget(self.status_label)

        # å³å´: ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
        version_label = QLabel(f"v{self.VERSION}")
        self.statusbar.addPermanentWidget(version_label)

    def _connect_signals(self):
        """ã‚·ã‚°ãƒŠãƒ«ã‚’æ¥ç¶š"""
        # Claudeã‚¿ãƒ–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ã¸Claude
        self.claude_tab.statusChanged.connect(self._update_status)

        # v3.9.0: Gemini Designerå‰Šé™¤

        # LLMmixã‚¿ãƒ–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        self.llmmix_tab.statusChanged.connect(self._update_status)

        # v8.5.0: æƒ…å ±åé›†ã‚¿ãƒ–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        self.info_tab.statusChanged.connect(self._update_status)

        # è¨­å®šå¤‰æ›´ã®åæ˜ 
        self.settings_tab.settingsChanged.connect(self._on_settings_changed)

    def _update_status(self, message: str):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°"""
        self.status_label.setText(message)

    # v3.9.0: _on_style_appliedå‰Šé™¤ï¼ˆGemini Designerå‰Šé™¤ã®ãŸã‚ï¼‰

    def _on_settings_changed(self):
        """è¨­å®šå¤‰æ›´æ™‚"""
        self._update_status("âš™ï¸ è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚(ä¸€éƒ¨è¨­å®šã¯å†èµ·å‹•å¾Œã«åæ˜ ã•ã‚Œã¾ã™)")

        # v3.9.0: Geminié–¢é€£å‰Šé™¤

        # TODO: ã‚¹ã‚¿ã‚¤ãƒ«ã‚·ãƒ¼ãƒˆå†é©ç”¨ãªã©ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åæ˜ å‡¦ç†

    def notify_workflow_state_changed(self):
        """
        ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹ãŒå¤‰æ›´ã•ã‚ŒãŸã“ã¨ã‚’å…¨ã‚¿ãƒ–ã«é€šçŸ¥

        Claude Codeã‚¿ãƒ–ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹
        """
        self.workflowStateChanged.emit(self.workflow_state)
        self.session_manager.save_workflow_state()

    # =========================================================================
    # v9.5.0: Webå®Ÿè¡Œãƒ­ãƒƒã‚¯ç›£è¦–
    # =========================================================================

    def _check_web_execution_lock(self):
        """Webå®Ÿè¡Œãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›£è¦–"""
        import json
        from pathlib import Path
        lock_file = Path("data/web_execution_lock.json")
        try:
            if lock_file.exists():
                data = json.loads(lock_file.read_text(encoding='utf-8'))
                is_locked = data.get("locked", False)
            else:
                is_locked = False
        except Exception:
            is_locked = False
            data = {}

        if is_locked and not self._web_locked:
            self._activate_web_lock(data)
        elif not is_locked and self._web_locked:
            self._deactivate_web_lock()

    def _activate_web_lock(self, lock_data: dict):
        """Webãƒ­ãƒƒã‚¯æœ‰åŠ¹åŒ– -- ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤è¡¨ç¤º"""
        self._web_locked = True
        tab = lock_data.get("tab", "Web")
        client = lock_data.get("client_info", "")
        preview = lock_data.get("prompt_preview", "")

        for tab_widget in [self.llmmix_tab, self.claude_tab]:
            if hasattr(tab_widget, 'web_lock_overlay'):
                tab_widget.web_lock_overlay.show_lock(
                    f"Web UIã‹ã‚‰å®Ÿè¡Œä¸­ ({tab})\n"
                    f"ç«¯æœ«: {client}\n"
                    f"å†…å®¹: {preview}"
                )
        self.status_label.setText(f"Web UIå®Ÿè¡Œä¸­: {tab} - {preview}")

    def _deactivate_web_lock(self):
        """Webãƒ­ãƒƒã‚¯è§£é™¤"""
        self._web_locked = False
        for tab_widget in [self.llmmix_tab, self.claude_tab]:
            if hasattr(tab_widget, 'web_lock_overlay'):
                tab_widget.web_lock_overlay.hide_lock()
        self.status_label.setText("Ready")

    def _apply_stylesheet(self):
        """ã‚¹ã‚¿ã‚¤ãƒ«ã‚·ãƒ¼ãƒˆã‚’é©ç”¨ (Cyberpunk Minimalãƒ†ãƒ¼ãƒ)"""
        stylesheet = """
/* Helix AI Studio - Cyberpunk Minimal Theme */
/* ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼èƒŒæ™¯ + ãƒã‚ªãƒ³ã‚·ã‚¢ãƒ³/ã‚°ãƒªãƒ¼ãƒ³ ã‚¢ã‚¯ã‚»ãƒ³ãƒˆ */

QMainWindow {
    background-color: #1a1a1a;
}

QWidget {
    background-color: #1a1a1a;
    color: #e0e0e0;
    font-family: "Segoe UI", "Yu Gothic UI", sans-serif;
    font-size: 10pt;
}

/* Tab Widget - Cyberpunk Style */
QTabWidget::pane {
    border: 1px solid #2d2d2d;
    background-color: #1a1a1a;
    border-radius: 6px;
}

QTabBar::tab {
    background-color: #252525;
    color: #888888;
    padding: 12px 24px;
    border-top-left-radius: 6px;
    border-top-right-radius: 6px;
    margin-right: 3px;
    border: 1px solid #2d2d2d;
    border-bottom: none;
}

QTabBar::tab:selected {
    background-color: #1a1a1a;
    color: #00d4ff;
    border-color: #00d4ff;
    border-bottom: 2px solid #00d4ff;
}

QTabBar::tab:hover:!selected {
    background-color: #2d2d2d;
    color: #00ff88;
}

/* Buttons - Neon Accent */
QPushButton {
    background-color: #2d2d2d;
    color: #00d4ff;
    border: 1px solid #00d4ff;
    padding: 8px 16px;
    border-radius: 6px;
    min-width: 80px;
}

QPushButton:hover {
    background-color: #00d4ff;
    color: #1a1a1a;
}

QPushButton:pressed {
    background-color: #00a0c0;
    color: #ffffff;
}

QPushButton:disabled {
    background-color: #252525;
    color: #555555;
    border-color: #3d3d3d;
}

/* Primary Action Button */
QPushButton[cssClass="primary"] {
    background-color: #00ff88;
    color: #1a1a1a;
    border: none;
    font-weight: bold;
}

QPushButton[cssClass="primary"]:hover {
    background-color: #00cc6a;
}

/* Input Fields - Subtle Glow on Focus */
QLineEdit, QTextEdit, QPlainTextEdit {
    background-color: #252525;
    color: #e0e0e0;
    border: 1px solid #3d3d3d;
    border-radius: 6px;
    padding: 8px;
    selection-background-color: #00d4ff;
    selection-color: #1a1a1a;
}

QLineEdit:focus, QTextEdit:focus, QPlainTextEdit:focus {
    border-color: #00d4ff;
    background-color: #2a2a2a;
}

/* ComboBox */
QComboBox {
    background-color: #252525;
    color: #e0e0e0;
    border: 1px solid #3d3d3d;
    border-radius: 6px;
    padding: 8px 12px;
    min-width: 120px;
}

QComboBox:hover {
    border-color: #00d4ff;
}

QComboBox::drop-down {
    border: none;
    width: 24px;
    background: transparent;
}

QComboBox QAbstractItemView {
    background-color: #252525;
    color: #e0e0e0;
    selection-background-color: #00d4ff;
    selection-color: #1a1a1a;
    border: 1px solid #00d4ff;
    border-radius: 4px;
}

/* CheckBox */
QCheckBox {
    spacing: 10px;
    color: #b0b0b0;
}

QCheckBox::indicator {
    width: 20px;
    height: 20px;
    border-radius: 4px;
    border: 2px solid #3d3d3d;
    background-color: #252525;
}

QCheckBox::indicator:hover {
    border-color: #00d4ff;
}

QCheckBox::indicator:checked {
    background-color: #00d4ff;
    border-color: #00d4ff;
}

/* GroupBox - Neon Border */
QGroupBox {
    border: 1px solid #2d2d2d;
    border-radius: 8px;
    margin-top: 16px;
    padding: 16px;
    padding-top: 24px;
    background-color: #1e1e1e;
}

QGroupBox::title {
    color: #00d4ff;
    subcontrol-origin: margin;
    subcontrol-position: top left;
    padding: 4px 12px;
    background-color: #1e1e1e;
    border-radius: 4px;
}

/* List/Tree Widget */
QListWidget, QTreeWidget {
    background-color: #252525;
    color: #e0e0e0;
    border: 1px solid #2d2d2d;
    border-radius: 6px;
    outline: none;
}

QListWidget::item, QTreeWidget::item {
    padding: 8px;
    border-radius: 4px;
}

QListWidget::item:selected, QTreeWidget::item:selected {
    background-color: #00d4ff;
    color: #1a1a1a;
}

QListWidget::item:hover, QTreeWidget::item:hover {
    background-color: #2d2d2d;
}

QTreeWidget::branch:selected {
    background-color: #00d4ff;
}

/* Scrollbar - Minimal */
QScrollBar:vertical {
    background-color: #1a1a1a;
    width: 10px;
    margin: 0;
    border-radius: 5px;
}

QScrollBar::handle:vertical {
    background-color: #3d3d3d;
    border-radius: 5px;
    min-height: 30px;
}

QScrollBar::handle:vertical:hover {
    background-color: #00d4ff;
}

QScrollBar::add-line:vertical, QScrollBar::sub-line:vertical {
    height: 0;
}

QScrollBar:horizontal {
    background-color: #1a1a1a;
    height: 10px;
    margin: 0;
    border-radius: 5px;
}

QScrollBar::handle:horizontal {
    background-color: #3d3d3d;
    border-radius: 5px;
    min-width: 30px;
}

QScrollBar::handle:horizontal:hover {
    background-color: #00d4ff;
}

QScrollBar::add-line:horizontal, QScrollBar::sub-line:horizontal {
    width: 0;
}

/* ToolBar */
QToolBar {
    background-color: #1e1e1e;
    border: none;
    padding: 6px;
    spacing: 10px;
}

/* StatusBar - Neon Accent */
QStatusBar {
    background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
        stop:0 #00d4ff, stop:1 #00ff88);
    color: #1a1a1a;
    font-weight: bold;
}

/* SpinBox */
QSpinBox {
    background-color: #252525;
    color: #e0e0e0;
    border: 1px solid #3d3d3d;
    border-radius: 6px;
    padding: 6px;
}

QSpinBox:focus {
    border-color: #00d4ff;
}

/* ProgressBar - Neon Glow Effect */
QProgressBar {
    border: 1px solid #2d2d2d;
    border-radius: 6px;
    background-color: #252525;
    text-align: center;
    color: #e0e0e0;
}

QProgressBar::chunk {
    background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
        stop:0 #00d4ff, stop:1 #00ff88);
    border-radius: 5px;
}

/* Splitter */
QSplitter::handle {
    background-color: #2d2d2d;
}

QSplitter::handle:hover {
    background-color: #00d4ff;
}

QSplitter::handle:horizontal {
    width: 3px;
}

QSplitter::handle:vertical {
    height: 3px;
}

/* Slider */
QSlider::groove:horizontal {
    background-color: #2d2d2d;
    height: 6px;
    border-radius: 3px;
}

QSlider::handle:horizontal {
    background-color: #00d4ff;
    width: 16px;
    height: 16px;
    margin: -5px 0;
    border-radius: 8px;
}

QSlider::handle:horizontal:hover {
    background-color: #00ff88;
}

/* ToolTip */
QToolTip {
    background-color: #252525;
    color: #e0e0e0;
    border: 1px solid #00d4ff;
    border-radius: 4px;
    padding: 6px;
}

/* Menu */
QMenu {
    background-color: #252525;
    border: 1px solid #2d2d2d;
    border-radius: 6px;
    padding: 4px;
}

QMenu::item {
    padding: 8px 24px;
    border-radius: 4px;
}

QMenu::item:selected {
    background-color: #00d4ff;
    color: #1a1a1a;
}

QMenu::separator {
    height: 1px;
    background-color: #3d3d3d;
    margin: 4px 8px;
}
"""
        self.setStyleSheet(stylesheet)

    def closeEvent(self, event):
        """ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¯ãƒ­ãƒ¼ã‚ºã‚¤ãƒ™ãƒ³ãƒˆ (v5.0.0: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ°¸ç¶šåŒ–è¿½åŠ )"""
        # v5.0.0: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºãƒ»ä½ç½®ã‚’ä¿å­˜
        self.settings.setValue("geometry", self.saveGeometry())
        self.settings.setValue("windowState", self.saveState())

        # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢
        self._cleanup_workers()

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä¿å­˜
        try:
            self.session_manager.save_workflow_state()
        except Exception as e:
            import logging
            logging.getLogger(__name__).warning(f"Failed to save workflow state on close: {e}")

        event.accept()

    def _cleanup_workers(self):
        """v3.9.6: ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        import logging
        logger = logging.getLogger(__name__)

        # mixAI (LLMmix) ã‚¿ãƒ–ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢
        if hasattr(self, 'llmmix_tab') and hasattr(self.llmmix_tab, 'worker'):
            worker = self.llmmix_tab.worker
            if worker and worker.isRunning():
                logger.info("[MainWindow] Stopping mixAI worker...")
                worker.cancel()
                worker.wait(3000)  # æœ€å¤§3ç§’å¾…æ©Ÿ
                if worker.isRunning():
                    worker.terminate()
                    worker.wait(1000)

        # soloAI (Claude) ã‚¿ãƒ–ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢
        if hasattr(self, 'claude_tab'):
            # claude_tabã«_workerãŒã‚ã‚‹å ´åˆ
            if hasattr(self.claude_tab, '_worker'):
                worker = self.claude_tab._worker
                if worker and worker.isRunning():
                    logger.info("[MainWindow] Stopping soloAI worker...")
                    if hasattr(worker, 'stop'):
                        worker.stop()
                    worker.wait(3000)
                    if worker.isRunning():
                        worker.terminate()
                        worker.wait(1000)

        logger.info("[MainWindow] Worker cleanup completed")


def create_application():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
    # High DPIå¯¾å¿œ (ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã®å‰ã«è¨­å®š)
    QApplication.setHighDpiScaleFactorRoundingPolicy(
        Qt.HighDpiScaleFactorRoundingPolicy.PassThrough
    )

    app = QApplication(sys.argv)
    app.setApplicationName("Helix AI Studio")
    app.setApplicationVersion(MainWindow.VERSION)

    return app


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    app = create_application()
    window = MainWindow()
    window.show()
    sys.exit(app.exec())


if __name__ == "__main__":
    main()

========================================
FILE: src/web/server.py
========================================
"""
Helix AI Studio - Web UIã‚µãƒ¼ãƒãƒ¼ (v9.3.0)

FastAPI + Uvicornã‚µãƒ¼ãƒãƒ¼ã€‚
PyQt6ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã¯åˆ¥ãƒ—ãƒ­ã‚»ã‚¹ã§èµ·å‹•ã—ã€
å…±æœ‰ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆClaude CLI, RAGBuildLockç­‰ï¼‰ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã€‚

èµ·å‹•æ–¹æ³•:
  1. ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³: python -m src.web.server
  2. PyQt6çµ±åˆ: HelixAIStudio.py ã®è¨­å®šç”»é¢ã‹ã‚‰ãƒˆã‚°ãƒ«ã§èµ·å‹•

æŠ€è¡“çš„ãªæ³¨æ„:
  - FastAPI (asyncio) ã¨ PyQt6 (QEventLoop) ã¯åˆ¥ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œ
  - ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡ã¯ç¾æ™‚ç‚¹ã§ã¯ä¸è¦ï¼ˆClaude CLIã¯éƒ½åº¦subprocesså®Ÿè¡Œã®ãŸã‚ï¼‰
  - RAGBuildLockã®å…±æœ‰ã¯Phase 2ä»¥é™ã§å¯¾å¿œ
"""

import asyncio
import json
import logging
import os
import secrets
import subprocess
import time as _time
import uuid
from contextlib import asynccontextmanager
from datetime import datetime
from pathlib import Path

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles

from .auth import WebAuthManager
from .api_routes import router as api_router
from .rag_bridge import WebRAGBridge
from .chat_store import ChatStore
from .ws_manager import WebSocketManager

logger = logging.getLogger(__name__)

# =============================================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹
# =============================================================================

rag_bridge = WebRAGBridge()
chat_store = ChatStore()

ws_manager = WebSocketManager(max_connections=3)
auth_manager = WebAuthManager()

_app_state = {
    "pyqt_running": False,
    "active_websockets": 0,
    "rag_locked": False,
}


def get_app_state() -> dict:
    """API routesã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã®çŠ¶æ…‹å–å¾—"""
    _app_state["active_websockets"] = ws_manager.active_count
    return _app_state


# =============================================================================
# v9.5.0: Webå®Ÿè¡Œãƒ­ãƒƒã‚¯
# =============================================================================

LOCK_FILE = Path("data/web_execution_lock.json")


def _set_execution_lock(tab: str, client_info: str, prompt: str):
    """Webå®Ÿè¡Œãƒ­ãƒƒã‚¯ã‚’è¨­å®š"""
    lock_data = {
        "locked": True,
        "tab": tab,
        "client_info": client_info,
        "started_at": datetime.now().isoformat(),
        "prompt_preview": prompt[:50],
    }
    LOCK_FILE.parent.mkdir(parents=True, exist_ok=True)
    LOCK_FILE.write_text(json.dumps(lock_data, ensure_ascii=False), encoding='utf-8')


def _release_execution_lock():
    """Webå®Ÿè¡Œãƒ­ãƒƒã‚¯ã‚’è§£é™¤"""
    try:
        LOCK_FILE.write_text('{"locked": false}', encoding='utf-8')
    except Exception:
        pass


# =============================================================================
# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# =============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """èµ·å‹•/çµ‚äº†ãƒ•ãƒƒã‚¯"""
    logger.info("Helix AI Studio Web Server starting...")
    logger.info(f"Port: {os.environ.get('HELIX_WEB_PORT', 8500)}")
    yield
    logger.info("Helix AI Studio Web Server shutting down...")


app = FastAPI(
    title="Helix AI Studio Web API",
    version="9.3.0",
    lifespan=lifespan,
)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Tailscale VPNå†…ãªã®ã§å…¨è¨±å¯
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# REST APIãƒ«ãƒ¼ã‚¿ãƒ¼
app.include_router(api_router)

# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰é™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡ï¼ˆStaticFilesã®ãƒ«ãƒ¼ãƒˆãƒã‚¦ãƒ³ãƒˆã‚’é¿ã‘ã‚‹ï¼‰
# ãƒ«ãƒ¼ãƒˆãƒã‚¦ãƒ³ãƒˆ("/")ã¯WebSocketãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ¨ªå–ã‚Šã—ã¦AssertionErrorã‚’èµ·ã“ã™ãŸã‚ã€
# /assets ã®ã¿StaticFilesã§ãƒã‚¦ãƒ³ãƒˆã—ã€ãã‚Œä»¥å¤–ã¯catch-all GETãƒ«ãƒ¼ãƒˆã§SPAå¯¾å¿œã™ã‚‹
frontend_dist = Path(__file__).parent.parent.parent / "frontend" / "dist"
if frontend_dist.exists():
    assets_dir = frontend_dist / "assets"
    if assets_dir.exists():
        app.mount("/assets", StaticFiles(directory=str(assets_dir)), name="assets")


# =============================================================================
# WebSocket ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (soloAI)
# =============================================================================

@app.websocket("/ws/solo")
async def websocket_solo(websocket: WebSocket, token: str = Query(...)):
    """
    soloAI WebSocketã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚
    æ¥ç¶šæ™‚ã«JWTèªè¨¼ã‚’è¡Œã„ã€èªè¨¼æˆåŠŸå¾Œã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã™ã‚‹ã€‚

    ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ â†’ ã‚µãƒ¼ãƒãƒ¼ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:
      {"action": "execute", "prompt": "...", "model_id": "...", ...}
      {"action": "cancel"}
      {"action": "ping"}

    ã‚µãƒ¼ãƒãƒ¼ â†’ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:
      {"type": "streaming", "chunk": "...", "done": false}
      {"type": "streaming", "chunk": "...", "done": true}
      {"type": "status", "status": "...", "detail": "..."}
      {"type": "error", "error": "..."}
      {"type": "pong"}
    """
    # JWTèªè¨¼
    client_ip = websocket.client.host
    if not auth_manager.check_ip(client_ip):
        await websocket.close(code=4003, reason="IP not allowed")
        return

    payload = auth_manager.verify_token(token)
    if payload is None:
        await websocket.close(code=4001, reason="Invalid token")
        return

    # æ¥ç¶šå—ã‘å…¥ã‚Œ
    client_id = str(uuid.uuid4())
    connected = await ws_manager.connect(websocket, client_id)
    if not connected:
        await websocket.close(code=4029, reason="Too many connections")
        return

    try:
        await ws_manager.send_status(client_id, "connected", "soloAI WebSocket ready")

        while True:
            data = await websocket.receive_json()
            action = data.get("action")

            if action == "ping":
                await ws_manager.send_to(client_id, {"type": "pong"})

            elif action == "execute":
                await _handle_solo_execute(client_id, data)

            elif action == "cancel":
                # Phase 1ã§ã¯æœªå®Ÿè£…ï¼ˆClaude CLIã¯subprocessãªã®ã§killãŒå¿…è¦ï¼‰
                await ws_manager.send_status(client_id, "cancelled", "ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã¯ç¾åœ¨æœªå¯¾å¿œã§ã™")

            else:
                await ws_manager.send_error(client_id, f"Unknown action: {action}")

    except WebSocketDisconnect:
        logger.info(f"WebSocket client disconnected: {client_id}")
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
    finally:
        await ws_manager.disconnect(client_id)


# =============================================================================
# WebSocket ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (mixAI)
# =============================================================================

@app.websocket("/ws/mix")
async def websocket_mix(websocket: WebSocket, token: str = Query(...)):
    """
    mixAI WebSocketã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚
    3Phaseå®Ÿè¡Œã®é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é…ä¿¡ã€‚

    ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ â†’ ã‚µãƒ¼ãƒãƒ¼:
      {"action": "execute", "prompt": "...", "model_id": "...",
       "model_assignments": {...}, "project_dir": "...", "attached_files": [...]}
      {"action": "cancel"}

    ã‚µãƒ¼ãƒãƒ¼ â†’ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ:
      {"type": "phase_changed", "phase": 1, "description": "..."}
      {"type": "streaming", "chunk": "...", "done": false}
      {"type": "llm_started", "category": "coding", "model": "devstral-2:123b"}
      {"type": "llm_finished", "category": "coding", "success": true, "elapsed": 12.5}
      {"type": "phase2_progress", "completed": 2, "total": 5}
      {"type": "streaming", "chunk": "...", "done": true}
      {"type": "error", "error": "..."}
    """
    # JWTèªè¨¼ï¼ˆsoloAIã¨åŒã˜ï¼‰
    client_ip = websocket.client.host
    if not auth_manager.check_ip(client_ip):
        await websocket.close(code=4003, reason="IP not allowed")
        return

    payload = auth_manager.verify_token(token)
    if payload is None:
        await websocket.close(code=4001, reason="Invalid token")
        return

    client_id = str(uuid.uuid4())
    connected = await ws_manager.connect(websocket, client_id)
    if not connected:
        await websocket.close(code=4029, reason="Too many connections")
        return

    try:
        await ws_manager.send_status(client_id, "connected", "mixAI WebSocket ready")

        while True:
            data = await websocket.receive_json()
            action = data.get("action")

            if action == "ping":
                await ws_manager.send_to(client_id, {"type": "pong"})
            elif action == "execute":
                await _handle_mix_execute(client_id, data)
            elif action == "cancel":
                await ws_manager.send_status(client_id, "cancelled", "ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã¯ç¾åœ¨æœªå¯¾å¿œã§ã™")
            else:
                await ws_manager.send_error(client_id, f"Unknown action: {action}")

    except WebSocketDisconnect:
        logger.info(f"mixAI WebSocket disconnected: {client_id}")
    except Exception as e:
        logger.error(f"mixAI WebSocket error: {e}")
    finally:
        await ws_manager.disconnect(client_id)


# =============================================================================
# SPA catch-all ãƒ«ãƒ¼ãƒˆï¼ˆWebSocketãƒ«ãƒ¼ãƒˆã‚ˆã‚Šå¾Œã«å®šç¾©ï¼‰
# =============================================================================

if frontend_dist.exists():
    # SPAå¯¾å¿œ: 404ã‚¨ãƒ©ãƒ¼æ™‚ã«index.htmlã‚’è¿”ã™ï¼ˆcatch-allãƒ«ãƒ¼ãƒˆã®ä»£ã‚ã‚Šï¼‰
    # ã“ã‚Œã«ã‚ˆã‚ŠAPIãƒ«ãƒ¼ãƒˆã¨ã®ç«¶åˆã‚’å®Œå…¨ã«å›é¿ã§ãã‚‹
    from starlette.exceptions import HTTPException as StarletteHTTPException
    from starlette.requests import Request as StarletteRequest

    _original_index = frontend_dist / "index.html"

    @app.exception_handler(404)
    async def spa_not_found_handler(request: StarletteRequest, exc: StarletteHTTPException):
        """404æ™‚ã«SPAã®index.htmlã‚’è¿”ã™ï¼ˆAPIãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯é™¤å¤–ï¼‰"""
        path = request.url.path
        # APIã‚„docsãƒ‘ã‚¹ã¯é€šå¸¸ã®404ã‚’è¿”ã™
        if path.startswith(("/api/", "/ws/", "/docs", "/openapi.json", "/redoc")):
            return JSONResponse(
                status_code=exc.status_code,
                content={"detail": exc.detail or "Not found"},
            )
        # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚Œã°ãã‚Œã‚’è¿”ã™
        file_path = frontend_dist / path.lstrip("/")
        if file_path.is_file() and ".." not in path:
            return FileResponse(file_path)
        # ãã‚Œä»¥å¤–ã¯SPAã®index.htmlã‚’è¿”ã™
        return FileResponse(_original_index)


async def _handle_solo_execute(client_id: str, data: dict):
    """
    soloAIå®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ© (v9.2.0: ChatStoreçµ±åˆ)ã€‚
    Claude CLIã‚’subprocessã§å®Ÿè¡Œã—ã€çµæœã‚’WebSocketã§é€ä¿¡ã€‚
    """
    from ..utils.subprocess_utils import run_hidden

    prompt = data.get("prompt", "")
    chat_id = data.get("chat_id")  # v9.2.0
    model_id = data.get("model_id", "claude-opus-4-6")
    project_dir = data.get("project_dir", "")
    timeout = data.get("timeout") or 0
    timeout = timeout if timeout > 0 else _get_claude_timeout_sec()
    use_mcp = data.get("use_mcp", True)
    auto_approve = data.get("auto_approve", True)
    enable_rag = data.get("enable_rag", True)
    attached_files = data.get("attached_files", [])
    client_info = data.get("client_info", "Web Client")  # v9.5.0

    if not prompt:
        await ws_manager.send_error(client_id, "Prompt is empty")
        return

    # v9.5.0: Webå®Ÿè¡Œãƒ­ãƒƒã‚¯è¨­å®š
    _set_execution_lock("soloAI", client_info, prompt)

    # v9.2.0: ãƒãƒ£ãƒƒãƒˆIDãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
    if not chat_id:
        chat = chat_store.create_chat(tab="soloAI")
        chat_id = chat["id"]
        await ws_manager.send_to(client_id, {
            "type": "chat_created",
            "chat_id": chat_id,
        })

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜
    chat_store.add_message(chat_id, "user", prompt)

    # ã‚¿ã‚¤ãƒˆãƒ«è‡ªå‹•ç”Ÿæˆï¼ˆæœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ™‚ï¼‰
    chat = chat_store.get_chat(chat_id)
    if chat and chat["message_count"] == 1:
        title = chat_store.auto_generate_title(chat_id)
        await ws_manager.send_to(client_id, {
            "type": "chat_title_updated",
            "chat_id": chat_id,
            "title": title,
        })

    # v9.2.0: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    context_result = chat_store.build_context_for_prompt(chat_id, prompt)
    full_prompt = context_result["prompt"]

    # ãƒˆãƒ¼ã‚¯ãƒ³è­¦å‘Š
    if context_result.get("warning"):
        await ws_manager.send_to(client_id, {
            "type": "token_warning",
            "message": context_result["warning"],
            "token_estimate": context_result["token_estimate"],
        })

    # RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥ï¼ˆãƒ•ãƒ«ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ï¼‰
    if enable_rag and context_result["mode"] != "full":
        try:
            rag_context = await rag_bridge.build_context(prompt, tab="soloAI")
            if rag_context:
                full_prompt = f"{rag_context}\n\n{full_prompt}"
                await ws_manager.send_to(client_id, {
                    "type": "status",
                    "status": "rag_injected",
                    "message": f"RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥: {len(rag_context)}æ–‡å­—",
                })
        except Exception as e:
            logger.warning(f"RAG context build failed: {e}")

    # ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜æƒ…å ±ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ 
    if attached_files:
        file_lines = [f"- {f}" for f in attached_files]
        full_prompt += f"\n\n[æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«]\n" + "\n".join(file_lines)

    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: å®Ÿè¡Œä¸­
    ws_manager.set_active_task(client_id, "soloAI")
    await ws_manager.send_status(client_id, "executing", f"Claude ({model_id}) å®Ÿè¡Œä¸­...")

    # Claude CLIæ§‹ç¯‰
    cmd = [
        "claude",
        "-p",
        "--output-format", "json",
        "--model", model_id,
    ]
    if auto_approve:
        cmd.append("--dangerously-skip-permissions")

    run_cwd = project_dir if project_dir and os.path.isdir(project_dir) else None

    try:
        result = await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: run_hidden(
                cmd,
                input=full_prompt,
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='replace',
                timeout=timeout,
                env={**os.environ, "FORCE_COLOR": "0", "PYTHONIOENCODING": "utf-8"},
                cwd=run_cwd,
            )
        )

        stdout = result.stdout or ""
        stderr = result.stderr or ""

        if result.returncode == 0:
            try:
                output_data = json.loads(stdout)
                response_text = output_data.get("result", stdout)
            except json.JSONDecodeError:
                response_text = stdout.strip()

            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”ä¿å­˜
            chat_store.add_message(chat_id, "assistant", response_text,
                                   metadata={"model": model_id, "mode": context_result["mode"],
                                             "tokens_estimated": context_result["token_estimate"]})

            # å®Œäº†é€ä¿¡
            await ws_manager.send_streaming(client_id, response_text, done=True)
            await ws_manager.send_status(client_id, "completed", "å®Ÿè¡Œå®Œäº†")

            # ä¼šè©±ã‚’RAGã«ä¿å­˜
            asyncio.ensure_future(_save_web_conversation(
                [{"role": "user", "content": prompt},
                 {"role": "assistant", "content": response_text}],
                tab="soloAI",
            ))
        else:
            error_msg = f"Claude CLI error (code {result.returncode}): {stderr[:500]}"
            chat_store.add_message(chat_id, "error", error_msg)
            await ws_manager.send_error(client_id, error_msg)

    except subprocess.TimeoutExpired:
        await ws_manager.send_error(client_id, f"Claude CLI timed out ({timeout}s)")
    except FileNotFoundError:
        await ws_manager.send_error(client_id, "Claude CLI not found")
    except Exception as e:
        await ws_manager.send_error(client_id, f"Execution error: {str(e)}")
    finally:
        _release_execution_lock()  # v9.5.0
        ws_manager.set_active_task(client_id, None)


# =============================================================================
# mixAI 3Phaseå®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ©
# =============================================================================

async def _handle_mix_execute(client_id: str, data: dict):
    """
    mixAI 3Phaseå®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ©ã€‚

    MixAIOrchestratorã¯QThread(PyQt6)å‰æã®ãŸã‚ã€Webç‰ˆã§ã¯
    ç›´æ¥Claude CLIã¨Ollama APIã‚’å‘¼ã³å‡ºã™è»½é‡ç‰ˆã‚’å®Ÿè£…ã™ã‚‹ã€‚

    Phase 1: Claude CLI â†’ è¨ˆç”»JSON + claude_answer
    Phase 2: Ollama API â†’ ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œ
    Phase 3: Claude CLI â†’ æ¯”è¼ƒçµ±åˆ â†’ æœ€çµ‚å›ç­”
    """
    prompt = data.get("prompt", "")
    chat_id = data.get("chat_id")  # v9.2.0
    model_id = data.get("model_id", "claude-opus-4-6")
    # v9.3.0: orchestrator_engineï¼ˆconfig.jsonã‹ã‚‰èª­ã¿å–ã‚Šï¼‰
    engine_id = _load_orchestrator_engine()
    model_assignments = data.get("model_assignments", {})
    project_dir = data.get("project_dir", "")
    attached_files = data.get("attached_files", [])
    timeout = data.get("timeout") or 0
    timeout = timeout if timeout > 0 else _get_claude_timeout_sec()
    enable_rag = data.get("enable_rag", True)
    client_info = data.get("client_info", "Web Client")  # v9.5.0

    if not prompt:
        await ws_manager.send_error(client_id, "Prompt is empty")
        return

    # v9.5.0: Webå®Ÿè¡Œãƒ­ãƒƒã‚¯è¨­å®š
    _set_execution_lock("mixAI", client_info, prompt)

    # v9.2.0: ãƒãƒ£ãƒƒãƒˆIDãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
    if not chat_id:
        chat = chat_store.create_chat(tab="mixAI")
        chat_id = chat["id"]
        await ws_manager.send_to(client_id, {
            "type": "chat_created",
            "chat_id": chat_id,
        })

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜
    chat_store.add_message(chat_id, "user", prompt)

    # ã‚¿ã‚¤ãƒˆãƒ«è‡ªå‹•ç”Ÿæˆ
    chat = chat_store.get_chat(chat_id)
    if chat and chat["message_count"] == 1:
        title = chat_store.auto_generate_title(chat_id)
        await ws_manager.send_to(client_id, {
            "type": "chat_title_updated",
            "chat_id": chat_id,
            "title": title,
        })

    # v9.2.0: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    context_result = chat_store.build_context_for_prompt(chat_id, prompt)
    rag_prompt = context_result["prompt"]

    ws_manager.set_active_task(client_id, "mixAI")

    # RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥ï¼ˆãƒ•ãƒ«ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ï¼‰
    if enable_rag and context_result["mode"] != "full":
        try:
            rag_context = await rag_bridge.build_context(prompt, tab="mixAI")
            if rag_context:
                rag_prompt = f"{rag_context}\n\n{rag_prompt}"
                await ws_manager.send_to(client_id, {
                    "type": "status",
                    "status": "rag_injected",
                    "message": f"RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥: {len(rag_context)}æ–‡å­—",
                })
        except Exception as e:
            logger.warning(f"RAG context build failed (mixAI): {e}")

    try:
        # â•â•â• Phase 1: è¨ˆç”»ç«‹æ¡ˆï¼ˆv9.3.0: ã‚¨ãƒ³ã‚¸ãƒ³åˆ†å²ï¼‰ â•â•â•
        engine_label = "ãƒ­ãƒ¼ã‚«ãƒ«LLM" if not _is_claude_engine(engine_id) else "Claude"
        await ws_manager.send_to(client_id, {
            "type": "phase_changed",
            "phase": 1,
            "description": f"Phase 1: {engine_label}è¨ˆç”»ç«‹æ¡ˆä¸­...",
        })

        if _is_claude_engine(engine_id):
            phase1_result = await _run_claude_cli_async(
                prompt=_build_phase1_prompt(rag_prompt),
                model_id=engine_id,
                project_dir=project_dir,
                timeout=timeout,
            )
        else:
            phase1_result = await _run_local_agent(
                prompt=_build_phase1_prompt(rag_prompt),
                model_name=engine_id,
                project_dir=project_dir,
                phase="p1",
            )

        # Phase 1çµæœãƒ‘ãƒ¼ã‚¹
        claude_answer = phase1_result.get("claude_answer", "")
        llm_instructions = phase1_result.get("local_llm_instructions", {})
        complexity = phase1_result.get("complexity", "low")
        skip_phase2 = phase1_result.get("skip_phase2", False)

        # Phase 1ã®Claudeå›ç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡
        if claude_answer:
            await ws_manager.send_to(client_id, {
                "type": "streaming",
                "chunk": f"**[Phase 1 Claudeå›ç­”]**\n{claude_answer[:500]}...\n\n",
                "done": False,
            })

        # complexityãŒlowã¾ãŸã¯skip_phase2ã®å ´åˆã€Phase 2-3ã‚¹ã‚­ãƒƒãƒ—
        if skip_phase2 or complexity == "low":
            await ws_manager.send_streaming(client_id, claude_answer, done=True)
            await ws_manager.send_status(client_id, "completed", "Phase 2-3ã‚¹ã‚­ãƒƒãƒ—ï¼ˆä½è¤‡é›‘åº¦ï¼‰")
            return

        # â•â•â• Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œ â•â•â•
        await ws_manager.send_to(client_id, {
            "type": "phase_changed",
            "phase": 2,
            "description": "Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œä¸­...",
        })

        tasks = _build_phase2_tasks(llm_instructions, model_assignments)
        phase2_results = []
        total_tasks = len(tasks)

        for i, task in enumerate(tasks):
            # LLMé–‹å§‹é€šçŸ¥
            await ws_manager.send_to(client_id, {
                "type": "llm_started",
                "category": task["category"],
                "model": task["model"],
            })

            # Ollama APIå‘¼ã³å‡ºã—
            start = _time.time()
            try:
                result = await _run_ollama_async(
                    model=task["model"],
                    prompt=task["prompt"],
                    timeout=task.get("timeout", 300),
                )
                elapsed = _time.time() - start
                phase2_results.append({
                    "category": task["category"],
                    "model": task["model"],
                    "response": result,
                    "success": True,
                    "elapsed": elapsed,
                })

                await ws_manager.send_to(client_id, {
                    "type": "llm_finished",
                    "category": task["category"],
                    "success": True,
                    "elapsed": round(elapsed, 1),
                })
            except Exception as e:
                elapsed = _time.time() - start
                phase2_results.append({
                    "category": task["category"],
                    "model": task["model"],
                    "response": str(e),
                    "success": False,
                    "elapsed": elapsed,
                })
                await ws_manager.send_to(client_id, {
                    "type": "llm_finished",
                    "category": task["category"],
                    "success": False,
                    "elapsed": round(elapsed, 1),
                })

            # é€²æ—é€šçŸ¥
            await ws_manager.send_to(client_id, {
                "type": "phase2_progress",
                "completed": i + 1,
                "total": total_tasks,
            })

        # â•â•â• Phase 3: æ¯”è¼ƒçµ±åˆï¼ˆv9.3.0: ã‚¨ãƒ³ã‚¸ãƒ³åˆ†å²ï¼‰ â•â•â•
        await ws_manager.send_to(client_id, {
            "type": "phase_changed",
            "phase": 3,
            "description": f"Phase 3: {engine_label}æ¯”è¼ƒçµ±åˆä¸­...",
        })

        phase3_prompt = _build_phase3_prompt(prompt, claude_answer, phase2_results)
        if _is_claude_engine(engine_id):
            phase3_result = await _run_claude_cli_async(
                prompt=phase3_prompt,
                model_id=engine_id,
                project_dir=project_dir,
                timeout=timeout,
            )
        else:
            phase3_result = await _run_local_agent(
                prompt=phase3_prompt,
                model_name=engine_id,
                project_dir=project_dir,
                phase="p3",
            )

        # æœ€çµ‚å›ç­”æŠ½å‡º
        if isinstance(phase3_result, dict):
            final_answer = phase3_result.get("final_answer", str(phase3_result))
        else:
            final_answer = str(phase3_result)

        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”ä¿å­˜
        chat_store.add_message(chat_id, "assistant", final_answer,
                               metadata={"model": model_id, "mode": context_result["mode"]})

        await ws_manager.send_streaming(client_id, final_answer, done=True)
        await ws_manager.send_status(client_id, "completed", "3Phaseå®Ÿè¡Œå®Œäº†")

        # ä¼šè©±ã‚’RAGã«ä¿å­˜
        asyncio.ensure_future(_save_web_conversation(
            [{"role": "user", "content": prompt},
             {"role": "assistant", "content": final_answer}],
            tab="mixAI",
        ))

    except Exception as e:
        await ws_manager.send_error(client_id, f"mixAI execution error: {str(e)}")
    finally:
        _release_execution_lock()  # v9.5.0
        ws_manager.set_active_task(client_id, None)


# =============================================================================
# mixAI ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =============================================================================

async def _run_claude_cli_async(prompt: str, model_id: str,
                                project_dir: str = "", timeout: int = 0) -> dict:
    """Claude CLIã‚’éåŒæœŸã§å®Ÿè¡Œ"""
    if timeout <= 0:
        timeout = _get_claude_timeout_sec()
    from ..utils.subprocess_utils import run_hidden

    cmd = ["claude", "-p", "--output-format", "json", "--model", model_id,
           "--dangerously-skip-permissions"]

    run_cwd = project_dir if project_dir and os.path.isdir(project_dir) else None

    result = await asyncio.get_event_loop().run_in_executor(
        None,
        lambda: run_hidden(
            cmd, input=prompt, capture_output=True, text=True,
            encoding='utf-8', errors='replace', timeout=timeout,
            env={**os.environ, "FORCE_COLOR": "0", "PYTHONIOENCODING": "utf-8"},
            cwd=run_cwd,
        )
    )

    stdout = result.stdout or ""
    if result.returncode == 0:
        try:
            data = json.loads(stdout)
            text = data.get("result", stdout)
        except json.JSONDecodeError:
            text = stdout.strip()

        # JSONæ§‹é€ ã®æŠ½å‡ºã‚’è©¦è¡Œ
        try:
            start = text.find('{')
            end = text.rfind('}') + 1
            if start >= 0 and end > start:
                return json.loads(text[start:end])
        except (json.JSONDecodeError, ValueError):
            pass

        return {"claude_answer": text, "complexity": "low", "skip_phase2": True}
    else:
        raise RuntimeError(f"Claude CLI error (code {result.returncode})")


async def _run_ollama_async(model: str, prompt: str,
                            timeout: int = 300, host: str = "http://localhost:11434") -> str:
    """Ollama APIã‚’éåŒæœŸã§å‘¼ã³å‡ºã—"""
    import httpx

    async with httpx.AsyncClient(timeout=httpx.Timeout(timeout)) as client:
        resp = await client.post(
            f"{host}/api/generate",
            json={"model": model, "prompt": prompt, "stream": False},
        )
        resp.raise_for_status()
        return resp.json().get("response", "")


# =============================================================================
# v9.3.0: ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ
# =============================================================================

def _get_claude_timeout_sec() -> int:
    """
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Claudeã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰ã‚’èª­ã¿å–ã‚‹ã€‚

    å„ªå…ˆé †ä½:
      1. general_settings.json â†’ timeout_minutesï¼ˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—è¨­å®šç”»é¢ã®å€¤ï¼‰
      2. config.json â†’ timeoutï¼ˆç§’å˜ä½ï¼‰
      3. app_settings.json â†’ claude.timeout_minutes
      4. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5400ç§’ï¼ˆ90åˆ†ï¼‰
    """
    timeout_sec = 5400  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 90åˆ†

    # app_settings.jsonï¼ˆæœ€ä½å„ªå…ˆåº¦ï¼‰
    try:
        p = Path("config/app_settings.json")
        if p.exists():
            with open(p, 'r', encoding='utf-8') as f:
                d = json.load(f)
            v = d.get("claude", {}).get("timeout_minutes")
            if v and isinstance(v, (int, float)) and v > 0:
                timeout_sec = int(v) * 60
    except Exception:
        pass

    # config.jsonï¼ˆç§’å˜ä½ï¼‰
    try:
        p = Path("config/config.json")
        if p.exists():
            with open(p, 'r', encoding='utf-8') as f:
                d = json.load(f)
            v = d.get("timeout")
            if v and isinstance(v, (int, float)) and v > 0:
                timeout_sec = int(v)
    except Exception:
        pass

    # general_settings.jsonï¼ˆæœ€é«˜å„ªå…ˆåº¦ï¼‰
    try:
        p = Path("config/general_settings.json")
        if p.exists():
            with open(p, 'r', encoding='utf-8') as f:
                d = json.load(f)
            v = d.get("timeout_minutes")
            if v and isinstance(v, (int, float)) and v > 0:
                timeout_sec = int(v) * 60
    except Exception:
        pass

    return timeout_sec


def _is_claude_engine(engine_id: str) -> bool:
    """Claude CLIã§å®Ÿè¡Œã™ã¹ãã‚¨ãƒ³ã‚¸ãƒ³ã‹ã©ã†ã‹"""
    return engine_id.startswith("claude-")


def _load_orchestrator_engine() -> str:
    """config.jsonã‹ã‚‰orchestrator_engineã‚’èª­ã¿å–ã‚Š"""
    try:
        config_path = Path("config/config.json")
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config.get("orchestrator_engine", "claude-opus-4-6")
    except Exception:
        pass
    return "claude-opus-4-6"


async def _run_local_agent(prompt: str, model_name: str,
                            project_dir: str, phase: str = "p1") -> dict:
    """ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’éåŒæœŸã§å®Ÿè¡Œ"""
    # local_agent.py è‡ªä½“ã¯PyQt6ã«ä¾å­˜ã—ãªã„ãŒã€
    # from ..backends.local_agent ã ã¨ backends/__init__.py ãŒå®Ÿè¡Œã•ã‚Œ
    # mix_orchestrator â†’ PyQt6 ã®é€£é–importãŒç™ºç”Ÿã™ã‚‹ã€‚
    # importlib.util ã§ .py ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ãƒ­ãƒ¼ãƒ‰ã—ã¦ __init__.py ã‚’ãƒã‚¤ãƒ‘ã‚¹ã™ã‚‹ã€‚
    import importlib.util as _ilu
    _spec = _ilu.spec_from_file_location(
        "src.backends.local_agent",
        str(Path(__file__).parent.parent / "backends" / "local_agent.py"),
    )
    _mod = _ilu.module_from_spec(_spec)
    _spec.loader.exec_module(_mod)
    LocalAgentRunner = _mod.LocalAgentRunner

    config_path = Path("config/config.json")
    tools_config = {}
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        tools_config = config.get("local_agent_tools", {})

    agent = LocalAgentRunner(
        model_name=model_name,
        project_dir=project_dir,
        tools_config=tools_config,
    )

    # Webç‰ˆã§ã¯æ›¸ãè¾¼ã¿è‡ªå‹•æ‰¿èª
    agent.on_write_confirm = lambda tool, path, preview: True

    system_prompt = _build_local_system_prompt(phase)
    result = await asyncio.to_thread(agent.run, system_prompt, prompt)

    # JSONæ§‹é€ ã®æŠ½å‡ºã‚’è©¦è¡Œ
    try:
        start = result.find('{')
        end = result.rfind('}') + 1
        if start >= 0 and end > start:
            return json.loads(result[start:end])
    except (json.JSONDecodeError, ValueError):
        pass

    if phase == "p1":
        return {"claude_answer": result, "complexity": "low", "skip_phase2": True}
    else:
        return {"status": "complete", "final_answer": result}


def _build_local_system_prompt(phase: str) -> str:
    """ãƒ­ãƒ¼ã‚«ãƒ«LLMç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
    if phase == "p1":
        return """ã‚ãªãŸã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®è¨ˆç”»ç«‹æ¡ˆã‚’è¡Œã†AIã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€ã¾ãšãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹é€ ã‚„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã€
é©åˆ‡ãªè¨ˆç”»ã‚’ç«‹æ¡ˆã—ã¦ãã ã•ã„ã€‚

åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«:
- read_file: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã‚€
- list_dir: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§
- search_files: ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢

ã¾ãšãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’ç¢ºèªã—ã€é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã‚“ã§ã‹ã‚‰å›ç­”ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§ ```json ``` ã§å›²ã‚“ã§ãã ã•ã„:
{
  "claude_answer": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å›ç­”ï¼ˆæ—¥æœ¬èªï¼‰",
  "local_llm_instructions": { ... },
  "complexity": "simple|moderate|complex",
  "skip_phase2": false
}"""
    else:  # p3
        return """ã‚ãªãŸã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®çµ±åˆãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã†AIã§ã™ã€‚
Phase 1ã®è¨ˆç”»ã¨Phase 2ã®ãƒ­ãƒ¼ã‚«ãƒ«LLMå®Ÿè¡Œçµæœã‚’æ¯”è¼ƒãƒ»çµ±åˆã—ã€
æœ€çµ‚çš„ãªå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§ ```json ``` ã§å›²ã‚“ã§ãã ã•ã„:
{
  "status": "complete",
  "final_answer": "çµ±åˆã•ã‚ŒãŸæœ€çµ‚å›ç­”ï¼ˆæ—¥æœ¬èªï¼‰"
}"""


def _build_phase1_prompt(user_prompt: str) -> str:
    """Phase 1ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆMixAIOrchestratorã®_execute_phase1ç›¸å½“ï¼‰"""
    return f"""ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®2ã¤ã‚’æä¾›ã—ã¦ãã ã•ã„:

1. ã‚ãªãŸè‡ªèº«ã®å›ç­” (claude_answer)
2. ãƒ­ãƒ¼ã‚«ãƒ«LLMã¸ã®æŒ‡ç¤º (local_llm_instructions)

JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
{{
  "claude_answer": "ã‚ãªãŸã®ç›´æ¥å›ç­”",
  "complexity": "low|medium|high",
  "skip_phase2": false,
  "local_llm_instructions": {{
    "coding": {{"skip": false, "prompt": "ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦³ç‚¹ã§ã®åˆ†ææŒ‡ç¤º", "expected_output": "ã‚³ãƒ¼ãƒ‰ä¾‹", "timeout_seconds": 300}},
    "research": {{"skip": false, "prompt": "èª¿æŸ»è¦³ç‚¹ã§ã®åˆ†ææŒ‡ç¤º", "expected_output": "èª¿æŸ»çµæœ", "timeout_seconds": 300}},
    "reasoning": {{"skip": false, "prompt": "æ¨è«–è¦³ç‚¹ã§ã®åˆ†ææŒ‡ç¤º", "expected_output": "æ¨è«–çµæœ", "timeout_seconds": 300}}
  }}
}}

complexity=lowã®å ´åˆã¯skip_phase2=trueã¨ã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:
{user_prompt}"""


def _build_phase2_tasks(llm_instructions: dict, model_assignments: dict) -> list:
    """Phase 2ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆæ§‹ç¯‰"""
    tasks = []
    for category, spec in llm_instructions.items():
        if isinstance(spec, dict) and not spec.get("skip", True):
            model = model_assignments.get(category)
            if not model:
                continue
            prompt = spec.get("prompt", "").strip()
            if not prompt:
                continue
            tasks.append({
                "category": category,
                "model": model,
                "prompt": prompt,
                "timeout": spec.get("timeout_seconds", 300),
            })
    return tasks


def _build_phase3_prompt(user_prompt: str, claude_answer: str,
                         phase2_results: list) -> str:
    """Phase 3ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
    results_text = ""
    for r in phase2_results:
        if r["success"]:
            results_text += f"\n### {r['category']} ({r['model']})\n{r['response'][:5000]}\n"

    return f"""ä»¥ä¸‹ã®æƒ…å ±ã‚’çµ±åˆã—ã¦ã€æœ€é«˜å“è³ªã®æœ€çµ‚å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
{user_prompt}

## Phase 1 Claudeå›ç­”
{claude_answer[:8000]}

## Phase 2 ãƒ­ãƒ¼ã‚«ãƒ«LLMçµæœ
{results_text}

## æŒ‡ç¤º
å…¨ã¦ã®æƒ…å ±ã‚’çµ±åˆã—ã€æœ€çµ‚å›ç­”ã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
{{"final_answer": "çµ±åˆã•ã‚ŒãŸæœ€çµ‚å›ç­”"}}"""


# =============================================================================
# ä¼šè©±ä¿å­˜ãƒ˜ãƒ«ãƒ‘ãƒ¼
# =============================================================================

async def _save_web_conversation(messages: list, tab: str):
    """Webä¼šè©±ã‚’RAGã«éåŒæœŸä¿å­˜ï¼ˆã‚¨ãƒ©ãƒ¼ç„¡è¦–ï¼‰"""
    try:
        session_id = await rag_bridge.save_conversation(messages, tab)
        logger.info(f"Web conversation saved to RAG: {session_id}")
    except Exception as e:
        logger.warning(f"Conversation save failed: {e}")


# =============================================================================
# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ï¼‰
# =============================================================================

def start_server(host: str = "0.0.0.0", port: int = 8500):
    """Uvicornã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•"""
    import uvicorn
    uvicorn.run(
        app,
        host=host,
        port=port,
        log_level="info",
        access_log=True,
    )


# =============================================================================
# PyQt6çµ±åˆ: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
# =============================================================================

import threading


class WebServerThread:
    """PyQt6ã‹ã‚‰èµ·å‹•ã™ã‚‹Web UIã‚µãƒ¼ãƒãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰"""

    def __init__(self, host="0.0.0.0", port=8500):
        self.host = host
        self.port = port
        self._thread = None
        self._server = None

    def start(self):
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()

    def _run(self):
        import uvicorn
        config = uvicorn.Config(app, host=self.host, port=self.port,
                                log_level="info")
        self._server = uvicorn.Server(config)
        self._server.run()

    def stop(self):
        if self._server:
            self._server.should_exit = True

    @property
    def is_running(self):
        return self._thread is not None and self._thread.is_alive()


def start_server_background(port=8500) -> WebServerThread:
    """PyQt6ã‹ã‚‰ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ï¼ˆåŒä¸€ãƒ—ãƒ­ã‚»ã‚¹ç‰ˆã€ç›´æ¥ä½¿ç”¨éæ¨å¥¨ï¼‰

    NOTE: PyQt6ã®è¨­å®šç”»é¢ã‹ã‚‰ã¯launcher.pyã®start_server_backgroundã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚
    ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’importã™ã‚‹ã¨fastapiã®ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«importãŒèµ°ã‚‹ãŸã‚ã€
    fastapiæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç’°å¢ƒã§ã¯ImportErrorãŒç™ºç”Ÿã™ã‚‹ã€‚
    """
    server = WebServerThread(port=port)
    server.start()
    return server


if __name__ == "__main__":
    import sys

    # HELIX_WEB_SERVER_ONLY=1 ã®å ´åˆã¯ã‚µãƒ¼ãƒãƒ¼ã®ã¿èµ·å‹•ï¼ˆPyQt6ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã‹ãªã„ï¼‰
    if os.environ.get("HELIX_WEB_SERVER_ONLY") != "1":
        print("Warning: HELIX_WEB_SERVER_ONLY is not set. "
              "If launched from PyQt6, set this env var to prevent GUI spawn.",
              file=sys.stderr)

    port = int(sys.argv[1]) if len(sys.argv) > 1 else 8500
    start_server(port=port)

========================================
FILE: src/web/api_routes.py
========================================
"""
Helix AI Studio - REST API Routes (v9.3.0)

ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ:
  POST /api/auth/login           - PINèªè¨¼ â†’ JWTå–å¾—
  GET  /api/auth/verify          - JWTæ¤œè¨¼
  GET  /api/status               - ã‚µãƒ¼ãƒãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
  POST /api/solo/execute         - soloAIå®Ÿè¡Œï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
  GET  /api/config/models        - åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
  GET  /api/config/ollama-models - Ollamaãƒ¢ãƒ‡ãƒ«ä¸€è¦§
  GET  /api/settings             - è¨­å®šå–å¾—
  PUT  /api/settings             - è¨­å®šæ›´æ–°
  GET  /api/monitor/gpu          - GPUãƒ¢ãƒ‹ã‚¿ãƒ¼
  GET  /api/files/browse         - ãƒ•ã‚¡ã‚¤ãƒ«ãƒ–ãƒ©ã‚¦ã‚¶
  GET  /api/health               - ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆèªè¨¼ä¸è¦ï¼‰
  GET  /api/chats                - ãƒãƒ£ãƒƒãƒˆä¸€è¦§
  POST /api/chats                - æ–°è¦ãƒãƒ£ãƒƒãƒˆä½œæˆ
  GET  /api/chats/{chat_id}      - ãƒãƒ£ãƒƒãƒˆè©³ç´°+ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
  PUT  /api/chats/{chat_id}/title - ã‚¿ã‚¤ãƒˆãƒ«æ›´æ–°
  PUT  /api/chats/{chat_id}/mode  - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å¤‰æ›´
  DELETE /api/chats/{chat_id}    - ãƒãƒ£ãƒƒãƒˆå‰Šé™¤
  GET  /api/chats/storage/stats  - ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµ±è¨ˆ
"""

import json
import logging
import os
import shutil
import subprocess
import uuid
from datetime import datetime
from pathlib import Path

from fastapi import APIRouter, Depends, HTTPException, Request, UploadFile, File
from fastapi.responses import FileResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel

from .auth import WebAuthManager
from .file_transfer import UPLOAD_MAX_SIZE_BYTES, UPLOAD_MAX_SIZE_MB, UPLOAD_ALLOWED_EXTENSIONS, validate_upload

logger = logging.getLogger(__name__)

# =============================================================================
# ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
# =============================================================================

class LoginRequest(BaseModel):
    pin: str

class LoginResponse(BaseModel):
    token: str
    expires_in_hours: int

class SoloExecuteRequest(BaseModel):
    prompt: str
    model_id: str = "claude-opus-4-6"
    attached_files: list[str] = []
    project_dir: str = ""
    timeout: int = 0  # 0 = è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
    use_mcp: bool = True
    auto_approve: bool = True

class StatusResponse(BaseModel):
    status: str
    version: str
    pyqt_running: bool
    active_websockets: int
    rag_locked: bool

class ModelInfo(BaseModel):
    id: str
    display_name: str
    description: str
    tier: str
    is_default: bool

# =============================================================================
# ä¾å­˜æ€§æ³¨å…¥: èªè¨¼ãƒã‚§ãƒƒã‚¯
# =============================================================================

security = HTTPBearer()
auth_manager = WebAuthManager()


async def verify_jwt(
    request: Request,
    credentials: HTTPAuthorizationCredentials = Depends(security),
) -> dict:
    """JWTèªè¨¼ã®ä¾å­˜æ€§æ³¨å…¥"""
    # IP ãƒã‚§ãƒƒã‚¯
    client_ip = request.client.host
    if not auth_manager.check_ip(client_ip):
        raise HTTPException(status_code=403, detail="Access denied: IP not in allowed range")

    # JWTæ¤œè¨¼
    payload = auth_manager.verify_token(credentials.credentials)
    if payload is None:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

    return payload

# =============================================================================
# ãƒ«ãƒ¼ã‚¿ãƒ¼å®šç¾©
# =============================================================================

router = APIRouter()


@router.get("/api/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆèªè¨¼ä¸è¦ï¼‰"""
    return {"status": "ok", "service": "helix-ai-studio", "version": "9.5.0"}


# =============================================================================
# v9.5.0: Webå®Ÿè¡Œãƒ­ãƒƒã‚¯
# =============================================================================

@router.get("/api/execution/lock")
async def get_execution_lock(payload: dict = Depends(verify_jwt)):
    """ç¾åœ¨ã®ãƒ­ãƒƒã‚¯çŠ¶æ…‹å–å¾—"""
    lock_file = Path("data/web_execution_lock.json")
    if lock_file.exists():
        try:
            data = json.loads(lock_file.read_text(encoding='utf-8'))
            return data
        except Exception:
            pass
    return {"locked": False}


@router.post("/api/auth/login", response_model=LoginResponse)
async def login(request: Request, body: LoginRequest):
    """PINèªè¨¼ â†’ JWTç™ºè¡Œ"""
    client_ip = request.client.host

    # IPãƒã‚§ãƒƒã‚¯
    if not auth_manager.check_ip(client_ip):
        raise HTTPException(status_code=403, detail="Access denied: IP not in allowed range")

    # PINæ¤œè¨¼
    if not auth_manager.verify_pin(body.pin):
        logger.warning(f"Failed login attempt from {client_ip}")
        raise HTTPException(status_code=401, detail="Invalid PIN")

    # JWTç™ºè¡Œ
    token = auth_manager.create_token(client_ip)
    logger.info(f"Login successful from {client_ip}")

    return LoginResponse(
        token=token,
        expires_in_hours=auth_manager.jwt_expiry_hours,
    )


@router.get("/api/auth/verify")
async def verify_auth(payload: dict = Depends(verify_jwt)):
    """JWTãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼"""
    return {"valid": True, "sub": payload.get("sub")}


@router.get("/api/status", response_model=StatusResponse)
async def get_status(payload: dict = Depends(verify_jwt)):
    """ã‚µãƒ¼ãƒãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—"""
    # WebSocketãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã¯server.pyã‹ã‚‰æ³¨å…¥ã•ã‚Œã‚‹ï¼ˆå¾Œè¿°ï¼‰
    from .server import get_app_state
    state = get_app_state()

    return StatusResponse(
        status="running",
        version="9.5.0",
        pyqt_running=state.get("pyqt_running", False),
        active_websockets=state.get("active_websockets", 0),
        rag_locked=state.get("rag_locked", False),
    )


@router.get("/api/config/models", response_model=list[ModelInfo])
async def get_models(payload: dict = Depends(verify_jwt)):
    """åˆ©ç”¨å¯èƒ½ãªClaudeãƒ¢ãƒ‡ãƒ«ä¸€è¦§"""
    # æ—¢å­˜ã®constants.pyã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆèª­ã¿å–ã‚Šã®ã¿ï¼‰
    try:
        from ..utils.constants import CLAUDE_MODELS
        return [ModelInfo(**m) for m in CLAUDE_MODELS]
    except ImportError:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return [
            ModelInfo(
                id="claude-opus-4-6",
                display_name="Claude Opus 4.6 (æœ€é«˜çŸ¥èƒ½)",
                description="æœ€ã‚‚é«˜åº¦ã§çŸ¥çš„ãªãƒ¢ãƒ‡ãƒ«",
                tier="opus",
                is_default=True,
            )
        ]


@router.post("/api/solo/execute")
async def solo_execute(body: SoloExecuteRequest, payload: dict = Depends(verify_jwt)):
    """
    soloAIå®Ÿè¡Œï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° / RESTç‰ˆï¼‰ã€‚
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç‰ˆã¯WebSocketã§åˆ¥é€”æä¾›ã€‚
    è»½é‡ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆå‘ã‘ã€‚
    """
    from ..utils.subprocess_utils import run_hidden

    cmd = [
        "claude",
        "-p",
        "--output-format", "json",
        "--model", body.model_id,
    ]

    if body.auto_approve:
        cmd.append("--dangerously-skip-permissions")

    run_cwd = body.project_dir if body.project_dir and os.path.isdir(body.project_dir) else None

    # timeout=0 ã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
    effective_timeout = body.timeout
    if effective_timeout <= 0:
        from .server import _get_claude_timeout_sec
        effective_timeout = _get_claude_timeout_sec()

    try:
        result = run_hidden(
            cmd,
            input=body.prompt,
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            timeout=effective_timeout,
            env={**os.environ, "FORCE_COLOR": "0", "PYTHONIOENCODING": "utf-8"},
            cwd=run_cwd,
        )

        stdout = result.stdout or ""
        stderr = result.stderr or ""

        if result.returncode == 0:
            try:
                output_data = json.loads(stdout)
                response_text = output_data.get("result", stdout)
            except json.JSONDecodeError:
                response_text = stdout.strip()

            return {
                "status": "success",
                "response": response_text,
                "model": body.model_id,
            }
        else:
            raise HTTPException(
                status_code=500,
                detail=f"Claude CLI error (code {result.returncode}): {stderr[:500]}",
            )

    except subprocess.TimeoutExpired:
        raise HTTPException(
            status_code=504,
            detail=f"Claude CLI timed out ({effective_timeout}s)",
        )
    except FileNotFoundError:
        raise HTTPException(
            status_code=500,
            detail="Claude CLI not found. Is 'claude' command installed?",
        )


# =============================================================================
# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ–ãƒ©ã‚¦ã‚¶API
# =============================================================================

ALLOWED_EXTENSIONS = {'.py', '.js', '.jsx', '.ts', '.tsx', '.md', '.txt',
                      '.json', '.yaml', '.yml', '.toml', '.cfg', '.ini',
                      '.html', '.css', '.sql', '.sh', '.bat', '.ps1',
                      '.csv', '.xml', '.env', '.gitignore', '.dockerfile'}
MAX_BROWSE_DEPTH = 3
EXCLUDED_DIRS = {'.git', 'node_modules', '__pycache__', '.venv', 'venv',
                 '.mypy_cache', '.pytest_cache', 'dist', 'build', '.egg-info'}


class FileItem(BaseModel):
    name: str
    path: str
    is_dir: bool
    size: int = 0
    extension: str = ""


@router.get("/api/files/browse", response_model=list[FileItem])
async def browse_files(
    dir_path: str = "",
    payload: dict = Depends(verify_jwt),
):
    """
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ã€‚
    ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢ + ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆæ‹¡å¼µå­ã®ã¿ã€‚
    """
    # config/config.jsonã‹ã‚‰project_dirã‚’å–å¾—
    project_dir = _get_project_dir()
    if not project_dir:
        raise HTTPException(status_code=400, detail="Project directory not configured")

    # ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢
    if dir_path:
        target = Path(project_dir) / dir_path
        try:
            target.resolve().relative_to(Path(project_dir).resolve())
        except ValueError:
            raise HTTPException(status_code=403, detail="Path traversal detected")
    else:
        target = Path(project_dir)

    if not target.is_dir():
        raise HTTPException(status_code=404, detail="Directory not found")

    items = []
    try:
        for entry in sorted(target.iterdir(), key=lambda e: (not e.is_dir(), e.name.lower())):
            if entry.name.startswith('.') and entry.name not in ('.env', '.gitignore'):
                continue
            if entry.is_dir() and entry.name in EXCLUDED_DIRS:
                continue

            item = FileItem(
                name=entry.name,
                path=str(entry.relative_to(Path(project_dir))),
                is_dir=entry.is_dir(),
                size=entry.stat().st_size if entry.is_file() else 0,
                extension=entry.suffix.lower() if entry.is_file() else "",
            )
            items.append(item)
    except PermissionError:
        raise HTTPException(status_code=403, detail="Permission denied")

    return items


def _get_project_dir() -> str | None:
    """config/config.jsonã‹ã‚‰project_dirã‚’å–å¾—"""
    try:
        config_path = Path("config/config.json")
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config.get("project_dir", "")
    except Exception:
        pass
    return None


# =============================================================================
# è¨­å®š API (GET/PUT)
# =============================================================================

class SettingsResponse(BaseModel):
    claude_model_id: str = "claude-opus-4-6"
    claude_timeout_minutes: int = 90
    model_assignments: dict = {}
    orchestrator_engine: str = "claude-opus-4-6"
    local_agent_tools: dict = {}
    project_dir: str = ""
    ollama_host: str = "http://localhost:11434"
    pin: str = ""
    jwt_expiry_hours: int = 168
    max_connections: int = 3


@router.get("/api/settings", response_model=SettingsResponse)
async def get_settings(payload: dict = Depends(verify_jwt)):
    """è¨­å®šå–å¾—ï¼ˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šå°‚ç”¨ + web_config.jsonçµ±åˆï¼‰"""
    settings = _load_merged_settings()
    settings["pin"] = ""  # PINã¯è¡¨ç¤ºã—ãªã„
    return settings


class SettingsUpdate(BaseModel):
    pin: str | None = None
    jwt_expiry_hours: int | None = None
    claude_timeout_minutes: int | None = None


@router.put("/api/settings")
async def update_settings(update: SettingsUpdate, payload: dict = Depends(verify_jwt)):
    """Web UIè¨­å®šã‚’æ›´æ–°ï¼ˆPIN, JWTæœ‰åŠ¹æœŸé™, Claudeã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰"""
    web_config_path = Path("config/web_config.json")

    if web_config_path.exists():
        with open(web_config_path, 'r', encoding='utf-8') as f:
            full_web_config = json.load(f)
    else:
        full_web_config = {}

    web_server = full_web_config.get("web_server", {})

    if update.pin and len(update.pin) >= 4:
        web_server["pin"] = update.pin
    if update.jwt_expiry_hours:
        web_server["jwt_expiry_hours"] = update.jwt_expiry_hours

    full_web_config["web_server"] = web_server
    with open(web_config_path, 'w', encoding='utf-8') as f:
        json.dump(full_web_config, f, ensure_ascii=False, indent=2)

    # Claudeã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: general_settings.json ã«ä¿å­˜ï¼ˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—/Webå…±é€šï¼‰
    if update.claude_timeout_minutes and update.claude_timeout_minutes > 0:
        try:
            gs_path = Path("config/general_settings.json")
            if gs_path.exists():
                with open(gs_path, 'r', encoding='utf-8') as f:
                    gs = json.load(f)
            else:
                gs = {}
            gs["timeout_minutes"] = update.claude_timeout_minutes
            with open(gs_path, 'w', encoding='utf-8') as f:
                json.dump(gs, f, ensure_ascii=False, indent=2)
            logger.info(f"Claude timeout updated to {update.claude_timeout_minutes} minutes")
        except Exception as e:
            logger.error(f"Failed to save timeout: {e}")

    return {"status": "ok", "message": "è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ"}


def _load_merged_settings() -> dict:
    """general_settings.json + app_settings.json + config.json + web_config.json ã‚’çµ±åˆèª­ã¿è¾¼ã¿"""
    result = {
        "claude_model_id": "claude-opus-4-6",
        "claude_timeout_minutes": 90,
        "model_assignments": {},
        "orchestrator_engine": "claude-opus-4-6",
        "local_agent_tools": {},
        "project_dir": "",
        "ollama_host": "http://localhost:11434",
        "pin": "",
        "jwt_expiry_hours": 168,
        "max_connections": 3,
    }

    # app_settings.jsonï¼ˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªè¨­å®š - èª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
    try:
        app_settings_path = Path("config/app_settings.json")
        if app_settings_path.exists():
            with open(app_settings_path, 'r', encoding='utf-8') as f:
                app_settings = json.load(f)
            claude = app_settings.get("claude", {})
            if claude.get("default_model"):
                result["claude_model_id"] = claude["default_model"]
            if claude.get("timeout_minutes"):
                result["claude_timeout_minutes"] = claude["timeout_minutes"]
            app_mgr = app_settings.get("app_manager", {})
            if app_mgr.get("base_directory"):
                result["project_dir"] = app_mgr["base_directory"]
    except Exception:
        pass

    # config.jsonï¼ˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªè¨­å®š - èª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
    try:
        config_path = Path("config/config.json")
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            if config.get("claude_model_id"):
                result["claude_model_id"] = config["claude_model_id"]
            if config.get("timeout"):
                result["claude_timeout_minutes"] = config["timeout"] // 60
            if config.get("model_assignments"):
                result["model_assignments"] = config["model_assignments"]
            if config.get("project_dir"):
                result["project_dir"] = config["project_dir"]
            if config.get("ollama_host"):
                result["ollama_host"] = config["ollama_host"]
            # v9.3.0
            if config.get("orchestrator_engine"):
                result["orchestrator_engine"] = config["orchestrator_engine"]
            if config.get("local_agent_tools"):
                result["local_agent_tools"] = config["local_agent_tools"]
    except Exception:
        pass

    # general_settings.jsonï¼ˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—è¨­å®šç”»é¢ã®å€¤ - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæœ€é«˜å„ªå…ˆåº¦ï¼‰
    try:
        gs_path = Path("config/general_settings.json")
        if gs_path.exists():
            with open(gs_path, 'r', encoding='utf-8') as f:
                gs = json.load(f)
            if gs.get("timeout_minutes"):
                result["claude_timeout_minutes"] = gs["timeout_minutes"]
    except Exception:
        pass

    # web_config.jsonï¼ˆWeb UIå›ºæœ‰è¨­å®š - ç·¨é›†å¯èƒ½ï¼‰
    try:
        web_config_path = Path("config/web_config.json")
        if web_config_path.exists():
            with open(web_config_path, 'r', encoding='utf-8') as f:
                full_web = json.load(f)
            web_server = full_web.get("web_server", {})
            result["jwt_expiry_hours"] = web_server.get("jwt_expiry_hours", result["jwt_expiry_hours"])
            result["max_connections"] = web_server.get("max_concurrent_sessions", result["max_connections"])
    except Exception:
        pass

    return result


# =============================================================================
# Ollamaãƒ¢ãƒ‡ãƒ«ä¸€è¦§
# =============================================================================

@router.get("/api/config/ollama-models")
async def get_ollama_models(payload: dict = Depends(verify_jwt)):
    """Ollama APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    import httpx
    settings = _load_merged_settings()
    ollama_host = settings.get("ollama_host", "http://localhost:11434")

    try:
        async with httpx.AsyncClient(timeout=10) as client:
            resp = await client.get(f"{ollama_host}/api/tags")
            resp.raise_for_status()
            models_data = resp.json().get("models", [])
            return [
                {
                    "name": m.get("name", ""),
                    "size": _format_size(m.get("size", 0)),
                    "modified": m.get("modified_at", ""),
                }
                for m in models_data
            ]
    except Exception:
        return []


def _format_size(size_bytes: int) -> str:
    """ãƒã‚¤ãƒˆæ•°ã‚’äººé–“å¯èª­å½¢å¼ã«å¤‰æ›"""
    if size_bytes < 1024 ** 2:
        return f"{size_bytes / 1024:.0f}KB"
    elif size_bytes < 1024 ** 3:
        return f"{size_bytes / (1024 ** 2):.1f}MB"
    else:
        return f"{size_bytes / (1024 ** 3):.1f}GB"


# =============================================================================
# GPUãƒ¢ãƒ‹ã‚¿ãƒ¼
# =============================================================================

@router.get("/api/monitor/gpu")
async def get_gpu_info(payload: dict = Depends(verify_jwt)):
    """nvidia-smiçµŒç”±ã§GPUæƒ…å ±ã‚’å–å¾—"""
    try:
        result = subprocess.run(
            [
                "nvidia-smi",
                "--query-gpu=name,memory.used,memory.total,utilization.gpu,temperature.gpu,power.draw",
                "--format=csv,noheader,nounits",
            ],
            capture_output=True, text=True, timeout=5,
        )

        if result.returncode != 0:
            return {"gpus": [], "error": "nvidia-smi failed"}

        gpus = []
        for line in result.stdout.strip().split("\n"):
            parts = [p.strip() for p in line.split(",")]
            if len(parts) >= 6:
                gpus.append({
                    "name": parts[0],
                    "memory_used": int(float(parts[1])),
                    "memory_total": int(float(parts[2])),
                    "utilization": int(float(parts[3])),
                    "temperature": int(float(parts[4])),
                    "power_draw": round(float(parts[5]), 1),
                })

        return {"gpus": gpus}

    except FileNotFoundError:
        return {"gpus": [], "error": "nvidia-smi not found"}
    except Exception as e:
        return {"gpus": [], "error": str(e)}


# =============================================================================
# ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹èª­ã¿æ›¸ãAPI (v9.1.0)
# =============================================================================

VIEWABLE_EXTENSIONS = {'.txt', '.md', '.py', '.js', '.jsx', '.ts', '.tsx',
                       '.json', '.yaml', '.yml', '.toml', '.html', '.css',
                       '.sql', '.sh', '.bat', '.csv', '.xml', '.env',
                       '.gitignore', '.cfg', '.ini', '.log'}
IMAGE_EXTENSIONS = {'.png', '.jpg', '.jpeg', '.gif', '.webp', '.bmp', '.svg'}
MAX_FILE_READ_SIZE = 1024 * 1024  # 1MB


@router.get("/api/files/content")
async def read_file_content(
    file_path: str,
    payload: dict = Depends(verify_jwt),
):
    """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å–å¾—ã€‚ãƒ†ã‚­ã‚¹ãƒˆã¯æ–‡å­—åˆ—ã€ç”»åƒã¯base64ã€‚"""
    project_dir = _get_project_dir()
    if not project_dir:
        raise HTTPException(status_code=400, detail="Project directory not configured")

    target = Path(project_dir) / file_path
    try:
        target.resolve().relative_to(Path(project_dir).resolve())
    except ValueError:
        raise HTTPException(status_code=403, detail="Path traversal detected")

    if not target.is_file():
        raise HTTPException(status_code=404, detail="File not found")

    ext = target.suffix.lower()
    file_size = target.stat().st_size

    if file_size > MAX_FILE_READ_SIZE:
        raise HTTPException(status_code=413, detail="File too large (max 1MB)")

    if ext in VIEWABLE_EXTENSIONS:
        try:
            content = target.read_text(encoding='utf-8', errors='replace')
            return {"type": "text", "content": content, "extension": ext,
                    "size": file_size, "path": file_path}
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    elif ext in IMAGE_EXTENSIONS:
        import base64
        content_bytes = target.read_bytes()
        b64 = base64.b64encode(content_bytes).decode('ascii')
        mime = {'.png': 'image/png', '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg',
                '.gif': 'image/gif', '.webp': 'image/webp', '.bmp': 'image/bmp',
                '.svg': 'image/svg+xml'}.get(ext, 'application/octet-stream')
        return {"type": "image", "content": b64, "mime": mime,
                "extension": ext, "size": file_size, "path": file_path}

    else:
        raise HTTPException(status_code=415, detail=f"Unsupported file type: {ext}")


class FileWriteRequest(BaseModel):
    content: str


@router.put("/api/files/content")
async def write_file_content(
    file_path: str,
    request: FileWriteRequest,
    payload: dict = Depends(verify_jwt),
):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ä¸Šæ›¸ãä¿å­˜ã€‚"""
    project_dir = _get_project_dir()
    if not project_dir:
        raise HTTPException(status_code=400, detail="Project directory not configured")

    target = Path(project_dir) / file_path
    try:
        target.resolve().relative_to(Path(project_dir).resolve())
    except ValueError:
        raise HTTPException(status_code=403, detail="Path traversal detected")

    ext = target.suffix.lower()
    if ext not in VIEWABLE_EXTENSIONS:
        raise HTTPException(status_code=415, detail="Only text files can be edited")

    if not target.exists():
        raise HTTPException(status_code=404, detail="File not found")

    try:
        target.write_text(request.content, encoding='utf-8')
        return {"status": "ok", "size": len(request.content.encode('utf-8')), "path": file_path}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# RAGã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹API (v9.1.0)
# =============================================================================

@router.get("/api/rag/status")
async def rag_status(payload: dict = Depends(verify_jwt)):
    """RAGçŠ¶æ…‹ï¼ˆãƒ­ãƒƒã‚¯çŠ¶æ…‹ + çµ±è¨ˆï¼‰"""
    from .rag_bridge import WebRAGBridge
    bridge = WebRAGBridge()
    lock = bridge.is_rag_locked()

    stats = {}
    try:
        from ..rag.rag_builder import RAGBuilder
        builder = RAGBuilder(folder_path="data/information")
        stats = builder.get_rag_stats()
    except Exception:
        pass

    return {"lock": lock, "stats": stats}


class RAGSearchRequest(BaseModel):
    query: str


@router.post("/api/rag/search")
async def rag_search(request: RAGSearchRequest, payload: dict = Depends(verify_jwt)):
    """RAGæ¤œç´¢ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
    from .rag_bridge import WebRAGBridge
    bridge = WebRAGBridge()
    context = await bridge.build_context(request.query)
    return {"context": context, "length": len(context)}


# =============================================================================
# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ API (v9.2.0)
# =============================================================================

from .chat_store import ChatStore

chat_store = ChatStore()


@router.get("/api/chats/storage/stats")
async def storage_stats(payload: dict = Depends(verify_jwt)):
    """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµ±è¨ˆ"""
    return chat_store.get_storage_stats()


@router.get("/api/chats")
async def list_chats(tab: str = None, payload: dict = Depends(verify_jwt)):
    """ãƒãƒ£ãƒƒãƒˆä¸€è¦§å–å¾—"""
    chats = chat_store.list_chats(tab=tab)
    return {"chats": chats}


@router.post("/api/chats")
async def create_chat(tab: str = "soloAI", context_mode: str = "session",
                      payload: dict = Depends(verify_jwt)):
    """æ–°è¦ãƒãƒ£ãƒƒãƒˆä½œæˆ"""
    chat = chat_store.create_chat(tab=tab, context_mode=context_mode)
    return chat


@router.get("/api/chats/{chat_id}")
async def get_chat_detail(chat_id: str, payload: dict = Depends(verify_jwt)):
    """ãƒãƒ£ãƒƒãƒˆè©³ç´° + ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—"""
    chat = chat_store.get_chat(chat_id)
    if not chat:
        raise HTTPException(status_code=404, detail="Chat not found")
    messages = chat_store.get_messages(chat_id)
    return {"chat": chat, "messages": messages}


class TitleUpdate(BaseModel):
    title: str


@router.put("/api/chats/{chat_id}/title")
async def update_title(chat_id: str, body: TitleUpdate, payload: dict = Depends(verify_jwt)):
    """ã‚¿ã‚¤ãƒˆãƒ«æ›´æ–°"""
    chat_store.update_chat_title(chat_id, body.title)
    return {"status": "ok"}


class ModeUpdate(BaseModel):
    mode: str


@router.put("/api/chats/{chat_id}/mode")
async def update_mode(chat_id: str, body: ModeUpdate, payload: dict = Depends(verify_jwt)):
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å¤‰æ›´"""
    chat_store.update_context_mode(chat_id, body.mode)
    return {"status": "ok", "mode": body.mode}


@router.delete("/api/chats/{chat_id}")
async def delete_chat(chat_id: str, payload: dict = Depends(verify_jwt)):
    """ãƒãƒ£ãƒƒãƒˆå‰Šé™¤"""
    chat_store.delete_chat(chat_id)
    return {"status": "ok"}


# =============================================================================
# v9.5.0: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ / è»¢é€ API
# =============================================================================

UPLOAD_DIR = Path("data/web_uploads")


@router.post("/api/files/upload")
async def upload_file(file: UploadFile = File(...),
                      payload: dict = Depends(verify_jwt)):
    """ãƒ¢ãƒã‚¤ãƒ«ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    filename = file.filename or "unnamed_file"
    logger.info(f"Upload request: filename={filename}, size={file.size}, content_type={file.content_type}")

    error = validate_upload(filename, file.size)
    if error:
        raise HTTPException(status_code=400, detail=error)

    UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_name = f"{timestamp}_{filename}"
    save_path = UPLOAD_DIR / safe_name

    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ›¸ãè¾¼ã¿ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ï¼‰
    total_size = 0
    with open(save_path, 'wb') as f:
        while chunk := await file.read(1024 * 64):  # 64KB chunks
            total_size += len(chunk)
            if total_size > UPLOAD_MAX_SIZE_BYTES:
                save_path.unlink(exist_ok=True)
                raise HTTPException(status_code=413,
                    detail=f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºä¸Šé™ ({UPLOAD_MAX_SIZE_MB}MB) è¶…é")
            f.write(chunk)

    return {
        "status": "ok",
        "filename": safe_name,
        "original_name": filename,
        "size": total_size,
        "path": str(save_path),
    }


@router.get("/api/files/uploads")
async def list_uploads(payload: dict = Depends(verify_jwt)):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§"""
    if not UPLOAD_DIR.exists():
        return {"files": []}
    files = []
    for f in sorted(UPLOAD_DIR.iterdir(), key=lambda x: x.stat().st_mtime, reverse=True):
        if f.is_file():
            files.append({
                "name": f.name,
                "size": f.stat().st_size,
                "uploaded_at": datetime.fromtimestamp(f.stat().st_mtime).isoformat(),
            })
    return {"files": files}


@router.delete("/api/files/uploads/{filename}")
async def delete_upload(filename: str, payload: dict = Depends(verify_jwt)):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
    target = UPLOAD_DIR / filename
    if not target.exists():
        raise HTTPException(status_code=404, detail="File not found")
    if not str(target.resolve()).startswith(str(UPLOAD_DIR.resolve())):
        raise HTTPException(status_code=403, detail="Access denied")
    target.unlink()
    return {"status": "ok"}


@router.get("/api/files/download")
async def download_file(path: str, payload: dict = Depends(verify_jwt)):
    """ã‚µãƒ¼ãƒãƒ¼ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¢ãƒã‚¤ãƒ«ç«¯æœ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    project_dir = _get_project_dir()
    if not project_dir:
        raise HTTPException(status_code=400, detail="Project directory not configured")

    target = Path(project_dir) / path

    # ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢
    if not str(target.resolve()).startswith(str(Path(project_dir).resolve())):
        raise HTTPException(status_code=403, detail="Access denied")

    if not target.is_file():
        raise HTTPException(status_code=404, detail="File not found")

    # ã‚µã‚¤ã‚ºåˆ¶é™
    if target.stat().st_size > UPLOAD_MAX_SIZE_BYTES:
        raise HTTPException(status_code=413,
            detail=f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒä¸Šé™ ({UPLOAD_MAX_SIZE_MB}MB) ã‚’è¶…ãˆã¦ã„ã¾ã™")

    # æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
    if target.suffix.lower() not in UPLOAD_ALLOWED_EXTENSIONS:
        raise HTTPException(status_code=400, detail=f"éå¯¾å¿œã®æ‹¡å¼µå­: {target.suffix}")

    return FileResponse(path=str(target), filename=target.name,
                        media_type="application/octet-stream")


@router.post("/api/files/copy-to-project")
async def copy_upload_to_project(filename: str, dest_dir: str = "",
                                  payload: dict = Depends(verify_jwt)):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼ï¼ˆãƒ¢ãƒã‚¤ãƒ«â†’Windowsï¼‰"""
    source = UPLOAD_DIR / filename
    if not source.exists():
        raise HTTPException(status_code=404, detail="Upload not found")

    project_dir = Path(_get_project_dir())
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹é™¤å»ï¼ˆYYYYMMDD_HHMMSS_originalnameï¼‰
    original_name = "_".join(filename.split("_")[2:]) if filename.count("_") >= 2 else filename
    dest = project_dir / dest_dir / original_name

    # ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«é˜²æ­¢
    if not str(dest.resolve()).startswith(str(project_dir.resolve())):
        raise HTTPException(status_code=403, detail="Access denied")

    dest.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(source, dest)

    return {"status": "ok", "path": str(dest.relative_to(project_dir))}


# =============================================================================
# v9.5.0: ãƒ­ã‚°ã‚¢ã‚¦ãƒˆå¾Œãƒãƒ£ãƒƒãƒˆé–²è¦§ï¼ˆèªè¨¼ä¸è¦ï¼‰
# =============================================================================

@router.get("/api/chats/public-list")
async def public_chat_list(limit: int = 10):
    """èªè¨¼ä¸è¦: ç›´è¿‘ãƒãƒ£ãƒƒãƒˆã®ã‚¿ã‚¤ãƒˆãƒ«+ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¿”ã™

    æ³¨æ„: JWTèªè¨¼ãªã—ã€‚Tailscale VPNå†…ã‚¢ã‚¯ã‚»ã‚¹å‰æã€‚
    ãƒãƒ£ãƒƒãƒˆæœ¬æ–‡ã¯å«ã¾ãªã„ã€‚ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ50æ–‡å­—ï¼‰ã®ã¿ã€‚
    """
    try:
        from .chat_store import ChatStore
        store = ChatStore()
        chats = store.list_chats(limit=limit)

        public_chats = []
        for chat in chats:
            # æœ€åˆã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡º
            preview = ""
            first_assistant = ""
            messages = store.get_messages(chat["id"], limit=2)
            for msg in messages:
                if msg["role"] == "user" and not preview:
                    preview = msg["content"][:50]
                if msg["role"] == "assistant" and not first_assistant:
                    first_assistant = msg["content"][:50]

            public_chats.append({
                "id": chat["id"],
                "title": chat.get("title", "ç„¡é¡Œ"),
                "tab": chat.get("tab", "soloAI"),
                "created_at": chat.get("created_at", ""),
                "updated_at": chat.get("updated_at", ""),
                "message_count": chat.get("message_count", 0),
                "user_preview": preview,
                "assistant_preview": first_assistant,
            })

        return {"chats": public_chats, "total": len(public_chats)}
    except Exception as e:
        return {"chats": [], "total": 0, "error": str(e)}

========================================
FILE: src/web/file_transfer.py
========================================
"""
Web UIãƒ•ã‚¡ã‚¤ãƒ«è»¢é€ã®åˆ¶é™ãƒ»ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®šç¾© (v9.5.0)ã€‚
"""

from pathlib import Path

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ¶é™
UPLOAD_MAX_SIZE_MB = 10
UPLOAD_MAX_SIZE_BYTES = UPLOAD_MAX_SIZE_MB * 1024 * 1024

UPLOAD_ALLOWED_EXTENSIONS = {
    # ãƒ†ã‚­ã‚¹ãƒˆç³»
    '.txt', '.md', '.csv', '.json', '.yaml', '.yml', '.toml',
    '.xml', '.html', '.css', '.log', '.ini', '.cfg', '.env',
    # ã‚³ãƒ¼ãƒ‰ç³»
    '.py', '.js', '.jsx', '.ts', '.tsx', '.java', '.c', '.cpp',
    '.h', '.hpp', '.cs', '.go', '.rs', '.rb', '.php', '.swift',
    '.kt', '.scala', '.sh', '.bat', '.ps1', '.sql',
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç³»
    '.pdf', '.docx',
    # ç”»åƒç³»
    '.png', '.jpg', '.jpeg', '.gif', '.webp', '.svg',
}

UPLOAD_BLOCKED_EXTENSIONS = {
    '.exe', '.dll', '.msi', '.scr', '.com',
    '.vbs', '.wsf', '.wsh',
    '.zip', '.rar', '.7z', '.tar', '.gz',
}


def validate_upload(filename: str, size: int = None) -> str | None:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã€‚ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™ã€‚Noneãªã‚‰ OKã€‚"""
    if not filename:
        return "ãƒ•ã‚¡ã‚¤ãƒ«åãŒç©ºã§ã™"

    ext = Path(filename).suffix.lower()

    if ext in UPLOAD_BLOCKED_EXTENSIONS:
        return f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®ç†ç”±ã§ {ext} ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“"

    if ext not in UPLOAD_ALLOWED_EXTENSIONS:
        return f"{ext} ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚å¯¾å¿œå½¢å¼: ãƒ†ã‚­ã‚¹ãƒˆ, ã‚³ãƒ¼ãƒ‰, ç”»åƒ, PDF, DOCX"

    if size and size > UPLOAD_MAX_SIZE_BYTES:
        return f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º ({size // (1024*1024)}MB) ãŒä¸Šé™ ({UPLOAD_MAX_SIZE_MB}MB) ã‚’è¶…ãˆã¦ã„ã¾ã™"

    return None

========================================
FILE: src/web/launcher.py
========================================
"""
Helix AI Studio - Webã‚µãƒ¼ãƒãƒ¼ãƒ©ãƒ³ãƒãƒ£ãƒ¼ (v9.3.0)

PyQt6ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰Webã‚µãƒ¼ãƒãƒ¼ã‚’ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã¨ã—ã¦èµ·å‹•ã™ã‚‹ãŸã‚ã®
è»½é‡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚fastapiç­‰ã®é‡ã„ä¾å­˜ã‚’ä¸€åˆ‡importã—ãªã„ãŸã‚ã€
PyQt6å´ã® ``from ..web.launcher import start_server_background``
ã§importã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„ã€‚

èµ·å‹•æ–¹å¼:
  uvicorn ã‚’ç›´æ¥ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§èµ·å‹•ã™ã‚‹ã€‚
  PyInstaller EXEç’°å¢ƒã§ã¯sys.executableãŒEXEè‡ªèº«ã‚’æŒ‡ã™ãŸã‚ã€
  sys.executableã¯ä½¿ç”¨ã›ãšã€å®Ÿéš›ã®python.exeã‚’æ¤œç´¢ã—ã¦ä½¿ç”¨ã™ã‚‹ã€‚
"""

import logging
import os
import shutil
import subprocess
import sys
from pathlib import Path

logger = logging.getLogger(__name__)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
_PROJECT_ROOT = Path(__file__).parent.parent.parent


def _find_python() -> str:
    """
    å®Ÿéš›ã®Pythonã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ã®ãƒ‘ã‚¹ã‚’è¿”ã™ã€‚

    PyInstaller EXEç’°å¢ƒã§ã¯ sys.executable ãŒ EXE è‡ªèº«ã‚’æŒ‡ã™ãŸã‚ã€
    ãã®ã¾ã¾ä½¿ã†ã¨EXEãŒå†èµ·å‹•ã—ã¦ã—ã¾ã†ã€‚
    ä»¥ä¸‹ã®å„ªå…ˆé †ä½ã§ python.exe ã‚’æ¤œç´¢ã™ã‚‹:
      1. sys.executable ãŒ .exe ã§çµ‚ã‚ã‚‰ãªã„ or 'python' ã‚’å«ã‚€ â†’ ãã®ã¾ã¾ä½¿ç”¨
      2. PyInstaller ã® _MEIPASS å†…ã® python.exe
      3. EXE ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® python.exe / pythonw.exe
      4. venv ã® python.exe
      5. PATH ä¸Šã® python.exe
    """
    exe = sys.executable

    # é€šå¸¸ã®Pythonå®Ÿè¡Œæ™‚: sys.executable ãŒ python ã‚’æŒ‡ã—ã¦ã„ã‚‹
    exe_name = Path(exe).stem.lower()
    if 'python' in exe_name:
        return exe

    # --- PyInstaller frozen ç’°å¢ƒ ---
    logger.info(f"Frozen environment detected: sys.executable={exe}")

    # _MEIPASS å†…ã® python
    meipass = getattr(sys, '_MEIPASS', None)
    if meipass:
        for name in ('python.exe', 'python3.exe', 'python'):
            candidate = Path(meipass) / name
            if candidate.exists():
                logger.info(f"Found Python in _MEIPASS: {candidate}")
                return str(candidate)

    # EXE ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    exe_dir = Path(exe).parent
    for name in ('python.exe', 'pythonw.exe', 'python3.exe', 'python'):
        candidate = exe_dir / name
        if candidate.exists():
            logger.info(f"Found Python next to exe: {candidate}")
            return str(candidate)

    # venvï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ/.venv or venvï¼‰
    for venv_dir in ('.venv', 'venv'):
        candidate = _PROJECT_ROOT / venv_dir / 'Scripts' / 'python.exe'
        if candidate.exists():
            logger.info(f"Found Python in venv: {candidate}")
            return str(candidate)

    # PATH ä¸Šã® python
    found = shutil.which('python')
    if found:
        logger.info(f"Found Python on PATH: {found}")
        return found

    found = shutil.which('python3')
    if found:
        logger.info(f"Found Python3 on PATH: {found}")
        return found

    # æœ€çµ‚æ‰‹æ®µ: sys.executable ã‚’ãã®ã¾ã¾è¿”ã™ï¼ˆå‹•ã‹ãªã„å¯èƒ½æ€§ã‚ã‚Šï¼‰
    logger.warning(f"Could not find python interpreter, falling back to {exe}")
    return exe


class SubprocessWebServer:
    """
    PyQt6ã‹ã‚‰èµ·å‹•ã™ã‚‹Webã‚µãƒ¼ãƒãƒ¼ï¼ˆã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ç‰ˆï¼‰ã€‚

    ``python -c "import uvicorn; uvicorn.run(...)"`` ã‚’ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã¨ã—ã¦å®Ÿè¡Œã™ã‚‹ã€‚
    å¤–éƒ¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚ä¾å­˜ã—ãªã„å®Œå…¨è‡ªå·±å®Œçµå‹ã€‚
    """

    def __init__(self, host: str = "0.0.0.0", port: int = 8500):
        self.host = host
        self.port = port
        self._process: subprocess.Popen | None = None

    def start(self):
        """ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•"""
        if self.is_running:
            logger.warning("Web server is already running")
            return

        python = _find_python()

        # python -c ã§ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã—ã¦èµ·å‹•ã€‚
        # å¤–éƒ¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¾å­˜ã—ãªã„ã€‚
        # uvicorn ã«æ–‡å­—åˆ—ãƒ‘ã‚¹ã‚’æ¸¡ã™ã“ã¨ã§ src ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç›´æ¥ import ã‚’å›é¿ã€‚
        inline_script = (
            "import sys, os;"
            f"sys.path.insert(0, os.getcwd());"
            "import uvicorn;"
            f"uvicorn.run('src.web.server:app',"
            f"host='{self.host}',port={self.port},"
            "log_level='info',access_log=True)"
        )

        cmd = [python, "-c", inline_script]
        logger.info(f"Starting web server: python={python}, port={self.port}")

        env = {**os.environ, "HELIX_WEB_SERVER_ONLY": "1"}

        kwargs = dict(
            cwd=str(_PROJECT_ROOT),
            stdin=subprocess.DEVNULL,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            env=env,
        )
        # Windows: ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’è¡¨ç¤ºã—ãªã„
        if sys.platform == "win32":
            kwargs["creationflags"] = subprocess.CREATE_NO_WINDOW

        self._process = subprocess.Popen(cmd, **kwargs)
        logger.info(f"Web server process started (pid={self._process.pid})")

    def stop(self):
        """ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†"""
        if self._process is None:
            return

        if self._process.poll() is None:
            logger.info(f"Terminating web server (pid={self._process.pid})")
            self._process.terminate()
            try:
                self._process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                logger.warning("Web server did not terminate, killing...")
                self._process.kill()

        self._process = None

    @property
    def is_running(self) -> bool:
        return self._process is not None and self._process.poll() is None


def start_server_background(port: int = 8500) -> SubprocessWebServer:
    """
    PyQt6ã‹ã‚‰ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§Webã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã™ã‚‹ã€‚

    python -c "import uvicorn; uvicorn.run(...)" ã‚’ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã¨ã—ã¦å®Ÿè¡Œã€‚
    PyInstaller EXEç’°å¢ƒã§ã‚‚å®Ÿéš›ã®python.exeã‚’ä½¿ã†ãŸã‚ã€
    EXEãŒå†èµ·å‹•ã—ã¦ã—ã¾ã†å•é¡ŒãŒç™ºç”Ÿã—ãªã„ã€‚
    """
    server = SubprocessWebServer(port=port)
    server.start()
    return server

========================================
FILE: src/widgets/web_lock_overlay.py
========================================
"""
Web UIå®Ÿè¡Œä¸­ã®ãƒ­ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ (v9.5.0)ã€‚
åŠé€æ˜ãƒ€ãƒ¼ã‚¯èƒŒæ™¯ã§è¦ªã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’è¦†ã„ã€å…¥åŠ›ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã™ã‚‹ã€‚
"""

from PyQt6.QtWidgets import QWidget, QLabel, QVBoxLayout
from PyQt6.QtCore import Qt
from PyQt6.QtGui import QFont


class WebLockOverlay(QWidget):

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setObjectName("webLockOverlay")
        self.setAttribute(Qt.WidgetAttribute.WA_TransparentForMouseEvents, False)

        self.setStyleSheet("""
            #webLockOverlay {
                background-color: rgba(0, 0, 0, 180);
            }
        """)

        layout = QVBoxLayout(self)
        layout.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # ã‚¹ãƒãƒ›ã‚¢ã‚¤ã‚³ãƒ³
        icon_label = QLabel("\U0001f4f1")
        icon_label.setFont(QFont("Segoe UI Emoji", 48))
        icon_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        layout.addWidget(icon_label)

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        self.message_label = QLabel("Web UIã‹ã‚‰å®Ÿè¡Œä¸­...")
        self.message_label.setStyleSheet(
            "color: #10b981; font-size: 16px; font-weight: bold; padding: 10px;")
        self.message_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.message_label.setWordWrap(True)
        layout.addWidget(self.message_label)

        # ã‚µãƒ–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        self.sub_label = QLabel("å®Œäº†ã™ã‚‹ã¾ã§ãŠå¾…ã¡ãã ã•ã„")
        self.sub_label.setStyleSheet("color: #6b7280; font-size: 12px;")
        self.sub_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        layout.addWidget(self.sub_label)

        self.hide()

    def show_lock(self, message: str = ""):
        if message:
            self.message_label.setText(message)
        if self.parent():
            self.setGeometry(self.parent().rect())
        self.raise_()
        self.show()

    def hide_lock(self):
        self.hide()

    def resizeEvent(self, event):
        if self.parent():
            self.setGeometry(self.parent().rect())

========================================
FILE: frontend/src/App.jsx
========================================
import React, { useState, useCallback, useEffect } from 'react';
import LoginScreen from './components/LoginScreen';
import ChatView from './components/ChatView';
import InputBar from './components/InputBar';
import StatusIndicator from './components/StatusIndicator';
import TabBar from './components/TabBar';
import MixAIView from './components/MixAIView';
import SettingsView from './components/SettingsView';
import FileManagerView from './components/FileManagerView';
import ChatListPanel from './components/ChatListPanel';
import { useAuth } from './hooks/useAuth';
import { useWebSocket } from './hooks/useWebSocket';

// v9.5.0: ãƒ­ã‚°ã‚¢ã‚¦ãƒˆå¾Œãƒãƒ£ãƒƒãƒˆé–²è¦§
function PreLoginView({ onLogin }) {
  const [recentChats, setRecentChats] = useState([]);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    fetchPublicChats();
  }, []);

  async function fetchPublicChats() {
    try {
      const res = await fetch('/api/chats/public-list?limit=10');
      if (res.ok) {
        const data = await res.json();
        setRecentChats(data.chats || []);
      }
    } catch (e) {
      console.error('Failed to fetch public chats:', e);
    }
    setLoading(false);
  }

  function formatDate(dateStr) {
    if (!dateStr) return '';
    const d = new Date(dateStr);
    const now = new Date();
    const isToday = d.toDateString() === now.toDateString();
    if (isToday) {
      return d.toLocaleTimeString('ja-JP', { hour: '2-digit', minute: '2-digit' });
    }
    return d.toLocaleDateString('ja-JP', { month: 'numeric', day: 'numeric' })
      + ' ' + d.toLocaleTimeString('ja-JP', { hour: '2-digit', minute: '2-digit' });
  }

  function tabBadge(tab) {
    if (tab === 'mixAI') return { text: 'mixAI', color: 'bg-purple-900/50 text-purple-300' };
    return { text: 'soloAI', color: 'bg-cyan-900/50 text-cyan-300' };
  }

  return (
    <div className="min-h-screen bg-gray-950 flex flex-col">
      {/* ãƒ˜ãƒƒãƒ€ãƒ¼ */}
      <div className="p-4 border-b border-gray-800 flex items-center justify-between">
        <div>
          <h1 className="text-lg font-bold text-emerald-400">Helix AI Studio</h1>
          <p className="text-[10px] text-gray-600">v9.5.0 Cross-Device Sync</p>
        </div>
        <button
          onClick={onLogin}
          className="px-4 py-2 bg-emerald-600 hover:bg-emerald-500 text-white
                     text-sm font-medium rounded-lg transition-colors"
        >
          ãƒ­ã‚°ã‚¤ãƒ³
        </button>
      </div>

      {/* ãƒãƒ£ãƒƒãƒˆä¸€è¦§ */}
      <div className="flex-1 overflow-auto p-4">
        <h2 className="text-sm font-medium text-gray-400 mb-3">æœ€è¿‘ã®ãƒãƒ£ãƒƒãƒˆ</h2>

        {loading && (
          <p className="text-gray-600 text-sm text-center py-8">èª­ã¿è¾¼ã¿ä¸­...</p>
        )}

        {!loading && recentChats.length === 0 && (
          <p className="text-gray-600 text-sm text-center py-8">
            ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“
          </p>
        )}

        <div className="space-y-2">
          {recentChats.map(chat => {
            const badge = tabBadge(chat.tab);
            return (
              <div key={chat.id}
                className="bg-gray-900 rounded-lg border border-gray-800 p-3
                           hover:border-gray-700 transition-colors">
                {/* ã‚¿ã‚¤ãƒˆãƒ«è¡Œ */}
                <div className="flex items-center justify-between mb-1">
                  <h3 className="text-sm font-medium text-gray-200 truncate flex-1">
                    {chat.title || 'ç„¡é¡Œ'}
                  </h3>
                  <span className={`text-[10px] px-1.5 py-0.5 rounded ${badge.color} ml-2 shrink-0`}>
                    {badge.text}
                  </span>
                </div>

                {/* ãƒ¡ã‚¿æƒ…å ± */}
                <div className="flex items-center gap-2 text-[10px] text-gray-600 mb-2">
                  <span>{formatDate(chat.updated_at)}</span>
                  <span>&middot;</span>
                  <span>{chat.message_count}ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸</span>
                </div>

                {/* ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ */}
                {chat.assistant_preview && (
                  <p className="text-xs text-gray-500 line-clamp-2">
                    {chat.assistant_preview}...
                  </p>
                )}

                {/* ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ç¶šè¡Œ */}
                <button
                  onClick={onLogin}
                  className="mt-2 text-[10px] text-emerald-500 hover:text-emerald-400
                             transition-colors"
                >
                  ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ç¶šè¡Œ &rarr;
                </button>
              </div>
            );
          })}
        </div>

        {recentChats.length > 0 && (
          <p className="text-[10px] text-gray-700 text-center mt-4">
            æœ€æ–°{recentChats.length}ä»¶ã‚’è¡¨ç¤º &middot; ãƒãƒ£ãƒƒãƒˆæœ¬æ–‡ã®é–²è¦§ã«ã¯ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™
          </p>
        )}
      </div>
    </div>
  );
}

export default function App() {
  const { token, isAuthenticated, login, logout } = useAuth();
  const [activeTab, setActiveTab] = useState('soloAI');
  const soloAI = useWebSocket(token, 'solo');
  const mixAI = useWebSocket(token, 'mix');

  const [showChatList, setShowChatList] = useState(false);
  const [showLogin, setShowLogin] = useState(false);
  // v9.2.0: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆsoloAIç”¨ï¼‰
  const [contextMode, setContextMode] = useState('session');
  const [tokenEstimate, setTokenEstimate] = useState(0);

  // v9.5.0: æœªèªè¨¼æ™‚ã¯PreLoginViewè¡¨ç¤º
  if (!isAuthenticated) {
    if (showLogin) {
      return <LoginScreen onLogin={(t) => { login(t); setShowLogin(false); }} />;
    }
    return <PreLoginView onLogin={() => setShowLogin(true)} />;
  }

  const current = activeTab === 'soloAI' ? soloAI : mixAI;

  function handleSelectChat(chat) {
    const ws = activeTab === 'soloAI' ? soloAI : mixAI;
    ws.loadChat(chat.id);
    setContextMode(chat.context_mode || 'session');
    setTokenEstimate(chat.total_tokens_estimated || 0);
  }

  function handleNewChat(chat) {
    const ws = activeTab === 'soloAI' ? soloAI : mixAI;
    if (chat) {
      ws.loadChat(chat.id);
      setContextMode(chat.context_mode || 'session');
    } else {
      ws.loadChat(null);
    }
    setTokenEstimate(0);
  }

  async function handleModeChange(mode) {
    setContextMode(mode);
    const chatId = current.activeChatId;
    if (chatId) {
      try {
        await fetch(`/api/chats/${chatId}/mode`, {
          method: 'PUT',
          headers: { 'Authorization': `Bearer ${token}`, 'Content-Type': 'application/json' },
          body: JSON.stringify({ mode }),
        });
      } catch (e) { console.error(e); }
    }
  }

  return (
    <div className="flex flex-col bg-gray-950" style={{ height: '100dvh' }}>
      {/* ãƒ˜ãƒƒãƒ€ãƒ¼ */}
      <header className="shrink-0 flex items-center justify-between px-4 py-3 bg-gray-900 border-b border-gray-800">
        <div className="flex items-center gap-2">
          <button onClick={() => setShowChatList(true)}
                  className="w-8 h-8 flex items-center justify-center text-gray-400 hover:text-white rounded-lg hover:bg-gray-800">
            <svg className="w-5 h-5" fill="none" viewBox="0 0 24 24" strokeWidth={2} stroke="currentColor">
              <path strokeLinecap="round" strokeLinejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" />
            </svg>
          </button>
          <span className="text-lg font-semibold text-gray-100">Helix AI Studio</span>
        </div>
        <div className="flex items-center gap-2">
          {current.activeChatId && tokenEstimate > 0 && (
            <span className={`text-[10px] px-2 py-0.5 rounded ${
              tokenEstimate > 50000 ? 'bg-red-900/50 text-red-400' :
              tokenEstimate > 20000 ? 'bg-amber-900/50 text-amber-400' :
              'bg-gray-800 text-gray-500'
            }`}>
              ~{(tokenEstimate / 1000).toFixed(1)}K
            </span>
          )}
          <StatusIndicator status={current.status} />
        </div>
      </header>

      <TabBar activeTab={activeTab} onTabChange={setActiveTab} />

      {/* ãƒãƒ£ãƒƒãƒˆä¸€è¦§ã‚µã‚¤ãƒ‰ãƒ‘ãƒãƒ« */}
      {showChatList && (
        <ChatListPanel
          token={token}
          activeTab={activeTab}
          activeChatId={current.activeChatId}
          onSelectChat={handleSelectChat}
          onNewChat={handleNewChat}
          onClose={() => setShowChatList(false)}
        />
      )}

      {activeTab === 'settings' ? (
        <SettingsView token={token} />
      ) : activeTab === 'files' ? (
        <FileManagerView token={token} />
      ) : activeTab === 'soloAI' ? (
        <>
          <ChatView messages={soloAI.messages} isExecuting={soloAI.isExecuting} />
          <InputBar
            onSend={soloAI.sendMessage}
            disabled={soloAI.isExecuting}
            token={token}
            contextMode={contextMode}
            onModeChange={handleModeChange}
            tokenEstimate={tokenEstimate}
          />
        </>
      ) : (
        <MixAIView
          mixAI={mixAI}
          token={token}
          contextMode={contextMode}
          onModeChange={handleModeChange}
          tokenEstimate={tokenEstimate}
        />
      )}
    </div>
  );
}

========================================
FILE: frontend/src/components/InputBar.jsx
========================================
import React, { useState, useRef } from 'react';
import FileBrowserModal from './FileBrowserModal';
import ContextModeSelector from './ContextModeSelector';

// v9.5.0: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ + ã‚µãƒ¼ãƒãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãƒ¡ãƒ‹ãƒ¥ãƒ¼
function AttachMenu({ token, onFileAttached, onOpenBrowser, onClose }) {
  const fileInputRef = useRef(null);
  const [uploading, setUploading] = useState(false);

  async function handleLocalUpload(e) {
    const file = e.target.files?.[0];
    if (!file) return;

    const maxSize = 10 * 1024 * 1024;
    if (file.size > maxSize) {
      alert(`ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºä¸Šé™: 10MBï¼ˆé¸æŠ: ${(file.size / (1024*1024)).toFixed(1)}MBï¼‰`);
      return;
    }

    const allowedExts = ['.txt','.md','.py','.js','.jsx','.ts','.json','.csv',
      '.html','.css','.yaml','.sql','.pdf','.docx','.png','.jpg','.jpeg','.gif'];
    const ext = '.' + file.name.split('.').pop().toLowerCase();
    if (!allowedExts.includes(ext)) {
      alert(`éå¯¾å¿œã®æ‹¡å¼µå­: ${ext}`);
      return;
    }

    setUploading(true);
    try {
      const formData = new FormData();
      formData.append('file', file);
      const res = await fetch('/api/files/upload', {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${token}` },
        body: formData,
      });
      if (res.ok) {
        const data = await res.json();
        onFileAttached({
          name: file.name,
          path: data.path || data.filename,
          size: data.size,
          source: 'upload',
        });
        onClose();
      } else {
        let detail = `ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•— (${res.status})`;
        try {
          const err = await res.json();
          detail = err.detail || detail;
        } catch (_) {
          // JSONã§ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        }
        alert(detail);
      }
    } catch (e) {
      alert('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: ' + (e.message || ''));
    }
    setUploading(false);
  }

  return (
    <div className="absolute bottom-full right-0 mb-2 bg-gray-800 rounded-lg
                    border border-gray-700 shadow-xl p-2 min-w-[200px] z-50">
      <button
        onClick={() => fileInputRef.current?.click()}
        disabled={uploading}
        className="w-full text-left px-3 py-2 text-sm text-gray-300
                   hover:bg-gray-700 rounded flex items-center gap-2"
      >
        <span>ã“ã®ç«¯æœ«ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</span>
        {uploading && <span className="text-[10px] text-emerald-400">é€ä¿¡ä¸­...</span>}
      </button>
      <input ref={fileInputRef} type="file" className="hidden"
             onChange={handleLocalUpload}
             accept=".txt,.md,.py,.js,.jsx,.ts,.json,.csv,.html,.css,.yaml,.sql,.pdf,.docx,.png,.jpg,.jpeg,.gif" />

      <button
        onClick={() => { onOpenBrowser(); onClose(); }}
        className="w-full text-left px-3 py-2 text-sm text-gray-300
                   hover:bg-gray-700 rounded flex items-center gap-2"
      >
        <span>ã‚µãƒ¼ãƒãƒ¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§</span>
      </button>

      <div className="px-3 py-1 text-[10px] text-gray-600 border-t border-gray-700 mt-1">
        ä¸Šé™: 10MB / ãƒ†ã‚­ã‚¹ãƒˆãƒ»ã‚³ãƒ¼ãƒ‰ãƒ»ç”»åƒãƒ»PDF
      </div>
    </div>
  );
}

export default function InputBar({ onSend, disabled, placeholder, token,
                                    contextMode, onModeChange, tokenEstimate }) {
  const [text, setText] = useState('');
  const [ragEnabled, setRagEnabled] = useState(true);
  const [attachedFiles, setAttachedFiles] = useState([]);
  const [showFileBrowser, setShowFileBrowser] = useState(false);
  const [showAttachMenu, setShowAttachMenu] = useState(false);
  const textareaRef = useRef(null);

  const handleSend = () => {
    const trimmed = text.trim();
    if (!trimmed || disabled) return;
    onSend(trimmed, {
      enableRag: ragEnabled,
      attachedFiles: attachedFiles.map(f => f.path),
    });
    setText('');
    setAttachedFiles([]);
    if (textareaRef.current) {
      textareaRef.current.style.height = 'auto';
    }
  };

  const handleKeyDown = (e) => {
    if ((e.ctrlKey || e.metaKey) && e.key === 'Enter') {
      e.preventDefault();
      handleSend();
    }
  };

  const handleInput = (e) => {
    setText(e.target.value);
    const el = e.target;
    el.style.height = 'auto';
    el.style.height = Math.min(el.scrollHeight, 200) + 'px';
  };

  return (
    <div className="shrink-0 border-t border-gray-800 bg-gray-900 safe-area-inset-bottom">
      {/* æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º */}
      {attachedFiles.length > 0 && (
        <div className="flex flex-wrap gap-1 px-4 py-1.5 bg-gray-900/50 border-b border-gray-800/50">
          {attachedFiles.map((f, i) => (
            <span key={i} className="inline-flex items-center gap-1 px-2 py-0.5 bg-gray-800 rounded text-xs text-gray-300">
              {f.name}
              {f.source === 'upload' && <span className="text-[10px] text-emerald-500">(upload)</span>}
              <button onClick={() => setAttachedFiles(prev => prev.filter((_, j) => j !== i))}
                      className="text-gray-500 hover:text-red-400 ml-0.5">&times;</button>
            </span>
          ))}
        </div>
      )}

      {/* ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ + RAGãƒˆã‚°ãƒ«è¡Œ */}
      <div className="flex items-center justify-between px-3 py-1 border-b border-gray-800/50">
        <ContextModeSelector mode={contextMode} onChange={onModeChange}
                              tokenEstimate={tokenEstimate} />
        <div className="flex items-center gap-2">
          <button onClick={() => setRagEnabled(!ragEnabled)}
            className={`px-2 py-0.5 rounded text-[10px] transition-colors ${
              ragEnabled ? 'bg-emerald-800 text-emerald-300' : 'bg-gray-800 text-gray-500'
            }`}>
            RAG {ragEnabled ? 'ON' : 'OFF'}
          </button>
          <div className="relative">
            <button onClick={() => setShowAttachMenu(!showAttachMenu)}
              disabled={disabled}
              className="px-2 py-0.5 rounded text-[10px] bg-gray-800 text-gray-400 hover:text-gray-200 disabled:opacity-50">
              + æ·»ä»˜
            </button>
            {showAttachMenu && (
              <>
                <div className="fixed inset-0 z-40" onClick={() => setShowAttachMenu(false)} />
                <AttachMenu
                  token={token}
                  onFileAttached={(f) => setAttachedFiles(prev => [...prev, f])}
                  onOpenBrowser={() => setShowFileBrowser(true)}
                  onClose={() => setShowAttachMenu(false)}
                />
              </>
            )}
          </div>
        </div>
      </div>

      {/* ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ› + é€ä¿¡ãƒœã‚¿ãƒ³ */}
      <div className="flex items-end gap-2 px-4 py-3">
        <textarea
          ref={textareaRef}
          value={text}
          onChange={handleInput}
          onKeyDown={handleKeyDown}
          placeholder={placeholder || "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›... (Ctrl+Enter ã§é€ä¿¡)"}
          rows={1}
          className="flex-1 resize-none bg-gray-800 border border-gray-700 rounded-xl px-4 py-3 text-gray-100 placeholder-gray-500 focus:outline-none focus:ring-2 focus:ring-emerald-500 max-h-[200px]"
          disabled={disabled}
        />
        <button
          onClick={handleSend}
          disabled={disabled || !text.trim()}
          className="shrink-0 w-12 h-12 rounded-xl bg-emerald-600 hover:bg-emerald-500 disabled:bg-gray-700 flex items-center justify-center transition-colors"
        >
          <svg className="w-5 h-5 text-white" fill="none" viewBox="0 0 24 24" strokeWidth={2} stroke="currentColor">
            <path strokeLinecap="round" strokeLinejoin="round" d="M6 12L3.269 3.126A59.768 59.768 0 0121.485 12 59.77 59.77 0 013.27 20.876L5.999 12zm0 0h7.5" />
          </svg>
        </button>
      </div>

      {showFileBrowser && (
        <FileBrowserModal
          token={token}
          onSelect={(files) => setAttachedFiles(prev => [...prev, ...files])}
          onClose={() => setShowFileBrowser(false)}
        />
      )}
    </div>
  );
}

========================================
FILE: frontend/src/components/FileManagerView.jsx
========================================
import React, { useState, useEffect, useRef } from 'react';

const TEXT_EXTENSIONS = ['.txt', '.md', '.py', '.js', '.jsx', '.ts', '.tsx',
  '.json', '.yaml', '.yml', '.html', '.css', '.sql', '.sh', '.csv', '.xml',
  '.env', '.cfg', '.ini', '.toml', '.log', '.bat', '.gitignore'];
const IMAGE_EXTENSIONS = ['.png', '.jpg', '.jpeg', '.gif', '.webp', '.svg'];

// v9.5.0: ãƒ•ã‚¡ã‚¤ãƒ«è»¢é€ã‚»ã‚¯ã‚·ãƒ§ãƒ³
function TransferSection({ token }) {
  const [uploads, setUploads] = useState([]);
  const [uploading, setUploading] = useState(false);
  const fileInputRef = useRef(null);

  useEffect(() => { fetchUploads(); }, []);

  async function fetchUploads() {
    try {
      const res = await fetch('/api/files/uploads', {
        headers: { 'Authorization': `Bearer ${token}` },
      });
      if (res.ok) {
        const data = await res.json();
        setUploads(data.files || []);
      }
    } catch (e) { console.error(e); }
  }

  async function handleUpload(e) {
    const file = e.target.files?.[0];
    if (!file) return;
    setUploading(true);
    try {
      const formData = new FormData();
      formData.append('file', file);
      const res = await fetch('/api/files/upload', {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${token}` },
        body: formData,
      });
      if (res.ok) fetchUploads();
      else {
        let detail = `ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•— (${res.status})`;
        try { const err = await res.json(); detail = err.detail || detail; } catch (_) {}
        alert(detail);
      }
    } catch (e) { alert('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: ' + (e.message || '')); }
    setUploading(false);
  }

  async function handleCopyToProject(filename) {
    const dest = prompt('ã‚³ãƒ”ãƒ¼å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆç©ºã§ãƒ«ãƒ¼ãƒˆï¼‰:', '');
    if (dest === null) return;
    try {
      const res = await fetch(
        `/api/files/copy-to-project?filename=${encodeURIComponent(filename)}&dest_dir=${encodeURIComponent(dest)}`,
        { method: 'POST', headers: { 'Authorization': `Bearer ${token}` } }
      );
      if (res.ok) {
        const data = await res.json();
        alert(`ã‚³ãƒ”ãƒ¼å®Œäº†: ${data.path}`);
      }
    } catch (e) { alert('ã‚³ãƒ”ãƒ¼å¤±æ•—'); }
  }

  async function handleDeleteUpload(filename) {
    if (!confirm(`${filename} ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ`)) return;
    try {
      await fetch(`/api/files/uploads/${encodeURIComponent(filename)}`, {
        method: 'DELETE',
        headers: { 'Authorization': `Bearer ${token}` },
      });
      fetchUploads();
    } catch (e) { console.error(e); }
  }

  function formatSize(bytes) {
    if (bytes < 1024) return `${bytes}B`;
    if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)}KB`;
    return `${(bytes / (1024 * 1024)).toFixed(1)}MB`;
  }

  return (
    <div className="mt-4 px-4">
      <div className="flex items-center justify-between mb-2">
        <h3 className="text-sm font-medium text-emerald-400">ãƒ•ã‚¡ã‚¤ãƒ«è»¢é€</h3>
        <button onClick={() => fileInputRef.current?.click()} disabled={uploading}
          className="px-3 py-1.5 bg-emerald-700 hover:bg-emerald-600 text-white
                     text-xs rounded-lg transition-colors disabled:opacity-50">
          {uploading ? 'é€ä¿¡ä¸­...' : 'ã“ã®ç«¯æœ«ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'}
        </button>
        <input ref={fileInputRef} type="file" className="hidden" onChange={handleUpload}
               accept=".txt,.md,.py,.js,.json,.csv,.html,.pdf,.docx,.png,.jpg,.jpeg" />
      </div>

      {uploads.length > 0 && (
        <div className="bg-gray-900 rounded-lg border border-gray-800 divide-y divide-gray-800">
          {uploads.map(f => (
            <div key={f.name} className="flex items-center justify-between px-3 py-2">
              <div className="flex-1 min-w-0">
                <p className="text-sm text-gray-300 truncate">{f.name}</p>
                <p className="text-[10px] text-gray-600">{formatSize(f.size)}</p>
              </div>
              <div className="flex items-center gap-1">
                <button onClick={() => handleCopyToProject(f.name)}
                  className="text-[10px] px-2 py-1 bg-blue-900/50 text-blue-300 rounded hover:bg-blue-800/50">
                  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã‚³ãƒ”ãƒ¼
                </button>
                <button onClick={() => handleDeleteUpload(f.name)}
                  className="text-[10px] px-2 py-1 text-red-400 hover:bg-red-900/30 rounded">
                  å‰Šé™¤
                </button>
              </div>
            </div>
          ))}
        </div>
      )}

      {uploads.length === 0 && (
        <p className="text-gray-600 text-xs text-center py-4">
          ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãªã—ï¼ˆä¸Šé™: 10MBï¼‰
        </p>
      )}

      <p className="text-[10px] text-gray-700 mt-2">
        å¯¾å¿œ: ãƒ†ã‚­ã‚¹ãƒˆ, ã‚³ãƒ¼ãƒ‰, ç”»åƒ, PDF, DOCX / ä¸Šé™: 10MB/ãƒ•ã‚¡ã‚¤ãƒ«
      </p>
    </div>
  );
}

export default function FileManagerView({ token }) {
  const [currentDir, setCurrentDir] = useState('');
  const [items, setItems] = useState([]);
  const [openFile, setOpenFile] = useState(null);
  const [editContent, setEditContent] = useState('');
  const [isEditing, setIsEditing] = useState(false);
  const [saving, setSaving] = useState(false);
  const [message, setMessage] = useState('');

  const headers = { 'Authorization': `Bearer ${token}`, 'Content-Type': 'application/json' };

  useEffect(() => { fetchDir(currentDir); }, [currentDir]);

  async function fetchDir(dir) {
    try {
      const res = await fetch(`/api/files/browse?dir_path=${encodeURIComponent(dir)}`,
        { headers: { 'Authorization': `Bearer ${token}` } });
      if (res.ok) setItems(await res.json());
      else setItems([]);
    } catch (e) { console.error(e); }
  }

  async function openFileHandler(item) {
    if (item.is_dir) {
      setCurrentDir(item.path);
      setOpenFile(null);
      return;
    }
    const ext = item.extension.toLowerCase();
    if (!TEXT_EXTENSIONS.includes(ext) && !IMAGE_EXTENSIONS.includes(ext)) {
      setMessage(`æœªå¯¾å¿œã®å½¢å¼: ${ext}`);
      setTimeout(() => setMessage(''), 3000);
      return;
    }
    try {
      const res = await fetch(`/api/files/content?file_path=${encodeURIComponent(item.path)}`,
        { headers: { 'Authorization': `Bearer ${token}` } });
      if (res.ok) {
        const data = await res.json();
        setOpenFile({ ...data, name: item.name });
        setEditContent(data.type === 'text' ? data.content : '');
        setIsEditing(false);
      }
    } catch (e) { console.error(e); }
  }

  async function saveFile() {
    if (!openFile) return;
    setSaving(true);
    try {
      const res = await fetch(`/api/files/content?file_path=${encodeURIComponent(openFile.path)}`, {
        method: 'PUT', headers,
        body: JSON.stringify({ content: editContent }),
      });
      if (res.ok) {
        setMessage('ä¿å­˜ã—ã¾ã—ãŸ');
        setOpenFile({ ...openFile, content: editContent });
        setIsEditing(false);
      } else {
        setMessage('ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ');
      }
    } catch (e) { setMessage('ã‚¨ãƒ©ãƒ¼: ' + e.message); }
    setSaving(false);
    setTimeout(() => setMessage(''), 3000);
  }

  // v9.5.0: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¢ãƒã‚¤ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
  async function handleDownload(path) {
    try {
      const res = await fetch(`/api/files/download?path=${encodeURIComponent(path)}`, {
        headers: { 'Authorization': `Bearer ${token}` },
      });
      if (res.ok) {
        const blob = await res.blob();
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = path.split('/').pop();
        a.click();
        URL.revokeObjectURL(url);
      } else {
        const err = await res.json();
        alert(err.detail);
      }
    } catch (e) { alert('ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼'); }
  }

  return (
    <div className="flex-1 flex flex-col min-h-0">
      {openFile ? (
        <div className="flex-1 flex flex-col min-h-0">
          <div className="shrink-0 flex items-center justify-between px-4 py-2 bg-gray-900 border-b border-gray-800">
            <div className="flex items-center gap-2">
              <button onClick={() => setOpenFile(null)} className="text-gray-400 hover:text-white">&larr;</button>
              <span className="text-gray-200 text-sm font-medium truncate">{openFile.name}</span>
              <span className="text-gray-500 text-xs">{(openFile.size / 1024).toFixed(1)}KB</span>
            </div>
            <div className="flex items-center gap-2">
              {openFile.type === 'text' && !isEditing && (
                <button onClick={() => { setIsEditing(true); setEditContent(openFile.content); }}
                  className="px-3 py-1 bg-emerald-700 text-emerald-200 rounded text-xs">
                  ç·¨é›†
                </button>
              )}
              {isEditing && (
                <>
                  <button onClick={() => setIsEditing(false)}
                    className="px-3 py-1 bg-gray-700 text-gray-300 rounded text-xs">
                    ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                  </button>
                  <button onClick={saveFile} disabled={saving}
                    className="px-3 py-1 bg-emerald-600 text-white rounded text-xs">
                    {saving ? 'ä¿å­˜ä¸­...' : 'ä¿å­˜'}
                  </button>
                </>
              )}
              {message && <span className="text-xs text-emerald-400">{message}</span>}
            </div>
          </div>

          <div className="flex-1 overflow-auto min-h-0">
            {openFile.type === 'text' ? (
              isEditing ? (
                <textarea
                  value={editContent}
                  onChange={e => setEditContent(e.target.value)}
                  className="w-full h-full bg-gray-950 text-gray-200 text-sm font-mono p-4 resize-none outline-none"
                  spellCheck={false}
                />
              ) : (
                <pre className="text-gray-200 text-sm font-mono p-4 whitespace-pre-wrap break-words">
                  {openFile.content}
                </pre>
              )
            ) : openFile.type === 'image' ? (
              <div className="flex items-center justify-center p-4">
                <img
                  src={`data:${openFile.mime};base64,${openFile.content}`}
                  alt={openFile.name}
                  className="max-w-full max-h-[70vh] object-contain rounded-lg"
                />
              </div>
            ) : null}
          </div>
        </div>
      ) : (
        <div className="flex-1 flex flex-col min-h-0">
          <div className="shrink-0 px-4 py-2 flex items-center gap-1 text-xs text-gray-400 bg-gray-900 border-b border-gray-800">
            <button onClick={() => setCurrentDir('')} className="hover:text-emerald-400">Project</button>
            {currentDir.split('/').filter(Boolean).map((seg, i, arr) => (
              <React.Fragment key={i}>
                <span className="mx-0.5">/</span>
                <button onClick={() => setCurrentDir(arr.slice(0, i + 1).join('/'))}
                  className="hover:text-emerald-400">{seg}</button>
              </React.Fragment>
            ))}
          </div>

          <div className="flex-1 overflow-y-auto min-h-0">
            {currentDir && (
              <button onClick={() => setCurrentDir(currentDir.split('/').slice(0, -1).join('/'))}
                className="w-full text-left px-4 py-3 text-gray-400 hover:bg-gray-800/50 text-sm border-b border-gray-800/50">
                &uarr; ä¸Šã®éšå±¤
              </button>
            )}
            {items.map(item => {
              const ext = item.extension?.toLowerCase() || '';
              const isViewable = TEXT_EXTENSIONS.includes(ext) || IMAGE_EXTENSIONS.includes(ext);
              const icon = item.is_dir ? '\uD83D\uDCC1' : IMAGE_EXTENSIONS.includes(ext) ? '\uD83D\uDDBC\uFE0F' : '\uD83D\uDCC4';

              return (
                <div
                  key={item.path}
                  className={`w-full px-4 py-3 flex items-center gap-3 text-sm border-b border-gray-800/30
                    ${item.is_dir || isViewable ? 'hover:bg-gray-800/50 text-gray-300' : 'text-gray-600'}`}
                >
                  <button
                    onClick={() => openFileHandler(item)}
                    className="flex-1 flex items-center gap-3 text-left min-w-0"
                    disabled={!item.is_dir && !isViewable}
                  >
                    <span className="text-lg">{icon}</span>
                    <span className="flex-1 truncate">{item.name}</span>
                  </button>
                  {!item.is_dir && (
                    <span className="text-xs text-gray-600 shrink-0">{(item.size / 1024).toFixed(1)}KB</span>
                  )}
                  {/* v9.5.0: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ */}
                  {!item.is_dir && (
                    <button onClick={() => handleDownload(item.path)}
                      className="text-[10px] px-2 py-1 text-gray-400 hover:text-emerald-300
                                 hover:bg-emerald-900/30 rounded shrink-0"
                      title="ã“ã®ç«¯æœ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰">
                      DL
                    </button>
                  )}
                </div>
              );
            })}
            {items.length === 0 && (
              <p className="text-gray-600 text-sm text-center py-8">ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€ã¾ãŸã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒæœªè¨­å®šã§ã™</p>
            )}

            {/* v9.5.0: ãƒ•ã‚¡ã‚¤ãƒ«è»¢é€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ */}
            <TransferSection token={token} />
          </div>
        </div>
      )}
    </div>
  );
}

========================================
FILE: frontend/src/components/SettingsView.jsx
========================================
import React, { useState, useEffect } from 'react';

const API_BASE = '';

export default function SettingsView({ token }) {
  const [settings, setSettings] = useState(null);
  const [gpuInfo, setGpuInfo] = useState(null);
  const [ragStatus, setRagStatus] = useState(null);
  const [saving, setSaving] = useState(false);
  const [message, setMessage] = useState('');
  // ç·¨é›†å¯èƒ½ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
  const [editPin, setEditPin] = useState('');
  const [editJwtExpiry, setEditJwtExpiry] = useState(168);
  const [editTimeout, setEditTimeout] = useState(90);

  useEffect(() => {
    fetchSettings();
    fetchGpuInfo();
    fetchRagStatus();
    const gpuInterval = setInterval(fetchGpuInfo, 5000);
    return () => clearInterval(gpuInterval);
  }, [token]);

  const headers = { 'Authorization': `Bearer ${token}`, 'Content-Type': 'application/json' };

  async function fetchSettings() {
    try {
      const res = await fetch(`${API_BASE}/api/settings`, { headers });
      if (res.ok) {
        const data = await res.json();
        setSettings(data);
        setEditJwtExpiry(data.jwt_expiry_hours || 168);
        setEditTimeout(data.claude_timeout_minutes || 90);
      }
    } catch (e) { console.error('Settings fetch error:', e); }
  }

  async function fetchGpuInfo() {
    try {
      const res = await fetch(`${API_BASE}/api/monitor/gpu`, { headers });
      if (res.ok) setGpuInfo(await res.json());
    } catch (e) { console.error('GPU fetch error:', e); }
  }

  async function fetchRagStatus() {
    try {
      const res = await fetch(`${API_BASE}/api/rag/status`, { headers });
      if (res.ok) setRagStatus(await res.json());
    } catch (e) { console.error('RAG status fetch error:', e); }
  }

  async function saveSettings() {
    setSaving(true);
    setMessage('');
    const body = {};
    if (editPin) body.pin = editPin;
    body.jwt_expiry_hours = editJwtExpiry;
    body.claude_timeout_minutes = editTimeout;
    try {
      const res = await fetch(`${API_BASE}/api/settings`, {
        method: 'PUT', headers, body: JSON.stringify(body),
      });
      if (res.ok) {
        setMessage('ä¿å­˜ã—ã¾ã—ãŸ');
        setEditPin('');
      } else {
        setMessage('ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ');
      }
    } catch (e) { setMessage('ã‚¨ãƒ©ãƒ¼: ' + e.message); }
    setSaving(false);
    setTimeout(() => setMessage(''), 3000);
  }

  if (!settings) return <div className="flex-1 flex items-center justify-center text-gray-500">èª­è¾¼ä¸­...</div>;

  return (
    <div className="flex-1 overflow-y-auto min-h-0 px-4 py-4 space-y-4">
      {/* Claudeãƒ¢ãƒ‡ãƒ«è¨­å®š */}
      <Section title="Claude ãƒ¢ãƒ‡ãƒ«">
        <InfoRow label="ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«" value={settings.claude_model_id || 'æœªè¨­å®š'} />
        <div className="flex items-center justify-between gap-3">
          <label className="text-gray-300 text-sm shrink-0">ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ</label>
          <select
            value={editTimeout}
            onChange={e => setEditTimeout(Number(e.target.value))}
            className="bg-gray-800 text-gray-200 text-sm rounded-lg px-3 py-1.5 border border-gray-700 focus:border-emerald-500 outline-none max-w-[200px]"
          >
            <option value={10}>10åˆ†</option>
            <option value={30}>30åˆ†</option>
            <option value={60}>60åˆ†ï¼ˆ1æ™‚é–“ï¼‰</option>
            <option value={90}>90åˆ†ï¼ˆ1.5æ™‚é–“ï¼‰</option>
            <option value={120}>120åˆ†ï¼ˆ2æ™‚é–“ï¼‰</option>
            <option value={180}>180åˆ†ï¼ˆ3æ™‚é–“ï¼‰</option>
          </select>
        </div>
      </Section>

      {/* P1/P3ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆv9.3.0ï¼‰ */}
      <Section title="P1/P3 ã‚¨ãƒ³ã‚¸ãƒ³" badge="ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªã§è¨­å®š">
        <InfoRow
          label="orchestrator_engine"
          value={settings.orchestrator_engine || 'claude-opus-4-6'}
        />
        <div className="text-[10px] text-gray-500 mt-1">
          {(settings.orchestrator_engine || '').startsWith('claude-') ? 'â˜ Claude API' : 'ğŸ–¥ ãƒ­ãƒ¼ã‚«ãƒ«LLM'}
        </div>
      </Section>

      {/* mixAIãƒ¢ãƒ‡ãƒ«å‰²å½“ï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰ */}
      <Section title="mixAI ãƒ¢ãƒ‡ãƒ«å‰²å½“" badge="ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªã§è¨­å®š">
        {['coding', 'research', 'reasoning', 'vision', 'translation'].map(cat => (
          <InfoRow
            key={cat}
            label={cat}
            value={settings.model_assignments?.[cat] || 'æœªå‰²å½“'}
          />
        ))}
      </Section>

      {/* ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰ */}
      <Section title="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ" badge="ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªã§è¨­å®š">
        <InfoRow label="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆDir" value={settings.project_dir || 'æœªè¨­å®š'} />
        <InfoRow label="Ollamaãƒ›ã‚¹ãƒˆ" value={settings.ollama_host || 'http://localhost:11434'} />
      </Section>

      {/* RAGã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ */}
      {ragStatus && (
        <Section title="RAG (æ¤œç´¢æ‹¡å¼µç”Ÿæˆ)">
          <InfoRow label="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹" value={ragStatus.available ? 'åˆ©ç”¨å¯èƒ½' : 'æœªæ§‹ç¯‰'} />
          {ragStatus.available && (
            <>
              <InfoRow label="Semanticãƒ¡ãƒ¢ãƒª" value={`${ragStatus.semantic_count || 0}ä»¶`} />
              <InfoRow label="Episodicãƒ¡ãƒ¢ãƒª" value={`${ragStatus.episodic_count || 0}ä»¶`} />
              <InfoRow label="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚¯" value={`${ragStatus.document_chunk_count || 0}ä»¶`} />
              <InfoRow label="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚µãƒãƒª" value={`${ragStatus.document_summary_count || 0}ä»¶`} />
            </>
          )}
        </Section>
      )}

      {/* GPUãƒ¢ãƒ‹ã‚¿ãƒ¼ */}
      <Section title="GPU ãƒ¢ãƒ‹ã‚¿ãƒ¼">
        {gpuInfo && gpuInfo.gpus && gpuInfo.gpus.length > 0 ? (
          <div className="space-y-2">
            {gpuInfo.gpus.map((gpu, i) => (
              <GpuCard key={i} gpu={gpu} />
            ))}
          </div>
        ) : (
          <p className="text-gray-500 text-sm">
            {gpuInfo?.error ? `GPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: ${gpuInfo.error}` : 'GPUæƒ…å ±å–å¾—ä¸­...'}
          </p>
        )}
      </Section>

      {/* ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼ˆWeb UIã§ç·¨é›†å¯èƒ½ï¼‰ */}
      <Section title="ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£">
        <InputRow
          label="PINå¤‰æ›´"
          type="password"
          value={editPin}
          onChange={setEditPin}
          placeholder="æ–°ã—ã„PINã‚’å…¥åŠ›"
        />
        <div className="flex items-center justify-between gap-3">
          <label className="text-gray-300 text-sm shrink-0">JWTæœ‰åŠ¹æœŸé™</label>
          <select
            value={editJwtExpiry}
            onChange={e => setEditJwtExpiry(Number(e.target.value))}
            className="bg-gray-800 text-gray-200 text-sm rounded-lg px-3 py-1.5 border border-gray-700 focus:border-emerald-500 outline-none max-w-[200px]"
          >
            <option value={24}>24æ™‚é–“ï¼ˆ1æ—¥ï¼‰</option>
            <option value={72}>72æ™‚é–“ï¼ˆ3æ—¥ï¼‰</option>
            <option value={168}>168æ™‚é–“ï¼ˆ7æ—¥ï¼‰</option>
            <option value={336}>336æ™‚é–“ï¼ˆ14æ—¥ï¼‰</option>
            <option value={720}>720æ™‚é–“ï¼ˆ30æ—¥ï¼‰</option>
          </select>
        </div>
        <InfoRow label="æœ€å¤§åŒæ™‚æ¥ç¶š" value={`${settings.max_connections || 3}`} />
      </Section>

      {/* ä¿å­˜ãƒœã‚¿ãƒ³ */}
      <div className="flex items-center gap-3 pt-2 pb-8">
        <button
          onClick={saveSettings}
          disabled={saving}
          className="px-6 py-2.5 bg-emerald-600 hover:bg-emerald-500 disabled:bg-gray-600 text-white rounded-lg font-medium transition-colors"
        >
          {saving ? 'ä¿å­˜ä¸­...' : 'è¨­å®šã‚’ä¿å­˜'}
        </button>
        {message && (
          <span className={`text-sm ${message.includes('ã‚¨ãƒ©ãƒ¼') ? 'text-red-400' : 'text-emerald-400'}`}>
            {message}
          </span>
        )}
      </div>
    </div>
  );
}

function Section({ title, badge, children }) {
  return (
    <div className="bg-gray-900 rounded-xl p-4 space-y-3">
      <div className="flex items-center gap-2">
        <h3 className="text-emerald-400 font-semibold text-sm">{title}</h3>
        {badge && (
          <span className="text-[10px] px-1.5 py-0.5 rounded bg-gray-800 text-gray-500 border border-gray-700">
            {badge}
          </span>
        )}
      </div>
      {children}
    </div>
  );
}

function InputRow({ label, type = 'text', value, onChange, placeholder }) {
  return (
    <div className="flex items-center justify-between gap-3">
      <label className="text-gray-300 text-sm shrink-0">{label}</label>
      <input
        type={type}
        value={value}
        onChange={e => onChange(e.target.value)}
        placeholder={placeholder}
        className="bg-gray-800 text-gray-200 text-sm rounded-lg px-3 py-1.5 border border-gray-700 focus:border-emerald-500 outline-none max-w-[200px]"
      />
    </div>
  );
}

function InfoRow({ label, value }) {
  return (
    <div className="flex items-center justify-between">
      <span className="text-gray-400 text-sm">{label}</span>
      <span className="text-gray-300 text-sm font-mono truncate max-w-[200px]">{value}</span>
    </div>
  );
}

function GpuCard({ gpu }) {
  const vramPercent = gpu.memory_total > 0 ? (gpu.memory_used / gpu.memory_total * 100) : 0;
  const barColor = vramPercent > 90 ? 'bg-red-500' : vramPercent > 70 ? 'bg-amber-500' : 'bg-emerald-500';

  return (
    <div className="bg-gray-800 rounded-lg p-3 space-y-2">
      <div className="flex items-center justify-between">
        <span className="text-gray-200 text-sm font-medium">{gpu.name}</span>
        <span className="text-gray-400 text-xs">{gpu.utilization}% util</span>
      </div>
      <div className="flex items-center gap-2">
        <div className="flex-1 h-2 bg-gray-700 rounded-full overflow-hidden">
          <div className={`h-full ${barColor} rounded-full transition-all duration-500`}
               style={{ width: `${vramPercent}%` }} />
        </div>
        <span className="text-gray-400 text-xs shrink-0">
          {(gpu.memory_used / 1024).toFixed(1)}/{(gpu.memory_total / 1024).toFixed(1)} GB
        </span>
      </div>
      <div className="text-gray-500 text-xs">
        æ¸©åº¦: {gpu.temperature}Â°C | é›»åŠ›: {gpu.power_draw}W
      </div>
    </div>
  );
}

========================================
FILE: frontend/src/hooks/useWebSocket.js
========================================
import { useState, useEffect, useRef, useCallback } from 'react';

export function useWebSocket(token, endpoint = 'solo') {
  const [status, setStatus] = useState('disconnected');
  const [messages, setMessages] = useState([]);
  const [isExecuting, setIsExecuting] = useState(false);
  const wsRef = useRef(null);
  const reconnectRef = useRef(null);

  // mixAIç”¨ã®è¿½åŠ ã‚¹ãƒ†ãƒ¼ãƒˆ
  const [phaseInfo, setPhaseInfo] = useState({ phase: 0, description: '' });
  const [llmStatus, setLlmStatus] = useState([]);
  const [phase2Progress, setPhase2Progress] = useState({ completed: 0, total: 0 });

  // v9.2.0: ãƒãƒ£ãƒƒãƒˆç®¡ç†
  const [activeChatId, setActiveChatId] = useState(null);
  const [chatTitle, setChatTitle] = useState('');

  // WebSocketæ¥ç¶š
  useEffect(() => {
    if (!token) return;

    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const host = window.location.host;
    const wsUrl = `${protocol}//${host}/ws/${endpoint}?token=${token}`;

    function connect() {
      const ws = new WebSocket(wsUrl);
      wsRef.current = ws;

      ws.onopen = () => {
        setStatus('connected');
        console.log(`WebSocket connected (${endpoint})`);
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        handleMessage(data);
      };

      ws.onclose = (event) => {
        setStatus('disconnected');
        wsRef.current = null;
        if (event.code !== 4001 && event.code !== 4003) {
          reconnectRef.current = setTimeout(connect, 5000);
        }
      };

      ws.onerror = () => {
        setStatus('error');
      };
    }

    connect();

    return () => {
      if (reconnectRef.current) clearTimeout(reconnectRef.current);
      if (wsRef.current) wsRef.current.close();
    };
  }, [token, endpoint]);

  // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ©
  function handleMessage(data) {
    switch (data.type) {
      case 'streaming':
        if (data.done) {
          setMessages(prev => {
            const updated = [...prev];
            const lastIdx = updated.length - 1;
            if (lastIdx >= 0 && updated[lastIdx].role === 'assistant' && updated[lastIdx].streaming) {
              updated[lastIdx] = {
                ...updated[lastIdx],
                content: data.chunk || updated[lastIdx].content,
                streaming: false,
              };
            } else {
              updated.push({ role: 'assistant', content: data.chunk, streaming: false });
            }
            return updated;
          });
          setIsExecuting(false);
        } else {
          setMessages(prev => {
            const updated = [...prev];
            const lastIdx = updated.length - 1;
            if (lastIdx >= 0 && updated[lastIdx].role === 'assistant' && updated[lastIdx].streaming) {
              updated[lastIdx] = {
                ...updated[lastIdx],
                content: updated[lastIdx].content + data.chunk,
              };
            } else {
              updated.push({ role: 'assistant', content: data.chunk, streaming: true });
            }
            return updated;
          });
        }
        break;

      case 'status':
        setStatus(data.status);
        if (data.status === 'executing') setIsExecuting(true);
        if (data.status === 'completed' || data.status === 'cancelled') setIsExecuting(false);
        break;

      case 'error':
        setMessages(prev => [
          ...prev,
          { role: 'system', content: `ã‚¨ãƒ©ãƒ¼: ${data.error}`, isError: true },
        ]);
        setIsExecuting(false);
        break;

      case 'pong':
        break;

      // v9.2.0: ãƒãƒ£ãƒƒãƒˆç®¡ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
      case 'chat_created':
        setActiveChatId(data.chat_id);
        break;

      case 'chat_title_updated':
        setChatTitle(data.title);
        break;

      case 'token_warning':
        setMessages(prev => [
          ...prev,
          { role: 'system', content: data.message, isError: false },
        ]);
        break;

      // mixAIç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—
      case 'phase_changed':
        setPhaseInfo({ phase: data.phase, description: data.description });
        setIsExecuting(true);
        break;

      case 'llm_started':
        setLlmStatus(prev => [
          ...prev,
          { category: data.category, model: data.model, status: 'running', elapsed: 0 },
        ]);
        break;

      case 'llm_finished':
        setLlmStatus(prev =>
          prev.map(s =>
            s.category === data.category
              ? { ...s, status: data.success ? 'done' : 'error', elapsed: data.elapsed }
              : s
          )
        );
        break;

      case 'phase2_progress':
        setPhase2Progress({ completed: data.completed, total: data.total });
        break;

      default:
        console.warn('Unknown WebSocket message type:', data.type);
    }
  }

  // soloAIç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ï¼ˆv9.2.0: chat_idå¯¾å¿œï¼‰
  const sendMessage = useCallback((prompt, options = {}) => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    setMessages(prev => [...prev, { role: 'user', content: prompt }]);
    setIsExecuting(true);

    wsRef.current.send(JSON.stringify({
      action: 'execute',
      prompt,
      chat_id: options.chatId || activeChatId || null,
      model_id: options.modelId || 'claude-opus-4-6',
      project_dir: options.projectDir || '',
      timeout: options.timeout || 0,  // 0 = ã‚µãƒ¼ãƒãƒ¼å´ã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿å–ã‚Š
      use_mcp: options.useMcp !== false,
      auto_approve: options.autoApprove !== false,
      enable_rag: options.enableRag !== false,
      attached_files: options.attachedFiles || [],
    }));
  }, [activeChatId]);

  // mixAIç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ï¼ˆv9.2.0: chat_idå¯¾å¿œï¼‰
  const sendMixMessage = useCallback((prompt, options = {}) => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    setMessages(prev => [...prev, { role: 'user', content: prompt }]);
    setIsExecuting(true);
    setPhaseInfo({ phase: 0, description: '' });
    setLlmStatus([]);
    setPhase2Progress({ completed: 0, total: 0 });

    wsRef.current.send(JSON.stringify({
      action: 'execute',
      prompt,
      chat_id: options.chatId || activeChatId || null,
      model_id: options.modelId || 'claude-opus-4-6',
      model_assignments: options.modelAssignments || {},
      project_dir: options.projectDir || '',
      attached_files: options.attachedFiles || [],
      timeout: options.timeout || 0,  // 0 = ã‚µãƒ¼ãƒãƒ¼å´ã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿å–ã‚Š
      enable_rag: options.enableRag !== false,
    }));
  }, [activeChatId]);

  // v9.2.0: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¯ãƒªã‚¢ + ãƒãƒ£ãƒƒãƒˆåˆ‡æ›¿
  const clearMessages = useCallback(() => {
    setMessages([]);
    setIsExecuting(false);
    setPhaseInfo({ phase: 0, description: '' });
    setLlmStatus([]);
    setPhase2Progress({ completed: 0, total: 0 });
  }, []);

  const loadChat = useCallback(async (chatId) => {
    setActiveChatId(chatId);
    if (!chatId) {
      clearMessages();
      setChatTitle('');
      return;
    }
    try {
      const res = await fetch(`/api/chats/${chatId}`, {
        headers: { 'Authorization': `Bearer ${token}` },
      });
      if (res.ok) {
        const data = await res.json();
        setChatTitle(data.chat.title || '');
        const restored = (data.messages || []).map(m => ({
          role: m.role,
          content: m.content,
          isError: m.role === 'error',
          streaming: false,
        }));
        setMessages(restored);
      }
    } catch (e) { console.error('Failed to load chat:', e); }
  }, [token, clearMessages]);

  return {
    status,
    messages,
    sendMessage,
    sendMixMessage,
    isExecuting,
    phaseInfo,
    llmStatus,
    phase2Progress,
    // v9.2.0
    activeChatId,
    setActiveChatId,
    chatTitle,
    clearMessages,
    loadChat,
  };
}

========================================
FILE: frontend/public/sw.js
========================================
const CACHE_NAME = 'helix-ai-studio-v9.5.0';
const STATIC_ASSETS = [
  '/',
  '/index.html',
  '/manifest.json',
  '/icon-192.png',
  '/icon-512.png',
];

self.addEventListener('install', (event) => {
  event.waitUntil(
    caches.open(CACHE_NAME).then((cache) => cache.addAll(STATIC_ASSETS))
  );
  self.skipWaiting();
});

self.addEventListener('activate', (event) => {
  event.waitUntil(
    caches.keys().then((keys) =>
      Promise.all(keys.filter(k => k !== CACHE_NAME).map(k => caches.delete(k)))
    )
  );
  self.clients.claim();
});

self.addEventListener('fetch', (event) => {
  // APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨WebSocketã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ãªã„
  if (event.request.url.includes('/api/') || event.request.url.includes('/ws/')) {
    return;
  }
  // Network-firstæˆ¦ç•¥: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å„ªå…ˆã—ã€å¤±æ•—æ™‚ã®ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨
  event.respondWith(
    fetch(event.request)
      .then((response) => {
        // æˆåŠŸã—ãŸã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
        if (response.ok) {
          const clone = response.clone();
          caches.open(CACHE_NAME).then((cache) => cache.put(event.request, clone));
        }
        return response;
      })
      .catch(() => caches.match(event.request))
  );
});

========================================
FILE: config/config.json
========================================
{
  "claude_model_id": "claude-opus-4-6",
  "timeout": 5400,
  "project_dir": "C:\\Users\\tomot\\Desktop\\é–‹ç™ºç’°å¢ƒ\\ç”ŸæˆAIã‚¢ãƒ—ãƒª\\Helix AI Studio",
  "orchestrator_engine": "claude-sonnet-4-5-20250929",
  "model_assignments": {
    "coding": "devstral-2:123b",
    "research": "command-a:latest",
    "reasoning": "gpt-oss:120b",
    "vision": "gemma3:27b",
    "translation": "translategemma:27b"
  },
  "local_agent_tools": {
    "read_file": true,
    "list_dir": true,
    "search_files": true,
    "write_file": true,
    "create_file": true,
    "require_write_confirmation": true
  },
  "web_server": {
    "auto_start": true,
    "port": 8500
  }
}

========================================
FILE: config/app_settings.json
========================================
{
  "version": "8.5.0",
  "general": {
    "dark_mode": true,
    "font_size": 10,
    "auto_save": true,
    "auto_context": true
  },
  "claude": {
    "default_model": "claude-opus-4-6",
    "timeout_minutes": 30,
    "mcp_enabled": true,
    "diff_view_enabled": true,
    "auto_context_enabled": true
  },
  "gemini": {
    "default_model": "gemini-2.5-pro",
    "yolo_mode": false,
    "sandbox_mode": true
  },
  "memory": {
    "auto_save": true,
    "risk_gate_enabled": true,
    "save_threshold": "ä¸­å„ªå…ˆåº¦ä»¥ä¸Š"
  },
  "bible": {
    "auto_discover": true,
    "auto_manage": true,
    "project_root": ""
  },
  "app_manager": {
    "base_directory": "",
    "show_hidden": false
  },
  "information_collection": {
    "folder_path": "data/information",
    "default_time_minutes": 30,
    "chunk_size": 512,
    "chunk_overlap": 64,
    "rag_model": "command-a:111b",
    "auto_rebuild_on_change": false,
    "last_build_timestamp": null,
    "last_plan_id": null
  },
  "rag": {
    "time_limit_minutes": 210,
    "chunk_size": 512,
    "overlap": 64
  }
}
