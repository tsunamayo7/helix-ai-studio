# Helix AI Studio v6.1.0 修正サマリー

**作成日**: 2026-02-05
**バージョン**: 6.0.0 → 6.1.0
**作業者**: Claude Opus 4.5

---

## 修正概要

v6.0.0の5Phase統合アーキテクチャ導入に伴い、不要となったオンデマンドモデル関連のUI・コード・ファイルを削除し、ベンチマークデータに基づいてカテゴリ別ローカルLLMモデルを最適化しました。

---

## 実施内容

### 1. オンデマンドモデル関連の削除

#### 削除ファイル
| ファイルパス | 削除理由 |
|-------------|----------|
| `src/backends/claude_executor.py` | 未使用（どこからもimportされていない） |
| `src/backends/ondemand_manager.py` | 5Phase統合で不要（旧Stage方式用） |
| `src/widgets/ondemand_settings.py` | オンデマンドUI削除に伴い不要 |

#### UIコード削除
**helix_orchestrator_tab.py**:
- オンデマンドモデル設定セクション（約80行）削除
- `_update_config_from_ui()`からオンデマンド設定保存コード削除

#### Import整理
**src/widgets/__init__.py**:
- `OnDemandModelSettings` のimportを削除

---

### 2. カテゴリ別ローカルLLMモデル最適化

ユーザー環境（RTX 5070 Ti 16GB + RTX PRO 6000 96GB = 112GB VRAM）とベンチマークPDFデータに基づき、以下のモデルを推奨設定として選定:

| カテゴリ | 推奨モデル | VRAM | ベンチマーク | 選定理由 |
|---------|------------|------|--------------|---------|
| 検索 | nemotron-3-nano:30b | 24GB | IFBench 71.5% | 1Mコンテキスト、ツール使用最適 |
| レポート | qwen3-next:80b | 50GB | 高効率MoE | 分析・レポート生成向き |
| アーキテクト | qwen3-next:80b | 50GB | 高効率MoE | 設計・推論力 |
| コーディング | devstral-2:123b | 75GB | SWE-bench 72.2% | 最高スコア、PRO 6000向け |

**参照PDF**:
- qwen3-coder.pdf: SWE-bench 69.6%, 19GB, 256K ctx
- nemotron-3-nano.pdf: IFBench 71.5%, 24GB, 1M ctx
- devstral-2.pdf: SWE-bench 72.2%, 75GB, 256K ctx
- qwen3-next.pdf: 高効率MoE, 50GB, 256K ctx

---

### 3. バージョン更新

| ファイル | 変更内容 |
|----------|----------|
| `src/utils/constants.py` | APP_VERSION: "6.0.0" → "6.1.0" |
| `src/widgets/__init__.py` | バージョンコメント: v5.0.0 → v6.1.0 |

---

### 4. PyInstaller設定更新

**HelixAIStudio.spec**:
```python
# 以下のhiddenimportsを削除（コメントアウト）
# 'src.backends.claude_executor'   # v6.1.0: 削除
# 'src.backends.ondemand_manager'  # v6.1.0: 削除
# 'src.widgets.ondemand_settings'  # v6.1.0: 削除
# 'src.tabs.chat_creation_tab'     # v6.0.0: 削除済み
```

---

## 受入条件の確認

| # | 受入条件 | 状態 |
|---|----------|------|
| 1 | オンデマンドモデル設定UIが表示されない | ✅ 確認済（コード削除） |
| 2 | 削除ファイルが存在しない | ✅ 3ファイル削除完了 |
| 3 | カテゴリ別モデル設定にVRAM情報表示 | ✅ コメント追加済 |
| 4 | Pythonインポートテストが全て成功 | ✅ 4テスト成功 |
| 5 | PyInstallerビルドが成功 | ✅ 80.6MB exe生成 |
| 6 | バージョンが6.1.0に更新 | ✅ constants.py更新済 |
| 7 | BIBLEドキュメント作成 | ✅ BIBLE_Helix AI Studio_6.1.0.md |

---

## 動作確認結果

### インポートテスト
```
✅ Version: 6.1.0
✅ Widgets import OK
✅ Backends import OK
✅ Main tab import OK
✅ MainWindow import OK
```

### ビルド結果
```
✅ PyInstaller 6.17.0 ビルド成功
✅ HelixAIStudio.exe: 84,491,180 bytes (約80.6MB)
✅ dist/ および ルートディレクトリにexe配置
```

---

## 差分一覧（git diff相当）

### 削除されたファイル
- `src/backends/claude_executor.py` (全削除)
- `src/backends/ondemand_manager.py` (全削除)
- `src/widgets/ondemand_settings.py` (全削除)

### 変更されたファイル

1. **src/utils/constants.py**
   - L10: `APP_VERSION = "6.0.0"` → `APP_VERSION = "6.1.0"`

2. **src/widgets/__init__.py**
   - L3: `v5.0.0` → `v6.1.0`
   - L12: `from .ondemand_settings import OnDemandModelSettings` 削除
   - L19: `"OnDemandModelSettings",` 削除

3. **src/tabs/helix_orchestrator_tab.py**
   - オンデマンドモデルUI作成セクション削除 (~80行)
   - `_update_config_from_ui()`からオンデマンド設定保存削除 (~8行)
   - カテゴリ別モデル選択にVRAM・ベンチマーク情報コメント追加

4. **HelixAIStudio.spec**
   - hiddenimportsから削除モジュール参照を除去（3エントリ）
   - chat_creation_tabのコメントアウトを更新

### 追加されたファイル
- `BIBLE/BIBLE_Helix AI Studio_6.1.0.md`
- `修正/v6.1.0_修正サマリー.md` (本ファイル)

---

## 注意事項

1. **後方互換性**: オンデマンドモデル設定は完全に削除されました。旧設定ファイルにオンデマンド関連の設定が残っていても無視されます。

2. **VRAM要件**: devstral-2:123b（コーディング用）は75GB VRAMが必要です。VRAMが不足する環境ではqwen3-coder:30b（19GB）を代替として使用してください。

3. **Ollamaモデルプル**: 新しいモデルを使用する前に、Ollamaで以下のコマンドを実行してください:
   ```bash
   ollama pull nemotron-3-nano:30b
   ollama pull qwen3-next:80b
   ollama pull devstral-2:123b
   ollama pull qwen3-coder:30b
   ```

---

*Generated by Claude Opus 4.5 - 2026-02-05*
