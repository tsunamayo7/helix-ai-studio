"""
Helix AI Studio - mixAI Tab (v7.0.0)
3Phaseå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: Claude Code + ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒãƒ¼ãƒ ã«ã‚ˆã‚‹é«˜ç²¾åº¦ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

v7.0.0 "Orchestrated Intelligence": æ—§5Phaseâ†’æ–°3PhaseåŒ–
- Phase 1: Claudeè¨ˆç”»ç«‹æ¡ˆï¼ˆ--cwdã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãã€ãƒ„ãƒ¼ãƒ«ä½¿ç”¨æŒ‡ç¤ºï¼‰
- Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œï¼ˆcoding/research/reasoning/vision/translationï¼‰
- Phase 3: Claudeæ¯”è¼ƒçµ±åˆï¼ˆ2å›ç›®å‘¼ã³å‡ºã—ã€å“è³ªæ¤œè¨¼ãƒ«ãƒ¼ãƒ—ã‚ã‚Šï¼‰
- Neural Flow Visualizerã®3PhaseåŒ–
- è¨­å®šã‚¿ãƒ–ã®ã‚«ãƒ†ã‚´ãƒªåˆ·æ–°ï¼ˆ5ã‚«ãƒ†ã‚´ãƒª + MCPè¨­å®šï¼‰
"""

import json
import logging
import time
import subprocess
import shutil
import os
from typing import Optional, Dict, Any, List

from ..utils.subprocess_utils import run_hidden
from pathlib import Path
from datetime import datetime

from PyQt6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QSplitter,
    QGroupBox, QLabel, QPushButton, QComboBox,
    QTextEdit, QPlainTextEdit, QProgressBar,
    QTableWidget, QTableWidgetItem, QHeaderView,
    QTabWidget, QCheckBox, QSpinBox, QFrame,
    QScrollArea, QFormLayout, QLineEdit, QMessageBox,
    QTreeWidget, QTreeWidgetItem, QSizePolicy, QSlider,
    QFileDialog  # v5.1: ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ç”¨
)
from PyQt6.QtCore import Qt, pyqtSignal, QThread, QTimer, QRect
from PyQt6.QtGui import QFont, QColor, QTextCursor, QPainter, QPen, QBrush, QPainterPath, QKeyEvent

from ..backends.tool_orchestrator import (
    ToolOrchestrator, ToolType, ToolResult,
    OrchestratorConfig, get_tool_orchestrator
)
# v7.0.0: 3Phaseå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
from ..backends.mix_orchestrator import MixAIOrchestrator
# v6.1.1: ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¡¨è¨˜ã®å‹•çš„å–å¾—
# v7.1.0: Claudeãƒ¢ãƒ‡ãƒ«å‹•çš„é¸æŠ
from ..utils.constants import APP_VERSION, CLAUDE_MODELS, DEFAULT_CLAUDE_MODEL_ID
from ..utils.markdown_renderer import markdown_to_html
from ..utils.styles import (
    SECTION_CARD_STYLE, PRIMARY_BTN, SECONDARY_BTN, DANGER_BTN,
    OUTPUT_AREA_STYLE, INPUT_AREA_STYLE, TAB_BAR_STYLE,
    SCROLLBAR_STYLE, COMBO_BOX_STYLE, PROGRESS_BAR_STYLE,
    SPINBOX_STYLE,
)
# Neural Flow Visualizer & VRAM Simulator
from ..widgets.neural_visualizer import NeuralFlowCompactWidget, PhaseState
from ..widgets.vram_simulator import VRAMBudgetSimulator, VRAMCompactWidget
# v8.0.0: BIBLE Manager
from ..widgets.bible_panel import BibleStatusPanel
from ..widgets.bible_notification import BibleNotificationWidget
from ..widgets.chat_widgets import PhaseIndicator, ExecutionIndicator, InterruptionBanner
from ..bible.bible_discovery import BibleDiscovery
from ..bible.bible_injector import BibleInjector
from ..utils.i18n import t

logger = logging.getLogger(__name__)


class NoScrollComboBox(QComboBox):
    """ãƒã‚¦ã‚¹ãƒ›ã‚¤ãƒ¼ãƒ«ã§å€¤ãŒå¤‰ã‚ã‚‰ãªã„QComboBox"""
    def wheelEvent(self, event):
        event.ignore()


# =============================================================================
# v5.1: mixAIç”¨å¼·åŒ–å…¥åŠ›ã‚¯ãƒ©ã‚¹
# =============================================================================

class MixAIEnhancedInput(QPlainTextEdit):
    """
    mixAIç”¨å¼·åŒ–å…¥åŠ›ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ (v5.1.1)

    æ©Ÿèƒ½:
    - ä¸Šä¸‹ã‚­ãƒ¼ã«ã‚ˆã‚‹ã‚«ãƒ¼ã‚½ãƒ«ç§»å‹•
    - å…ˆé ­è¡Œ+ä¸Šã‚­ãƒ¼ -> ãƒ†ã‚­ã‚¹ãƒˆå…ˆé ­ã¸
    - æœ€çµ‚è¡Œ+ä¸‹ã‚­ãƒ¼ -> ãƒ†ã‚­ã‚¹ãƒˆæœ«å°¾ã¸
    - ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‰ãƒ­ãƒƒãƒ—ã‚µãƒãƒ¼ãƒˆ
    - Ctrl+Vã§ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ (v5.1.1)
    """
    file_dropped = pyqtSignal(list)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‰ãƒ­ãƒƒãƒ—æ™‚ã®ã‚·ã‚°ãƒŠãƒ«

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setAcceptDrops(True)

    def keyPressEvent(self, event: QKeyEvent):
        """ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†"""
        key = event.key()
        modifiers = event.modifiers()

        # Ctrl+V: ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ã‚’ãƒã‚§ãƒƒã‚¯ (v5.1.1)
        if key == Qt.Key.Key_V and modifiers == Qt.KeyboardModifier.ControlModifier:
            from PyQt6.QtWidgets import QApplication
            clipboard = QApplication.clipboard()
            mime_data = clipboard.mimeData()

            # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ãƒ•ã‚¡ã‚¤ãƒ«URLãŒã‚ã‚‹å ´åˆ
            if mime_data.hasUrls():
                files = [url.toLocalFile() for url in mime_data.urls()
                         if url.toLocalFile() and os.path.exists(url.toLocalFile())]
                if files:
                    self.file_dropped.emit(files)
                    return  # ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ã—ãŸå ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆè²¼ã‚Šä»˜ã‘ã—ãªã„

            # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ç”»åƒãŒã‚ã‚‹å ´åˆã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            if mime_data.hasImage():
                import tempfile
                from PyQt6.QtGui import QImage
                image = clipboard.image()
                if not image.isNull():
                    temp_dir = tempfile.gettempdir()
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    temp_path = os.path.join(temp_dir, f"clipboard_image_{timestamp}.png")
                    if image.save(temp_path, "PNG"):
                        self.file_dropped.emit([temp_path])
                        return

            # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆè²¼ã‚Šä»˜ã‘
            super().keyPressEvent(event)
            return

        # ä¸Šã‚­ãƒ¼å‡¦ç†: å…ˆé ­è¡Œã«ã„ã‚‹å ´åˆ -> ãƒ†ã‚­ã‚¹ãƒˆå…ˆé ­ã¸
        if key == Qt.Key.Key_Up:
            cursor = self.textCursor()
            cursor_block = cursor.block()
            first_block = self.document().firstBlock()
            if cursor_block == first_block:
                cursor.movePosition(QTextCursor.MoveOperation.Start)
                self.setTextCursor(cursor)
                return
            super().keyPressEvent(event)
            return

        # ä¸‹ã‚­ãƒ¼å‡¦ç†: æœ€çµ‚è¡Œã«ã„ã‚‹å ´åˆ -> ãƒ†ã‚­ã‚¹ãƒˆæœ«å°¾ã¸
        if key == Qt.Key.Key_Down:
            cursor = self.textCursor()
            cursor_block = cursor.block()
            last_block = self.document().lastBlock()
            if cursor_block == last_block:
                cursor.movePosition(QTextCursor.MoveOperation.End)
                self.setTextCursor(cursor)
                return
            super().keyPressEvent(event)
            return

        super().keyPressEvent(event)

    def dragEnterEvent(self, event):
        """ãƒ‰ãƒ©ãƒƒã‚°é€²å…¥ã‚¤ãƒ™ãƒ³ãƒˆ"""
        if event.mimeData().hasUrls():
            event.acceptProposedAction()
        else:
            super().dragEnterEvent(event)

    def dropEvent(self, event):
        """ãƒ‰ãƒ­ãƒƒãƒ—ã‚¤ãƒ™ãƒ³ãƒˆ"""
        if event.mimeData().hasUrls():
            files = [url.toLocalFile() for url in event.mimeData().urls()
                     if url.toLocalFile()]
            if files:
                self.file_dropped.emit(files)
                event.acceptProposedAction()
                return
        super().dropEvent(event)


class MixAIAttachmentWidget(QFrame):
    """mixAIç”¨å€‹åˆ¥æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ"""
    removed = pyqtSignal(str)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    FILE_ICONS = {
        ".py": "ğŸ", ".js": "ğŸ“œ", ".ts": "ğŸ“˜",
        ".html": "ğŸŒ", ".css": "ğŸ¨", ".json": "ğŸ“‹",
        ".md": "ğŸ“", ".txt": "ğŸ“„", ".pdf": "ğŸ“•",
        ".png": "ğŸ–¼ï¸", ".jpg": "ğŸ–¼ï¸", ".jpeg": "ğŸ–¼ï¸",
        ".gif": "ğŸ–¼ï¸", ".svg": "ğŸ–¼ï¸", ".webp": "ğŸ–¼ï¸",
        ".zip": "ğŸ“¦", ".csv": "ğŸ“Š", ".xlsx": "ğŸ“Š",
    }

    def __init__(self, filepath: str, parent=None):
        super().__init__(parent)
        self.filepath = filepath
        self.setFrameStyle(QFrame.Shape.StyledPanel)
        self.setStyleSheet("""
            MixAIAttachmentWidget {
                background-color: #2d3748;
                border: 1px solid #4a5568;
                border-radius: 6px;
                padding: 2px 6px;
            }
            MixAIAttachmentWidget:hover {
                border-color: #63b3ed;
            }
        """)

        layout = QHBoxLayout(self)
        layout.setContentsMargins(4, 2, 4, 2)
        layout.setSpacing(4)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¤ã‚³ãƒ³ + åå‰
        import os
        filename = os.path.basename(filepath)
        ext = os.path.splitext(filename)[1].lower()
        icon = self.FILE_ICONS.get(ext, "ğŸ“")

        icon_label = QLabel(icon)
        name_label = QLabel(filename)
        name_label.setStyleSheet("color: #e2e8f0; font-size: 10px;")
        name_label.setMaximumWidth(150)
        name_label.setToolTip(filepath)

        # Ã—ãƒœã‚¿ãƒ³ (v5.2.0: è¦–èªæ€§å¤§å¹…å‘ä¸Š - å¸¸ã«èµ¤èƒŒæ™¯ã§ç›®ç«‹ãŸã›ã‚‹)
        remove_btn = QPushButton("Ã—")
        remove_btn.setFixedSize(20, 20)
        remove_btn.setToolTip(t('desktop.mixAI.removeAttachTip'))
        remove_btn.setStyleSheet("""
            QPushButton {
                background-color: #e53e3e;
                color: #ffffff;
                border: 2px solid #fc8181;
                border-radius: 10px;
                font-size: 14px;
                font-weight: bold;
                padding: 0px;
            }
            QPushButton:hover {
                background-color: #c53030;
                color: #ffffff;
                border-color: #feb2b2;
            }
            QPushButton:pressed {
                background-color: #9b2c2c;
            }
        """)
        remove_btn.clicked.connect(lambda: self.removed.emit(self.filepath))

        layout.addWidget(icon_label)
        layout.addWidget(name_label)
        layout.addWidget(remove_btn)


class MixAIAttachmentBar(QWidget):
    """mixAIç”¨æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ¼"""
    attachments_changed = pyqtSignal(list)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ

    def __init__(self, parent=None):
        super().__init__(parent)
        import os
        self._files: List[str] = []
        self.setVisible(False)

        layout = QHBoxLayout(self)
        layout.setContentsMargins(4, 4, 4, 4)
        layout.setSpacing(4)

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¨ãƒªã‚¢
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area.setHorizontalScrollBarPolicy(
            Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scroll_area.setVerticalScrollBarPolicy(
            Qt.ScrollBarPolicy.ScrollBarAlwaysOff)
        self.scroll_area.setMaximumHeight(36)
        self.scroll_area.setStyleSheet("border: none; background: transparent;")

        self.container = QWidget()
        self.container_layout = QHBoxLayout(self.container)
        self.container_layout.setContentsMargins(0, 0, 0, 0)
        self.container_layout.setSpacing(4)
        self.container_layout.addStretch()

        self.scroll_area.setWidget(self.container)
        layout.addWidget(self.scroll_area)

    def add_files(self, filepaths: List[str]):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ """
        import os
        for fp in filepaths:
            if fp not in self._files and os.path.exists(fp):
                self._files.append(fp)
                widget = MixAIAttachmentWidget(fp)
                widget.removed.connect(self.remove_file)
                self.container_layout.insertWidget(
                    self.container_layout.count() - 1, widget)

        self.setVisible(bool(self._files))
        self.attachments_changed.emit(self._files.copy())

    def remove_file(self, filepath: str):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
        if filepath in self._files:
            self._files.remove(filepath)
        for i in range(self.container_layout.count()):
            item = self.container_layout.itemAt(i)
            if item and item.widget():
                w = item.widget()
                if isinstance(w, MixAIAttachmentWidget) and w.filepath == filepath:
                    w.deleteLater()
                    break
        self.setVisible(bool(self._files))
        self.attachments_changed.emit(self._files.copy())

    def clear_all(self):
        """å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        self._files.clear()
        while self.container_layout.count() > 1:
            item = self.container_layout.takeAt(0)
            if item.widget():
                item.widget().deleteLater()
        self.setVisible(False)
        self.attachments_changed.emit([])

    def get_files(self) -> List[str]:
        """æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return self._files.copy()


class GPUUsageGraph(QWidget):
    """GPUä½¿ç”¨é‡ã®å‹•çš„ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆï¼ˆæ™‚é–“è»¸é¸æŠãƒ»ã‚·ãƒ¼ã‚¯ãƒãƒ¼å¯¾å¿œï¼‰"""

    # æ™‚é–“ç¯„å›²å®šç¾©ï¼ˆç§’ï¼‰
    TIME_RANGES = {}  # populated dynamically from i18n

    @classmethod
    def init_time_ranges(cls):
        """v9.6.0: i18nã‹ã‚‰æ™‚é–“ç¯„å›²ãƒ©ãƒ™ãƒ«ã‚’åˆæœŸåŒ–"""
        ranges = t('desktop.mixAI.gpuTimeRanges')
        if isinstance(ranges, dict):
            cls.TIME_RANGES = {
                ranges.get('60s', '60s'): 60,
                ranges.get('5m', '5m'): 300,
                ranges.get('15m', '15m'): 900,
                ranges.get('30m', '30m'): 1800,
                ranges.get('1h', '1h'): 3600,
            }
        else:
            cls.TIME_RANGES = {"60s": 60, "5min": 300, "15min": 900, "30min": 1800, "1h": 3600}

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setMinimumHeight(120)
        self.setMaximumHeight(180)

        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ï¼ˆæœ€å¤§3600ã‚µãƒ³ãƒ—ãƒ« = 1æ™‚é–“åˆ†ï¼‰
        self.max_samples = 3600
        self.gpu_data: Dict[int, List[Dict[str, Any]]] = {}  # GPU index -> [{timestamp, vram_used, vram_total, event}]
        self.events: List[Dict[str, Any]] = []  # LLMèµ·å‹•ã‚¤ãƒ™ãƒ³ãƒˆ

        # æ™‚é–“è»¸è¨­å®š
        self.time_range = 60  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60ç§’
        self.view_offset = 0  # ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆç§’ï¼‰: 0 = ç¾åœ¨ã€æ­£ã®å€¤ = éå»

        # è‰²å®šç¾©
        self.gpu_colors = [
            QColor("#22c55e"),  # GPU 0: ç·‘
            QColor("#3b82f6"),  # GPU 1: é’
            QColor("#f59e0b"),  # GPU 2: ã‚ªãƒ¬ãƒ³ã‚¸
            QColor("#ef4444"),  # GPU 3: èµ¤
        ]

    def set_time_range(self, seconds: int):
        """æ™‚é–“ç¯„å›²ã‚’è¨­å®š"""
        self.time_range = seconds
        self.view_offset = 0  # æ™‚é–“ç¯„å›²å¤‰æ›´æ™‚ã¯ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
        self.update()

    def set_view_offset(self, offset_seconds: int):
        """è¡¨ç¤ºã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è¨­å®šï¼ˆã‚·ãƒ¼ã‚¯ãƒãƒ¼ç”¨ï¼‰"""
        self.view_offset = max(0, offset_seconds)
        self.update()

    def get_data_duration(self) -> float:
        """è¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ã®å…¨æœŸé–“ï¼ˆç§’ï¼‰ã‚’å–å¾—"""
        if not self.gpu_data:
            return 0
        all_timestamps = []
        for data_points in self.gpu_data.values():
            if data_points:
                all_timestamps.extend([dp["timestamp"] for dp in data_points])
        if not all_timestamps:
            return 0
        return time.time() - min(all_timestamps)

    def add_data_point(self, gpu_index: int, vram_used_mb: int, vram_total_mb: int, event: str = ""):
        """ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ """
        if gpu_index not in self.gpu_data:
            self.gpu_data[gpu_index] = []

        self.gpu_data[gpu_index].append({
            "timestamp": time.time(),
            "vram_used": vram_used_mb,
            "vram_total": vram_total_mb,
            "event": event,
        })

        # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆ1æ™‚é–“ä»¥ä¸Šå‰ï¼‰
        cutoff = time.time() - 3600
        self.gpu_data[gpu_index] = [dp for dp in self.gpu_data[gpu_index] if dp["timestamp"] > cutoff]

        self.update()

    def add_event(self, event_name: str):
        """LLMèµ·å‹•ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²"""
        self.events.append({
            "timestamp": time.time(),
            "name": event_name,
        })
        # å¤ã„ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‰Šé™¤ï¼ˆ1æ™‚é–“ä»¥ä¸Šå‰ï¼‰
        cutoff = time.time() - 3600
        self.events = [e for e in self.events if e["timestamp"] > cutoff]
        self.update()

    def clear_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"""
        self.gpu_data.clear()
        self.events.clear()
        self.view_offset = 0
        self.update()

    def paintEvent(self, event):
        """ã‚°ãƒ©ãƒ•ã‚’æç”»"""
        painter = QPainter(self)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)

        # èƒŒæ™¯
        painter.fillRect(self.rect(), QColor("#1f2937"))

        # ãƒãƒ¼ã‚¸ãƒ³
        margin_left = 50
        margin_right = 10
        margin_top = 20
        margin_bottom = 25

        graph_width = self.width() - margin_left - margin_right
        graph_height = self.height() - margin_top - margin_bottom

        if graph_width <= 0 or graph_height <= 0:
            return

        # ã‚°ãƒ©ãƒ•é ˜åŸŸã®èƒŒæ™¯
        graph_rect = QRect(margin_left, margin_top, graph_width, graph_height)
        painter.fillRect(graph_rect, QColor("#111827"))

        # è»¸ã‚’æç”»
        pen = QPen(QColor("#4b5563"))
        pen.setWidth(1)
        painter.setPen(pen)

        # Yè»¸
        painter.drawLine(margin_left, margin_top, margin_left, margin_top + graph_height)
        # Xè»¸
        painter.drawLine(margin_left, margin_top + graph_height, margin_left + graph_width, margin_top + graph_height)

        # Yè»¸ãƒ©ãƒ™ãƒ« (0%, 50%, 100%)
        painter.setPen(QColor("#9ca3af"))
        font = painter.font()
        font.setPointSize(8)
        painter.setFont(font)
        painter.drawText(5, margin_top + 5, "100%")
        painter.drawText(5, margin_top + graph_height // 2, "50%")
        painter.drawText(5, margin_top + graph_height, "0%")

        # Xè»¸æ™‚é–“ãƒ©ãƒ™ãƒ«
        time_label_left = f"-{self._format_time(self.time_range + self.view_offset)}"
        time_label_right = f"-{self._format_time(self.view_offset)}" if self.view_offset > 0 else t('desktop.mixAI.gpuNowLabel')
        painter.drawText(margin_left, margin_top + graph_height + 15, time_label_left)
        painter.drawText(margin_left + graph_width - 30, margin_top + graph_height + 15, time_label_right)

        # æ°´å¹³ã‚°ãƒªãƒƒãƒ‰ç·š
        pen.setColor(QColor("#374151"))
        pen.setStyle(Qt.PenStyle.DotLine)
        painter.setPen(pen)
        painter.drawLine(margin_left, margin_top + graph_height // 2, margin_left + graph_width, margin_top + graph_height // 2)

        # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ
        if not self.gpu_data:
            painter.setPen(QColor("#6b7280"))
            painter.drawText(graph_rect, Qt.AlignmentFlag.AlignCenter, t('desktop.mixAI.gpuNoData'))
            return

        # è¡¨ç¤ºç¯„å›²ã‚’è¨ˆç®—ï¼ˆã‚·ãƒ¼ã‚¯ãƒãƒ¼å¯¾å¿œï¼‰
        now = time.time()
        view_end = now - self.view_offset  # è¡¨ç¤ºçµ‚äº†æ™‚åˆ»
        view_start = view_end - self.time_range  # è¡¨ç¤ºé–‹å§‹æ™‚åˆ»

        # å„GPUã®ãƒ‡ãƒ¼ã‚¿ã‚’æç”»
        for gpu_index, data_points in self.gpu_data.items():
            if not data_points:
                continue

            color = self.gpu_colors[gpu_index % len(self.gpu_colors)]
            pen = QPen(color)
            pen.setWidth(2)
            painter.setPen(pen)

            # ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
            path = QPainterPath()
            first_point = True

            for dp in data_points:
                ts = dp["timestamp"]
                # è¡¨ç¤ºç¯„å›²å†…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿æç”»
                if ts < view_start or ts > view_end:
                    continue

                # Xåº§æ¨™: è¡¨ç¤ºç¯„å›²å†…ã§ã®ä½ç½®
                x = margin_left + graph_width * ((ts - view_start) / self.time_range)
                usage_pct = dp["vram_used"] / dp["vram_total"] if dp["vram_total"] > 0 else 0
                y = margin_top + graph_height - (usage_pct * graph_height)

                if first_point:
                    path.moveTo(x, y)
                    first_point = False
                else:
                    path.lineTo(x, y)

            painter.drawPath(path)

        # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ¼ã‚«ãƒ¼ã‚’æç”»
        for evt in self.events:
            ts = evt["timestamp"]
            if ts < view_start or ts > view_end:
                continue

            x = margin_left + graph_width * ((ts - view_start) / self.time_range)
            pen = QPen(QColor("#f59e0b"))
            pen.setWidth(1)
            pen.setStyle(Qt.PenStyle.DashLine)
            painter.setPen(pen)
            painter.drawLine(int(x), margin_top, int(x), margin_top + graph_height)

            # ã‚¤ãƒ™ãƒ³ãƒˆå
            painter.setPen(QColor("#f59e0b"))
            font = painter.font()
            font.setPointSize(7)
            painter.setFont(font)
            painter.drawText(int(x) - 30, margin_top - 3, evt["name"][:15])

        # å‡¡ä¾‹
        legend_x = margin_left + 5
        legend_y = margin_top + 5
        for gpu_index in sorted(self.gpu_data.keys()):
            color = self.gpu_colors[gpu_index % len(self.gpu_colors)]
            painter.fillRect(legend_x, legend_y, 10, 10, color)
            painter.setPen(QColor("#ffffff"))
            font = painter.font()
            font.setPointSize(8)
            painter.setFont(font)
            painter.drawText(legend_x + 15, legend_y + 9, f"GPU {gpu_index}")
            legend_x += 60

    def _format_time(self, seconds: float) -> str:
        """ç§’æ•°ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if seconds < 60:
            return f"{int(seconds)}{t('desktop.mixAI.gpuSecond')}"
        elif seconds < 3600:
            return f"{int(seconds / 60)}{t('desktop.mixAI.gpuMinute')}"
        else:
            return f"{int(seconds / 3600)}{t('desktop.mixAI.gpuHour')}"


class MixAIWorker(QThread):
    """mixAI v7.0.0 å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼ - Claudeä¸»å°å‹ãƒãƒ«ãƒãƒ•ã‚§ãƒ¼ã‚ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    progress = pyqtSignal(str, int)
    tool_executed = pyqtSignal(dict)
    message_chunk = pyqtSignal(str)
    finished = pyqtSignal(str)
    error = pyqtSignal(str)

    def __init__(self, prompt: str, config: OrchestratorConfig, image_path: str = None):
        super().__init__()
        self.prompt = prompt
        self.config = config
        self.image_path = image_path
        self._cancelled = False
        self.orchestrator = None
        self._stage_outputs: List[Dict[str, Any]] = []  # å„ã‚¹ãƒ†ãƒ¼ã‚¸ã®å‡ºåŠ›ã‚’è“„ç©

    def cancel(self):
        self._cancelled = True

    def run(self):
        """ãƒãƒ«ãƒãƒ•ã‚§ãƒ¼ã‚ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ (v7.0.0)"""
        try:
            self.orchestrator = ToolOrchestrator(self.config)
            if not self.orchestrator.initialize():
                self.error.emit(t('desktop.mixAI.ollamaConnFailedFull'))
                return

            # ãƒ•ã‚§ãƒ¼ã‚ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
            self._execute_phase_1_task_analysis()
            if self._cancelled:
                return

            # Phase 2: Claude CLIçµŒç”±ã§å®Ÿéš›ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
            self._execute_phase_2_claude_execution()
            if self._cancelled:
                return

            self._execute_phase_3_image_analysis()
            if self._cancelled:
                return

            self._execute_phase_4_rag_search()
            if self._cancelled:
                return

            self._execute_phase_5_validation_report()

            self.progress.emit("å®Œäº†", 100)

        except Exception as e:
            logger.exception("mixAI Worker error")
            self.error.emit(str(e))

    def _execute_claude_cli(self, prompt: str, timeout_seconds: int = 300) -> Dict[str, Any]:
        """
        Claude CLIã‚’å‘¼ã³å‡ºã—ã¦MCPãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ

        Args:
            prompt: Claudeã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            timeout_seconds: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰

        Returns:
            Dict with 'success', 'output', 'error'
        """
        try:
            # Claude CLIã®å­˜åœ¨ç¢ºèª
            claude_cmd = shutil.which("claude")
            if claude_cmd is None:
                # Windows ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ç¢ºèª
                possible_paths = [
                    os.path.expanduser("~/.claude/local/claude.exe"),
                    os.path.expanduser("~/AppData/Local/Programs/claude/claude.exe"),
                    "claude",
                ]
                for path in possible_paths:
                    if os.path.exists(path):
                        claude_cmd = path
                        break

            if claude_cmd is None:
                return {
                    "success": False,
                    "output": "",
                    "error": "Claude CLIãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Claude Codeã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚",
                }

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«çµŒç”±ã§æ¸¡ã™ï¼ˆé•·ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œï¼‰
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
                f.write(prompt)
                prompt_file = f.name

            try:
                # v5.0.0: Claude CLIå®Ÿè¡Œï¼ˆ--dangerously-skip-permissions ã§è‡ªå‹•è¨±å¯ï¼‰
                result = run_hidden(
                    [claude_cmd, "-p", "--dangerously-skip-permissions", prompt],
                    capture_output=True,
                    text=True,
                    timeout=timeout_seconds,
                    encoding='utf-8',
                    errors='replace',
                )

                if result.returncode == 0:
                    return {
                        "success": True,
                        "output": result.stdout.strip(),
                        "error": "",
                    }
                else:
                    return {
                        "success": False,
                        "output": result.stdout.strip(),
                        "error": result.stderr.strip() or f"Exit code: {result.returncode}",
                    }
            finally:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                try:
                    os.unlink(prompt_file)
                except:
                    pass

        except subprocess.TimeoutExpired:
            return {
                "success": False,
                "output": "",
                "error": f"Claude CLIãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ{timeout_seconds}ç§’ï¼‰",
            }
        except Exception as e:
            return {
                "success": False,
                "output": "",
                "error": f"Claude CLIå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}",
            }

    def _execute_phase_1_task_analysis(self):
        """Phase 1: ã‚¿ã‚¹ã‚¯åˆ†æ"""
        self.progress.emit("Phase 1: ã‚¿ã‚¹ã‚¯åˆ†æä¸­...", 10)

        analysis_prompt = f"""ã€é‡è¦ã€‘å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®å›ç­”ã¯ç¦æ­¢ã§ã™ã€‚

ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’åˆ†æã—ã€å®Ÿè¡Œè¨ˆç”»ã‚’æœ€å¤§6è¡Œã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

ã€ã‚¿ã‚¹ã‚¯ã€‘
{self.prompt}

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
- è¡Œ1-6: è¨­è¨ˆãƒ»ä»®èª¬ãƒ»ãƒ¢ãƒ‡ãƒ«å‰²ã‚Šå½“ã¦ã®è¨ˆç”»

å¿…ãšå…·ä½“çš„ãªã‚¹ãƒ†ãƒƒãƒ—ã¨ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å€™è£œã‚’å«ã‚ã¦ãã ã•ã„ã€‚ã™ã¹ã¦æ—¥æœ¬èªã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚"""

        result = self.orchestrator.execute_tool(
            ToolType.UNIVERSAL_AGENT,
            analysis_prompt,
            thinking_enabled=True,
        )

        # å‡ºåŠ›æœ«å°¾ã«ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•è¿½åŠ 
        model_name = result.metadata.get("model", self.config.universal_agent_model)
        output_with_model = f"{result.output}\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"
        result.output = output_with_model

        self._emit_tool_result(result, "ã‚¿ã‚¹ã‚¯åˆ†æ")
        self._stage_outputs.append({
            "stage": 1,
            "name": "ã‚¿ã‚¹ã‚¯åˆ†æ",
            "output": result.output,
            "model": model_name,
            "success": result.success,
        })
        self.progress.emit("Phase 1 å®Œäº†", 20)

    def _execute_phase_2_claude_execution(self):
        """Phase 2: Claude CLIçµŒç”±ã§å®Ÿéš›ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        self.progress.emit("Phase 2: Claudeå®Ÿè¡Œä¸­...", 30)

        # Phase 1ã®åˆ†æçµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦åˆ©ç”¨
        context = self._stage_outputs[0]["output"] if self._stage_outputs else ""

        # Claude CLIã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆMCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦å®Ÿéš›ã«å®Ÿè¡Œï¼‰
        claude_prompt = f"""ã€é‡è¦ã€‘ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿéš›ã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚è¨ˆç”»ã‚’ç«‹ã¦ã‚‹ã ã‘ã§ãªãã€MCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦å®Ÿéš›ã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„ã€‚

ã€ã‚¿ã‚¹ã‚¯ã€‘
{self.prompt}

ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ã‚ˆã‚‹åˆ†æçµæœã€‘
{context}

ã€å®Ÿè¡ŒæŒ‡ç¤ºã€‘
1. Webæ¤œç´¢ãŒå¿…è¦ãªå ´åˆã¯ã€å®Ÿéš›ã«Webæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦æƒ…å ±ã‚’å–å¾—ã—ã¦ãã ã•ã„
2. ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ãŒå¿…è¦ãªå ´åˆã¯ã€æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«å®Ÿéš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„
3. ã™ã¹ã¦ã®å‡¦ç†ã‚’å®Œäº†ã—ãŸã‚‰ã€å®Ÿè¡Œçµæœã‚’æ—¥æœ¬èªã§å ±å‘Šã—ã¦ãã ã•ã„

å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""

        # Claude CLIã‚’å‘¼ã³å‡ºã—
        start_time = time.time()
        claude_result = self._execute_claude_cli(claude_prompt, timeout_seconds=300)
        execution_time = (time.time() - start_time) * 1000

        if claude_result["success"]:
            output = claude_result["output"]
            model_name = "Claude CLI (MCP)"
            success = True
        else:
            # Claude CLIå¤±æ•—æ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self.progress.emit("Phase 2: ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯...", 35)

            fallback_prompt = f"""ã€é‡è¦ã€‘å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®å›ç­”ã¯ç¦æ­¢ã§ã™ã€‚

ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å‡¦ç†è¨ˆç”»ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
â€»æ³¨æ„: Claude CLIãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã§è¨ˆç”»ã‚’ä½œæˆã—ã¾ã™ã€‚

ã€å…ƒã‚¿ã‚¹ã‚¯ã€‘
{self.prompt}

ã€åˆ†æçµæœã€‘
{context}

ã€Claude CLIã‚¨ãƒ©ãƒ¼ã€‘
{claude_result["error"]}

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
- å®Ÿè¡Œã™ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å…·ä½“çš„ã«è¨˜è¿°
- æ‰‹å‹•ã§å®Ÿè¡Œã™ã‚‹æ‰‹é †ã‚’æ—¥æœ¬èªã§èª¬æ˜"""

            result = self.orchestrator.execute_tool(
                ToolType.CODE_SPECIALIST,
                fallback_prompt,
                context=context,
            )
            output = f"[ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯]\n{result.output}\n\nâ€»Claude CLIã‚¨ãƒ©ãƒ¼: {claude_result['error']}"
            model_name = result.metadata.get("model", self.config.code_specialist_model)
            execution_time = result.execution_time_ms
            success = result.success

        output_with_model = f"{output}\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"

        self.tool_executed.emit({
            "stage": "Claudeå®Ÿè¡Œ",
            "tool_name": "claude_cli",
            "model": model_name,
            "success": success,
            "output": output_with_model[:500] if output_with_model else "",
            "execution_time_ms": execution_time,
            "error": "" if success else claude_result.get("error", ""),
        })

        self._stage_outputs.append({
            "stage": 2,
            "name": "Claudeå®Ÿè¡Œ",
            "output": output_with_model,
            "model": model_name,
            "success": success,
        })
        self.progress.emit("Phase 2 å®Œäº†", 45)

    def _execute_phase_3_image_analysis(self):
        """Phase 3: ç”»åƒè§£æ"""
        self.progress.emit("Phase 3: ç”»åƒè§£æä¸­...", 55)

        # ç”»åƒãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿å®Ÿè¡Œ
        if self.image_path:
            image_prompt = f"""ã€é‡è¦ã€‘å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®å›ç­”ã¯ç¦æ­¢ã§ã™ã€‚

æ·»ä»˜ã•ã‚ŒãŸç”»åƒã‚’è§£æã—ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’JSONå½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºé …ç›®ã€‘
- selected_claude_model: é¸æŠã•ã‚Œã¦ã„ã‚‹Claudeãƒ¢ãƒ‡ãƒ«å
- auth_method: èªè¨¼æ–¹å¼
- thinking_setting: Thinkingè¨­å®š
- ollama_host: Ollamaãƒ›ã‚¹ãƒˆURL
- ollama_connection_status: æ¥ç¶šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
- resident_models: å¸¸é§ãƒ¢ãƒ‡ãƒ«ï¼ˆä¸‡èƒ½Agent/ç”»åƒ/è»½é‡/Embeddingï¼‰ã¨GPUå‰²ã‚Šå½“ã¦
- gpu_monitor: GPUåã€VRAMä½¿ç”¨é‡

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
å¿…ãšæœ‰åŠ¹ãªJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚JSONã®ã‚­ãƒ¼ã¯è‹±èªã€å€¤ã§æ—¥æœ¬èªã‚’å«ã‚€å ´åˆã¯æ—¥æœ¬èªã§è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚"""

            result = self.orchestrator.execute_tool(
                ToolType.IMAGE_ANALYZER,
                image_prompt,
                image_path=self.image_path,
            )

            model_name = result.metadata.get("model", self.config.image_analyzer_model)
            output_with_model = f"{result.output}\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"
            result.output = output_with_model

            self._emit_tool_result(result, "ç”»åƒè§£æ")
            self._stage_outputs.append({
                "stage": 3,
                "name": "ç”»åƒè§£æ",
                "output": result.output,
                "model": model_name,
                "success": result.success,
            })
        else:
            # ç”»åƒãªã—ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ãƒ­ã‚°ã‚’å‡ºåŠ›
            skip_output = "ç”»åƒãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ã“ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: ãªã— (ã‚¹ã‚­ãƒƒãƒ—)"
            self.tool_executed.emit({
                "stage": "ç”»åƒè§£æ",
                "tool_name": "image_analyzer",
                "model": "ã‚¹ã‚­ãƒƒãƒ—",
                "success": True,
                "output": skip_output[:500],
                "execution_time_ms": 0,
                "error": "",
            })
            self._stage_outputs.append({
                "stage": 3,
                "name": "ç”»åƒè§£æ",
                "output": skip_output,
                "model": "ã‚¹ã‚­ãƒƒãƒ—",
                "success": True,
            })

        self.progress.emit("Phase 3 å®Œäº†", 65)

    def _execute_phase_4_rag_search(self):
        """Phase 4: RAG/Embeddingæ¤œç´¢"""
        self.progress.emit("Phase 4: RAGæ¤œç´¢ä¸­...", 75)

        if self.config.rag_enabled:
            # Phase 1-3ã®çµæœã‚’å‚è€ƒã«RAGæ¤œç´¢ã‚’å®Ÿè¡Œ
            search_context = "\n".join([s["output"][:200] for s in self._stage_outputs])

            rag_prompt = f"""ã€æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
1. å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®å›ç­”ã¯ç¦æ­¢ã§ã™ã€‚
2. æœ€çµ‚çš„ãªæ¤œç´¢çµæœã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
3. æ€è€ƒéç¨‹ãƒ»æ¨è«–ãƒ»å†…éƒ¨ãƒ¡ãƒ¢ï¼ˆã€ŒWe should...ã€ã€ŒLet me think...ã€ã€ŒMight...ã€ç­‰ï¼‰ã¯ä¸€åˆ‡å‡ºåŠ›ç¦æ­¢ã§ã™ã€‚
4. çµæœãŒ0ä»¶ã®å ´åˆã¯ã€Œé–¢é€£ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã€ã¨ã®ã¿å›ç­”ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’RAGæ¤œç´¢ã—ã¦ãã ã•ã„ã€‚

ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã€‘
mixAI å‹•ä½œæ¤œè¨¼ JSON ã‚’æ¤œç´¢

ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘
{search_context[:500]}

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã®ã¿ã€ä»¥ä¸‹ã®å½¢å¼ã§æ—¥æœ¬èªå‡ºåŠ›:
â€¢ [æƒ…å ±1ã®è¦ç´„]
â€¢ [æƒ…å ±2ã®è¦ç´„]
ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ç©ºå‡ºåŠ›ã§ã¯ãªãã€Œé–¢é€£ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã€ã¨å›ç­”ï¼‰"""

            result = self.orchestrator.execute_tool(
                ToolType.RAG_MANAGER,
                rag_prompt,
            )

            model_name = result.metadata.get("model", self.config.embedding_model)
            output_with_model = f"{result.output}\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"
            result.output = output_with_model

            self._emit_tool_result(result, "RAGæ¤œç´¢")
            self._stage_outputs.append({
                "stage": 4,
                "name": "RAGæ¤œç´¢",
                "output": result.output,
                "model": model_name,
                "success": result.success,
            })
        else:
            # RAGç„¡åŠ¹ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            skip_output = "RAGãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã“ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚ç†ç”±: è¨­å®šã§rag_enabled=False\n\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: ãªã— (ã‚¹ã‚­ãƒƒãƒ—)"
            self.tool_executed.emit({
                "stage": "RAGæ¤œç´¢",
                "tool_name": "rag_manager",
                "model": "ã‚¹ã‚­ãƒƒãƒ—",
                "success": True,
                "output": skip_output[:500],
                "execution_time_ms": 0,
                "error": "",
            })
            self._stage_outputs.append({
                "stage": 4,
                "name": "RAGæ¤œç´¢",
                "output": skip_output,
                "model": "ã‚¹ã‚­ãƒƒãƒ—",
                "success": True,
            })

        self.progress.emit("Phase 4 å®Œäº†", 85)

    def _execute_phase_5_validation_report(self):
        """Phase 5: æœ€çµ‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ"""
        self.progress.emit("Phase 5: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...", 90)

        # å…¨ã‚¹ãƒ†ãƒ¼ã‚¸ã®çµæœã‚’çµ±åˆ
        stage_summaries = []
        for stage in self._stage_outputs:
            status = "âœ… PASS" if stage["success"] else "âŒ FAIL"
            stage_summaries.append(f"Phase {stage['stage']} ({stage['name']}): {status} - Model: {stage['model']}")

        all_passed = all(s["success"] for s in self._stage_outputs)
        overall_status = "PASS" if all_passed else "FAIL"

        validation_prompt = f"""ã€é‡è¦ã€‘å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®å›ç­”ã¯ç¦æ­¢ã§ã™ã€‚

ä»¥ä¸‹ã®å…¨ã‚¹ãƒ†ãƒ¼ã‚¸çµæœã‚’åŸºã«ã€æœ€çµ‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€ã‚¹ãƒ†ãƒ¼ã‚¸çµæœã‚µãƒãƒªãƒ¼ã€‘
{chr(10).join(stage_summaries)}

ã€å…¨ä½“åˆ¤å®šã€‘
{overall_status}

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
## æœ€çµ‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ

### åˆ¤å®šçµæœ
(PASS/FAIL ã¨ç†ç”±ã‚’æ—¥æœ¬èªã®ç®‡æ¡æ›¸ãã§)

### ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥è©³ç´°
(å„ã‚¹ãƒ†ãƒ¼ã‚¸ã®çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§ã€ã™ã¹ã¦æ—¥æœ¬èª)

### ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ç¢ºèªäº‹é …
(ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚°ã§ç¢ºèªã™ã¹ããƒ¢ãƒ‡ãƒ«åã®ãƒ†ãƒ¼ãƒ–ãƒ«ã€æ—¥æœ¬èªã§è¨˜è¿°)"""

        result = self.orchestrator.execute_tool(
            ToolType.UNIVERSAL_AGENT,
            validation_prompt,
            thinking_enabled=True,
        )

        model_name = result.metadata.get("model", self.config.universal_agent_model)

        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’æ§‹ç¯‰
        final_report = f"""## æœ€çµ‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ

### åˆ¤å®šçµæœ: **{overall_status}**

{result.output}

### ã‚¹ãƒ†ãƒ¼ã‚¸å®Ÿè¡Œãƒ­ã‚°

| Phase | åå‰ | ãƒ¢ãƒ‡ãƒ« | çµæœ |
|-------|------|--------|------|
"""
        for s in self._stage_outputs:
            status_icon = "âœ…" if s["success"] else "âŒ"
            final_report += f"| {s['stage']} | {s['name']} | {s['model']} | {status_icon} |\n"

        final_report += f"\n(è‡ªå·±ç”³å‘Š) ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}"

        result.output = final_report

        self._emit_tool_result(result, "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³")
        self._stage_outputs.append({
            "stage": 5,
            "name": "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³",
            "output": final_report,
            "model": model_name,
            "success": result.success,
        })

        # æœ€çµ‚çµæœã‚’å‡ºåŠ›
        self.finished.emit(self._generate_final_response())

    def _emit_tool_result(self, result: ToolResult, stage: str):
        """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã‚’ã‚·ã‚°ãƒŠãƒ«ã§é€ä¿¡"""
        # metadataã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—
        model_name = result.metadata.get("model", "") if result.metadata else ""
        self.tool_executed.emit({
            "stage": stage,
            "tool_name": result.tool_name,
            "model": model_name,  # ãƒ¢ãƒ‡ãƒ«åã‚’è¿½åŠ 
            "success": result.success,
            "output": result.output[:500] if result.output else "",
            "execution_time_ms": result.execution_time_ms,
            "error": result.error_message,
        })

    def _generate_final_response(self) -> str:
        """æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆï¼ˆv4.4: ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸çµ±åˆï¼‰"""
        if not self._stage_outputs:
            return "ã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã—ã¾ã—ãŸãŒã€å‡ºåŠ›ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

        # å…¨ã‚¹ãƒ†ãƒ¼ã‚¸ã®å‡ºåŠ›ã‚’çµ±åˆ
        sections = []
        for stage in self._stage_outputs:
            section = f"""---

## Phase {stage['stage']}: {stage['name']}

**ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«**: `{stage['model']}`

{stage['output']}
"""
            sections.append(section)

        return "\n".join(sections)


class HelixOrchestratorTab(QWidget):
    """
    mixAI v7.0.0 ã‚¿ãƒ–
    3Phaseå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + Claude Code CLI + ãƒ­ãƒ¼ã‚«ãƒ«LLMé †æ¬¡å®Ÿè¡Œ
    """

    statusChanged = pyqtSignal(str)

    def __init__(self, workflow_state=None, main_window=None):
        super().__init__()
        self.workflow_state = workflow_state
        self.main_window = main_window
        self.worker: Optional[MixAIWorker] = None
        self.config = OrchestratorConfig()

        # v5.0.0: ä¼šè©±å±¥æ­´ï¼ˆãƒŠãƒ¬ãƒƒã‚¸ç®¡ç†ç”¨ï¼‰
        self._conversation_history: List[Dict[str, str]] = []
        self._attached_files: List[str] = []

        # v5.0.0: ãƒŠãƒ¬ãƒƒã‚¸ãƒ¯ãƒ¼ã‚«ãƒ¼
        self._knowledge_worker = None

        # v8.1.0: ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self._memory_manager = None
        try:
            from ..memory.memory_manager import HelixMemoryManager
            self._memory_manager = HelixMemoryManager()
            logger.info("HelixMemoryManager initialized for mixAI")
        except Exception as e:
            logger.warning(f"Memory manager init failed for mixAI: {e}")

        self._load_config()
        self._init_ui()
        self._restore_ui_from_config()

        # v9.5.0: Webå®Ÿè¡Œãƒ­ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
        from ..widgets.web_lock_overlay import WebLockOverlay
        self.web_lock_overlay = WebLockOverlay(self)

    def _restore_ui_from_config(self):
        """v8.4.2: ä¿å­˜æ¸ˆã¿è¨­å®šå€¤ã‚’UIã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã«åæ˜ """
        if hasattr(self, 'max_retries_spin') and hasattr(self.config, 'max_phase2_retries'):
            self.max_retries_spin.setValue(self.config.max_phase2_retries)

    def _get_claude_timeout_sec(self) -> int:
        """v8.4.3: ä¸€èˆ¬è¨­å®šã‚¿ãƒ–ã®Claudeã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã‚’å–å¾—ï¼ˆç§’ï¼‰

        general_settings.json ã® timeout_minutes ã‚’èª­ã¿å–ã‚Šç§’æ•°ã«å¤‰æ›ã—ã¦è¿”ã™ã€‚
        è¨­å®šãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ DefaultSettings.CLAUDE_TIMEOUT_MIN (30åˆ†) ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨ã€‚
        """
        from ..utils.constants import DefaultSettings
        default_min = DefaultSettings.CLAUDE_TIMEOUT_MIN  # 30åˆ†

        # main_windowçµŒç”±ã§ä¸€èˆ¬è¨­å®šã‚¿ãƒ–ã®timeout_spinã‚’ç›´æ¥å‚ç…§
        if self.main_window and hasattr(self.main_window, 'settings_tab'):
            settings_tab = self.main_window.settings_tab
            if hasattr(settings_tab, 'timeout_spin'):
                return settings_tab.timeout_spin.value() * 60

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: general_settings.json ã‹ã‚‰èª­ã¿è¾¼ã¿
        try:
            config_path = Path(__file__).parent.parent.parent / "config" / "general_settings.json"
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                return data.get("timeout_minutes", default_min) * 60
        except Exception as e:
            logger.debug(f"general_settings.json read failed: {e}")

        return default_min * 60

    def _get_config_path(self) -> Path:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—ï¼ˆPyInstallerå¯¾å¿œï¼‰"""
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ›ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ï¼ˆæ°¸ç¶šåŒ–ã®ãŸã‚ï¼‰
        config_dir = Path.home() / ".helix_ai_studio"
        config_dir.mkdir(exist_ok=True)
        return config_dir / "tool_orchestrator.json"

    def _load_config(self):
        """è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        config_path = self._get_config_path()
        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.config = OrchestratorConfig.from_dict(data)
                logger.info(f"[mixAI v5.1] è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {config_path}")
            except Exception as e:
                logger.warning(f"[mixAI v5.1] è¨­å®šèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        else:
            # æ—§ãƒ‘ã‚¹ã‹ã‚‰ã®ç§»è¡Œã‚’è©¦ã¿ã‚‹
            old_config_path = Path(__file__).parent.parent.parent / "config" / "tool_orchestrator.json"
            if old_config_path.exists():
                try:
                    with open(old_config_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        self.config = OrchestratorConfig.from_dict(data)
                    # æ–°ãƒ‘ã‚¹ã«ã‚³ãƒ”ãƒ¼
                    self._save_config()
                    logger.info(f"[mixAI v5.1] æ—§è¨­å®šã‚’æ–°ãƒ‘ã‚¹ã«ç§»è¡Œã—ã¾ã—ãŸ: {config_path}")
                except Exception as e:
                    logger.warning(f"[mixAI v5.1] æ—§è¨­å®šç§»è¡Œå¤±æ•—: {e}")

    def _save_config(self):
        """è¨­å®šã‚’ä¿å­˜"""
        config_path = self._get_config_path()
        config_path.parent.mkdir(exist_ok=True)
        try:
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(self.config.to_dict(), f, indent=2, ensure_ascii=False)
            logger.info(f"[mixAI v5.1] è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ: {config_path}")
        except Exception as e:
            logger.error(f"[mixAI v5.1] è¨­å®šä¿å­˜å¤±æ•—: {e}")

    def _init_ui(self):
        """UIã‚’åˆæœŸåŒ–"""
        layout = QVBoxLayout(self)
        layout.setContentsMargins(10, 10, 10, 10)

        # ã‚µãƒ–ã‚¿ãƒ–ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
        self.sub_tabs = QTabWidget()

        # ãƒãƒ£ãƒƒãƒˆã‚¿ãƒ–
        chat_panel = self._create_chat_panel()
        self.sub_tabs.addTab(chat_panel, t('desktop.mixAI.chatTab'))

        # è¨­å®šã‚¿ãƒ–
        settings_panel = self._create_settings_panel()
        self.sub_tabs.addTab(settings_panel, t('desktop.mixAI.settingsTab'))

        layout.addWidget(self.sub_tabs)

    def retranslateUi(self):
        """Update all translatable text on all widgets (called on language switch)."""

        # === Sub-tabs ===
        self.sub_tabs.setTabText(0, t('desktop.mixAI.chatTab'))
        self.sub_tabs.setTabText(1, t('desktop.mixAI.settingsTab'))

        # === Chat panel ===
        self.chat_title_label.setText(t('desktop.mixAI.title', version=APP_VERSION))
        self.input_text.setPlaceholderText(t('desktop.mixAI.inputPlaceholder'))
        self.execute_btn.setText(t('desktop.mixAI.executeBtn'))
        self.execute_btn.setToolTip(t('desktop.mixAI.executeTip'))
        self.cancel_btn.setText(t('desktop.mixAI.cancelBtn'))
        self.clear_btn.setText(t('desktop.mixAI.clearBtn'))

        # Engine combo (preserve selection)
        self.engine_combo.setToolTip(t('desktop.mixAI.engineTip'))
        engine_idx = self.engine_combo.currentIndex()
        self._engine_options = [
            ("claude-opus-4-6", t('desktop.mixAI.engineOpus46')),
            ("claude-opus-4-5-20250929", t('desktop.mixAI.engineOpus45')),
            ("claude-sonnet-4-5-20250929", t('desktop.mixAI.engineSonnet45')),
        ]
        self._add_ollama_engines()
        self.engine_combo.blockSignals(True)
        self.engine_combo.clear()
        for engine_id, display_name in self._engine_options:
            self.engine_combo.addItem(display_name, engine_id)
        if 0 <= engine_idx < self.engine_combo.count():
            self.engine_combo.setCurrentIndex(engine_idx)
        self.engine_combo.blockSignals(False)

        # Engine type indicator
        current_engine_id = self.engine_combo.currentData()
        if current_engine_id:
            self._update_engine_indicator(current_engine_id)

        # Chat panel buttons
        self.mixai_attach_btn.setText(t('desktop.mixAI.attachBtn'))
        self.mixai_attach_btn.setToolTip(t('desktop.mixAI.attachTip'))
        self.mixai_history_btn.setText(t('desktop.mixAI.historyBtn'))
        self.mixai_history_btn.setToolTip(t('desktop.mixAI.historyTip'))
        self.mixai_snippet_btn.setText(t('desktop.mixAI.snippetBtn'))
        self.mixai_snippet_btn.setToolTip(t('desktop.mixAI.snippetTip'))
        self.mixai_snippet_add_btn.setText(t('desktop.mixAI.snippetAddBtn'))
        self.mixai_snippet_add_btn.setToolTip(t('desktop.mixAI.snippetAddTip'))

        # Neural flow tooltip
        self.neural_flow.setToolTip(t('desktop.mixAI.neuralFlowTip'))

        # Tool log group (state-dependent title)
        if self.tool_log_group.isChecked():
            self.tool_log_group.setTitle(t('desktop.mixAI.toolLogCollapse'))
        else:
            self.tool_log_group.setTitle(t('desktop.mixAI.toolLogExpand'))

        # Tool log tree headers
        self.tool_log_tree.setHeaderLabels(t('desktop.mixAI.toolLogHeaders'))

        # Output placeholder
        self.output_text.setPlaceholderText(t('desktop.mixAI.outputPlaceholder'))

        # === Settings panel ===

        # Claude settings group
        self.claude_group.setTitle(t('desktop.mixAI.claudeSettings'))
        self.claude_model_label.setText(t('desktop.mixAI.modelLabel'))
        self.claude_model_combo.setToolTip(t('desktop.settings.defaultModelTip'))

        # Claude model combo (preserve selection, update display names)
        model_idx = self.claude_model_combo.currentIndex()
        self.claude_model_combo.blockSignals(True)
        for i, model_def in enumerate(CLAUDE_MODELS):
            if i < self.claude_model_combo.count():
                display = t(model_def["i18n_display"]) if "i18n_display" in model_def else model_def["display_name"]
                desc = t(model_def["i18n_desc"]) if "i18n_desc" in model_def else model_def["description"]
                self.claude_model_combo.setItemText(i, display)
                self.claude_model_combo.setItemData(i, desc, Qt.ItemDataRole.ToolTipRole)
        if 0 <= model_idx < self.claude_model_combo.count():
            self.claude_model_combo.setCurrentIndex(model_idx)
        self.claude_model_combo.blockSignals(False)

        self.claude_auth_label.setText(t('desktop.mixAI.authLabel'))

        # Auth mode combo (preserve index)
        auth_idx = self.auth_mode_combo.currentIndex()
        self.auth_mode_combo.blockSignals(True)
        self.auth_mode_combo.clear()
        self.auth_mode_combo.addItems([t('desktop.mixAI.authCli')])
        if 0 <= auth_idx < self.auth_mode_combo.count():
            self.auth_mode_combo.setCurrentIndex(auth_idx)
        self.auth_mode_combo.blockSignals(False)

        self.claude_thinking_label.setText(t('desktop.mixAI.thinkingLabel'))
        self.thinking_combo.setToolTip(t('desktop.mixAI.thinkingTip'))

        # Ollama group
        self.ollama_group.setTitle(t('desktop.mixAI.ollamaGroup'))
        self.ollama_url_label.setText(t('desktop.mixAI.ollamaUrl'))
        self.ollama_test_btn.setText(t('desktop.mixAI.ollamaTest'))
        self.ollama_test_btn.setToolTip(t('desktop.mixAI.ollamaTestTip'))
        self.ollama_status_label.setText(t('desktop.mixAI.ollamaStatus'))

        # Resident models group
        self.always_load_group.setTitle(t('desktop.mixAI.residentGroup'))
        self.control_ai_label.setText(t('desktop.mixAI.controlAi'))
        self.total_vram_label.setText(t('desktop.mixAI.totalVramLabel'))

        # 3Phase group
        self.phase_group.setTitle(t('desktop.mixAI.phaseGroup'))
        self.phase_desc_label.setText(t('desktop.mixAI.phaseDesc'))
        self.engine_note_label.setText(t('desktop.mixAI.engineNote'))
        self.category_label.setText(t('desktop.mixAI.categoryLabel'))
        self.retry_label.setText(t('desktop.mixAI.retryLabel'))
        self.max_retries_label.setText(t('desktop.mixAI.maxRetries'))
        self.max_retries_spin.setToolTip(t('desktop.mixAI.maxRetriesTip'))

        # BIBLE group
        self.bible_group.setTitle(t('desktop.mixAI.bibleGroup'))
        self.bible_group.setToolTip(t('desktop.mixAI.bibleTip'))

        # VRAM group
        self.vram_group.setTitle(t('desktop.mixAI.vramGroup'))
        self.vram_group.setToolTip(t('desktop.mixAI.vramTip'))
        self.vram_desc_label.setText(t('desktop.mixAI.vramDesc'))
        self.open_simulator_btn.setText(t('desktop.mixAI.vramOpenBtn'))

        # GPU group
        self.gpu_group.setTitle(t('desktop.mixAI.gpuGroup'))
        self.gpu_group.setToolTip(t('desktop.mixAI.gpuGroupTip'))
        self.gpu_time_range_label.setText(t('desktop.mixAI.gpuTimeRange'))
        self.gpu_show_past_label.setText(t('desktop.mixAI.gpuShowPast'))
        self.gpu_info_label.setText(t('desktop.mixAI.gpuInfo'))

        # GPU time range combo (preserve selection)
        GPUUsageGraph.init_time_ranges()
        gpu_tr_idx = self.gpu_time_range_combo.currentIndex()
        self.gpu_time_range_combo.blockSignals(True)
        self.gpu_time_range_combo.clear()
        self.gpu_time_range_combo.addItems(list(GPUUsageGraph.TIME_RANGES.keys()))
        if 0 <= gpu_tr_idx < self.gpu_time_range_combo.count():
            self.gpu_time_range_combo.setCurrentIndex(gpu_tr_idx)
        self.gpu_time_range_combo.blockSignals(False)

        self.gpu_seekbar_label.setText(t('desktop.mixAI.gpuNow'))
        self.refresh_gpu_btn.setText(t('desktop.mixAI.gpuRefreshBtn'))
        self.refresh_gpu_btn.setToolTip(t('desktop.mixAI.gpuRefreshTip'))

        # GPU record button (state-dependent)
        if self._gpu_recording:
            self.gpu_record_btn.setText(t('desktop.mixAI.gpuRecordStop'))
        else:
            self.gpu_record_btn.setText(t('desktop.mixAI.gpuRecordStart'))

        self.clear_graph_btn.setText(t('desktop.mixAI.clearBtn2'))
        self.goto_now_btn.setText(t('desktop.mixAI.gpuGotoNow'))
        self.goto_now_btn.setToolTip(t('desktop.mixAI.gpuGotoNowTip'))
        self.gpu_desc_label.setText(t('desktop.mixAI.gpuAutoDesc'))

        # RAG threshold combo (hidden, preserve index)
        rag_idx = self.rag_threshold_combo.currentIndex()
        self.rag_threshold_combo.blockSignals(True)
        self.rag_threshold_combo.clear()
        self.rag_threshold_combo.addItems([
            t('desktop.mixAI.filterLowPlus'),
            t('desktop.mixAI.filterMedPlus'),
            t('desktop.mixAI.filterHighOnly'),
        ])
        if 0 <= rag_idx < self.rag_threshold_combo.count():
            self.rag_threshold_combo.setCurrentIndex(rag_idx)
        self.rag_threshold_combo.blockSignals(False)

        # Save button
        self.save_btn.setText(t('desktop.mixAI.saveBtn'))
        self.save_btn.setToolTip(t('desktop.mixAI.saveTip'))

        # Child widget retranslation
        if hasattr(self, 'neural_flow') and hasattr(self.neural_flow, 'retranslateUi'):
            self.neural_flow.retranslateUi()
        if hasattr(self, 'phase_indicator') and hasattr(self.phase_indicator, 'retranslateUi'):
            self.phase_indicator.retranslateUi()
        if hasattr(self, 'bible_panel') and hasattr(self.bible_panel, 'retranslateUi'):
            self.bible_panel.retranslateUi()

    def _create_chat_panel(self) -> QWidget:
        """ãƒãƒ£ãƒƒãƒˆãƒ‘ãƒãƒ«ã‚’ä½œæˆ (v4.0 æ–°UI)"""
        panel = QWidget()
        layout = QVBoxLayout(panel)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        header_layout = QHBoxLayout()
        self.chat_title_label = QLabel(t('desktop.mixAI.title', version=APP_VERSION))
        self.chat_title_label.setFont(QFont("Segoe UI", 12, QFont.Weight.Bold))
        header_layout.addWidget(self.chat_title_label)

        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒãƒƒã‚¸
        version_badge = QLabel(f"v{APP_VERSION}")
        version_badge.setStyleSheet("""
            QLabel {
                background-color: #f0a030;
                color: white;
                padding: 4px 10px;
                border-radius: 10px;
                font-weight: bold;
                font-size: 10px;
            }
        """)
        header_layout.addWidget(version_badge)
        header_layout.addStretch()
        layout.addLayout(header_layout)

        # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆã‚¹ãƒ—ãƒªãƒƒã‚¿ãƒ¼ï¼‰
        splitter = QSplitter(Qt.Orientation.Vertical)

        # === å…¥åŠ›ã‚¨ãƒªã‚¢ (v5.1: å¼·åŒ–å…¥åŠ› + æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ) ===
        input_widget = QWidget()
        input_layout = QVBoxLayout(input_widget)
        input_layout.setContentsMargins(0, 10, 0, 5)

        # v5.1: æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ¼ï¼ˆå…¥åŠ›æ¬„ã®ä¸Šã«è¡¨ç¤ºï¼‰
        self.attachment_bar = MixAIAttachmentBar()
        self.attachment_bar.attachments_changed.connect(self._on_attachments_changed)
        input_layout.addWidget(self.attachment_bar)

        # v5.1: å¼·åŒ–ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ï¼ˆä¸Šä¸‹ã‚­ãƒ¼å¯¾å¿œã€ãƒ‰ãƒ­ãƒƒãƒ—å¯¾å¿œï¼‰
        self.input_text = MixAIEnhancedInput()
        self.input_text.setPlaceholderText(t('desktop.mixAI.inputPlaceholder'))
        self.input_text.setMaximumHeight(120)
        self.input_text.file_dropped.connect(self.attachment_bar.add_files)
        input_layout.addWidget(self.input_text)

        # ãƒœã‚¿ãƒ³è¡Œ
        btn_layout = QHBoxLayout()

        self.execute_btn = QPushButton(t('desktop.mixAI.executeBtn'))
        self.execute_btn.setStyleSheet(PRIMARY_BTN)
        self.execute_btn.setToolTip(t('desktop.mixAI.executeTip'))
        self.execute_btn.clicked.connect(self._on_execute)
        btn_layout.addWidget(self.execute_btn)

        self.cancel_btn = QPushButton(t('desktop.mixAI.cancelBtn'))
        self.cancel_btn.setStyleSheet(DANGER_BTN)
        self.cancel_btn.setEnabled(False)
        self.cancel_btn.clicked.connect(self._on_cancel)
        btn_layout.addWidget(self.cancel_btn)

        # v9.3.0: P1/P3ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠï¼ˆãƒãƒ£ãƒƒãƒˆãƒ‘ãƒãƒ«å†…ã«é…ç½®ï¼‰
        btn_layout.addWidget(QLabel("  "))  # ã‚¹ãƒšãƒ¼ã‚µãƒ¼
        engine_label_chat = QLabel("P1/P3:")
        engine_label_chat.setStyleSheet("color: #9ca3af; font-size: 11px;")
        btn_layout.addWidget(engine_label_chat)

        self.engine_combo = NoScrollComboBox()
        self.engine_combo.setToolTip(t('desktop.mixAI.engineTip'))
        self.engine_combo.setMinimumWidth(200)
        self._engine_options = [
            ("claude-opus-4-6", t('desktop.mixAI.engineOpus46')),
            ("claude-opus-4-5-20250929", t('desktop.mixAI.engineOpus45')),
            ("claude-sonnet-4-5-20250929", t('desktop.mixAI.engineSonnet45')),
        ]
        self._add_ollama_engines()
        for engine_id, display_name in self._engine_options:
            self.engine_combo.addItem(display_name, engine_id)
        current_engine = self._load_engine_setting()
        idx = self.engine_combo.findData(current_engine)
        if idx >= 0:
            self.engine_combo.setCurrentIndex(idx)
        self.engine_combo.currentIndexChanged.connect(self._on_engine_changed)
        btn_layout.addWidget(self.engine_combo)

        self.engine_type_label = QLabel()
        self._update_engine_indicator(current_engine)
        btn_layout.addWidget(self.engine_type_label)

        # v5.1: soloAIã¨åŒæ§˜ã®ãƒœã‚¿ãƒ³ç¾¤ã‚’è¿½åŠ 
        btn_layout.addWidget(QLabel("  "))  # ã‚¹ãƒšãƒ¼ã‚µãƒ¼

        # ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ãƒœã‚¿ãƒ³
        self.mixai_attach_btn = QPushButton(t('desktop.mixAI.attachBtn'))
        self.mixai_attach_btn.setStyleSheet(SECONDARY_BTN)
        self.mixai_attach_btn.setToolTip(t('desktop.mixAI.attachTip'))
        self.mixai_attach_btn.clicked.connect(self._on_attach_file)
        btn_layout.addWidget(self.mixai_attach_btn)

        # å±¥æ­´ã‹ã‚‰å¼•ç”¨ãƒœã‚¿ãƒ³
        self.mixai_history_btn = QPushButton(t('desktop.mixAI.historyBtn'))
        self.mixai_history_btn.setStyleSheet(SECONDARY_BTN)
        self.mixai_history_btn.setToolTip(t('desktop.mixAI.historyTip'))
        self.mixai_history_btn.clicked.connect(self._on_cite_history)
        btn_layout.addWidget(self.mixai_history_btn)

        # ã‚¹ãƒ‹ãƒšãƒƒãƒˆãƒœã‚¿ãƒ³
        self.mixai_snippet_btn = QPushButton(t('desktop.mixAI.snippetBtn'))
        self.mixai_snippet_btn.setStyleSheet(SECONDARY_BTN)
        self.mixai_snippet_btn.setToolTip(t('desktop.mixAI.snippetTip'))
        self.mixai_snippet_btn.clicked.connect(self._on_snippet_menu)
        btn_layout.addWidget(self.mixai_snippet_btn)

        # è¿½åŠ ãƒœã‚¿ãƒ³ (v5.1.1: å³ã‚¯ãƒªãƒƒã‚¯ã§ç·¨é›†ãƒ»å‰Šé™¤ãƒ¡ãƒ‹ãƒ¥ãƒ¼)
        self.mixai_snippet_add_btn = QPushButton(t('desktop.mixAI.snippetAddBtn'))
        self.mixai_snippet_add_btn.setToolTip(t('desktop.mixAI.snippetAddTip'))
        self.mixai_snippet_add_btn.setMaximumWidth(60)
        self.mixai_snippet_add_btn.clicked.connect(self._on_snippet_add)
        self.mixai_snippet_add_btn.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.mixai_snippet_add_btn.customContextMenuRequested.connect(self._on_snippet_context_menu)
        btn_layout.addWidget(self.mixai_snippet_add_btn)

        btn_layout.addStretch()

        # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        self.clear_btn = QPushButton(t('desktop.mixAI.clearBtn'))
        self.clear_btn.clicked.connect(self._on_clear)
        btn_layout.addWidget(self.clear_btn)

        input_layout.addLayout(btn_layout)
        splitter.addWidget(input_widget)

        # === å‡ºåŠ›ã‚¨ãƒªã‚¢ï¼ˆãƒãƒ£ãƒƒãƒˆå½¢å¼ï¼‰ ===
        output_widget = QWidget()
        output_layout = QVBoxLayout(output_widget)
        output_layout.setContentsMargins(0, 5, 0, 0)

        # v8.0.0: PhaseIndicator - 3Phaseå®Ÿè¡ŒçŠ¶æ…‹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
        self.phase_indicator = PhaseIndicator()
        output_layout.addWidget(self.phase_indicator)

        # v7.0.0: Neural Flow Compact Widget - 3Phaseå¯è¦–åŒ–
        self.neural_flow = NeuralFlowCompactWidget()
        self.neural_flow.setToolTip(t('desktop.mixAI.neuralFlowTip'))
        self.neural_flow.setStyleSheet("""
            NeuralFlowCompactWidget {
                background-color: #1a1a1a;
                border: 1px solid #2d2d2d;
                border-radius: 6px;
            }
        """)
        output_layout.addWidget(self.neural_flow)

        # v8.0.0: BIBLEæ¤œå‡ºé€šçŸ¥ãƒãƒ¼
        self.bible_notification = BibleNotificationWidget()
        self.bible_notification.add_clicked.connect(self._on_bible_add_context)
        output_layout.addWidget(self.bible_notification)

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        self.progress_bar = QProgressBar()
        self.progress_bar.setTextVisible(True)
        self.progress_bar.setFormat("%p% - %v")
        self.progress_bar.setMaximumHeight(20)
        self.progress_bar.setVisible(False)
        output_layout.addWidget(self.progress_bar)

        # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚°ï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰
        self.tool_log_group = QGroupBox(t('desktop.mixAI.toolLogExpand'))
        self.tool_log_group.setCheckable(True)
        self.tool_log_group.setChecked(False)
        self.tool_log_group.toggled.connect(self._on_tool_log_toggled)
        self.tool_log_group.setStyleSheet("""
            QGroupBox {
                border: 1px solid #4b5563;
                border-radius: 4px;
                margin-top: 8px;
                padding-top: 8px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                subcontrol-position: top left;
                padding: 0 5px;
                color: #9ca3af;
            }
        """)

        tool_log_layout = QVBoxLayout()
        self.tool_log_tree = QTreeWidget()
        self.tool_log_tree.setHeaderLabels(t('desktop.mixAI.toolLogHeaders'))
        self.tool_log_tree.setColumnWidth(0, 100)
        self.tool_log_tree.setColumnWidth(1, 180)  # ãƒ¢ãƒ‡ãƒ«åç”¨ã«åºƒã‚
        self.tool_log_tree.setColumnWidth(2, 70)
        self.tool_log_tree.setColumnWidth(3, 80)
        # v5.1: å›ºå®šé«˜ã•ã‚’å‰Šé™¤ã—ã€ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ‹¡å¼µæ™‚ã«è¡¨ç¤ºè¡Œæ•°ãŒå¢—ãˆã‚‹ã‚ˆã†ã«
        self.tool_log_tree.setMinimumHeight(80)
        self.tool_log_tree.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Expanding)
        self.tool_log_tree.setVisible(False)
        tool_log_layout.addWidget(self.tool_log_tree)
        self.tool_log_group.setLayout(tool_log_layout)
        # v5.1: GroupBoxè‡ªä½“ã‚‚Expandingã«è¨­å®š
        self.tool_log_group.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Expanding)
        output_layout.addWidget(self.tool_log_group)

        # å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢
        self.output_text = QTextEdit()
        self.output_text.setReadOnly(True)
        self.output_text.setPlaceholderText(t('desktop.mixAI.outputPlaceholder'))
        self.output_text.setStyleSheet(OUTPUT_AREA_STYLE + SCROLLBAR_STYLE)
        output_layout.addWidget(self.output_text)

        splitter.addWidget(output_widget)
        splitter.setSizes([150, 450])

        layout.addWidget(splitter)

        return panel

    def _create_settings_panel(self) -> QWidget:
        """è¨­å®šãƒ‘ãƒãƒ«ã‚’ä½œæˆ (v4.0 æ–°UI)"""
        panel = QWidget()
        layout = QVBoxLayout(panel)

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¨ãƒªã‚¢
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setStyleSheet(SCROLLBAR_STYLE)
        scroll_content = QWidget()
        scroll_content.setStyleSheet(SECTION_CARD_STYLE + COMBO_BOX_STYLE)
        scroll_layout = QVBoxLayout(scroll_content)

        # === Claudeè¨­å®š ===
        self.claude_group = QGroupBox(t('desktop.mixAI.claudeSettings'))
        claude_layout = QFormLayout()

        # ãƒ¢ãƒ‡ãƒ«é¸æŠ (v7.1.0: CLAUDE_MODELSã‹ã‚‰å‹•çš„ç”Ÿæˆ, v9.6.1: i18nå¯¾å¿œ)
        self.claude_model_combo = NoScrollComboBox()
        self.claude_model_combo.setToolTip(t('desktop.settings.defaultModelTip'))
        default_idx = 0
        for i, model_def in enumerate(CLAUDE_MODELS):
            display = t(model_def["i18n_display"]) if "i18n_display" in model_def else model_def["display_name"]
            desc = t(model_def["i18n_desc"]) if "i18n_desc" in model_def else model_def["description"]
            self.claude_model_combo.addItem(display, userData=model_def["id"])
            self.claude_model_combo.setItemData(i, desc, Qt.ItemDataRole.ToolTipRole)
            if model_def["is_default"]:
                default_idx = i
        # ä¿å­˜æ¸ˆã¿model_idã‹ã‚‰å¾©å…ƒã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        saved_model_id = getattr(self.config, 'claude_model_id', None) or getattr(self.config, 'claude_model', '')
        restored = False
        for i in range(self.claude_model_combo.count()):
            if self.claude_model_combo.itemData(i) == saved_model_id:
                self.claude_model_combo.setCurrentIndex(i)
                restored = True
                break
        if not restored:
            self.claude_model_combo.setCurrentIndex(default_idx)
        self.claude_model_label = QLabel(t('desktop.mixAI.modelLabel'))
        claude_layout.addRow(self.claude_model_label, self.claude_model_combo)

        # v6.0.0: èªè¨¼æ–¹å¼ã¯CLIå°‚ç”¨ï¼ˆAPIå»ƒæ­¢ï¼‰
        self.auth_mode_combo = NoScrollComboBox()
        self.auth_mode_combo.addItems([t('desktop.mixAI.authCli')])
        self.auth_mode_combo.setCurrentIndex(0)
        self.auth_mode_combo.setEnabled(False)  # å¤‰æ›´ä¸å¯
        self.claude_auth_label = QLabel(t('desktop.mixAI.authLabel'))
        claude_layout.addRow(self.claude_auth_label, self.auth_mode_combo)

        # æ€è€ƒãƒ¢ãƒ¼ãƒ‰
        self.thinking_combo = NoScrollComboBox()
        self.thinking_combo.addItems(["OFF", "Standard", "Deep"])
        self.thinking_combo.setToolTip(t('desktop.mixAI.thinkingTip'))
        self._set_combo_value(self.thinking_combo, self.config.thinking_mode)
        self.claude_thinking_label = QLabel(t('desktop.mixAI.thinkingLabel'))
        claude_layout.addRow(self.claude_thinking_label, self.thinking_combo)

        self.claude_group.setLayout(claude_layout)
        scroll_layout.addWidget(self.claude_group)

        # === Ollamaæ¥ç¶šè¨­å®š ===
        self.ollama_group = QGroupBox(t('desktop.mixAI.ollamaGroup'))
        ollama_layout = QVBoxLayout()

        url_layout = QHBoxLayout()
        self.ollama_url_label = QLabel(t('desktop.mixAI.ollamaUrl'))
        url_layout.addWidget(self.ollama_url_label)
        self.ollama_url_edit = QLineEdit(self.config.ollama_url)
        url_layout.addWidget(self.ollama_url_edit)
        self.ollama_test_btn = QPushButton(t('desktop.mixAI.ollamaTest'))
        self.ollama_test_btn.setToolTip(t('desktop.mixAI.ollamaTestTip'))
        self.ollama_test_btn.clicked.connect(self._test_ollama_connection)
        url_layout.addWidget(self.ollama_test_btn)
        ollama_layout.addLayout(url_layout)

        self.ollama_status_label = QLabel(t('desktop.mixAI.ollamaStatus'))
        self.ollama_status_label.setStyleSheet("color: #9ca3af;")
        ollama_layout.addWidget(self.ollama_status_label)

        self.ollama_group.setLayout(ollama_layout)
        scroll_layout.addWidget(self.ollama_group)

        # === v7.0.0: å¸¸é§ãƒ¢ãƒ‡ãƒ«ï¼ˆGPUå‰²ã‚Šå½“ã¦ï¼‰ ===
        self.always_load_group = QGroupBox(t('desktop.mixAI.residentGroup'))
        always_load_layout = QVBoxLayout()

        # åˆ¶å¾¡AI (ministral-3:8b)
        image_row = QHBoxLayout()
        self.control_ai_label = QLabel(t('desktop.mixAI.controlAi'))
        image_row.addWidget(self.control_ai_label)
        self.image_model_combo = NoScrollComboBox()
        self.image_model_combo.setEditable(True)
        self.image_model_combo.addItems([
            "ministral-3:8b",
            "ministral-3:14b",
        ])
        self.image_model_combo.setCurrentText(self.config.image_analyzer_model)
        image_row.addWidget(self.image_model_combo)
        image_gpu = QLabel("â†’ 5070 Ti (6.0GB)")
        image_gpu.setStyleSheet("color: #22c55e; font-size: 10px;")
        image_row.addWidget(image_gpu)
        self.image_status = QLabel("ğŸŸ¢")
        image_row.addWidget(self.image_status)
        image_row.addStretch()
        always_load_layout.addLayout(image_row)

        # Embedding (qwen3-embedding:4b)
        embedding_row = QHBoxLayout()
        embedding_row.addWidget(QLabel("Embedding:"))
        self.embedding_model_combo = NoScrollComboBox()
        self.embedding_model_combo.setEditable(True)
        self.embedding_model_combo.addItems([
            "qwen3-embedding:4b",
            "qwen3-embedding:8b",
            "qwen3-embedding:0.6b",
            "bge-m3:latest",
        ])
        self.embedding_model_combo.setCurrentText(self.config.embedding_model)
        embedding_row.addWidget(self.embedding_model_combo)
        embedding_gpu = QLabel("â†’ 5070 Ti (2.5GB)")
        embedding_gpu.setStyleSheet("color: #22c55e; font-size: 10px;")
        embedding_row.addWidget(embedding_gpu)
        self.embedding_status = QLabel("ğŸŸ¢")
        embedding_row.addWidget(self.embedding_status)
        embedding_row.addStretch()
        always_load_layout.addLayout(embedding_row)

        self.total_vram_label = QLabel(t('desktop.mixAI.totalVramLabel'))
        self.total_vram_label.setStyleSheet("color: #9ca3af; font-size: 10px; margin-top: 5px;")
        always_load_layout.addWidget(self.total_vram_label)

        self.always_load_group.setLayout(always_load_layout)
        scroll_layout.addWidget(self.always_load_group)

        # === v7.0.0: 3Phaseå®Ÿè¡Œè¨­å®š ===
        self.phase_group = QGroupBox(t('desktop.mixAI.phaseGroup'))
        phase_layout = QVBoxLayout()

        self.phase_desc_label = QLabel(t('desktop.mixAI.phaseDesc'))
        self.phase_desc_label.setStyleSheet("color: #9ca3af; font-size: 10px;")
        self.phase_desc_label.setWordWrap(True)
        phase_layout.addWidget(self.phase_desc_label)

        # v9.3.0: P1/P3ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠ â†’ ãƒãƒ£ãƒƒãƒˆã‚¿ãƒ–ã®å®Ÿè¡Œãƒœã‚¿ãƒ³æ¨ªã«ç§»å‹•
        self.engine_note_label = QLabel(t('desktop.mixAI.engineNote'))
        self.engine_note_label.setStyleSheet("color: #6b7280; font-size: 10px; margin-top: 4px;")
        phase_layout.addWidget(self.engine_note_label)

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ‹…å½“ãƒ¢ãƒ‡ãƒ«
        self.category_label = QLabel(t('desktop.mixAI.categoryLabel'))
        self.category_label.setStyleSheet("font-weight: bold; margin-top: 8px;")
        phase_layout.addWidget(self.category_label)

        # coding: ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»ä¿®æ­£ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼
        coding_row = QHBoxLayout()
        coding_row.addWidget(QLabel("coding:"))
        self.coding_model_combo = NoScrollComboBox()
        self.coding_model_combo.setEditable(True)
        self.coding_model_combo.addItems([
            "devstral-2:123b",          # 75GB, SWE-benchæœ€é«˜ (æ¨å¥¨)
            "qwen3-coder-next:80b",     # 50GB, è»½é‡ä»£æ›¿
            "qwen3-coder:30b",
        ])
        self.coding_model_combo.setCurrentText("devstral-2:123b")
        coding_row.addWidget(self.coding_model_combo)
        coding_vram = QLabel("(75GB)")
        coding_vram.setStyleSheet("color: #22c55e; font-size: 10px;")
        coding_row.addWidget(coding_vram)
        coding_row.addStretch()
        phase_layout.addLayout(coding_row)

        # research: èª¿æŸ»ãƒ»RAGæ¤œç´¢ãƒ»æƒ…å ±åé›†
        research_row = QHBoxLayout()
        research_row.addWidget(QLabel("research:"))
        self.research_model_combo = NoScrollComboBox()
        self.research_model_combo.setEditable(True)
        self.research_model_combo.addItems([
            "command-a:latest",          # 67GB, èª¿æŸ»ãƒ»RAGå‘ã (æ¨å¥¨)
            "nemotron-3-nano:30b",      # 24GB, ä»£æ›¿
            "qwen3:30b",
        ])
        self.research_model_combo.setCurrentText("command-a:latest")
        research_row.addWidget(self.research_model_combo)
        research_vram = QLabel("(67GB)")
        research_vram.setStyleSheet("color: #22c55e; font-size: 10px;")
        research_row.addWidget(research_vram)
        research_row.addStretch()
        phase_layout.addLayout(research_row)

        # reasoning: æ¨è«–ãƒ»è«–ç†æ¤œè¨¼ãƒ»å“è³ªãƒã‚§ãƒƒã‚¯
        reasoning_row = QHBoxLayout()
        reasoning_row.addWidget(QLabel("reasoning:"))
        self.reasoning_model_combo = NoScrollComboBox()
        self.reasoning_model_combo.setEditable(True)
        self.reasoning_model_combo.addItems([
            "gpt-oss:120b",            # 80GB, æ¨è«–æœ€å¼· (æ¨å¥¨)
            "phi4-reasoning:14b",       # 9GB, è»½é‡ä»£æ›¿
            "qwen3:30b",
        ])
        self.reasoning_model_combo.setCurrentText("gpt-oss:120b")
        reasoning_row.addWidget(self.reasoning_model_combo)
        reasoning_vram = QLabel("(80GB)")
        reasoning_vram.setStyleSheet("color: #22c55e; font-size: 10px;")
        reasoning_row.addWidget(reasoning_vram)
        reasoning_row.addStretch()
        phase_layout.addLayout(reasoning_row)

        # translation: ç¿»è¨³ã‚¿ã‚¹ã‚¯
        translation_row = QHBoxLayout()
        translation_row.addWidget(QLabel("translation:"))
        self.translation_model_combo = NoScrollComboBox()
        self.translation_model_combo.setEditable(True)
        self.translation_model_combo.addItems([
            "translategemma:27b",       # 18GB, ç¿»è¨³å°‚ç”¨
        ])
        self.translation_model_combo.setCurrentText("translategemma:27b")
        translation_row.addWidget(self.translation_model_combo)
        translation_vram = QLabel("(18GB)")
        translation_vram.setStyleSheet("color: #22c55e; font-size: 10px;")
        translation_row.addWidget(translation_vram)
        translation_row.addStretch()
        phase_layout.addLayout(translation_row)

        # vision: ç”»åƒè§£æãƒ»UIæ¤œè¨¼
        vision_row = QHBoxLayout()
        vision_row.addWidget(QLabel("vision:"))
        self.vision_model_combo = NoScrollComboBox()
        self.vision_model_combo.setEditable(True)
        self.vision_model_combo.addItems([
            "gemma3:27b",               # 18GB, ç”»åƒè§£æ (æ¨å¥¨)
            "mistral-small3.2:24b",     # 15GB, ä»£æ›¿
        ])
        self.vision_model_combo.setCurrentText("gemma3:27b")
        vision_row.addWidget(self.vision_model_combo)
        vision_vram = QLabel("(18GB)")
        vision_vram.setStyleSheet("color: #22c55e; font-size: 10px;")
        vision_row.addWidget(vision_vram)
        vision_row.addStretch()
        phase_layout.addLayout(vision_row)

        # å“è³ªæ¤œè¨¼è¨­å®šï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMå†å®Ÿè¡Œï¼‰
        self.retry_label = QLabel(t('desktop.mixAI.retryLabel'))
        self.retry_label.setStyleSheet("font-weight: bold; margin-top: 8px;")
        phase_layout.addWidget(self.retry_label)

        retry_row = QHBoxLayout()
        self.max_retries_label = QLabel(t('desktop.mixAI.maxRetries'))
        retry_row.addWidget(self.max_retries_label)
        self.max_retries_spin = QSpinBox()
        self.max_retries_spin.setStyleSheet(SPINBOX_STYLE)
        self.max_retries_spin.setRange(0, 3)
        self.max_retries_spin.setValue(2)
        self.max_retries_spin.setToolTip(t('desktop.mixAI.maxRetriesTip'))
        retry_row.addWidget(self.max_retries_spin)
        retry_row.addStretch()
        phase_layout.addLayout(retry_row)

        self.phase_group.setLayout(phase_layout)
        scroll_layout.addWidget(self.phase_group)

        # === v8.0.0: BIBLE Manager ===
        self.bible_group = QGroupBox(t('desktop.mixAI.bibleGroup'))
        self.bible_group.setToolTip(t('desktop.mixAI.bibleTip'))
        bible_layout = QVBoxLayout()
        self.bible_panel = BibleStatusPanel()
        self.bible_panel.create_requested.connect(self._on_bible_create)
        self.bible_panel.update_requested.connect(self._on_bible_update)
        self.bible_panel.detail_requested.connect(self._on_bible_detail)
        self.bible_panel.path_submitted.connect(self._on_bible_path_submitted)
        bible_layout.addWidget(self.bible_panel)
        self.bible_group.setLayout(bible_layout)
        scroll_layout.addWidget(self.bible_group)

        # v8.3.1: èµ·å‹•æ™‚BIBLEè‡ªå‹•æ¤œå‡ºï¼ˆã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰3æ®µéšæ¢ç´¢ï¼‰
        self._auto_discover_bible_on_startup()

        # v8.1.0: MCPè¨­å®šã¯ä¸€èˆ¬è¨­å®šã‚¿ãƒ–ã«çµ±åˆæ¸ˆã¿
        self.mcp_status_label = QLabel("")  # äº’æ›æ€§ç”¨ãƒ€ãƒŸãƒ¼

        # === VRAM Budget Simulator ===
        self.vram_group = QGroupBox(t('desktop.mixAI.vramGroup'))
        self.vram_group.setToolTip(t('desktop.mixAI.vramTip'))
        vram_layout = QVBoxLayout()

        self.vram_desc_label = QLabel(t('desktop.mixAI.vramDesc'))
        self.vram_desc_label.setStyleSheet("color: #9ca3af; font-size: 10px;")
        self.vram_desc_label.setWordWrap(True)
        vram_layout.addWidget(self.vram_desc_label)

        # VRAM Compact Widget
        self.vram_compact = VRAMCompactWidget()
        vram_layout.addWidget(self.vram_compact)

        # VRAM Simulatorã¸ã®ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³
        self.open_simulator_btn = QPushButton(t('desktop.mixAI.vramOpenBtn'))
        self.open_simulator_btn.clicked.connect(self._open_vram_simulator)
        vram_layout.addWidget(self.open_simulator_btn)

        self.vram_group.setLayout(vram_layout)
        scroll_layout.addWidget(self.vram_group)

        # === GPUãƒ¢ãƒ‹ã‚¿ãƒ¼ ===
        self.gpu_group = QGroupBox(t('desktop.mixAI.gpuGroup'))
        self.gpu_group.setToolTip(t('desktop.mixAI.gpuGroupTip'))
        gpu_layout = QVBoxLayout()

        # GPUä½¿ç”¨é‡ã‚°ãƒ©ãƒ•
        self.gpu_graph = GPUUsageGraph()
        gpu_layout.addWidget(self.gpu_graph)

        # æ™‚é–“è»¸é¸æŠè¡Œ
        time_control_layout = QHBoxLayout()
        self.gpu_time_range_label = QLabel(t('desktop.mixAI.gpuTimeRange'))
        time_control_layout.addWidget(self.gpu_time_range_label)
        self.gpu_time_range_combo = NoScrollComboBox()
        GPUUsageGraph.init_time_ranges()  # v9.6.0: i18nã‹ã‚‰æ™‚é–“ç¯„å›²ãƒ©ãƒ™ãƒ«ã‚’åˆæœŸåŒ–
        self.gpu_time_range_combo.addItems(list(GPUUsageGraph.TIME_RANGES.keys()))
        self.gpu_time_range_combo.setCurrentIndex(0)  # v9.6.0: i18nå¯¾å¿œï¼ˆå…ˆé ­=60ç§’/60secï¼‰
        self.gpu_time_range_combo.currentTextChanged.connect(self._on_gpu_time_range_changed)
        time_control_layout.addWidget(self.gpu_time_range_combo)

        time_control_layout.addWidget(QLabel("  "))

        # ã‚·ãƒ¼ã‚¯ãƒãƒ¼ï¼ˆéå»ã®ãƒ‡ãƒ¼ã‚¿å‚ç…§ç”¨ï¼‰
        self.gpu_show_past_label = QLabel(t('desktop.mixAI.gpuShowPast'))
        time_control_layout.addWidget(self.gpu_show_past_label)
        self.gpu_seekbar = QSlider(Qt.Orientation.Horizontal)
        self.gpu_seekbar.setMinimum(0)
        self.gpu_seekbar.setMaximum(0)  # ãƒ‡ãƒ¼ã‚¿ãŒãªã„æ™‚ã¯0
        self.gpu_seekbar.setValue(0)
        self.gpu_seekbar.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.gpu_seekbar.setTickInterval(60)
        self.gpu_seekbar.valueChanged.connect(self._on_gpu_seekbar_changed)
        self.gpu_seekbar.setMinimumWidth(150)
        time_control_layout.addWidget(self.gpu_seekbar)

        self.gpu_seekbar_label = QLabel(t('desktop.mixAI.gpuNow'))
        self.gpu_seekbar_label.setMinimumWidth(50)
        time_control_layout.addWidget(self.gpu_seekbar_label)

        time_control_layout.addStretch()
        gpu_layout.addLayout(time_control_layout)

        # GPUæƒ…å ±ãƒ†ã‚­ã‚¹ãƒˆ
        self.gpu_info_label = QLabel(t('desktop.mixAI.gpuInfo'))
        self.gpu_info_label.setStyleSheet("color: #9ca3af;")
        gpu_layout.addWidget(self.gpu_info_label)

        # ãƒœã‚¿ãƒ³è¡Œ
        gpu_btn_layout = QHBoxLayout()

        # æ›´æ–°ãƒœã‚¿ãƒ³
        self.refresh_gpu_btn = QPushButton(t('desktop.mixAI.gpuRefreshBtn'))
        self.refresh_gpu_btn.setToolTip(t('desktop.mixAI.gpuRefreshTip'))
        self.refresh_gpu_btn.clicked.connect(self._refresh_gpu_info)
        gpu_btn_layout.addWidget(self.refresh_gpu_btn)

        # è¨˜éŒ²é–‹å§‹/åœæ­¢ãƒœã‚¿ãƒ³
        self.gpu_record_btn = QPushButton(t('desktop.mixAI.gpuRecordStart'))
        self.gpu_record_btn.clicked.connect(self._toggle_gpu_recording)
        gpu_btn_layout.addWidget(self.gpu_record_btn)

        # ã‚°ãƒ©ãƒ•ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        self.clear_graph_btn = QPushButton(t('desktop.mixAI.clearBtn2'))
        self.clear_graph_btn.clicked.connect(self._clear_gpu_graph)
        gpu_btn_layout.addWidget(self.clear_graph_btn)

        # ç¾åœ¨ã«æˆ»ã‚‹ãƒœã‚¿ãƒ³
        self.goto_now_btn = QPushButton(t('desktop.mixAI.gpuGotoNow'))
        self.goto_now_btn.clicked.connect(self._on_gpu_goto_now)
        self.goto_now_btn.setToolTip(t('desktop.mixAI.gpuGotoNowTip'))
        gpu_btn_layout.addWidget(self.goto_now_btn)

        gpu_btn_layout.addStretch()
        gpu_layout.addLayout(gpu_btn_layout)

        # èª¬æ˜ãƒ©ãƒ™ãƒ«
        self.gpu_desc_label = QLabel(t('desktop.mixAI.gpuAutoDesc'))
        self.gpu_desc_label.setStyleSheet("color: #6b7280; font-size: 9px;")
        gpu_layout.addWidget(self.gpu_desc_label)

        self.gpu_group.setLayout(gpu_layout)
        scroll_layout.addWidget(self.gpu_group)

        # GPUè¨˜éŒ²ç”¨ã‚¿ã‚¤ãƒãƒ¼
        self._gpu_recording = False
        self._gpu_timer = QTimer()
        self._gpu_timer.timeout.connect(self._record_gpu_usage)

        # v8.1.0: RAGè¨­å®šã¯ä¸€èˆ¬è¨­å®šã‚¿ãƒ–ã€Œè¨˜æ†¶ãƒ»çŸ¥è­˜ç®¡ç†ã€ã«çµ±åˆæ¸ˆã¿
        # äº’æ›æ€§ç”¨ãƒ€ãƒŸãƒ¼ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
        self.rag_enabled_check = QCheckBox()
        self.rag_enabled_check.setChecked(True)
        self.rag_enabled_check.setVisible(False)
        self.rag_auto_save_check = QCheckBox()
        self.rag_auto_save_check.setChecked(True)
        self.rag_auto_save_check.setVisible(False)
        self.rag_threshold_combo = NoScrollComboBox()
        self.rag_threshold_combo.addItems([t('desktop.mixAI.filterLowPlus'), t('desktop.mixAI.filterMedPlus'), t('desktop.mixAI.filterHighOnly')])
        self.rag_threshold_combo.setCurrentIndex(1)
        self.rag_threshold_combo.setVisible(False)

        # === ä¿å­˜ãƒœã‚¿ãƒ³ (v8.4.2: soloAI/ä¸€èˆ¬è¨­å®šã¨çµ±ä¸€ â€” å³å¯„ã›å°å‹) ===
        save_btn_layout = QHBoxLayout()
        save_btn_layout.addStretch()
        self.save_btn = QPushButton(t('desktop.mixAI.saveBtn'))
        self.save_btn.setToolTip(t('desktop.mixAI.saveTip'))
        self.save_btn.clicked.connect(self._on_save_settings)
        save_btn_layout.addWidget(self.save_btn)
        scroll_layout.addLayout(save_btn_layout)

        scroll_layout.addStretch()
        scroll.setWidget(scroll_content)
        layout.addWidget(scroll)

        # GPUæƒ…å ±ã‚’é…å»¶èª­ã¿è¾¼ã¿
        QTimer.singleShot(500, self._refresh_gpu_info)

        return panel

    def _set_combo_value(self, combo: QComboBox, value: str):
        """ComboBoxã®å€¤ã‚’è¨­å®š"""
        for i in range(combo.count()):
            if value.lower() in combo.itemText(i).lower():
                combo.setCurrentIndex(i)
                return
        combo.setCurrentText(value)

    def _set_combo_by_index(self, combo: QComboBox, index: int):
        """ComboBoxã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š"""
        if 0 <= index < combo.count():
            combo.setCurrentIndex(index)

    def _on_tool_log_toggled(self, checked: bool):
        """ãƒ„ãƒ¼ãƒ«ãƒ­ã‚°ã®å±•é–‹/æŠ˜ã‚ŠãŸãŸã¿"""
        self.tool_log_tree.setVisible(checked)
        if checked:
            self.tool_log_group.setTitle(t('desktop.mixAI.toolLogCollapse'))
        else:
            self.tool_log_group.setTitle(t('desktop.mixAI.toolLogExpand'))

    def _on_execute(self):
        """å®Ÿè¡Œé–‹å§‹"""
        # v8.5.0: RAGæ§‹ç¯‰ä¸­ãƒ­ãƒƒã‚¯åˆ¤å®š
        if hasattr(self, 'main_window') and self.main_window:
            rag_lock = getattr(self.main_window, '_rag_lock', None)
            if rag_lock and rag_lock.is_locked:
                QMessageBox.information(
                    self, t('desktop.mixAI.ragBuildingTitle'),
                    t('desktop.mixAI.ragBuildingMsg')
                )
                return

        prompt = self.input_text.toPlainText().strip()
        if not prompt:
            QMessageBox.warning(self, t('desktop.mixAI.inputError'), t('desktop.mixAI.inputRequired'))
            return

        # UIæ›´æ–°
        self.execute_btn.setEnabled(False)
        self.cancel_btn.setEnabled(True)
        self.progress_bar.setVisible(True)
        self.progress_bar.setValue(0)
        self.tool_log_tree.clear()
        self.output_text.clear()

        # v5.0.0: ä¼šè©±å±¥æ­´ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        self._conversation_history.append({
            "role": "user",
            "content": prompt,
        })

        # è¨­å®šã‚’æ›´æ–°
        self._update_config_from_ui()

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ç”»åƒãƒ‘ã‚¹ã‚’æŠ½å‡º (v4.4)
        image_path = self._extract_image_path(prompt)

        # v4.5: GPUè¨˜éŒ²ã‚’è‡ªå‹•é–‹å§‹
        if not self._gpu_recording:
            self._start_gpu_recording()
        self._record_gpu_with_event("å®Ÿè¡Œé–‹å§‹")

        # v7.0.0: æ–°3Phase MixAIOrchestrator ã‚’ä½¿ç”¨
        model_assignments = self._get_model_assignments()
        # v7.1.0: claude_model_id ã‚’å„ªå…ˆä½¿ç”¨
        claude_model_id = getattr(self.config, 'claude_model_id', None) or getattr(self.config, 'claude_model', DEFAULT_CLAUDE_MODEL_ID)
        # v9.3.0: ã‚¨ãƒ³ã‚¸ãƒ³åˆ‡æ›¿
        engine_id = self.engine_combo.currentData() if hasattr(self, 'engine_combo') else claude_model_id
        orchestrator_config = {
            "claude_model": claude_model_id,
            "claude_model_id": claude_model_id,
            "orchestrator_engine": engine_id,
            "timeout": self._get_claude_timeout_sec(),
            "auto_knowledge": True,
            "project_dir": os.getcwd(),
            "max_phase2_retries": self.max_retries_spin.value() if hasattr(self, 'max_retries_spin') else 2,
            "local_agent_tools": self._load_local_agent_tools_config(),
        }
        attached_files = []
        if image_path:
            attached_files.append(image_path)

        # v8.0.0: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ã‚‚BIBLEæ¤œç´¢
        try:
            prompt_bibles = BibleDiscovery.discover_from_prompt(prompt)
            if prompt_bibles and not self.bible_panel.current_bible:
                self.bible_panel.update_bible(prompt_bibles[0])
                logger.info(f"[BIBLE] Discovered from prompt: {prompt_bibles[0].project_name}")
        except Exception as e:
            logger.debug(f"[BIBLE] Prompt discovery error: {e}")

        self.worker = MixAIOrchestrator(
            user_prompt=prompt,
            attached_files=attached_files,
            model_assignments=model_assignments,
            config=orchestrator_config,
        )

        # v8.0.0: BIBLE ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ³¨å…¥
        if self.bible_panel.current_bible:
            self.worker.set_bible_context(self.bible_panel.current_bible)

        # v8.1.0: ãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼æ³¨å…¥
        if hasattr(self, '_memory_manager') and self._memory_manager:
            self.worker.set_memory_manager(self._memory_manager)

        self.worker.phase_changed.connect(self._on_phase_changed)
        self.worker.local_llm_started.connect(self._on_local_llm_started)
        self.worker.local_llm_finished.connect(self._on_local_llm_finished)
        self.worker.phase2_progress.connect(self._on_phase2_progress)
        self.worker.all_finished.connect(self._on_finished)
        self.worker.error_occurred.connect(self._on_error)
        # v8.0.0: BIBLEè‡ªå¾‹ç®¡ç†ã‚·ã‚°ãƒŠãƒ«
        if hasattr(self.worker, 'bible_action_proposed'):
            self.worker.bible_action_proposed.connect(self._on_bible_action_proposed)
        self.worker.start()

        # v7.1.0: é¸æŠãƒ¢ãƒ‡ãƒ«åã‚’ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«è¡¨ç¤º
        model_display = self.claude_model_combo.currentText() if hasattr(self, 'claude_model_combo') else claude_model_id
        self.statusChanged.emit(t('desktop.mixAI.processing3Phase', model=model_display))

    def _extract_image_path(self, prompt: str) -> Optional[str]:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ç”»åƒãƒ‘ã‚¹ã‚’æŠ½å‡º (v4.4)"""
        import re
        import os

        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ãƒ‘ã‚¿ãƒ¼ãƒ³
        image_extensions = r'\.(png|jpg|jpeg|gif|bmp|webp|PNG|JPG|JPEG|GIF|BMP|WEBP)'

        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: å¼•ç”¨ç¬¦ã§å›²ã¾ã‚ŒãŸãƒ‘ã‚¹
        quoted_patterns = [
            r'"([^"]+' + image_extensions + r')"',
            r"'([^']+' + image_extensions + r')",
        ]

        for pattern in quoted_patterns:
            matches = re.findall(pattern, prompt)
            for match in matches:
                if isinstance(match, tuple):
                    path = match[0]
                else:
                    path = match
                if os.path.exists(path):
                    logger.info(f"[mixAI v4.4] ç”»åƒãƒ‘ã‚¹æ¤œå‡º: {path}")
                    return path

        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: Windowsçµ¶å¯¾ãƒ‘ã‚¹ (C:\... or D:\...)
        win_pattern = r'([A-Za-z]:\\[^\s"\'<>|]+' + image_extensions + r')'
        matches = re.findall(win_pattern, prompt)
        for match in matches:
            if os.path.exists(match):
                logger.info(f"[mixAI v4.4] ç”»åƒãƒ‘ã‚¹æ¤œå‡º(Windows): {match}")
                return match

        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: Unixçµ¶å¯¾ãƒ‘ã‚¹ (/home/... or /Users/...)
        unix_pattern = r'(/[^\s"\'<>|]+' + image_extensions + r')'
        matches = re.findall(unix_pattern, prompt)
        for match in matches:
            if os.path.exists(match):
                logger.info(f"[mixAI v4.4] ç”»åƒãƒ‘ã‚¹æ¤œå‡º(Unix): {match}")
                return match

        return None

    def _get_model_assignments(self) -> dict[str, str]:
        """v7.0.0: è¨­å®šUIã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¢ãƒ‡ãƒ«å‰²ã‚Šå½“ã¦ã‚’å–å¾—"""
        assignments = {}
        if hasattr(self, 'coding_model_combo'):
            assignments["coding"] = self.coding_model_combo.currentText()
        if hasattr(self, 'research_model_combo'):
            assignments["research"] = self.research_model_combo.currentText()
        if hasattr(self, 'reasoning_model_combo'):
            assignments["reasoning"] = self.reasoning_model_combo.currentText()
        if hasattr(self, 'translation_model_combo'):
            assignments["translation"] = self.translation_model_combo.currentText()
        if hasattr(self, 'vision_model_combo'):
            assignments["vision"] = self.vision_model_combo.currentText()
        return assignments

    # â•â•â• v9.3.0: P1/P3ã‚¨ãƒ³ã‚¸ãƒ³åˆ‡æ›¿ â•â•â•

    def _add_ollama_engines(self):
        """Ollamaã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ """
        agent_capable = [
            "devstral-2:123b",
            "gpt-oss:120b",
            "command-a:latest",
        ]
        try:
            import httpx
            resp = httpx.get("http://localhost:11434/api/tags", timeout=5)
            if resp.status_code == 200:
                models = resp.json().get("models", [])
                installed = {m["name"] for m in models}
                for model_name in agent_capable:
                    if model_name in installed:
                        size = next((m.get("size", 0) for m in models
                                     if m["name"] == model_name), 0)
                        size_str = f" {size / (1024**3):.0f}GB" if size else ""
                        self._engine_options.append(
                            (model_name, f"{model_name} {t('desktop.mixAI.localSuffix', size=size_str)}")
                        )
        except Exception:
            pass  # Ollamaæœªèµ·å‹•æ™‚ã¯Claudeé¸æŠè‚¢ã®ã¿

    def _on_engine_changed(self, index):
        """ã‚¨ãƒ³ã‚¸ãƒ³å¤‰æ›´æ™‚ã®å‡¦ç†"""
        engine_id = self.engine_combo.currentData()
        if engine_id:
            self._save_engine_setting(engine_id)
            self._update_engine_indicator(engine_id)

    def _update_engine_indicator(self, engine_id: str):
        """ã‚¨ãƒ³ã‚¸ãƒ³ç¨®åˆ¥ãƒ©ãƒ™ãƒ«ã‚’æ›´æ–°"""
        if engine_id.startswith("claude-"):
            self.engine_type_label.setText(t('desktop.mixAI.engineApi'))
            self.engine_type_label.setStyleSheet(
                "color: #06b6d4; font-size: 11px; padding: 2px 6px; "
                "background-color: rgba(6, 182, 212, 0.15); border-radius: 4px;")
        else:
            self.engine_type_label.setText(t('desktop.mixAI.engineLocal'))
            self.engine_type_label.setStyleSheet(
                "color: #10b981; font-size: 11px; padding: 2px 6px; "
                "background-color: rgba(16, 185, 129, 0.15); border-radius: 4px;")

    def _load_engine_setting(self) -> str:
        """config.jsonã‹ã‚‰ã‚¨ãƒ³ã‚¸ãƒ³è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        try:
            config_path = Path("config/config.json")
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                return config.get("orchestrator_engine", "claude-opus-4-6")
        except Exception:
            pass
        return "claude-opus-4-6"

    def _save_engine_setting(self, engine_id: str):
        """config.jsonã«ã‚¨ãƒ³ã‚¸ãƒ³è¨­å®šã‚’ä¿å­˜"""
        try:
            config_path = Path("config/config.json")
            config = {}
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            config["orchestrator_engine"] = engine_id
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Engine setting save failed: {e}")

    def _load_local_agent_tools_config(self) -> dict:
        """config.jsonã‹ã‚‰local_agent_toolsè¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        try:
            config_path = Path("config/config.json")
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                return config.get("local_agent_tools", {})
        except Exception:
            pass
        return {}

    def _on_phase_changed(self, phase_num: int, description: str):
        """v7.0.0: Phaseå¤‰æ›´ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©"""
        percentage = {1: 10, 2: 40, 3: 70}.get(phase_num, 50)
        self.progress_bar.setValue(percentage)
        self.progress_bar.setFormat(f"{percentage}% - {description}")
        self._update_neural_flow_from_progress(description, percentage)
        # v8.0.0: PhaseIndicatoræ›´æ–°
        if hasattr(self, 'phase_indicator'):
            self.phase_indicator.set_active_phase(phase_num - 1)

        # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒ­ã‚°ã«Phaseé–‹å§‹ã‚’è¨˜éŒ²
        phase_item = QTreeWidgetItem(self.tool_log_tree)
        phase_item.setText(0, description)
        phase_item.setText(1, t('desktop.mixAI.phaseRunning'))
        phase_item.setText(2, "")

    def _on_local_llm_started(self, category: str, model: str):
        """v7.0.0: ãƒ­ãƒ¼ã‚«ãƒ«LLMå®Ÿè¡Œé–‹å§‹"""
        self.statusChanged.emit(t('desktop.mixAI.phase2Running', category=category, model=model))

    def _on_local_llm_finished(self, category: str, success: bool, elapsed: float):
        """v7.0.0: ãƒ­ãƒ¼ã‚«ãƒ«LLMå®Ÿè¡Œå®Œäº†"""
        status = t('desktop.mixAI.llmDone') if success else t('desktop.mixAI.llmFailed')
        item = QTreeWidgetItem(self.tool_log_tree)
        item.setText(0, f"  Phase 2: {category}")
        item.setText(1, status)
        item.setText(2, f"{elapsed:.1f}s")

    def _on_phase2_progress(self, completed: int, total: int):
        """v7.0.0: Phase 2é€²æ—"""
        pct = 40 + int((completed / max(total, 1)) * 30)
        self.progress_bar.setValue(pct)
        self.progress_bar.setFormat(t('desktop.mixAI.phase2Progress', pct=pct, completed=completed, total=total))

    def _on_cancel(self):
        """ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        if self.worker:
            self.worker.cancel()
            self.statusChanged.emit(t('desktop.mixAI.cancelled'))

    def _on_clear(self):
        """ã‚¯ãƒªã‚¢"""
        self.output_text.clear()
        self.tool_log_tree.clear()
        self.input_text.clear()
        # v5.1: æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ã‚¯ãƒªã‚¢
        self.attachment_bar.clear_all()
        self._attached_files.clear()
        # Neural Flowã‚’ãƒªã‚»ãƒƒãƒˆ
        if hasattr(self, 'neural_flow'):
            self.neural_flow.reset_all()
        # v8.0.0: PhaseIndicatorãƒªã‚»ãƒƒãƒˆ
        if hasattr(self, 'phase_indicator'):
            self.phase_indicator.reset()

    # =========================================================================
    # v5.1: ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ãƒ»ã‚¹ãƒ‹ãƒšãƒƒãƒˆé–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰
    # =========================================================================

    def _on_attach_file(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯"""
        files, _ = QFileDialog.getOpenFileNames(
            self, t('desktop.mixAI.fileSelectTitle'), "",
            t('desktop.mixAI.fileFilter')
        )
        if files:
            self.attachment_bar.add_files(files)

    def _on_attachments_changed(self, files: List[str]):
        """æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚ŒãŸ"""
        self._attached_files = files.copy()
        logger.info(f"[mixAI v5.1] æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°: {len(files)}ä»¶")

        # v8.0.0: æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰BIBLEè‡ªå‹•æ¤œå‡º
        if files:
            self._discover_bible_from_files(files)

    # =========================================================================
    # v8.0.0: BIBLE Manager ãƒ¡ã‚½ãƒƒãƒ‰
    # =========================================================================

    def _auto_discover_bible_on_startup(self):
        """v8.3.1: èµ·å‹•æ™‚ã«ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰BIBLEè‡ªå‹•æ¤œå‡º"""
        try:
            cwd = os.getcwd()
            logger.info(f"[BIBLE] Startup auto-discovery from: {cwd}")
            bibles = BibleDiscovery.discover(cwd)
            if bibles:
                best = bibles[0]
                self.bible_panel.update_bible(best)
                logger.info(
                    f"[BIBLE] Startup auto-discovered: {best.project_name} "
                    f"v{best.version} at {best.file_path}"
                )
            else:
                logger.info("[BIBLE] Startup auto-discovery: no BIBLE found")
        except Exception as e:
            logger.debug(f"[BIBLE] Startup discovery error: {e}")

    def _on_bible_path_submitted(self, path: str):
        """v8.3.1: ãƒ‘ã‚¹å…¥åŠ›æ¬„ã‹ã‚‰ã®BIBLEæ¤œç´¢"""
        try:
            logger.info(f"[BIBLE] Manual path search: {path}")
            bibles = BibleDiscovery.discover(path)
            if bibles:
                best = bibles[0]
                self.bible_panel.update_bible(best)
                self.bible_notification.show_bible(best)
                logger.info(
                    f"[BIBLE] Found from manual path: {best.project_name} "
                    f"v{best.version}"
                )
            else:
                from PyQt6.QtWidgets import QMessageBox
                QMessageBox.information(
                    self, t('desktop.mixAI.bibleSearchTitle'),
                    t('desktop.mixAI.bibleSearchNotFound', path=path)
                )
                logger.info(f"[BIBLE] No BIBLE found at manual path: {path}")
        except Exception as e:
            logger.error(f"[BIBLE] Manual path discovery error: {e}")

    def _discover_bible_from_files(self, files: List[str]):
        """æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰BIBLEè‡ªå‹•æ¤œå‡º"""
        try:
            for f in files:
                bibles = BibleDiscovery.discover(f)
                if bibles:
                    best = bibles[0]
                    self.bible_panel.update_bible(best)
                    self.bible_notification.show_bible(best)
                    logger.info(
                        f"[BIBLE] Auto-discovered: {best.project_name} "
                        f"v{best.version} from {f}"
                    )
                    return
        except Exception as e:
            logger.debug(f"[BIBLE] Discovery from files error: {e}")

    def _on_bible_add_context(self, bible):
        """é€šçŸ¥ãƒãƒ¼ã®ã€Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ ã€ãƒœã‚¿ãƒ³"""
        self.bible_panel.update_bible(bible)
        logger.info(f"[BIBLE] Context added: {bible.project_name} v{bible.version}")

    def _on_bible_create(self):
        """BIBLEæ–°è¦ä½œæˆ"""
        try:
            from ..bible.bible_lifecycle import BibleLifecycleManager, BibleAction
            project_dir = os.getcwd()
            result = {"changed_files": [], "app_version": APP_VERSION}
            content = BibleLifecycleManager.execute_action(
                BibleAction.CREATE_NEW, None, result, project_dir
            )
            if content:
                from pathlib import Path
                bible_path = Path(project_dir) / "BIBLE.md"
                bible_path.write_text(content, encoding="utf-8")
                # å†æ¤œå‡ºã—ã¦ãƒ‘ãƒãƒ«æ›´æ–°
                bibles = BibleDiscovery.discover(str(bible_path))
                if bibles:
                    self.bible_panel.update_bible(bibles[0])
                logger.info(f"[BIBLE] Created new BIBLE at {bible_path}")
                QMessageBox.information(
                    self, t('desktop.mixAI.bibleCreateDone'),
                    t('desktop.mixAI.bibleCreateMsg', path=str(bible_path))
                )
        except Exception as e:
            logger.error(f"[BIBLE] Create error: {e}")
            QMessageBox.warning(self, t('common.error'), f"BIBLE create failed: {e}")

    def _on_bible_update(self):
        """BIBLEæ›´æ–°"""
        bible = self.bible_panel.current_bible
        if not bible:
            return
        try:
            from ..bible.bible_lifecycle import BibleLifecycleManager, BibleAction
            result = {"changed_files": [], "app_version": APP_VERSION}
            action, reason = BibleLifecycleManager.determine_action(
                bible, result, {}
            )
            if action != BibleAction.NONE:
                content = BibleLifecycleManager.execute_action(
                    action, bible, result, str(bible.file_path.parent)
                )
                if content:
                    bible.file_path.write_text(content, encoding="utf-8")
                    # å†ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ‘ãƒãƒ«æ›´æ–°
                    from ..bible.bible_parser import BibleParser
                    updated = BibleParser.parse_full(bible.file_path)
                    if updated:
                        self.bible_panel.update_bible(updated)
                    logger.info(f"[BIBLE] Updated: {action.value} - {reason}")
            else:
                QMessageBox.information(
                    self, "BIBLE", t('desktop.mixAI.bibleNoUpdate')
                )
        except Exception as e:
            logger.error(f"[BIBLE] Update error: {e}")

    def _on_bible_detail(self):
        """BIBLEè©³ç´°è¡¨ç¤º"""
        bible = self.bible_panel.current_bible
        if not bible:
            return
        missing = bible.missing_required_sections
        missing_str = (
            t('desktop.mixAI.bibleMissingSections', sections=", ".join(s.value for s in missing))
            if missing else t('desktop.mixAI.bibleAllSections')
        )
        sections_str = "\n".join(
            t('desktop.mixAI.bibleSectionItem', title=s.title, type=s.type.value, completeness=f"{s.completeness:.0%}")
            for s in bible.sections
        )
        detail = (
            f"{t('desktop.mixAI.bibleProjectLabel', name=bible.project_name)}\n"
            f"{t('desktop.mixAI.bibleVersionLabel', version=bible.version)}\n"
            f"{t('desktop.mixAI.bibleCodenameLabel', codename=bible.codename or t('desktop.mixAI.bibleCodenameNone'))}\n"
            f"{t('desktop.mixAI.bibleFileLabel', path=bible.file_path)}\n"
            f"{t('desktop.mixAI.bibleLineCount', count=bible.line_count)}\n"
            f"{t('desktop.mixAI.bibleSectionCount', count=len(bible.sections))}\n"
            f"{t('desktop.mixAI.bibleCompletenessScore', score=f'{bible.completeness_score:.0%}')}"
            f"{missing_str}\n\n"
            f"{t('desktop.mixAI.bibleSectionListTitle')}\n{sections_str}"
        )
        QMessageBox.information(self, t('desktop.mixAI.bibleDetailTitle'), detail)

    def _on_bible_action_proposed(self, action, reason):
        """Post-Phase: BIBLEè‡ªå¾‹ç®¡ç†ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ"""
        try:
            from ..bible.bible_lifecycle import BibleAction
            if action == BibleAction.NONE:
                return
            reply = QMessageBox.question(
                self, t('desktop.mixAI.bibleUpdateProposal'),
                t('desktop.mixAI.bibleUpdateConfirm', reason=reason),
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            )
            if reply == QMessageBox.StandardButton.Yes:
                from ..bible.bible_lifecycle import BibleLifecycleManager
                bible = self.bible_panel.current_bible
                result = {"changed_files": [], "app_version": APP_VERSION}
                project_dir = os.getcwd()
                content = BibleLifecycleManager.execute_action(
                    action, bible, result, project_dir
                )
                if content and bible:
                    bible.file_path.write_text(content, encoding="utf-8")
                    from ..bible.bible_parser import BibleParser
                    updated = BibleParser.parse_full(bible.file_path)
                    if updated:
                        self.bible_panel.update_bible(updated)
                    logger.info(f"[BIBLE] Action executed: {action.value}")
        except Exception as e:
            logger.error(f"[BIBLE] Action execution error: {e}")

    def _on_cite_history(self):
        """å±¥æ­´ã‹ã‚‰å¼•ç”¨ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯"""
        try:
            from ..ui.components.history_citation_widget import HistoryCitationDialog
            dialog = HistoryCitationDialog(storage_key="mixai_history", parent=self)
            if dialog.exec():
                citation = dialog.get_selected_citation()
                if citation:
                    current = self.input_text.toPlainText()
                    if current:
                        self.input_text.setPlainText(current + "\n\n" + citation)
                    else:
                        self.input_text.setPlainText(citation)
        except ImportError:
            QMessageBox.information(self, t('desktop.mixAI.historyNotReady'), t('desktop.mixAI.historyNotReadyMsg'))

    def _get_snippet_manager(self):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å–å¾— (v5.1.1: soloAIã¨å…±é€šåŒ–)"""
        from ..claude.snippet_manager import SnippetManager
        from pathlib import Path
        import sys

        # PyInstallerã§ãƒ“ãƒ«ãƒ‰ã•ã‚ŒãŸå ´åˆã¨ãã†ã§ãªã„å ´åˆã§ãƒ‘ã‚¹ã‚’åˆ†å²
        if getattr(sys, 'frozen', False):
            # PyInstallerã§ãƒ“ãƒ«ãƒ‰ã•ã‚ŒãŸå ´åˆ: exeã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
            app_dir = Path(sys.executable).parent
        else:
            # é–‹ç™ºæ™‚: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ä½¿ç”¨
            app_dir = Path(__file__).parent.parent.parent

        data_dir = app_dir / "data"
        unipet_dir = app_dir / "ãƒ¦ãƒ‹ãƒšãƒƒãƒˆ"

        # ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°ä½œæˆ
        data_dir.mkdir(parents=True, exist_ok=True)
        unipet_dir.mkdir(parents=True, exist_ok=True)

        return SnippetManager(data_dir=data_dir, unipet_dir=unipet_dir)

    def _on_snippet_menu(self):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤º (v5.1.1: soloAIã¨å…±é€šåŒ–)"""
        from PyQt6.QtWidgets import QMenu
        from PyQt6.QtCore import QPoint

        try:
            snippet_manager = self._get_snippet_manager()
            snippets = snippet_manager.get_all()

            menu = QMenu(self)

            if not snippets:
                no_snippet_action = menu.addAction(t('desktop.mixAI.noSnippets'))
                no_snippet_action.setEnabled(False)
            else:
                # ã‚«ãƒ†ã‚´ãƒªã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                categories = snippet_manager.get_categories()
                uncategorized = [s for s in snippets if not s.get("category")]

                # ã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚‹ã‚¹ãƒ‹ãƒšãƒƒãƒˆ
                for category in categories:
                    cat_menu = menu.addMenu(f"ğŸ“ {category}")
                    cat_snippets = snippet_manager.get_by_category(category)
                    for snippet in cat_snippets:
                        action = cat_menu.addAction(snippet.get("name", t('desktop.mixAI.untitled')))
                        action.setData(snippet)
                        action.triggered.connect(lambda checked, s=snippet: self._insert_snippet(s))

                # ã‚«ãƒ†ã‚´ãƒªãªã—ã‚¹ãƒ‹ãƒšãƒƒãƒˆ
                if uncategorized:
                    if categories:
                        menu.addSeparator()
                    for snippet in uncategorized:
                        action = menu.addAction(f"ğŸ“‹ {snippet.get('name', t('desktop.mixAI.untitled'))}")
                        action.setData(snippet)
                        action.triggered.connect(lambda checked, s=snippet: self._insert_snippet(s))

            menu.addSeparator()
            open_folder_action = menu.addAction(t('desktop.mixAI.openSnippetFolder'))
            open_folder_action.triggered.connect(lambda: snippet_manager.open_unipet_folder())

            # ãƒœã‚¿ãƒ³ã®ä¸‹ã«è¡¨ç¤º
            btn_pos = self.mixai_snippet_btn.mapToGlobal(QPoint(0, self.mixai_snippet_btn.height()))
            menu.exec(btn_pos)

        except Exception as e:
            logger.error(f"[MixAI._on_snippet_menu] Error: {e}", exc_info=True)
            QMessageBox.warning(self, t('common.error'), t('desktop.mixAI.snippetMenuError', error=e))

    def _insert_snippet(self, snippet: dict):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’å…¥åŠ›æ¬„ã«æŒ¿å…¥ (v5.1.1)"""
        content = snippet.get("content", "")
        name = snippet.get("name", t('desktop.mixAI.untitled'))

        current_text = self.input_text.toPlainText()
        if current_text:
            new_text = f"{current_text}\n\n{content}"
        else:
            new_text = content

        self.input_text.setPlainText(new_text)
        self.statusChanged.emit(t('desktop.mixAI.snippetInserted', name=name))
        logger.info(f"[MixAI] Snippet inserted: {name}")

    def _on_snippet_add(self):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆè¿½åŠ  (v5.1.1: soloAIã¨å…±é€šåŒ–)"""
        from PyQt6.QtWidgets import QDialog, QVBoxLayout, QLineEdit, QTextEdit, QDialogButtonBox

        try:
            dialog = QDialog(self)
            dialog.setWindowTitle(t('desktop.mixAI.snippetAddTitle'))
            dialog.setMinimumWidth(400)
            layout = QVBoxLayout(dialog)

            # åå‰å…¥åŠ›
            name_label = QLabel(t('desktop.mixAI.snippetNameLabel'))
            layout.addWidget(name_label)
            name_input = QLineEdit()
            name_input.setPlaceholderText(t('desktop.mixAI.snippetNamePlaceholder'))
            layout.addWidget(name_input)

            # ã‚«ãƒ†ã‚´ãƒªå…¥åŠ›
            cat_label = QLabel(t('desktop.mixAI.snippetCategoryLabel'))
            layout.addWidget(cat_label)
            cat_input = QLineEdit()
            cat_input.setPlaceholderText(t('desktop.mixAI.snippetCategoryPlaceholder'))
            layout.addWidget(cat_input)

            # å†…å®¹å…¥åŠ›
            content_label = QLabel(t('desktop.mixAI.snippetContentLabel'))
            layout.addWidget(content_label)
            content_input = QTextEdit()
            content_input.setPlaceholderText(t('desktop.mixAI.snippetContentPlaceholder'))
            content_input.setMinimumHeight(150)
            layout.addWidget(content_input)

            # ãƒœã‚¿ãƒ³
            buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
            buttons.accepted.connect(dialog.accept)
            buttons.rejected.connect(dialog.reject)
            layout.addWidget(buttons)

            if dialog.exec() == QDialog.DialogCode.Accepted:
                name = name_input.text().strip()
                content = content_input.toPlainText().strip()

                if not name or not content:
                    QMessageBox.warning(self, t('desktop.mixAI.snippetInputError'), t('desktop.mixAI.snippetInputRequired'))
                    return

                category = cat_input.text().strip()
                snippet_manager = self._get_snippet_manager()
                snippet_manager.add(name=name, content=content, category=category)

                self.statusChanged.emit(t('desktop.mixAI.snippetAdded', name=name))
                logger.info(f"[MixAI] Snippet added: {name}")

        except Exception as e:
            logger.error(f"[MixAI._on_snippet_add] Error: {e}", exc_info=True)
            QMessageBox.warning(self, t('common.error'), t('desktop.mixAI.snippetAddError', error=e))

    def _on_snippet_context_menu(self, pos):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆå³ã‚¯ãƒªãƒƒã‚¯ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆç·¨é›†ãƒ»å‰Šé™¤ï¼‰(v5.2.0: ãƒ¦ãƒ‹ãƒšãƒƒãƒˆå‰Šé™¤å¯¾å¿œ)"""
        from PyQt6.QtWidgets import QMenu

        try:
            snippet_manager = self._get_snippet_manager()
            snippets = snippet_manager.get_all()

            if not snippets:
                return

            menu = QMenu(self)

            # ç·¨é›†ãƒ¡ãƒ‹ãƒ¥ãƒ¼
            edit_menu = menu.addMenu(t('desktop.mixAI.snippetEditMenu'))
            for snippet in snippets:
                action = edit_menu.addAction(snippet.get("name", t('desktop.mixAI.untitled')))
                action.triggered.connect(lambda checked, s=snippet: self._edit_snippet(s))

            # å‰Šé™¤ãƒ¡ãƒ‹ãƒ¥ãƒ¼ (v5.2.0: ãƒ¦ãƒ‹ãƒšãƒƒãƒˆã‚‚å‰Šé™¤å¯èƒ½ã«)
            delete_menu = menu.addMenu(t('desktop.mixAI.snippetDeleteMenu'))
            for snippet in snippets:
                source = snippet.get("source", "json")
                if source == "unipet":
                    action = delete_menu.addAction(f"ğŸ—‚ï¸ {snippet.get('name', t('desktop.mixAI.untitled'))} ({t('desktop.mixAI.snippetFileDelete')})")
                    action.triggered.connect(lambda checked, s=snippet: self._delete_snippet(s))
                else:
                    action = delete_menu.addAction(snippet.get("name", t('desktop.mixAI.untitled')))
                    action.triggered.connect(lambda checked, s=snippet: self._delete_snippet(s))

            menu.addSeparator()
            reload_action = menu.addAction(t('desktop.mixAI.snippetReload'))
            reload_action.triggered.connect(lambda: (self._get_snippet_manager().reload(), self.statusChanged.emit(t('desktop.mixAI.snippetReloaded'))))

            menu.exec(self.mixai_snippet_add_btn.mapToGlobal(pos))

        except Exception as e:
            logger.error(f"[MixAI._on_snippet_context_menu] Error: {e}", exc_info=True)

    def _edit_snippet(self, snippet: dict):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆç·¨é›†ãƒ€ã‚¤ã‚¢ãƒ­ã‚° (v5.1.1)"""
        from PyQt6.QtWidgets import QDialog, QVBoxLayout, QLineEdit, QTextEdit, QDialogButtonBox

        try:
            dialog = QDialog(self)
            dialog.setWindowTitle(t('desktop.mixAI.snippetEditTitle', name=snippet.get('name', t('desktop.mixAI.untitled'))))
            dialog.setMinimumWidth(400)
            layout = QVBoxLayout(dialog)

            # åå‰å…¥åŠ›
            name_label = QLabel(t('desktop.mixAI.snippetNameLabel'))
            layout.addWidget(name_label)
            name_input = QLineEdit(snippet.get("name", ""))
            layout.addWidget(name_input)

            # ã‚«ãƒ†ã‚´ãƒªå…¥åŠ›
            cat_label = QLabel(t('desktop.mixAI.snippetCategoryLabel'))
            layout.addWidget(cat_label)
            cat_input = QLineEdit(snippet.get("category", ""))
            layout.addWidget(cat_input)

            # å†…å®¹å…¥åŠ›
            content_label = QLabel(t('desktop.mixAI.snippetContentLabel'))
            layout.addWidget(content_label)
            content_input = QTextEdit()
            content_input.setPlainText(snippet.get("content", ""))
            content_input.setMinimumHeight(150)
            layout.addWidget(content_input)

            # ãƒœã‚¿ãƒ³
            buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
            buttons.accepted.connect(dialog.accept)
            buttons.rejected.connect(dialog.reject)
            layout.addWidget(buttons)

            if dialog.exec() == QDialog.DialogCode.Accepted:
                snippet_manager = self._get_snippet_manager()
                snippet_manager.update(
                    snippet.get("id"),
                    name=name_input.text().strip(),
                    content=content_input.toPlainText().strip(),
                    category=cat_input.text().strip()
                )
                self.statusChanged.emit(t('desktop.mixAI.snippetUpdated', name=name_input.text()))
                logger.info(f"[MixAI] Snippet updated: {name_input.text()}")

        except Exception as e:
            logger.error(f"[MixAI._edit_snippet] Error: {e}", exc_info=True)
            QMessageBox.warning(self, t('common.error'), t('desktop.mixAI.snippetEditError', error=e))

    def _delete_snippet(self, snippet: dict):
        """ã‚¹ãƒ‹ãƒšãƒƒãƒˆå‰Šé™¤ (v5.2.0: ãƒ¦ãƒ‹ãƒšãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¯¾å¿œ)"""
        name = snippet.get("name", t('desktop.mixAI.untitled'))
        is_unipet = snippet.get("source") == "unipet"

        # ãƒ¦ãƒ‹ãƒšãƒƒãƒˆã®å ´åˆã¯è­¦å‘Šã‚’è¿½åŠ 
        if is_unipet:
            file_path = snippet.get("file_path", "")
            msg = t('desktop.mixAI.snippetDeleteUnipet', name=name, path=file_path)
        else:
            msg = t('desktop.mixAI.snippetDeleteConfirm', name=name)

        reply = QMessageBox.question(
            self,
            t('desktop.mixAI.snippetDeleteTitle'),
            msg,
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.Yes:
            try:
                snippet_manager = self._get_snippet_manager()
                # ãƒ¦ãƒ‹ãƒšãƒƒãƒˆã®å ´åˆã¯delete_file=Trueã‚’æ¸¡ã™
                if snippet_manager.delete(snippet.get("id"), delete_file=is_unipet):
                    self.statusChanged.emit(t('desktop.mixAI.snippetDeleted', name=name))
                    logger.info(f"[MixAI] Snippet deleted: {name}")
                else:
                    QMessageBox.warning(self, t('desktop.mixAI.snippetDeleteFailed'), t('desktop.mixAI.snippetDeleteFailedMsg', name=name))
            except Exception as e:
                logger.error(f"[MixAI._delete_snippet] Error: {e}", exc_info=True)
                QMessageBox.warning(self, t('common.error'), t('desktop.mixAI.snippetDeleteError', error=e))

    def _on_progress(self, message: str, percentage: int):
        """é€²æ—æ›´æ–°"""
        self.progress_bar.setValue(percentage)
        self.progress_bar.setFormat(f"{percentage}% - {message}")

        # Neural Flow Visualizerã®çŠ¶æ…‹æ›´æ–°
        self._update_neural_flow_from_progress(message, percentage)

    def _update_neural_flow_from_progress(self, message: str, percentage: int):
        """v7.0.0: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰Neural Flowã®çŠ¶æ…‹ã‚’æ›´æ–°ï¼ˆ3Phaseå¯¾å¿œï¼‰"""
        if not hasattr(self, 'neural_flow'):
            return

        # v7.0.0: 3Phase ãƒãƒƒãƒ”ãƒ³ã‚°
        stage_to_phase = {
            "phase 1": 1, "claudeè¨ˆç”»": 1, "è¨ˆç”»ç«‹æ¡ˆ": 1,
            "phase 2": 2, "ãƒ­ãƒ¼ã‚«ãƒ«llm": 2, "é †æ¬¡å®Ÿè¡Œ": 2, "å†å®Ÿè¡Œ": 2,
            "phase 3": 3, "claudeçµ±åˆ": 3, "æ¯”è¼ƒçµ±åˆ": 3, "å†çµ±åˆ": 3,
            "å®Œäº†": 3,
        }

        msg_lower = message.lower()

        for key, phase_id in stage_to_phase.items():
            if key in msg_lower:
                if "å®Œäº†" in message or percentage >= 100:
                    self.neural_flow.set_phase_state(phase_id, PhaseState.COMPLETED)
                elif "ä¸­" in message or "å®Ÿè¡Œ" in message or "é–‹å§‹" in message:
                    # å‰ã®Phaseã‚’å®Œäº†çŠ¶æ…‹ã«
                    for prev_phase in range(1, phase_id):
                        self.neural_flow.set_phase_state(prev_phase, PhaseState.COMPLETED)
                    self.neural_flow.set_phase_state(phase_id, PhaseState.RUNNING)
                break

    def _on_tool_executed(self, result: dict):
        """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå®Œäº†"""
        # v4.5: GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²ï¼ˆ5ç§’å¾Œã«ã‚‚è¨˜éŒ²ï¼‰
        stage_name = result.get("stage", "Tool")
        model_name_full = result.get("model", "")
        self._schedule_gpu_record_after_llm(stage_name)

        # ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—ï¼ˆé•·ã„å ´åˆã¯çŸ­ç¸®è¡¨ç¤ºï¼‰
        model_name = model_name_full
        if len(model_name) > 25:
            model_name = model_name[:22] + "..."

        output_text = result.get("output", "")
        output_display = output_text[:40] + "..." if len(output_text) > 40 else output_text

        item = QTreeWidgetItem([
            result.get("stage", ""),
            model_name,  # ãƒ¢ãƒ‡ãƒ«ååˆ—ã‚’è¿½åŠ 
            "âœ…" if result.get("success") else "âŒ",
            f"{result.get('execution_time_ms', 0):.0f}ms",
            output_display,
        ])

        if result.get("success"):
            item.setForeground(2, QColor("#22c55e"))  # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°
        else:
            item.setForeground(2, QColor("#ef4444"))

        # ãƒ¢ãƒ‡ãƒ«ååˆ—ã«è‰²ã‚’ä»˜ã‘ã‚‹ï¼ˆè­˜åˆ¥ã—ã‚„ã™ãã™ã‚‹ãŸã‚ï¼‰
        item.setForeground(1, QColor("#60a5fa"))  # é’ç³»

        self.tool_log_tree.addTopLevelItem(item)

    def _on_finished(self, result: str):
        """å®Œäº†"""
        self.execute_btn.setEnabled(True)
        self.cancel_btn.setEnabled(False)
        self.progress_bar.setVisible(False)

        # v7.0.0: Neural Flow - å…¨Phaseå®Œäº†ï¼ˆ3Phaseï¼‰
        if hasattr(self, 'neural_flow'):
            for phase_id in range(1, 4):
                self.neural_flow.set_phase_state(phase_id, PhaseState.COMPLETED)
        # v8.0.0: PhaseIndicatorå…¨å®Œäº†
        if hasattr(self, 'phase_indicator'):
            self.phase_indicator.set_all_completed()

        # çµæœã‚’è¡¨ç¤ºï¼ˆMarkdownâ†’HTMLãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼‰
        self.output_text.setHtml(markdown_to_html(result))
        self.statusChanged.emit(t('desktop.mixAI.completed'))
        self.worker = None

        # v5.0.0: ä¼šè©±å±¥æ­´ã«AIå¿œç­”ã‚’è¿½åŠ 
        self._conversation_history.append({
            "role": "assistant",
            "content": result,
        })

        # v5.0.0: è‡ªå‹•ãƒŠãƒ¬ãƒƒã‚¸ç®¡ç†ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œï¼‰
        self._start_knowledge_processing()

    def _on_error(self, error: str):
        """ã‚¨ãƒ©ãƒ¼"""
        self.execute_btn.setEnabled(True)
        self.cancel_btn.setEnabled(False)
        self.progress_bar.setVisible(False)

        # v7.0.0: Neural Flow - ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹è¡¨ç¤ºï¼ˆ3Phaseï¼‰
        if hasattr(self, 'neural_flow'):
            # ç¾åœ¨å®Ÿè¡Œä¸­ã®Phaseã‚’å¤±æ•—çŠ¶æ…‹ã«
            for phase_id in range(1, 4):
                from ..widgets.neural_visualizer import PhaseState
                state = self.neural_flow._phase_states.get(phase_id, PhaseState.IDLE)
                if state == PhaseState.RUNNING:
                    self.neural_flow.set_phase_state(phase_id, PhaseState.FAILED)
                    break

        self.output_text.setPlainText(t('desktop.mixAI.errorPrefix', error=error))
        self.statusChanged.emit(t('desktop.mixAI.errorStatus', error=error[:50]))
        self.worker = None

    # =========================================================================
    # v5.0.0: è‡ªå‹•ãƒŠãƒ¬ãƒƒã‚¸ç®¡ç†
    # =========================================================================

    def _start_knowledge_processing(self):
        """v5.0.0: è‡ªå‹•ãƒŠãƒ¬ãƒƒã‚¸å‡¦ç†ã‚’é–‹å§‹ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰"""
        if not self._conversation_history:
            return

        try:
            from ..knowledge import KnowledgeWorker, get_knowledge_manager

            km = get_knowledge_manager()
            self._knowledge_worker = KnowledgeWorker(
                conversation=self._conversation_history.copy(),
                knowledge_manager=km,
            )
            self._knowledge_worker.completed.connect(self._on_knowledge_saved)
            self._knowledge_worker.error.connect(self._on_knowledge_error)
            self._knowledge_worker.start()

            logger.info("[mixAI v5.0] ãƒŠãƒ¬ãƒƒã‚¸å‡¦ç†ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§é–‹å§‹")

        except ImportError as e:
            logger.warning(f"[mixAI v5.0] ãƒŠãƒ¬ãƒƒã‚¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")
        except Exception as e:
            logger.warning(f"[mixAI v5.0] ãƒŠãƒ¬ãƒƒã‚¸å‡¦ç†é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")

    def _on_knowledge_saved(self, knowledge: dict):
        """v5.0.0: ãƒŠãƒ¬ãƒƒã‚¸ä¿å­˜å®Œäº†"""
        topic = knowledge.get("topic", t('desktop.mixAI.knowledgeUnknown'))
        models_used = knowledge.get("ondemand_models_used", [])
        model_info = t('desktop.mixAI.knowledgeVerify', models=', '.join(models_used)) if models_used else ""
        self.statusChanged.emit(t('desktop.mixAI.knowledgeSaved', topic=topic, model_info=model_info))
        logger.info(f"[mixAI v5.0] ãƒŠãƒ¬ãƒƒã‚¸ä¿å­˜å®Œäº†: {topic}")
        self._knowledge_worker = None

    def _on_knowledge_error(self, error: str):
        """v5.0.0: ãƒŠãƒ¬ãƒƒã‚¸ä¿å­˜ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ“ä½œã«ã¯å½±éŸ¿ã—ãªã„ï¼‰"""
        logger.warning(f"[mixAI v5.0] ãƒŠãƒ¬ãƒƒã‚¸ä¿å­˜ã‚¨ãƒ©ãƒ¼: {error}")
        self._knowledge_worker = None

    def _update_config_from_ui(self):
        """UIã‹ã‚‰è¨­å®šã‚’æ›´æ–°"""
        # Claudeè¨­å®š (v7.1.0: model_idç›´æ¥ä¿å­˜)
        selected_model_id = self.claude_model_combo.currentData()
        if selected_model_id:
            self.config.claude_model_id = selected_model_id
            self.config.claude_model = selected_model_id
        else:
            self.config.claude_model_id = DEFAULT_CLAUDE_MODEL_ID
            self.config.claude_model = DEFAULT_CLAUDE_MODEL_ID

        self.config.claude_auth_mode = "cli" if self.auth_mode_combo.currentIndex() == 0 else "api"
        self.config.thinking_mode = self.thinking_combo.currentText()

        # Ollamaè¨­å®š
        self.config.ollama_url = self.ollama_url_edit.text().strip()

        # å¸¸é§ãƒ¢ãƒ‡ãƒ«è¨­å®š (v7.0.0: åˆ¶å¾¡AI + Embedding)
        self.config.image_analyzer_model = self.image_model_combo.currentText()
        self.config.embedding_model = self.embedding_model_combo.currentText()

        # RAGè¨­å®š
        self.config.rag_enabled = self.rag_enabled_check.isChecked()
        self.config.rag_auto_save = self.rag_auto_save_check.isChecked()
        threshold_map = {0: "low", 1: "medium", 2: "high"}
        self.config.rag_save_threshold = threshold_map.get(self.rag_threshold_combo.currentIndex(), "medium")

        # v8.4.2: å“è³ªæ¤œè¨¼è¨­å®šï¼ˆPhase 2å†å®Ÿè¡Œå›æ•°ï¼‰
        if hasattr(self, 'max_retries_spin'):
            self.config.max_phase2_retries = self.max_retries_spin.value()

    def _on_save_settings(self):
        """è¨­å®šä¿å­˜"""
        self._update_config_from_ui()
        self._save_config()
        QMessageBox.information(self, t('desktop.mixAI.saveCompleteTitle'), t('desktop.mixAI.saveCompleteMsg'))
        self.statusChanged.emit(t('desktop.mixAI.savedStatus'))

    def _test_ollama_connection(self):
        """Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«åˆ¥ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªï¼‰"""
        try:
            import ollama
            import httpx
            url = self.ollama_url_edit.text().strip()
            client = ollama.Client(host=url)

            start = time.time()
            response = client.list()
            latency = time.time() - start

            # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
            installed_models = {}
            if hasattr(response, 'models'):
                raw_models = response.models
            elif isinstance(response, dict) and 'models' in response:
                raw_models = response['models']
            else:
                raw_models = []

            for model in raw_models:
                if isinstance(model, dict):
                    name = model.get('model') or model.get('name', '')
                    size = model.get('size', 0)
                else:
                    name = getattr(model, 'model', None) or getattr(model, 'name', '')
                    size = getattr(model, 'size', 0)
                if name:
                    installed_models[name] = {"size_gb": size / 1e9 if isinstance(size, int) else 0}

            # ãƒ­ãƒ¼ãƒ‰ä¸­ã®ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
            loaded_models = {}
            try:
                with httpx.Client(timeout=5) as http_client:
                    ps_resp = http_client.get(f"{url}/api/ps")
                    if ps_resp.status_code == 200:
                        ps_data = ps_resp.json()
                        for m in ps_data.get("models", []):
                            loaded_models[m.get("name", "")] = {
                                "size_vram": m.get("size_vram", 0),
                            }
            except Exception:
                pass  # ãƒ­ãƒ¼ãƒ‰ä¸­ãƒ¢ãƒ‡ãƒ«å–å¾—å¤±æ•—ã¯ç„¡è¦–

            # è¨­å®šãƒ¢ãƒ‡ãƒ«ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª
            configured_models = self._get_configured_models()
            status_lines = []

            for model_info in configured_models:
                name = model_info["name"]
                role = model_info["role"]
                model_type = model_info["type"]

                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
                is_loaded = self._match_model_name(name, loaded_models)
                is_installed = self._match_model_name(name, installed_models)

                if is_loaded:
                    vram_info = loaded_models.get(name, {}).get("size_vram", 0)
                    vram_mb = vram_info // (1024 * 1024) if vram_info else 0
                    icon = "ğŸŸ¢"
                    status = t('desktop.mixAI.ollamaLoaded')
                    vram_text = f"{vram_mb:,}MB" if vram_mb else "-"
                elif is_installed:
                    icon = "ğŸŸ¡"
                    status = t('desktop.mixAI.ollamaStandby')
                    vram_text = "-"
                else:
                    icon = "ğŸ”´"
                    status = t('desktop.mixAI.ollamaNotDL')
                    vram_text = "-"

                type_label = t('desktop.mixAI.ollamaResident') if model_type == "resident" else t('desktop.mixAI.ollamaOD')
                status_lines.append(f"{icon} {name:<26} {status:<8} {vram_text:<10} [{type_label}]")

            # çµæœã‚’è¡¨ç¤º
            header = t('desktop.mixAI.ollamaConnected', latency=f"{latency:.2f}")
            self.ollama_status_label.setText(header + "\n".join(status_lines))
            self.ollama_status_label.setStyleSheet("color: #22c55e;")

            # ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’æ›´æ–°
            self._update_model_combos(response)

        except ImportError:
            self.ollama_status_label.setText(t('desktop.mixAI.ollamaNoLibrary'))
            self.ollama_status_label.setStyleSheet("color: #ef4444;")
        except Exception as e:
            self.ollama_status_label.setText(t('desktop.mixAI.ollamaConnFailed', error=str(e)[:50]))
            self.ollama_status_label.setStyleSheet("color: #ef4444;")

    def _check_claude_cli_mcp(self):
        """v7.0.0: Claude Code CLIã®MCPã‚µãƒ¼ãƒãƒ¼è¨­å®šã‚’ç¢ºèª"""
        try:
            # Claude CLIã®å­˜åœ¨ç¢ºèª
            from ..backends.claude_cli_backend import find_claude_command
            claude_cmd = find_claude_command()

            if not claude_cmd:
                self.mcp_status_label.setText(f"  {t('desktop.mixAI.mcpClaudeNotFound')}")
                self.mcp_status_label.setStyleSheet("color: #ef4444; font-size: 10px;")
                return

            # claude mcp list ã§MCPã‚µãƒ¼ãƒãƒ¼ä¸€è¦§ã‚’å–å¾—
            result = run_hidden(
                [claude_cmd, "mcp", "list"],
                capture_output=True, text=True, timeout=10,
            )

            if result.returncode == 0 and result.stdout.strip():
                lines = result.stdout.strip().split("\n")
                status_text = f"  {t('desktop.mixAI.mcpStatus', cmd=claude_cmd, count=len(lines))}"
                for line in lines:
                    status_text += f"    {line}\n"
                self.mcp_status_label.setText(status_text.rstrip())
                self.mcp_status_label.setStyleSheet("color: #22c55e; font-size: 10px;")
            elif result.returncode == 0:
                self.mcp_status_label.setText(
                    f"  {t('desktop.mixAI.mcpNotConfigured', cmd=claude_cmd)}"
                )
                self.mcp_status_label.setStyleSheet("color: #f59e0b; font-size: 10px;")
            else:
                self.mcp_status_label.setText(
                    f"  {t('desktop.mixAI.mcpCheckFailed', cmd=claude_cmd, error=result.stderr[:100])}"
                )
                self.mcp_status_label.setStyleSheet("color: #f59e0b; font-size: 10px;")

        except subprocess.TimeoutExpired:
            self.mcp_status_label.setText(f"  {t('desktop.mixAI.mcpTimeout')}")
            self.mcp_status_label.setStyleSheet("color: #f59e0b; font-size: 10px;")
        except Exception as e:
            self.mcp_status_label.setText(f"  {t('desktop.mixAI.mcpError', error=str(e)[:80])}")
            self.mcp_status_label.setStyleSheet("color: #ef4444; font-size: 10px;")

    def _get_configured_models(self) -> List[Dict[str, Any]]:
        """è¨­å®šæ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾— (v7.0.0: 3Phaseè¨­å®šUIå¯¾å¿œ)"""
        models = []

        # å¸¸é§ãƒ¢ãƒ‡ãƒ«ï¼ˆåŸºæœ¬æ©Ÿèƒ½ç”¨ï¼‰
        if hasattr(self, 'image_model_combo'):
            models.append({"name": self.image_model_combo.currentText(), "role": "åˆ¶å¾¡AI", "type": "resident"})
        if hasattr(self, 'embedding_model_combo'):
            models.append({"name": self.embedding_model_combo.currentText(), "role": "Embedding", "type": "resident"})

        # 3Phase ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¢ãƒ‡ãƒ«ï¼ˆPhase 2ã§é †æ¬¡å®Ÿè¡Œï¼‰
        if hasattr(self, 'coding_model_combo'):
            models.append({"name": self.coding_model_combo.currentText(), "role": "coding", "type": "phase2"})
        if hasattr(self, 'research_model_combo'):
            models.append({"name": self.research_model_combo.currentText(), "role": "research", "type": "phase2"})
        if hasattr(self, 'reasoning_model_combo'):
            models.append({"name": self.reasoning_model_combo.currentText(), "role": "reasoning", "type": "phase2"})
        if hasattr(self, 'translation_model_combo'):
            models.append({"name": self.translation_model_combo.currentText(), "role": "translation", "type": "phase2"})
        if hasattr(self, 'vision_model_combo'):
            models.append({"name": self.vision_model_combo.currentText(), "role": "vision", "type": "phase2"})

        return models

    def _match_model_name(self, name: str, model_dict: Dict[str, Any]) -> bool:
        """ãƒ¢ãƒ‡ãƒ«åã®ãƒãƒƒãƒãƒ³ã‚°ï¼ˆã‚¿ã‚°çœç•¥å¯¾å¿œï¼‰"""
        if name in model_dict:
            return True
        for key in model_dict:
            if key.startswith(name.split(":")[0]) or name.startswith(key.split(":")[0]):
                return True
        return False

    # =========================================================================
    # GPUå‹•çš„è¨˜éŒ²ãƒ»ã‚°ãƒ©ãƒ•è¡¨ç¤ºæ©Ÿèƒ½ï¼ˆæ™‚é–“è»¸é¸æŠãƒ»ã‚·ãƒ¼ã‚¯ãƒãƒ¼å¯¾å¿œï¼‰
    # =========================================================================

    def _toggle_gpu_recording(self):
        """GPUè¨˜éŒ²ã®é–‹å§‹/åœæ­¢"""
        if self._gpu_recording:
            self._stop_gpu_recording()
        else:
            self._start_gpu_recording()

    def _start_gpu_recording(self):
        """GPUè¨˜éŒ²ã‚’é–‹å§‹"""
        self._gpu_recording = True
        self.gpu_record_btn.setText(t('desktop.mixAI.gpuRecordStop'))
        self.gpu_record_btn.setStyleSheet("""
            QPushButton {
                background-color: #ef4444;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
            }
            QPushButton:hover { background-color: #dc2626; }
        """)
        self._gpu_timer.start(1000)  # 1ç§’é–“éš”ã§è¨˜éŒ²
        self.statusChanged.emit(t('desktop.mixAI.gpuRecordStarted'))

    def _stop_gpu_recording(self):
        """GPUè¨˜éŒ²ã‚’åœæ­¢"""
        self._gpu_recording = False
        self._gpu_timer.stop()
        self.gpu_record_btn.setText(t('desktop.mixAI.gpuRecordStart'))
        self.gpu_record_btn.setStyleSheet("")
        self.statusChanged.emit(t('desktop.mixAI.gpuRecordStopped'))

    def _clear_gpu_graph(self):
        """GPUã‚°ãƒ©ãƒ•ã‚’ã‚¯ãƒªã‚¢"""
        self.gpu_graph.clear_data()
        self.gpu_seekbar.setMaximum(0)
        self.gpu_seekbar.setValue(0)
        self.gpu_seekbar_label.setText(t('desktop.mixAI.gpuNow'))
        self.statusChanged.emit(t('desktop.mixAI.gpuGraphCleared'))

    def _on_gpu_time_range_changed(self, text: str):
        """æ™‚é–“ç¯„å›²ãŒå¤‰æ›´ã•ã‚ŒãŸ"""
        seconds = GPUUsageGraph.TIME_RANGES.get(text, 60)
        self.gpu_graph.set_time_range(seconds)
        self._update_gpu_seekbar_range()
        self.statusChanged.emit(t('desktop.mixAI.gpuTimeChanged', range=text))

    def _on_gpu_seekbar_changed(self, value: int):
        """ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã®å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸ"""
        self.gpu_graph.set_view_offset(value)
        if value == 0:
            self.gpu_seekbar_label.setText(t('desktop.mixAI.gpuNow'))
        elif value < 60:
            self.gpu_seekbar_label.setText(t('desktop.mixAI.seekbarSecond', val=value))
        elif value < 3600:
            self.gpu_seekbar_label.setText(t('desktop.mixAI.seekbarMinute', val=value // 60))
        else:
            self.gpu_seekbar_label.setText(t('desktop.mixAI.seekbarHour', val=value // 3600))

    def _on_gpu_goto_now(self):
        """ç¾åœ¨ã«æˆ»ã‚‹"""
        self.gpu_seekbar.setValue(0)
        self.gpu_graph.set_view_offset(0)
        self.gpu_seekbar_label.setText(t('desktop.mixAI.gpuNow'))

    def _update_gpu_seekbar_range(self):
        """ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã®ç¯„å›²ã‚’æ›´æ–°"""
        data_duration = int(self.gpu_graph.get_data_duration())
        current_time_range = self.gpu_graph.time_range
        # ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã®æœ€å¤§å€¤ = ãƒ‡ãƒ¼ã‚¿æœŸé–“ - ç¾åœ¨ã®è¡¨ç¤ºç¯„å›²ï¼ˆ0æœªæº€ã«ãªã‚‰ãªã„ã‚ˆã†ã«ï¼‰
        max_offset = max(0, data_duration - current_time_range)
        self.gpu_seekbar.setMaximum(max_offset)
        if self.gpu_seekbar.value() > max_offset:
            self.gpu_seekbar.setValue(max_offset)

    def _record_gpu_usage(self):
        """GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²ï¼ˆã‚¿ã‚¤ãƒãƒ¼ã‹ã‚‰å‘¼ã³å‡ºã—ï¼‰"""
        try:
            nvidia_smi = shutil.which("nvidia-smi")
            if nvidia_smi is None:
                default_paths = [
                    r"C:\Windows\System32\nvidia-smi.exe",
                    r"C:\Program Files\NVIDIA Corporation\NVSMI\nvidia-smi.exe",
                ]
                for path in default_paths:
                    if os.path.exists(path):
                        nvidia_smi = path
                        break

            if nvidia_smi is None:
                return

            result = run_hidden(
                [nvidia_smi,
                 "--query-gpu=index,memory.used,memory.total",
                 "--format=csv,noheader,nounits"],
                capture_output=True,
                text=True,
                timeout=5,
            )

            if result.returncode != 0:
                return

            lines = result.stdout.strip().split('\n')
            for line in lines:
                parts = [p.strip() for p in line.split(',')]
                if len(parts) >= 3:
                    try:
                        idx = int(parts[0])
                        used_mb = int(parts[1])
                        total_mb = int(parts[2])
                        self.gpu_graph.add_data_point(idx, used_mb, total_mb)
                    except ValueError:
                        continue

            # ã‚·ãƒ¼ã‚¯ãƒãƒ¼ã®ç¯„å›²ã‚’æ›´æ–°
            self._update_gpu_seekbar_range()

        except Exception as e:
            logger.debug(f"[GPU Record] Error: {e}")

    def _record_gpu_with_event(self, event_name: str):
        """ã‚¤ãƒ™ãƒ³ãƒˆä»˜ãã§GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²"""
        self.gpu_graph.add_event(event_name)
        self._record_gpu_usage()

    def _schedule_gpu_record_after_llm(self, stage_name: str):
        """LLMèµ·å‹•å¾Œ5ç§’å¾Œã«GPUä½¿ç”¨é‡ã‚’è¨˜éŒ²ã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"""
        # å³åº§ã«è¨˜éŒ²ï¼ˆèµ·å‹•æ™‚ï¼‰
        self._record_gpu_with_event(f"{stage_name}é–‹å§‹")

        # 5ç§’å¾Œã«è¨˜éŒ²
        QTimer.singleShot(5000, lambda: self._record_gpu_with_event(f"{stage_name}+5s"))

    def _update_model_combos(self, response):
        """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã§ComboBoxã‚’æ›´æ–°"""
        models = []
        if hasattr(response, 'models'):
            raw_models = response.models
        elif isinstance(response, dict) and 'models' in response:
            raw_models = response['models']
        else:
            return

        for model in raw_models:
            if isinstance(model, dict):
                name = model.get('model') or model.get('name', '')
            else:
                name = getattr(model, 'model', None) or getattr(model, 'name', '')
            if name:
                models.append(name)

        # å„ã‚³ãƒ³ãƒœãƒœãƒƒã‚¯ã‚¹ã«ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ ï¼ˆv7.0.0: å¸¸é§ + 5ã‚«ãƒ†ã‚´ãƒªï¼‰
        all_combos = [
            self.image_model_combo, self.embedding_model_combo,
            self.coding_model_combo, self.research_model_combo,
            self.reasoning_model_combo, self.translation_model_combo,
            self.vision_model_combo,
        ]
        for combo in all_combos:
            current = combo.currentText()
            for model in models:
                if combo.findText(model) == -1:
                    combo.addItem(model)
            combo.setCurrentText(current)

    def _open_vram_simulator(self):
        """VRAM Budget Simulatorãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’é–‹ã"""
        from PyQt6.QtWidgets import QDialog, QVBoxLayout

        dialog = QDialog(self)
        dialog.setWindowTitle("VRAM Budget Simulator")
        dialog.setMinimumSize(900, 600)

        layout = QVBoxLayout(dialog)
        simulator = VRAMBudgetSimulator()

        # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼è­¦å‘Š
        simulator.overflowDetected.connect(
            lambda gpu_idx, overflow: QMessageBox.warning(
                dialog, t('desktop.mixAI.vramWarningTitle'),
                t('desktop.mixAI.vramWarningMsg', gpu=gpu_idx, overflow=f"{overflow:.1f}")
            ) if overflow > 0 else None
        )

        layout.addWidget(simulator)
        dialog.setStyleSheet("""
            QDialog {
                background-color: #1e1e1e;
            }
        """)
        dialog.exec()

    def _refresh_gpu_info(self):
        """GPUæƒ…å ±ã‚’å®‰å…¨ã«æ›´æ–°ï¼ˆPyInstallerç’°å¢ƒå¯¾å¿œï¼‰"""
        try:
            import subprocess
            import shutil
            import os

            # nvidia-smi ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’æ¢ç´¢
            nvidia_smi = shutil.which("nvidia-smi")
            if nvidia_smi is None:
                # Windows ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ç›´æ¥æŒ‡å®š
                default_paths = [
                    r"C:\Windows\System32\nvidia-smi.exe",
                    r"C:\Program Files\NVIDIA Corporation\NVSMI\nvidia-smi.exe",
                ]
                for path in default_paths:
                    if os.path.exists(path):
                        nvidia_smi = path
                        break

            if nvidia_smi is None:
                self.gpu_info_label.setText(t('desktop.mixAI.gpuNoNvidiaSmi'))
                self.gpu_info_label.setStyleSheet("color: #9ca3af;")
                return

            result = run_hidden(
                [nvidia_smi,
                 "--query-gpu=index,name,memory.used,memory.total,utilization.gpu",
                 "--format=csv,noheader,nounits"],
                capture_output=True,
                text=True,
                timeout=10,
            )

            if result.returncode != 0:
                self.gpu_info_label.setText(t('desktop.mixAI.gpuNvidiaSmiError', error=result.stderr.strip()[:50]))
                self.gpu_info_label.setStyleSheet("color: #f59e0b;")
                return

            lines = result.stdout.strip().split('\n')
            info_text = ""
            total_vram_used = 0
            total_vram_total = 0

            for line in lines:
                parts = [p.strip() for p in line.split(',')]
                if len(parts) >= 5:
                    idx, name, used, total, util = parts[:5]
                    try:
                        used_mb = int(used)
                        total_mb = int(total)
                        util_pct = int(util)
                        usage_pct = (used_mb / total_mb) * 100 if total_mb > 0 else 0

                        total_vram_used += used_mb
                        total_vram_total += total_mb

                        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼é¢¨è¡¨ç¤º
                        bar_len = 20
                        filled = int(usage_pct / 100 * bar_len)
                        bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)

                        info_text += f"GPU {idx}: {name}\n"
                        info_text += f"  VRAM: [{bar}] {used_mb:,}/{total_mb:,} MB ({usage_pct:.1f}%)\n"
                        info_text += f"  {t('desktop.mixAI.gpuUsageLabel', pct=util_pct)}\n"
                    except ValueError:
                        continue

            if total_vram_total > 0:
                info_text += t('desktop.mixAI.gpuTotalVram', used=f"{total_vram_used:,}", total=f"{total_vram_total:,}")

            self.gpu_info_label.setText(info_text.strip() or t('desktop.mixAI.gpuNoInfo'))
            self.gpu_info_label.setStyleSheet("color: #22c55e;")

        except subprocess.TimeoutExpired:
            self.gpu_info_label.setText(t('desktop.mixAI.gpuTimeout'))
            self.gpu_info_label.setStyleSheet("color: #f59e0b;")
        except FileNotFoundError:
            self.gpu_info_label.setText(t('desktop.mixAI.gpuNoNvidiaSmi'))
            self.gpu_info_label.setStyleSheet("color: #9ca3af;")
        except Exception as e:
            self.gpu_info_label.setText(t('desktop.mixAI.gpuInfoError', error=str(e)[:40]))
            self.gpu_info_label.setStyleSheet("color: #ef4444;")
