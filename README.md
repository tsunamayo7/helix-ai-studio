<!-- SPDX-FileCopyrightText: 2026 Helix AI Studio Contributors -->
<!-- SPDX-License-Identifier: MIT -->

<div align="center">

# ğŸ§¬ Helix AI Studio

**One prompt. Multiple AI models. One integrated answer.**

*A desktop app that makes Claude, GPT, Gemini, and local LLMs actually work **together** â€” no copy-pasting, no coding required.*

[![GitHub stars](https://img.shields.io/github/stars/tsunamayo7/helix-ai-studio?style=social)](https://github.com/tsunamayo7/helix-ai-studio/stargazers)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyQt6](https://img.shields.io/badge/UI-PyQt6-green.svg)](https://pypi.org/project/PyQt6/)
[![Version](https://img.shields.io/badge/version-v11.9.4-brightgreen.svg)](https://github.com/tsunamayo7/helix-ai-studio/releases)
![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS-lightgrey)
![i18n](https://img.shields.io/badge/i18n-ja%20%7C%20en-emerald)

[ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª README](README_ja.md) Â· [ğŸ“– Setup Guide](SETUP_GUIDE.md) Â· [ğŸ“‹ Changelog](CHANGELOG.md) Â· [ğŸ”’ Security](SECURITY.md)

> â­ **If Helix AI Studio looks useful to you, a star helps more developers discover it. Thank you!**

</div>

---

## ğŸ“‹ Table of Contents

- [See It in Action](#-see-it-in-action)
- [Get Started in 60 Seconds](#-get-started-in-60-seconds)
- [What Makes Helix Different?](#-what-makes-helix-different)
- [How the Pipeline Works](#-how-the-pipeline-works)
- [Features at a Glance](#-features-at-a-glance)
- [Installation Guide](#-installation-guide)
- [Tech Stack](#-tech-stack)
- [Security & Privacy](#-security--privacy)
- [Screenshots](#-screenshots)
- [Version History](#-version-history)
- [Articles & Resources](#-articles--resources)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¬ See It in Action

### mixAI Pipeline â€” Multiple AIs collaborating on your task

![mixAI Pipeline Demo](docs/demo/mixai_pipeline.gif)

> Claude plans the work, local LLMs execute in parallel, Claude validates the result. All in one click.

### Desktop + Web UI â€” Use it anywhere

| Desktop (PyQt6) | Web UI (React) |
|:---:|:---:|
| ![Desktop](docs/demo/desktop_mixai.png) | ![Web UI](docs/demo/webui_main.png) |

> The desktop app runs on your PC. The Web UI lets you chat from your phone, tablet, or any browser on your network.

### Helix Pilot v2.0 â€” AI that controls the UI for you

> ğŸ†• **New in v11.9.4**: Helix Pilot is a local Vision LLM agent that reads your screen and operates the app autonomously. Claude Code describes a task in plain English â€” Helix Pilot handles every click, scroll, and keystroke.

```bash
python scripts/helix_pilot.py auto "Open the mixAI tab, type a prompt, and send it" --window "Helix AI Studio"
```

---

## ğŸš€ Get Started in 60 Seconds

```bash
git clone https://github.com/tsunamayo7/helix-ai-studio.git
cd helix-ai-studio
pip install -r requirements.txt
python HelixAIStudio.py
```

That's it. The app opens with a built-in Web UI at `http://localhost:8500`.
Add your API keys in **Settings**, or install [Ollama](https://ollama.com) for fully local, private inference.

> **New to this?** Check out [SETUP_GUIDE.md](SETUP_GUIDE.md) for a step-by-step walkthrough.

---

## ğŸ’¡ What Makes Helix Different?

Most AI tools give you a chat window with **one** model. Helix gives you a **pipeline** where multiple models collaborate.

**The key insight**: every AI has blind spots. Routing your prompt through models with different architectures â€” then validating the combined result â€” produces answers that are more accurate and complete than any single model.

| | Helix AI Studio | Single-model apps |
|---|---|---|
| ğŸ¤– **Multi-AI pipeline** | Claude plans, local LLMs execute, Claude validates | One model does everything |
| ğŸ’° **Cost efficient** | Claude handles 20% (planning + validation). Free local models handle 80%. | Everything goes through the paid API |
| ğŸ”’ **Privacy where it matters** | Execution runs entirely on your GPU. Sensitive code never leaves your machine. | Cloud-only |
| ğŸ“± **Desktop + Mobile** | Native desktop app with built-in Web UI. Chat from your phone. | Usually one or the other |
| ğŸ¤– **Helix Pilot v2.0** | Vision LLM agent that operates the app via plain English. | Static UI, no automation |
| ğŸ–±ï¸ **No code required** | GUI app with settings panels. Point and click. | Many orchestration tools require code |
| ğŸ†“ **Free and open** | MIT licensed. No subscription, no telemetry. | Often SaaS or freemium |

### Helix vs. Popular Alternatives

| | Open WebUI | AnythingLLM | Dify | LangChain | **Helix** |
|---|:---:|:---:|:---:|:---:|:---:|
| **GitHub Stars** | 60k+ â­ | 30k+ â­ | 129k+ â­ | 80k+ â­ | â€” |
| **Auto pipeline (cloud+local)** | âŒ Manual | âŒ Manual | âš ï¸ Visual builder | âš ï¸ Code required | âœ… 1-click |
| **Desktop app** | âŒ | âœ… | âŒ | âŒ | âœ… |
| **LAN Web UI** | âœ… | âŒ | âŒ | âŒ | âœ… |
| **Docker required** | âœ… Required | Optional | âœ… Required | N/A | âŒ Not needed |
| **Setup** | `docker run` | Installer | `docker compose` | `pip` + code | `pip` + run |
| **Claude/GPT/Gemini native** | âš ï¸ Via proxy | âœ… | âœ… | âœ… | âœ… |
| **Cost optimization** | âŒ | âŒ | âŒ | Manual | âœ… Built-in |
| **MIT License** | âœ… | âœ… | âœ… | âœ… | âœ… |

> **The gap Helix fills**: A GUI desktop app that automatically orchestrates cloud + local models in a cost-optimized pipeline â€” zero Docker, LAN access built in.

---

## âš™ï¸ How the Pipeline Works

```
        YOUR PROMPT
              |
              v
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚    Phase 1: PLANNING    â”‚  â† Cloud AI (Claude / GPT / Gemini)
 â”‚  - Design analysis      â”‚
 â”‚  - Acceptance criteria  â”‚
 â”‚  - Per-model tasks      â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              |
    â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”¬â”€â”€â”€â”€â”
    v    v       v    v
 â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚Codingâ”‚ â”‚Researchâ”‚ â”‚Reasoningâ”‚ â”‚ Vision â”‚  â† Phase 2: LOCAL
 â”‚(GPU) â”‚ â”‚ (GPU)  â”‚ â”‚  (GPU)  â”‚ â”‚ (GPU)  â”‚     Your GPU
 â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    |         |           |           |
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    v
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Phase 3: VALIDATION   â”‚  â† Cloud AI (Claude / GPT / Gemini)
 â”‚  - Integrate outputs    â”‚
 â”‚  - PASS/FAIL check      â”‚
 â”‚  - Final synthesis      â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    |
                    v
              FINAL OUTPUT
```

| Phase | Who runs it | What happens |
|-------|-------------|-------------|
| **Phase 1** | Cloud AI | Analyzes your prompt, creates structured instructions for each local model |
| **Phase 2** | Local LLMs (your GPU) | Coding, research, reasoning, translation, and vision specialists run in parallel |
| **Phase 3** | Cloud AI | Combines outputs, validates against acceptance criteria, produces the final answer |

---

## âœ¨ Features at a Glance

| Feature | What it does |
|---------|-------------|
| ğŸ”€ **mixAI Pipeline** | 3+1 Phase orchestration: plan â†’ execute â†’ validate â†’ (optionally) apply file changes |
| â˜ï¸ **cloudAI Chat** | Direct chat with Claude, GPT, Gemini via API or CLI |
| ğŸ’» **localAI Chat** | Chat with any Ollama model on your local GPU |
| ğŸ¤– **Helix Pilot v2.0** | Vision LLM agent that reads your screen and operates the app via plain-English commands |
| ğŸ“š **RAG Builder** | Drop documents in â€” AI builds a searchable knowledge base automatically |
| ğŸŒ **Web UI** | React-based mobile-friendly interface, accessible from any device on your network |
| ğŸ§  **4-Layer Memory** | Thread, Episodic, Semantic, Procedural â€” your AI remembers context across sessions |
| ğŸŒ **i18n** | Full Japanese and English UI, switchable at any time |
| ğŸ”” **Discord Notifications** | Get notified when your AI tasks complete |
| ğŸ“œ **Chat History** | SQLite-backed history shared between Desktop and Web |
| ğŸ“– **BIBLE System** | Project documentation auto-injected into AI prompts for better context |

---

## ğŸ“¦ Installation Guide

### Requirements

| Item | Requirement |
|------|-------------|
| OS | Windows 10/11 or macOS 12 Monterey+ (Apple Silicon & Intel) |
| Python | 3.10+ (3.11 recommended) |
| GPU | NVIDIA with CUDA (optional, for local LLMs on Windows) |
| RAM | 16GB+ (32GB+ recommended for large models) |

> macOS: Ollama uses Metal/CPU inference. NVIDIA GPU is **not** required.

### Step-by-step

**1. Clone and install**

```bash
git clone https://github.com/tsunamayo7/helix-ai-studio.git
cd helix-ai-studio
pip install -r requirements.txt
```

**2. (Optional) Set up local LLMs**

```bash
# Download Ollama from https://ollama.com/download, then:
ollama pull gemma3:4b         # Lightweight â€” runs on most GPUs
ollama pull gemma3:27b        # Higher quality â€” needs 16GB+ VRAM
ollama pull mistral-small3.2  # Good for vision tasks
```

**3. (Optional) Add API keys for cloud AI**

```bash
# Windows
copy config\general_settings.example.json config\general_settings.json
# macOS / Linux
cp config/general_settings.example.json config/general_settings.json
```

Then edit `config/general_settings.json` with your keys:

| Provider | Where to get a key | What it enables |
|---|---|---|
| Anthropic | [console.anthropic.com](https://console.anthropic.com/settings/keys) | Claude chat + pipeline planning |
| Google | [aistudio.google.com](https://aistudio.google.com/app/apikey) *(free tier)* | Gemini chat |
| OpenAI | [platform.openai.com](https://platform.openai.com/api-keys) | GPT chat |

**4. Launch**

```bash
# Windows
python HelixAIStudio.py

# macOS
python3 HelixAIStudio.py
```

**5. (Optional) Access from your phone**

Enable Web UI in Settings, then open `http://localhost:8500` from any device on your network.

> For detailed setup including CLI tools, Node.js, and troubleshooting, see [SETUP_GUIDE.md](SETUP_GUIDE.md).

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| Desktop GUI | PyQt6 |
| Web UI | React + Vite + Tailwind CSS |
| Web Server | FastAPI + Uvicorn (WebSocket) |
| Cloud AI | Anthropic / OpenAI / Google Gemini APIs |
| CLI Backends | Claude Code CLI / Codex CLI |
| Local LLM | Ollama |
| Memory | SQLite + vector embeddings + knowledge graph |
| i18n | Shared JSON (ja/en) for Desktop + Web |

---

## ğŸ”’ Security & Privacy

- **Phase 2 is 100% local** â€” Your code and documents stay on your machine during the execution phase
- **API keys stay local** â€” Stored in `config/general_settings.json` (git-ignored), never transmitted
- **Web UI is private** â€” Designed for local/VPN access, not public internet
- **Memory injection guard** â€” Safety prompts prevent stored context from being used for prompt injection

> For details on compliance with Anthropic, OpenAI, and Ollama terms, see [SECURITY.md](SECURITY.md).

---

## ğŸ“¸ Screenshots

<details>
<summary><strong>Click to expand screenshots</strong></summary>

### Pipeline Monitor â€” Watch your AIs work in real time
![Pipeline Monitor](docs/demo/mixai_monitor.png)

### Pipeline Complete â€” Validated output with PASS/FAIL checks
![Pipeline Complete](docs/demo/mixai_complete.png)

### Claude Sonnet Chat â€” Cloud AI direct conversation
![Claude Chat](docs/demo/cloudai_chat.png)

### Gemini API Chat â€” Multi-provider support
![Gemini Chat](docs/demo/gemini_chat.png)

### Local AI Chat with gemma3 â€” Multi-model switching
![Local AI Chat](docs/demo/desktop_localai_chat.png)

### RAG Knowledge Base â€” Build and search your own knowledge
![RAG Build](docs/demo/rag_build.png)

### Settings â€” API keys, themes, and automation
![Settings](docs/demo/desktop_settings.png)

### Web UI â€” Chat from your phone
![Web UI Chat](docs/demo/webui_chat.png)

### Web UI (English) â€” Full i18n support
![Web UI English](docs/demo/webui_english.png)

</details>

---

## ğŸ“… Version History

| Version | Highlights |
|---------|-----------|
| **v11.9.4** | ğŸ†• **Helix Pilot v2.0** â€” autonomous Vision LLM GUI agent; Gemini thread safety fix |
| v11.9.3 | Provider-based model classification, combo width fix |
| v11.9.2 | Terminal toggle, Enter-to-send toggle, 240+ color literals purged |
| v11.9.0 | Unified Obsidian theme, SS semantic helpers, SplashScreen |
| v11.8.0 | 4-layer color system, global stylesheet |
| v11.5.0 | Multi-provider API (Anthropic/OpenAI/Google), model-agnostic architecture |
| v11.0.0 | History tab, BIBLE cross-tab, cloud model selector |
| v9.0.0 | Web UI (React + FastAPI) |

See [CHANGELOG.md](CHANGELOG.md) for the full history.

---

## ğŸ“° Articles & Resources

| Article | Language | Link |
|---------|----------|------|
| Introduction & Setup Guide | ğŸ‡¯ğŸ‡µ JP | [note.com](https://note.com/ai_tsunamayo_7/n/n410331c01ab0) |
| Architecture Deep Dive | ğŸ‡¯ğŸ‡µ JP | [note.com](https://note.com/ai_tsunamayo_7/n/n5a97fbf68798) |
| v11.9.2 Release Notes | ğŸ‡¯ğŸ‡µ JP | [note.com](https://note.com/ai_tsunamayo_7/n/n410888aabe47) |

---

## ğŸ¤ Contributing

Contributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.
For security issues, see [SECURITY.md](SECURITY.md).

---

## ğŸ“„ License

MIT â€” see [LICENSE](LICENSE)

**Author**: tsunamayo7 ([@tsunamayo7](https://github.com/tsunamayo7))

---

<div align="center">

**If Helix AI Studio is useful to you, please â­ star the repo!**
Feedback, issues, and PRs are always welcome.

</div>
